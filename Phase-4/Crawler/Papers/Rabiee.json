[
    {
        "Id": "5ca94050fcf3382b50ec44629c0dda80c8843558",
        "title": "Spatial-Aware Dictionary Learning for Hyperspectral Image Classification",
        "authors": [
            "Ali Soltani-Farani",
            "Hamid R. Rabiee",
            "Seyyed Abbas Hosseini"
        ],
        "date": "5 August 2013",
        "abstract": "A structured dictionary-based model for hyperspectral data that incorporates both spectral and contextual characteristics of spectral samples and is capable of finding representations that may effectively be used for classification of multispectral resolution samples is presented. This paper presents a structured dictionary-based model for hyperspectral data that incorporates both spectral and contextual characteristics of spectral samples. The idea is to partition the pixels of a hyperspectral image into a number of spatial neighborhoods called contextual groups and to model the pixels inside a group as members of a common subspace. That is, each pixel is represented using a linear combination of a few dictionary elements learned from the data, but since pixels inside a contextual group are often made up of the same materials, their linear combinations are constrained to use common elements from the dictionary. To this end, dictionary learning is carried out with a joint sparse regularizer to induce a common sparsity pattern in the sparse coefficients of a contextual group. The sparse coefficients are then used for classification using a linear support vector machine. Experimental results on a number of real hyperspectral images confirm the effectiveness of the proposed representation for hyperspectral image classification. Moreover, experiments with simulated multispectral data show that the proposed model is capable of finding representations that may effectively be used for classification of multispectral resolution samples.",
        "references": [
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "15f7662fadf686beae8ce704ee9b48262ac62237",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "f5f963d7872625c75f43d422f3c4cf7d70d2de7d",
            "f6e92c66ba553d6ae1d52e94f83278ede73c696f",
            "2b07d0bfcbc64b8cefa2d5d7b84a3dd13b6d7b51",
            "7c997a648976fb9df320c6ca332c9dc155820454",
            "c5389f0d9751ce9cd39160320ef17ae968a79edf",
            "41f426e2dc5b4944148014d9c86d20fdd21dc968",
            "2badd8953397d757693859918cf9318fe7ec5e3b"
        ],
        "related_topics": [
            "Spatial-Aware Dictionary Learning",
            "Hyperspectral Image Classification",
            "Pixel",
            "Hyperspectral Data",
            "Linear SVM",
            "Dictionary Learning",
            "Sparsity Pattern",
            "Real Hyperspectral Images"
        ],
        "reference_count": "67",
        "citation_count": "122"
    },
    {
        "Id": "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
        "title": "Multiresolution Knowledge Distillation for Anomaly Detection",
        "authors": [
            "Mohammadreza Salehi",
            "Niousha Sadjadi",
            "Soroosh Baselizadeh",
            "Mohammad Hossein Rohban",
            "Hamid R. Rabiee"
        ],
        "date": "22 November 2020",
        "abstract": "This work proposes to use the \"distillation\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle anomaly detection and localization. Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the \"distillation\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks\u2019 intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert\u2019s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.",
        "references": [
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "2b75ba7f75170b73d913c515cc0deefef6c88f5f",
            "8381157eae4fbf8908d0312a9642f8e69e944449",
            "d9d7ab13ce305ccee309c989a2341d72b1252070",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d"
        ],
        "related_topics": [
            "Multiresolution Knowledge Distillation",
            "Anomaly Localization",
            "One-class Setting",
            "Uninformed Students",
            "f-AnoGAN",
            "Anomalous Regions",
            "Anomalous Images",
            "Anomaly Detection",
            "ImageNet",
            "Region-based Training"
        ],
        "reference_count": "62",
        "citation_count": "218"
    },
    {
        "Id": "6f0685d61328f0f90972fe822258d574b74e9c7a",
        "title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics",
        "authors": [
            "Seyed Ali Osia",
            "Ali Shahin Shamsabadi",
            "Sina Sajadmanesh",
            "Ali Taheri",
            "Kleomenis Katevas",
            "Hamid R. Rabiee",
            "Nicholas D. Lane",
            "Hamed Haddadi"
        ],
        "date": "8 March 2017",
        "abstract": "This article presents a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics, and shows that by using Siamese fine-tuning and at a small processing cost, this approach can greatly reduce the level of unnecessary, potentially sensitive information in the personal data. Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user\u2019s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.",
        "references": [
            "65c8a794830f9a11aa0b9ab682f3b6256be67185",
            "6c20cd584e7258056840eb88437d69731000bb0f",
            "60951974d24dd83e288117b0cd217af6a5d34178",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "8a5d0579590465494c9aba58a857af43b190b6a6",
            "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "187a78ebfe654e9c1d3e8d070c8845a49c1d1a42",
            "5a7a7dfea3674d4e0474f7fdd596951da44babe4",
            "7fcb90f68529cbfab49f471b54719ded7528d0ef",
            "405006da005398279bdf7c3423d47aa0951c5391"
        ],
        "related_topics": [
            "Face Recognition",
            "Privacy Guarantees",
            "Inference Attacks",
            "Mobile Analytics",
            "Photo-editing",
            "Object Detection",
            "Siamese Networks",
            "Architecture",
            "Computer Vision",
            "Gender Classification"
        ],
        "reference_count": "70",
        "citation_count": "204"
    },
    {
        "Id": "c626a9d75dfd73e26cf30793d5ef71527cd9fa95",
        "title": "Novel dataset for fine-grained abnormal behavior understanding in crowd",
        "authors": [
            "Hamid R. Rabiee",
            "Javad Haddadnia",
            "Hossein Mousavi",
            "Maziyar Kalantarzadeh",
            "Moin Nabi",
            "Vittorio Murino"
        ],
        "date": "1 August 2016",
        "abstract": "This work presents a novel crowd dataset which contains around 45,000 video clips which annotated by one of the five different fine-grained abnormal behavior categories and evaluated two state-of-the-art methods on this dataset, showing that this dataset can be effectively used as a benchmark for fine- grained abnormality detection. Despite the huge research on crowd on behavior understanding in visual surveillance community, lack of publicly available realistic datasets for evaluating crowd behavioral interaction led not to have a fair common test bed for researchers to compare the strength of their methods in the real scenarios. This work presents a novel crowd dataset contains around 45,000 video clips which annotated by one of the five different fine-grained abnormal behavior categories. We also evaluated two state-of-the-art methods on our dataset, showing that our dataset can be effectively used as a benchmark for fine-grained abnormality detection. The details of the dataset and the results of the baseline methods are presented in the paper.",
        "references": [
            "3950b335fd77d6f025cdf29e9733ee92189b6a9b",
            "9d3f0d47449c7db37d1bae3b70db2928610a8db7",
            "fd52349a019d928cd9b09c2f6a8a689f174bbbf2",
            "655b1f83ef218ee6a030b5541d2865bc6599e6d9",
            "c3113eaad326a955ba96c11b7b65d0c065fb2054",
            "27839232387db332bdc9024d014a6d1bc47c35eb",
            "5194cbd51f9769ab25260446b4fa17204752e799",
            "02a98118ce990942432c0147ff3c0de756b4b76a",
            "e65ec773059770c45da16bb9ce638d24870b1adf",
            "84af83ff6412a756df58b6436f0d2e3c049e1f12"
        ],
        "related_topics": [
            "Crowd Datasets"
        ],
        "reference_count": "26",
        "citation_count": "50"
    },
    {
        "Id": "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
        "title": "Deep Private-Feature Extraction",
        "authors": [
            "Seyed Ali Ossia",
            "Ali Taheri",
            "Ali Shahin Shamsabadi",
            "Kleomenis Katevas",
            "Hamed Haddadi",
            "Hamid R. Rabiee"
        ],
        "date": "9 February 2018",
        "abstract": "The log-rank privacy is introduced and utilize, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy trade-off. We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which is trained and evaluated based on information theoretic constraints. Using the selective exchange of information between a user's device and a service provider, DPFE enables the user to prevent certain sensitive information from being shared with a service provider, while allowing them to extract approved information using their model. We introduce and utilize the log-rank privacy, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy trade-off. We then implement and evaluate the performance of DPFE on smartphones to understand its complexity, resource demands, and efficiency trade-offs. Our results on benchmark image datasets demonstrate that under moderate resource utilization, DPFE can achieve high accuracy for primary tasks while preserving the privacy of sensitive information.",
        "references": [
            "6cefb70f4668ee6c0bf0c18ea36fd49dd60e8365",
            "bc3f84ae122815aba616a310ae22abf216864b85",
            "44a97f4eaaefaf5338f8aed2913d5debb2459f7e",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "e6050e19c82ac215194cc311016094b71f57b17d",
            "65c8a794830f9a11aa0b9ab682f3b6256be67185",
            "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "53969301953b5e3d908a057f95d29eef2f11970f",
            "3625202d710db29ee117f7502d86901f50f92e1c"
        ],
        "related_topics": [
            "Sensitive Information",
            "Sensitive Features",
            "Deep Model"
        ],
        "reference_count": "63",
        "citation_count": "78"
    },
    {
        "Id": "96d5444cfd4fb60ed7fd4460a92683fda358eb23",
        "title": "Super pixel-level dictionary learning for hyperspectral image classification",
        "authors": [
            "Wei Zhao",
            "Wen Zhu",
            "Bo Liao",
            "Xiangzheng Fu"
        ],
        "date": "3 August 2017",
        "abstract": "The idea is to divide the hyperspectral image into a number of super-pixels by means of the super-pixel segmentation method, and each super- pixel is a spatial neighborhood called contextual group that has a common sparse pattern by using the joint sparse regularizer for dictionary learning. This paper presents a superpixel-level dictionary learning model for hyperspectral data. The idea is to divide the hyperspectral image into a number of super-pixels by means of the super-pixel segmentation method. Each super-pixel is a spatial neighborhood called contextual group. That is, each pixel is represented using a linear combination of a few dictionary items learned from the train data, but since pixels inside a super-pixel are often consisting of the same materials, their linear combinations are constrained to use common items from the dictionary. To this end, the sparse coefficients of the context group have a common sparse pattern by using the joint sparse regularizer for dictionary learning. The sparse coefficients are then used for classification using linear support vector machines. The validity of the proposed method is experimentally verified on a real hyperspectral images.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "0088d6433a9715b7e74a623920925f2bfb04c920",
            "ede30b1b265e62b12410bbf796a23437a64619a6",
            "cf80cc34528273d8fbe17783efe802a6509e1562",
            "83b522f4bfa5db7f7d34f839475af7d078107634",
            "0baa66007d2cfe8e98720310ad0ed7bdee7a873d",
            "684732677d91a93b115f57e8d671ef7f5f13ee14"
        ],
        "related_topics": [
            "Dictionary Learning",
            "Hyperspectral Data",
            "Classification",
            "Linear Support Vector Machines",
            "Real Hyperspectral Images",
            "Hyperspectral Image Classification",
            "Super-pixel"
        ],
        "reference_count": "0",
        "citation_count": "8"
    },
    {
        "Id": "498a42bd4e51182e5e7931a80dcfa2e0a007f33d",
        "title": "Hyperspectral Image Classification With Online Structured Dictionary Learning",
        "authors": [
            "Saeideh Ghanbari Azar",
            "Saeed Meshgini",
            "Tohid Yousefi Rezaii",
            "Ali Farzamnia"
        ],
        "date": "1 October 2019",
        "abstract": "The spectral and spatial redundancies of hyperspectral images are used for designing a sparse representation-based classification approach and a sparse coding algorithm is proposed that alleviates the instability of the sparse coefficients. In this study, the spectral and spatial redundancies of hyperspectral images are used for designing a sparse representation-based classification approach. The spectral redundancy is used to define spectral blocks and they are used to adaptively recognize the distinctive bands. The most distinctive blocks are identified as active blocks in a block sparse representation approach. Then the sparse coefficients within each spatial group are imposed to share a common subspace. To achieve this hierarchical sparsity pattern a sparse coding algorithm is proposed. This sparse coding is done over a block-structured dictionary, which is learned from the image data using the online dictionary learning algorithm. The obtained sparse coefficients are then classified using a support vector machine classifier. This structured sparsity pattern alleviates the instability of the sparse coefficients. Experiments on two standard datasets namely, Indian Pines and Pavia University, verify the effectiveness of the proposed approach for the classification of hyperspectral images.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "22ae9bc79e07285144adef621b09d4f0ddd2f757",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "58c239e6c2c38dea061310ed5d719c3221d4428f",
            "ec9aa46ebc50a03ea9d7d20d80a232e6bd4293de",
            "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6",
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "5a391667242b4a631acdd5917681b16a86523987"
        ],
        "related_topics": [
            "Spatial Redundancy",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "0",
        "citation_count": "23"
    },
    {
        "Id": "e30fcfa9e0e8c7d03315848e823781b7a72203ef",
        "title": "Shapelet-Based Sparse Representation for Landcover Classification of Hyperspectral Images",
        "authors": [
            "Ribana Roscher",
            "Bj{\\&quot;o}rn Waske"
        ],
        "date": "1 March 2016",
        "abstract": "This paper presents a sparse-representation-based classification approach with a novel dictionary construction procedure, based on the assumption that each image patch can be factorized into characteristic spatial patterns, also called shapelets, and patch-specific spectral information. This paper presents a sparse-representation-based classification approach with a novel dictionary construction procedure. By using the constructed dictionary, sophisticated prior knowledge about the spatial nature of the image can be integrated. The approach is based on the assumption that each image patch can be factorized into characteristic spatial patterns, also called shapelets, and patch-specific spectral information. A set of shapelets is learned in an unsupervised way, and spectral information is embodied by training samples. A combination of shapelets and spectral information is represented in an undercomplete spatial-spectral dictionary for each individual patch, where the elements of the dictionary are linearly combined to a sparse representation of the patch. The patch-based classification is obtained by means of the representation error. Experiments are conducted on three well-known hyperspectral image data sets. They illustrate that our proposed approach shows superior results in comparison to sparse-representation-based classifiers that use only limited spatial information and behaves competitively with or better than state-of-the-art classifiers utilizing spatial information and kernelized sparse-representation-based classifiers.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "9f2f1a5d4f6e582d4afd857915802805a7f4185e",
            "ab754fecbca13aeb08f42de7bd3be4938e4813f8",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "a1a183c1e263526465c8d3097d13b3e2be273ea8",
            "15f7662fadf686beae8ce704ee9b48262ac62237",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "23c6b983cc56ec821d17436746f0458785fa7b5c"
        ],
        "related_topics": [
            "Shapelets",
            "Shapelet-based",
            "Sparse Representation",
            "Sparse Representation Based Classification",
            "Patches"
        ],
        "reference_count": "56",
        "citation_count": "30"
    },
    {
        "Id": "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
        "title": "Local adaptive joint sparse representation for hyperspectral image classification",
        "authors": [
            "Jiangtao Peng",
            "Xue Jiang",
            "Na Chen",
            "Huijing Fu"
        ],
        "date": "21 March 2019",
        "abstract": "Semantic Scholar extracted view of \"Local adaptive joint sparse representation for hyperspectral image classification\" by Jiangtao Peng et al.",
        "references": [
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "f206be139e71051e3bab8588854728cc07c20988",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "08884fbf871f5e31a71573dcc61c1492714b25f4",
            "37423bdebb70930eeaae8e00c97b44ecc397e684",
            "cafbdf6b8d7f38f0a6e0543dbcf20299f20e71c1"
        ],
        "related_topics": [
            "Joint Spectral Radius",
            "Benchmark Hyperspectral Data Sets",
            "Testing Pixel",
            "Training Dictionary",
            "Classification",
            "Sparse Representation",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "35",
        "citation_count": "24"
    },
    {
        "Id": "a87f0358993d9d24eb9f52f8534c60be9a213503",
        "title": "Shapelet-based sparse image representation for landcover classification of hyperspectral data",
        "authors": [
            "Ribana Roscher",
            "Bj{\\&quot;o}rn Waske"
        ],
        "date": "2 October 2014",
        "abstract": "This paper presents a novel sparse representation-based classifier for landcover mapping of hyperspectral image data that shows superior results in comparison to sparse-representation based classifiers that use no or only limited spatial information and behaves competitive or better than state-of-the-art classifiers utilizing spatial information. This paper presents a novel sparse representation-based classifier for landcover mapping of hyperspectral image data. Each image patch is factorized into segmentation patterns, also called shapelets, and patch-specific spectral features. The combination of both is represented in a patch-specific spatial-spectral dictionary, which is used for a sparse coding procedure for the reconstruction and classification of image patches. Hereby, each image patch is sparsely represented by a linear combination of elements out of the dictionary. The set of shapelets is specifically learned for each image in an unsupervised way in order to capture the image structure. The spectral features are assumed to be the training data. The experiments show that the proposed approach shows superior results in comparison to sparse-representation based classifiers that use no or only limited spatial information and behaves competitive or better than state-of-the-art classifiers utilizing spatial information and kernelized sparse representation-based classifiers.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "ab754fecbca13aeb08f42de7bd3be4938e4813f8",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "a1a183c1e263526465c8d3097d13b3e2be273ea8",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "15f7662fadf686beae8ce704ee9b48262ac62237",
            "23c6b983cc56ec821d17436746f0458785fa7b5c",
            "7fc0624d3161c51f03bf496065a1ccb9f05caa45",
            "92261e8f1ab997a33892322c3231afc76b2d3158"
        ],
        "related_topics": [],
        "reference_count": "33",
        "citation_count": "5"
    },
    {
        "Id": "0974a7957910de34c709e2d63411834f59323774",
        "title": "Spectral-spatial online dictionary learning for hyperspectral image classification",
        "authors": [
            "Wei Fu",
            "Shutao Li",
            "Leyuan Fang",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "1 July 2017",
        "abstract": "A novel spectral-spatial online dictionary learning (SSODL) method for HSI classification is proposed, which aims to learn a complete and discriminative dictionary by exploiting both spatial and spectral information all over the whole image. Sparse representation (SR) based hyperspectral image (HSI) classification is a rapidly evolving research topic. How to construct an optimized dictionary to better characterize spectral-spatial features of HSI is an important problem. In this paper, a novel spectral-spatial online dictionary learning (SSODL) method for HSI classification is proposed. The main idea is to learn a complete and discriminative dictionary by exploiting both spatial and spectral information all over the whole image. Rather than only using training samples for dictionary construction, the online dictionary learning (ODL) mechanism can effectively improve the adaptive representation capability of different pixels. Specifically, the contextual characteristics of HSI are integrated with discriminative spectral information for the ODL, i.e., pushing similar pixels in neighborhood to share similar sparse coefficients w.r.t. the well learnt dictionary. By this way, the yielding sparse coefficients are structured and discriminative. Finally, a traditional classifier, i.e., linear support vector mechine (SVM), is applied to the sparse coefficients and the final classification results are obtained. Experimental results on real HSIs show the effectiveness of the proposed method.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "d80e7c2280caf016404ffa02469b331e755cfc7b",
            "fff45cbbb315fffb4c72d8459fcd9fe28a87519c",
            "544d6cd24db5adad8453033e0cc1aa7d3d6224ab",
            "0088d6433a9715b7e74a623920925f2bfb04c920",
            "2badd8953397d757693859918cf9318fe7ec5e3b"
        ],
        "related_topics": [
            "Dictionary",
            "Hyperspectral Imagery",
            "Online Dictionary Learning",
            "Pixel",
            "Classification",
            "HSIs",
            "Classifier",
            "Spectral-Spatial",
            "Sparse Representation",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "9",
        "citation_count": "2"
    },
    {
        "Id": "692541a740b2b3c5c82a47390a7cbb40872efec5",
        "title": "Contextual Online Dictionary Learning for Hyperspectral Image Classification",
        "authors": [
            "Wei Fu",
            "Shutao Li",
            "Leyuan Fang",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "1 March 2018",
        "abstract": "A contextual online dictionary learning (DL) method for HSIs classification is proposed, which learns a dictionary over the whole image rather than few labeled pixels, and can effectively and efficiently improve the adaptive representation capability of different pixels with an online learning mechanism. Sparse representation (SR) has been successfully used in the classification of hyperspectral images (HSIs) by representing HSI pixels over a dictionary and yielding discriminative sparse coefficients. Most of SR-based classification methods construct the dictionary by directly using some labeled pixels as atoms. Such dictionary can lead to inefficient SR for large-sized HSIs, and may be incomplete when the number of labeled pixels is less than the number of spectral bands. This paper proposes a contextual online dictionary learning (DL) method for HSIs classification, which learns a dictionary over the whole image rather than few labeled pixels. The proposed method can effectively and efficiently improve the adaptive representation capability of different pixels with an online learning mechanism. Specifically, the contextual characteristics of the HSI are integrated with discriminative spectral information for online DL, i.e., pushing similar pixels in neighborhood to share similar sparse coefficients with respect to the well-learned dictionary. By this way, the obtained sparse coefficients are structured and discriminative. Finally, a traditional classifier, i.e., the linear support vector machine, is applied to the sparse coefficients, and the final classification results are obtained. Experimental results on real HSIs show the effectiveness of the proposed method.",
        "references": [
            "e860267bdaba7eba2fbfbdbb9974d6fd574d522b",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "15f7662fadf686beae8ce704ee9b48262ac62237",
            "083b3a4d102c08c9553ad4db4afd6dd37a5ca448",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "cdd338408ce5b93dc78609af10fee43d5a45fab9",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "28370ac959ea8a46fdf05d1092ee476ace3afe3d"
        ],
        "related_topics": [
            "Dictionary",
            "HSIs",
            "Classification",
            "Online Dictionary Learning",
            "Sparse Representation",
            "Hyperspectral Image Classification",
            "Linear Support Vector Machines",
            "Neighborhood"
        ],
        "reference_count": "50",
        "citation_count": "21"
    },
    {
        "Id": "d5adb37bf7cb56774e6cdae87d04770f892ac754",
        "title": "Discriminative Eigenpixels-Based Dictionary Learning for Hyperspectral Image Classification",
        "authors": [
            "Lin Song",
            "Shuying Li"
        ],
        "date": "1 August 2020",
        "abstract": "A new algorithm of HSI classification based on discriminative eigenpixels-based dictionary learning is proposed, which code a homogeneous region associated with a query pixel on the learned dictionary to determine its label by use of both the nearest neighbor (NN) classifier and majority voting. Sparse representation (SR) model has been applied to hyperspectral image (HSI) classification based on the observation that any spectral pixel could be approximately represented by a linear combination of several common pixels, but its discriminative ability is not deeply explored due to an insufficient description on spatial\u2013spectral information and less emphasis on the dictionary structure. In this letter, we propose a new algorithm of HSI classification based on discriminative eigenpixels-based dictionary learning. Instead of using neighbor pixels directly, we define a new homogeneous region for each pixel, respectively, to exploit more spatial\u2013spectral information and extract eigenpixels from homogeneous regions to preserve the essentials for each class. For the representation-based model, a discriminative eigenpixels-based dictionary is learned in homogeneous regions, where the locality of pixels is exploited to enhance the discriminative ability. Finally, we code a homogeneous region associated with a query pixel on the learned dictionary to determine its label by use of both the nearest neighbor (NN) classifier and majority voting. Experiments are conducted on four HSIs to demonstrate the effectiveness of the proposed method.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "f59d79f5ab81718cf5fa7bfaf2be635451d7953f",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "4ab0d77862353cfc1c5d39d4a85fc12c5764843b",
            "85efd6887be908584bd85e8004dcad3bd53f51aa",
            "5154456c5b0b82206005f3df9fc4b478174db1ff",
            "3a5f27e244711177872b349207bec4d64d37e986",
            "a80b169a86da15040d41033368a07ab052f4315d",
            "c11c86f46fa1b42257ea72591792b1dd79e809e6",
            "87fa9b8d8a49a9ee54b9c55228a6531ee8e8dd3b"
        ],
        "related_topics": [
            "Pixel",
            "Hyperspectral Imagery",
            "Spatial-spectral Information",
            "HSIs",
            "Dictionary Learning",
            "Sparse Representation",
            "Hyperspectral Image Classification",
            "Representation Based Models",
            "Classification"
        ],
        "reference_count": "0",
        "citation_count": "23"
    },
    {
        "Id": "28f3446718da6fed450bded33576322bd8d60448",
        "title": "Hyperspectral Image Classification Based on Sparse Modeling of Spectral Blocks",
        "authors": [
            "Saeideh Ghanbari Azar",
            "Saeed Meshgini",
            "Tohid Yousefi Rezaii",
            "Soosan Beheshti"
        ],
        "date": "17 May 2020",
        "abstract": "Semantic Scholar extracted view of \"Hyperspectral Image Classification Based on Sparse Modeling of Spectral Blocks\" by Saeideh Ghanbari Azar et al.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "adfd2883433e457c7e5167121714c81247cb4e15",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "541ebe34978254e0717bd3f59087e20c861a6753",
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "10fb16414324a5db44f5d830adcb4810af59eed0"
        ],
        "related_topics": [
            "Spatial Redundancy",
            "Benchmark Dataset",
            "Computational Complexity",
            "Classification Accuracy",
            "Classification",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "38",
        "citation_count": "15"
    },
    {
        "Id": "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
        "title": "Learning group-based sparse and low-rank representation for hyperspectral image classification",
        "authors": [
            "Zhi He",
            "Lin Liu",
            "Suhong Zhou",
            "Yi Shen"
        ],
        "date": "1 December 2016",
        "abstract": "Semantic Scholar extracted view of \"Learning group-based sparse and low-rank representation for hyperspectral image classification\" by Zhi He et al.",
        "references": [
            "383a5b15bf4eee3084b21f260c97be2e23b9a5b6",
            "9f2f1a5d4f6e582d4afd857915802805a7f4185e",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "e860267bdaba7eba2fbfbdbb9974d6fd574d522b",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "5c8f91f7ead043544e2606d1997f9ce15a421107",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "5f346dc3df2a256003fd037cd770ea3838d781a4",
            "8f512f556a992851a7191e730c5be34dc420fe4f"
        ],
        "related_topics": [
            "Dictionary",
            "Inexact Augmented Lagrangian Methods",
            "Low-Rank Representation",
            "Support Vector Machines",
            "HSIs",
            "Class Labels",
            "Linear Support Vector Machines",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "42",
        "citation_count": "30"
    },
    {
        "Id": "8488cbb0edb6e0955efacbb6870e8566eac6b833",
        "title": "Mixed Distillation for Unsupervised Anomaly Detection",
        "authors": [
            "Fuzhen Cai",
            "Siyu Xia"
        ],
        "date": "23 July 2023",
        "abstract": "A skip distillation method is proposed, which allows the deep layers of the student network to learn directly from the shallow of the teacher, avoiding a worse deep fit. Anomaly detection is typically a class of unsupervised learning problems in which the model is trained with only normal samples. Knowledge distillation (KD) has shown promising results in the field of image anomaly detection, especially for texture images. However, the knowledge of the classical KD model is step-by-step transferred from the shallow layers to the deep, which causes the deep layers not to be well-fitted due to an incomplete match of the shallow layers of the student network. For this problem, we propose a skip distillation method, which allows the deep layers of the student network to learn directly from the shallow of the teacher, avoiding a worse deep fit. We also design a symmetric path that allows the shallow layers of the student network to learn directly from the deep of the teacher. These two paths encode su\ufb03cient information for the student network. We have done thorough experiments on the anomaly detection benchmark dataset MvtecAD, and the experimental results show that our model exceeds the current state-of-the-art anomaly detection methods in terms of texture classes.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "5fdd9cfb9b22b9e575d36e98e5d6f52a83729e42",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "9277dc70c74bcadf80dab11c28ead83fd085deec"
        ],
        "related_topics": [
            "Student Network",
            "Anomaly Detection",
            "Image Anomaly Detection",
            "Unsupervised Learning",
            "Knowledge Distillation",
            "UnSupervised Anomaly Detection",
            "Benchmark Dataset",
            "Texture Classes"
        ],
        "reference_count": "0",
        "citation_count": "18"
    },
    {
        "Id": "388ed5032dcc5f5e5b59e4cd4ca5a5d3751a1588",
        "title": "Unsupervised anomaly detection via knowledge distillation with non-directly-coupled student block fusion",
        "authors": [
            "Zhiyuan Feng",
            "Ying Chen",
            "Linbo Xie"
        ],
        "date": "13 September 2023",
        "abstract": "A novel distillation network is proposed for unsupervised anomaly detection, consisting of a complete teacher network and a set of non-directly-coupled student blocks, which independently take features of each layer of teacher network as their input and target to recover the multi-scale representation of the teacher. Recently, knowledge distillation has achieved excellent results in unsupervised anomaly detection. The representation difference of anomalies between teacher and student model is an essential basis for unsupervised anomaly detection. To fully exploit the diversity of anomaly representations, a novel distillation network is proposed for unsupervised anomaly detection, consisting of a complete teacher network and a set of non-directly-coupled student blocks. Instead of taking a complete network as a student which sequentially inherits the distilled knowledge from the previous layer, the student blocks are specifically designed, which independently take features of each layer of teacher network as their input and target to recover the multi-scale representation of the teacher. For each block, an adaptive weighted multi-branch feature extraction strategy is presented to enable the blocks to better focus on key messages from the teacher model. In addition, a feature reunion technique is given during distillation to make multi-scale features more robust to noisy input. The experimental results indicate that the proposed method achieves an outstanding performance on MVTec AD dataset. Compared with the baseline method, the proposed method improves by 2.21% at ROC-AUC of image level and improves by 1.00 and 2.22% for both ROC-AUC and PRO-AUC at pixel level.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "4dd78b8d466b4cfe55a1bbdc694291197ce62541",
            "1c0165247ce1d56a9de7be50ca6c4a49f0db4a82",
            "6517f92d519fc126cc18924231bafd8945a554d1",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "39"
    },
    {
        "Id": "0e8446c00ed21c19f62d71ab208a7b3601671766",
        "title": "A Unified Model for Multi-class Anomaly Detection",
        "authors": [
            "Zhiyuan You",
            "Lei Cui",
            "Yujun Shen",
            "Kai Yang",
            "Xin Lu",
            "Yu Zheng",
            "Xinyi Le"
        ],
        "date": "8 June 2022",
        "abstract": "UniAD is presented, that accomplishes anomaly detection for multiple classes with a unified framework and makes three improvements, including a layer-wise query decoder to help model the multi-class distribution and a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a unified framework. Under such a challenging setting, popular reconstruction networks may fall into an\"identical shortcut\", where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and confirm the important role of query embedding (i.e., within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10 datasets, where we surpass the state-of-the-art alternatives by a sufficiently large margin. For example, when learning a unified model for 15 categories in MVTec-AD, we surpass the second competitor on the tasks of both anomaly detection (from 88.1% to 96.5%) and anomaly localization (from 89.5% to 96.8%). Code is available at https://github.com/zhiyuanyou/UniAD.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "4758baad6b22c61682e7f7182bb93723046f36f5",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "2e8d62277e40d465343e8dfb32ecc246f320540e",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "8ee35ed698527d9695c872e3b76715fec4ef69ad",
            "93040f8a5d10e8fde279e18d353aa3dca2873900"
        ],
        "related_topics": [
            "UniAD",
            "DRAEM",
            "Pixel-level AUROC",
            "MVTec AD",
            "Anomaly Detection",
            "Anomaly Localization",
            "Input Features",
            "Fully Connected Layers",
            "Layers",
            "Convolutional Layers"
        ],
        "reference_count": "71",
        "citation_count": "56"
    },
    {
        "Id": "787c063a11df7facc43d5be3a49343746f2d27ef",
        "title": "Adapting Generic Features to A Specific Task: A Large Discrepancy Knowledge Distillation for Image Anomaly Detection",
        "authors": [
            "Chenkai Zhang",
            "Tianqi Du",
            "Yueming Wang"
        ],
        "date": "2023",
        "abstract": "A novel angular margin loss is introduced to improve the regular training loss of knowledge distillation and ensure larger discrepancies between T-S models on anomalies and help state-of-the-art KD-based methods achieve better detection performance. Anomaly detection is a challenging task due to the lack of data on unexpected anomalies. Recent approaches using Knowledge Distillation (KD) between Teacher-Student (T-S) models have shown great potential for anomaly detection. These techniques use pre-trained models on natural images as the teacher model. However, for industrial images, defects typically occur in a small region, while the global semantics of the anomaly image remain similar to normal images. This situation results in generic features being unable to capture defects well, leading to a loss of discriminability in detecting anomalies. This paper proposes a way to improve this situation by applying learnable feature mappings to adapt the generic features for the data-specific task. Additionally, a novel angular margin loss is introduced to improve the regular training loss of knowledge distillation and ensure larger discrepancies between T-S models on anomalies. Extensive experiments show that the proposed feature mappings and angular loss can effectively improve the feature discriminability for anomaly detection and help state-of-the-art KD-based methods achieve better detection performance.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "8ee35ed698527d9695c872e3b76715fec4ef69ad",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "7b7087b7452adc2fe8a874678049f591c1342c0f",
            "38ca689c2f916c648ea3ecb1043facbc4bea0d4f"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "26"
    },
    {
        "Id": "3b3aefbbdb64e5812f133f220b3f129a36a30065",
        "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
        "authors": [
            "Hanqiu Deng",
            "Xingyu Li"
        ],
        "date": "26 January 2022",
        "abstract": "A novel T-S model consisting of a teacher encoder and a student decoder is proposed and a simple yet effective \u201creverse distillation\u201d paradigm is introduced, demonstrating the proposed approach's effectiveness and generalizability. Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "599fd051c9438011ec5b581983c89e8922b4a5e6",
            "30895c61bb836f2cae7ef5ba6516886f746a7153",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "93040f8a5d10e8fde279e18d353aa3dca2873900",
            "9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ],
        "related_topics": [
            "Reverse Distillation",
            "Student Decoder",
            "One-Class Embedding",
            "CutPaste",
            "Multiresolution Knowledge Distillation",
            "Large Defects",
            "Anomaly-free Samples",
            "Pseudo Anomalies",
            "WideResnet-50",
            "Localize Anomaly"
        ],
        "reference_count": "52",
        "citation_count": "161"
    },
    {
        "Id": "cec282840ed7992af45400472fa545c94a6e3f7d",
        "title": "ADPS: Asymmetric Distillation Post-Segmentation for Image Anomaly Detection",
        "authors": [
            "Peng Xing",
            "Hao Tang",
            "Jinhui Tang",
            "Zechao Li"
        ],
        "date": "19 October 2022",
        "abstract": "This work proposes an innovative approach called Asymmetric Distillation Post-Segmentation (ADPS), which employs an asymmetric distillation paradigm that takes distinct forms of the same image as the input of the teacher-student networks, driving the student network to learn discriminating representations for anomalous regions. Knowledge Distillation-based Anomaly Detection (KDAD) methods rely on the teacher-student paradigm to detect and segment anomalous regions by contrasting the unique features extracted by both networks. However, existing KDAD methods suffer from two main limitations: 1) the student network can effortlessly replicate the teacher network's representations, and 2) the features of the teacher network serve solely as a ``reference standard\"and are not fully leveraged. Toward this end, we depart from the established paradigm and instead propose an innovative approach called Asymmetric Distillation Post-Segmentation (ADPS). Our ADPS employs an asymmetric distillation paradigm that takes distinct forms of the same image as the input of the teacher-student networks, driving the student network to learn discriminating representations for anomalous regions. Meanwhile, a customized Weight Mask Block (WMB) is proposed to generate a coarse anomaly localization mask that transfers the distilled knowledge acquired from the asymmetric paradigm to the teacher network. Equipped with WMB, the proposed Post-Segmentation Module (PSM) is able to effectively detect and segment abnormal regions with fine structures and clear boundaries. Experimental results demonstrate that the proposed ADPS outperforms the state-of-the-art methods in detecting and segmenting anomalies. Surprisingly, ADPS significantly improves Average Precision (AP) metric by 9% and 20% on the MVTec AD and KolektorSDD2 datasets, respectively.",
        "references": [
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "d08775cf2bebcffa05c6fa506f687ef56953f128",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "93040f8a5d10e8fde279e18d353aa3dca2873900"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "66"
    },
    {
        "Id": "2013f18832e0fb11c7aaf1f4f8da453aebda488c",
        "title": "Pull & Push: Leveraging Differential Knowledge Distillation for Efficient Unsupervised Anomaly Detection and Localization",
        "authors": [
            "Qihang Zhou",
            "Shibo He",
            "Haoyu Liu",
            "Tao Chen",
            "Jiming Chen"
        ],
        "date": "1 May 2023",
        "abstract": "This work designs an efficient teacher-student model for anomaly detection and localization, which maximizes pixel-wise discrepancies for anomalous regions approximated by data augmentation and simultaneously minimizes discrepancies for pixel- wise normal regions between these two networks. Recently, much attention has been paid to segmenting subtle unknown defect regions by knowledge distillation in an unsupervised setting. Most previous studies concentrated on guiding the student network to learn the same representations on the normality, neglecting the different behaviors of the abnormality. This leads to a high probability of false detection of subtle defects. To address such an issue, we propose to push representations on abnormal areas of the teacher and student network as far as possible while pulling representations on normal areas as close as possible. Based on this idea, we design an efficient teacher-student model for anomaly detection and localization, which maximizes pixel-wise discrepancies for anomalous regions approximated by data augmentation and simultaneously minimizes discrepancies for pixel-wise normal regions between these two networks. The explicit differential knowledge distillation enlarges the margin between normal representations and abnormal ones in favour of discriminating them. Then, the appropriate small student network is not only efficient, but more importantly, helps inhibit the generalization ability of anomalous patterns when learning normal patterns, facilitating the precise decision boundary. The experimental results on the MVTec AD, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our proposed method achieves better performance than current state-of-the-art (SOTA) approaches. Especially, For the MVTec AD dataset with high resolution images, we achieve 98.1 AUROC% and 93.6 AUPRO% in anomaly localization, outperforming knowledge distillation based SOTA methods by 1.1 AUROC% and 1.5 AUPRO% with a lightweight model.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "4dd78b8d466b4cfe55a1bbdc694291197ce62541",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "7d90243c5a46430a36c5ba88627b5d254450a1e1",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "23ad8fc48530ce366f8192dfb48d0f7df1dba277"
        ],
        "related_topics": [
            "Student Network",
            "Knowledge Distillation",
            "MVTec AD",
            "Self-organizing Tree Algorithm",
            "Area Under The Receiver Operating Characteristic Curve",
            "Margin",
            "Student Model",
            "CIFAR-10",
            "UnSupervised Anomaly Detection",
            "Anomaly Detection"
        ],
        "reference_count": "64",
        "citation_count": "8"
    },
    {
        "Id": "25e72f27ebf69da3171f99724539c1b88f8837f9",
        "title": "Autoencoder-Like Knowledge Distillation Network for Anomaly Detection",
        "authors": [
            "Caie Xu",
            "Bingyan Wang",
            "Dandan Ni",
            "Jin Gan",
            "Mingyang Wu",
            "Wujie Zhou"
        ],
        "date": "2023",
        "abstract": "A novel autoencoder-like KD model based on the attention mechanism for anomaly detection that attains the state-of-the-art (SOTA) performance in anomaly detection on the public dataset MVTec and exhibits superior performance compared to other existing anomaly detection models on specific datasets. Anomaly detection is a crucial research field in computer vision with diverse applications in practical scenarios. The common anomaly detection methods employed currently consist of autoencoders, generative adversarial networks, and knowledge distillation (KD) models. However, the teacher and student models in KD might not always yield distinct representations to signify anomalies due to their similar model structure and data flow. This study proposes a novel autoencoder-like KD model based on the attention mechanism for anomaly detection. The pre-trained teacher model incorporates a dual attention module as the encoder, while the student model integrates the same dual attention module as the decoder. The teacher guides the student to learn the feature knowledge of the input image. To connect the teacher-student model, a BottleNeck module is employed, converting the features extracted from the teacher model into more compact latent codes for precise restoration by the student model, thereby achieving anomaly detection. In general, the proposed model exhibits superior performance compared to other existing anomaly detection models on specific datasets. Experimental results demonstrate that the proposed model attains the state-of-the-art (SOTA) performance in anomaly detection on the public dataset MVTec. It achieves an average AUC of 98.2% and 98.0% at sample and pixel levels, respectively.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "98fa8f7b28f43830a22612be53bb393cf421bbc1",
            "f37bc75aa1833e1330c39c4f04b131baca08d67b"
        ],
        "related_topics": [],
        "reference_count": "37",
        "citation_count": "One"
    },
    {
        "Id": "61840de4d9610558d510cfcf32986e93511a4cef",
        "title": "Asymmetric Distillation Post-Segmentation Method for Image Anomaly Detection",
        "authors": [
            "Peng-Fei Xing",
            "Zechao Li"
        ],
        "date": "2022",
        "abstract": "A novel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network is proposed and achieves state-of-the-art anomaly segmentation results. Knowledge distillation-based anomaly detection methods generate same outputs for unknown classes due to the symmetric form of the input and ignore the powerful semantic information of the output of the teacher network since it is only used as a \u201creference standard\u201d. Towards this end, this work proposes a novel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network. Speci\ufb01cally, a simple yet effective asymmetric input approach is proposed to make different data \ufb02ows through the teacher and student networks. The student network enables to have different inductive and expressive abilities, which can generate different outputs in anomalous regions. Besides, to further explore the semantic information of the teacher network and obtain effective discriminative boundaries, the Weight Mask Block (WMB) and the post-segmentation module are proposede. WMB leverages a weighted strategy by exploring teacher-student feature maps to highlight anomalous features. The post-segmentation module further learns the anomalous features and obtains valid discriminative boundaries. Experimental results on three benchmark datasets demonstrate that the proposed ADPS achieves state-of-the-art anomaly segmentation results.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "2b32b46f346d9b13268f0e74e5242a10a712a352",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "d08775cf2bebcffa05c6fa506f687ef56953f128",
            "6517f92d519fc126cc18924231bafd8945a554d1",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f"
        ],
        "related_topics": [
            "Teacher Network",
            "Student Network",
            "Semantic Information",
            "Weighted Mini-bucket",
            "Unknown Classes",
            "Image Anomaly Detection",
            "Anomalous Regions",
            "Knowledge Distillation",
            "Anomaly Detection",
            "Benchmark Dataset"
        ],
        "reference_count": "0",
        "citation_count": "52"
    },
    {
        "Id": "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
        "title": "Explainable Deep Few-shot Anomaly Detection with Deviation Networks",
        "authors": [
            "Guansong Pang",
            "Choubo Ding",
            "Chunhua Shen",
            "Anton van den Hengel"
        ],
        "date": "1 August 2021",
        "abstract": "This work introduces a novel weakly-supervised anomaly detection framework to train detection models without assuming the examples illustrating all possible classes of anomaly, and learns discriminative normality by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. Existing anomaly detection paradigms overwhelmingly focus on training detection models using exclusively normal data or unlabeled data (mostly normal samples). One notorious issue with these approaches is that they are weak in discriminating anomalies from normal samples due to the lack of the knowledge about the anomalies. Here, we study the problem of few-shot anomaly detection, in which we aim at using a few labeled anomaly examples to train sample-efficient discriminative detection models. To address this problem, we introduce a novel weakly-supervised anomaly detection framework to train detection models without assuming the examples illustrating all possible classes of anomaly. Specifically, the proposed approach learns discriminative normality (regularity) by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. This is achieved by an end-to-end optimization of anomaly scores with a neural deviation learning, in which the anomaly scores of normal samples are imposed to approximate scalar scores drawn from the prior while that of anomaly examples is enforced to have statistically significant deviations from these sampled scores in the upper tail. Furthermore, our model is optimized to learn fine-grained normality and abnormality by top-K multiple-instance-learning-based feature subspace deviation learning, allowing more generalized representations. Comprehensive experiments on nine real-world image anomaly detection benchmarks show that our model is substantially more sample-efficient and robust, and performs significantly better than state-of-the-art competing methods in both closed-set and open-set settings. Our model can also offer explanation capability as a result of its prior-driven anomaly score learning. Code and datasets are available at: https://git.io/DevNet.",
        "references": [
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "8ed98bd58c799718d6fd389e2218bb89b1ecb9d7",
            "30aa23a6a32312666f2609339582744203024993",
            "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "c48def9076e58095c4aea49a8daa931af1990701",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "f5a951b9596be0df5ad7ede180b405c9e97a65c9",
            "182d11020bf2842f135f1ec1dcac20237e0dc8b7",
            "5f61089d3d548a515f01b473f0119137d1f340d4"
        ],
        "related_topics": [
            "Few Shot Anomaly Detection",
            "Deviation Networks",
            "Fractional Lower Order Statistics",
            "Deviation Loss",
            "DevNet",
            "Anomaly Contamination",
            "Unseen Anomalies",
            "Anomaly Score",
            "Normal Samples",
            "Explainable"
        ],
        "reference_count": "76",
        "citation_count": "43"
    },
    {
        "Id": "61724a421569317ba470d48ebdd7316ab8e91b50",
        "title": "Local Differential Privacy for Deep Learning",
        "authors": [
            "Pathum Chamikara Mahawaga Arachchige",
            "Peter Bert{\\&#x27;o}k",
            "Ibrahim Khalil",
            "Dongxi Liu",
            "Seyit Ahmet \u00c7amtepe",
            "Mohammed Atiquzzaman"
        ],
        "date": "8 August 2019",
        "abstract": "A new local differentially private (LDP) algorithm named LATENT is proposed that redesigns the training process and enables a data owner to add a randomization layer before data leave the data owners\u2019 devices and reach a potentially untrusted machine learning service. The Internet of Things (IoT) is transforming major industries, including but not limited to healthcare, agriculture, finance, energy, and transportation. IoT platforms are continually improving with innovations, such as the amalgamation of software-defined networks (SDNs) and network function virtualization (NFV) in the edge-cloud interplay. Deep learning (DL) is becoming popular due to its remarkable accuracy when trained with a massive amount of data such as generated by IoT. However, DL algorithms tend to leak privacy when trained on highly sensitive crowd-sourced data such as medical data. The existing privacy-preserving DL algorithms rely on the traditional server-centric approaches requiring high processing powers. We propose a new local differentially private (LDP) algorithm named LATENT that redesigns the training process. LATENT enables a data owner to add a randomization layer before data leave the data owners\u2019 devices and reach a potentially untrusted machine learning service. This feature is achieved by splitting the architecture of a convolutional neural network (CNN) into three layers: 1) convolutional module (CNM); 2) randomization module; and 3) fully connected module. Hence, the randomization module can operate as an NFV privacy preservation service in an SDN-controlled NFV, making LATENT more practical for IoT-driven cloud-based environments compared to existing approaches. The randomization module employs a newly proposed LDP protocol named utility enhancing randomization, which allows LATENT to maintain high utility compared to existing LDP protocols. Our experimental evaluation of LATENT on convolutional deep neural networks demonstrates excellent accuracy (e.g., 91%\u201396%) with high model quality even under low privacy budgets (e.g., $\\varepsilon =0.5$ ).",
        "references": [
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "5ef568b893f6dca14a63e03f85bb509105f9cd7f",
            "8b8ffd58620f30e330b7ba23236e573604279de8",
            "e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9",
            "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "0abcdfd71e43a65df13fc9f9171d95de6f9c1826",
            "d1b9a3b11e6c9571a1553556f82b605b2b4baec3",
            "2e70cb13dfcd2aac4f463c35f97530b043f5bff2",
            "6227544195ed3cb30e411b31507e330ac2397398"
        ],
        "related_topics": [
            "Randomization Layer",
            "Postprocessing Invariance",
            "LDP Algorithms",
            "Hybrid Perturbation",
            "Network Function Virtualization",
            "Local Differential Privacy",
            "Introduction Internet",
            "Software-defined Network",
            "Deep Learning",
            "Convolutional Neural Network"
        ],
        "reference_count": "63",
        "citation_count": "158"
    },
    {
        "Id": "50e111f895b3b059f927efb0cb917edeb3eadad2",
        "title": "A Survey of Machine and Deep Learning Methods for Privacy Protection in the Internet of Things",
        "authors": [
            "Eva Rodr{\\&#x27;i}guez",
            "Beatriz Otero",
            "Ramon Canal"
        ],
        "date": "21 January 2023",
        "abstract": "This paper presents a comprehensive survey of recent Machine Learning (ML)- and Deep Learning (DL)-based solutions for privacy in IoT, and identifies the most effective solutions for the different threats and attacks. Recent advances in hardware and information technology have accelerated the proliferation of smart and interconnected devices facilitating the rapid development of the Internet of Things (IoT). IoT applications and services are widely adopted in environments such as smart cities, smart industry, autonomous vehicles, and eHealth. As such, IoT devices are ubiquitously connected, transferring sensitive and personal data without requiring human interaction. Consequently, it is crucial to preserve data privacy. This paper presents a comprehensive survey of recent Machine Learning (ML)- and Deep Learning (DL)-based solutions for privacy in IoT. First, we present an in depth analysis of current privacy threats and attacks. Then, for each ML architecture proposed, we present the implementations, details, and the published results. Finally, we identify the most effective solutions for the different threats and attacks.",
        "references": [
            "da8a949f9c9f1df3a38f12c2cac97b789c705465",
            "b17222d017d4069bf2c4dde2f4925a95b705d045",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "fa11e69ffcec69801ca55edc0d5a03200c25e813",
            "bfdad8066d2b8dff3e9bae43715724813ad5dbc3",
            "49a4be47999f435c24bc3419a0b983cb123f86b4",
            "591f494070725a31609157dc9c6f639c9603c7f9",
            "98549b26284d3465d46a6ac7189d947266c9a055",
            "a302000c290f3a36954de8dab01dcec409132430",
            "4444a3baa86b44bac2fc03b5b2ae1226438c374c"
        ],
        "related_topics": [
            "Introduction Internet",
            "Deep Learning",
            "Data Privacy",
            "Machine Learning",
            "Privacy Protection"
        ],
        "reference_count": "106",
        "citation_count": "7"
    },
    {
        "Id": "8dbe9e08808d54a3481262e8cd8597bd6a9eb975",
        "title": "FORESEEN: Towards Differentially Private Deep Inference for Intelligent Internet of Things",
        "authors": [
            "L. Lyu",
            "James C. Bezdek",
            "Jiong Jin",
            "Yang Yang"
        ],
        "date": "8 June 2020",
        "abstract": "This work proposes a FOg-based pRivacy prEServing dEep lEarNing framework named FORESEEN, capable of reducing the communication cost and providing inherent support for robustness and scalability, and builds deep models with mixed-precision. In state-of-the-art deep learning, centralized deep learning forces end devices to pool their data in the cloud in order to train a global model on the joint data, while distributed deep learning requires a parameter server to mediate the training process among multiple end devices. However, none of these architectures scale gracefully to large-scale privacy and time-sensitive IoT applications. Therefore, we are motivated to propose a FOg-based pRivacy prEServing dEep lEarNing framework named FORESEEN, so as to achieve scalable, accurate yet private analytics. In FORESEEN, the intermediate fog nodes and the cloud collaboratively perform noisy training of deep neural networks (DNNs), while each end device and its connected fog node collaboratively perform fast, private yet accurate inference. To enhance robustness and ensure privacy, we put forward a collaborative noisy training algorithm and develop a novel representation perturber to perturb the extracted features by combining random projection, random noise addition and data nullification. To meet the required constraints of accuracy, memory and energy in IoT end devices, we build deep models with mixed-precision. Through these sophisticated designs, FORESEEN is able to not only preserve privacy but also maintain comparable inference performance. Extensive experimental results under different datasets, different inference schemes and different noise addition strategies validate the effectiveness of FORESEEN. Moreover, FORESEEN is capable of reducing the communication cost and providing inherent support for robustness and scalability.",
        "references": [
            "2c7ebce685f4098e70af41ae746b98c2d4a89a9b",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "51b4bde0f3e381ae75dee5e41a43a32c71c61f71",
            "1f2bd6c334f3970e20e56c5640e304a75c13122f",
            "d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "da773af7e4f1248f47e6057eabcb595b3997eac9",
            "e72264a50c1125f5de40e8414216168b26b9c73e",
            "db0cc2f21b20cbc0ab8946090967399c25709614",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "f3b684f3d2ddd29134c842f6d31664157703a089"
        ],
        "related_topics": [
            "Deep Inference",
            "Random Projection",
            "Distributed Deep Learning",
            "Parameter Server",
            "Deep Learning",
            "Global Model",
            "Mixed Precision",
            "Introduction Internet",
            "Differentially Private"
        ],
        "reference_count": "30",
        "citation_count": "20"
    },
    {
        "Id": "3369909da934c17cf86f90954e92bdda25b03be0",
        "title": "Privacy preserving and performance improvement in edgecomputing using Machine learning",
        "authors": [
            "Saumya Bhadauria",
            "Mohit Kumar",
            "Navneet Pratap Singh"
        ],
        "date": "23 September 2022",
        "abstract": "The goal of this study is to implement an effective and safe proactive strategy on edge devices which will provide more privacy, as personal data are processed at the nearest edge that can be leaked or exploited by any intruder. With the increase in the usage of IoT and mobile devices in our day to day lives results in generating vast amount of data, as well as increase in advanced services and applications such as VR, augmented reality and a race for building smart cities made it a challenging situation for cloud computing in terms of latency, privacy and scalability to resolve all these challenges edge computing falls into play as a modern model of computing where computing and storage are located closer to the data center, allowing a new latency and bandwidth-sensitive application class where data is processed at the nearer edge without sending it to the cloud [9]. The goal of this study is to implement an effective and safe proactive strategy (instead of sending a response of a query to each node, node should have its own local computational resources that updates the parameter to the central server) on edge devices which will provide more privacy, as personal data are processed at the nearest edge that can be leaked or exploited by any intruder and because of latency problem in the centralized approach there is a need for effective decentralized system, which additionally should give better outcome as off-base outcome can at some point be calamitous, like in the case of auto-driving car. We will also be presenting how we can utilize numerous encryption technique to scramble data for model training which regardless of whether get hacked by an intruder would be of no use, as if confidential data learned by the model or leaked to an intruder might lead to a significant loss. The proposed method would be tested to all the machine learning problems like word suggestion, image classification and many more.",
        "references": [
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "4fe2bd10fba40632235de54a56b1b47760423203",
            "f863f0aaea94656807d21b66ba786137f5e28e1f",
            "60951974d24dd83e288117b0cd217af6a5d34178",
            "5aec150fa6164403dede021882e407696bdea072",
            "baca7484872a17f77bd0b558cfd8a7d1b942bb0b",
            "e7f84b1d7f8378ffaadbf85c33bacc8bcd9e28dd",
            "19031f8bb0ed20f238d1017ff7384f2ff30246b7",
            "0863067ff56f84ddb408f2d72af267e5c764e889",
            "c94145d960d8f77cbf820a4cf814d33ec486a420"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "14"
    },
    {
        "Id": "51b4bde0f3e381ae75dee5e41a43a32c71c61f71",
        "title": "Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud",
        "authors": [
            "Ji Wang",
            "Jianguo Zhang",
            "Weidong Bao",
            "Xiaomin Zhu",
            "Bokai Cao",
            "Philip S. Yu"
        ],
        "date": "19 July 2018",
        "abstract": "A noisy training method is proposed to enhance the cloud-side network robustness to perturbed data and can not only preserve privacy but also improve the inference performance. The increasing demand for on-device deep learning services calls for a highly efficient manner to deploy deep neural networks (DNNs) on mobile devices with limited capacity. The cloud-based solution is a promising approach to enabling deep learning applications on mobile devices where the large portions of a DNN are offloaded to the cloud. However, revealing data to the cloud leads to potential privacy risk. To benefit from the cloud data center without the privacy risk, we design, evaluate, and implement a cloud-based framework ARDEN which partitions the DNN across mobile devices and cloud data centers. A simple data transformation is performed on the mobile device, while the resource-hungry training and the complex inference rely on the cloud data center. To protect the sensitive information, a lightweight privacy-preserving mechanism consisting of arbitrary data nullification and random noise addition is introduced, which provides strong privacy guarantee. A rigorous privacy budget analysis is given. Nonetheless, the private perturbation to the original data inevitably has a negative impact on the performance of further inference on the cloud side. To mitigate this influence, we propose a noisy training method to enhance the cloud-side network robustness to perturbed data. Through the sophisticated design, ARDEN can not only preserve privacy but also improve the inference performance. To validate the proposed ARDEN, a series of experiments based on three image datasets and a real mobile application are conducted. The experimental results demonstrate the effectiveness of ARDEN. Finally, we implement ARDEN on a demo system to verify its practicality.",
        "references": [
            "05ead8a840404c6075b5740e49bc9b34739a6a87",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "0a6278324c6216a789ed0ccd8ee055c612607db3",
            "d9ccaa75a7c55dc5af5d821316fbd549cd09249a",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "da773af7e4f1248f47e6057eabcb595b3997eac9",
            "6c20cd584e7258056840eb88437d69731000bb0f",
            "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9",
            "a1f83d89a3a8ab74f8968f5b875a8d8f98bb9475"
        ],
        "related_topics": [
            "ARDEN",
            "Deep Learning",
            "Network Robustness",
            "Private Deep Learning",
            "Image Datasets",
            "Inference"
        ],
        "reference_count": "49",
        "citation_count": "170"
    },
    {
        "Id": "7b1707391bf47ed5a99fe3626be6b4514c317745",
        "title": "DataMix: Efficient Privacy-Preserving Edge-Cloud Inference",
        "authors": [
            "Zhijian Liu",
            "Zhanghao Wu",
            "Chuang Gan",
            "Ligeng Zhu",
            "Song Han"
        ],
        "date": "2020",
        "abstract": "This paper mediate between the resource-constrained edge devices and the privacy-invasive cloud servers by introducing a novel privacy-preserving edge-cloud inference framework, DataMix, which off-load the majority of the computations to the cloud and leverage a pair of mixing and de-mixing operation, inspired by mixup. Deep neural networks are widely deployed on edge devices (e.g ., for computer vision and speech recognition). Users either perform the inference locally (i.e., edge-based) or send the data to the cloud and run inference remotely (i.e., cloud-based). However, both solutions have their limitations: edge devices are heavily constrained by insufficient hardware resources and cannot afford to run large models; cloud servers, if not trustworthy, will raise serious privacy issues. In this paper, we mediate between the resource-constrained edge devices and the privacy-invasive cloud servers by introducing a novel privacy-preserving edge-cloud inference framework, DataMix. We off-load the majority of the computations to the cloud and leverage a pair of mixing and de-mixing operation, inspired by mixup, to protect the privacy of the data transmitted to the cloud. Our framework has three advantages. First, it is privacy-preserving as the mixing cannot be inverted without the user\u2019s private mixing coefficients. Second, our framework is accuracy-preserving because our framework takes advantage of the space spanned by images, and we train the model in a mixing-aware manner to maintain accuracy. Third, our solution is efficient on the edge since the majority of the workload is delegated to the cloud, and our mixing and de-mixing processes introduce very few extra computations. Also, our framework introduces small communication overhead and maintains high hardware utilization on the cloud. Extensive experiments on multiple computer vision and speech recognition datasets demonstrate that our framework can greatly reduce the local computations on the edge (to fewer than 20% of FLOPs) with negligible loss of accuracy and no leakages of private information.",
        "references": [
            "51b4bde0f3e381ae75dee5e41a43a32c71c61f71",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "0a6278324c6216a789ed0ccd8ee055c612607db3",
            "c19cb5489fd65967dd6b6f0a0f2f2e0dec7509e2",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "662f3ca1f074e24803d33fcd6c7d19564de107f2",
            "8974968bdd99f5ca4755a501c577e1416fc3224a",
            "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "20780ad665e496aa128f82713bb78d13fd87cd0a"
        ],
        "related_topics": [
            "DataMix",
            "Computer Vision",
            "Speech Recognition",
            "Inference",
            "Deep Neural Networks",
            "Mixup",
            "Accuracy-preserving",
            "Float Point Operations"
        ],
        "reference_count": "62",
        "citation_count": "24"
    },
    {
        "Id": "d1b9480d967c7f446c0c299f34c02dfcee207cbe",
        "title": "Inductive learning and local differential privacy for privacy-preserving offloading in mobile edge intelligent systems",
        "authors": [
            "Jude Tchaye-Kondi",
            "Yanlong Zhai",
            "Liehuang Zhu"
        ],
        "date": "6 February 2021",
        "abstract": "A new local deferentially private algorithm is proposed that allows the Edge devices to apply random noise to features extracted from their sensitive data before transferred to an untrusted server. We address privacy and latency issues in the edge/cloud computing environment while training a centralized AI model. In our particular case, the edge devices are the only data source for the model to train on the central server. Current privacy-preserving and reducing network latency solutions rely on a pre-trained feature extractor deployed on the devices to help extract only important features from the sensitive dataset. However, finding a pre-trained model or pubic dataset to build a feature extractor for certain tasks may turn out to be very challenging. With the large amount of data generated by edge devices, the edge environment does not really lack data, but its improper access may lead to privacy concerns. In this paper, we present DeepGuess , a new privacy-preserving, and latency aware deeplearning framework. DeepGuess uses a new learning mechanism enabled by the AutoEncoder(AE) architecture called Inductive Learning, which makes it possible to train a central neural network using the data produced by end-devices while preserving their privacy. With inductive learning, sensitive data remains on devices and is not explicitly involved in any backpropagation process. The AE\u2019s Encoder is deployed on devices to extracts and transfers important features to the server. To enhance privacy, we propose a new local deferentially private algorithm that allows the Edge devices to apply random noise to features extracted from their sensitive data before transferred to an untrusted server. The experimental evaluation of DeepGuess demonstrates its effectiveness and ability to converge on a series of experiments.",
        "references": [
            "51b4bde0f3e381ae75dee5e41a43a32c71c61f71",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "60951974d24dd83e288117b0cd217af6a5d34178",
            "61724a421569317ba470d48ebdd7316ab8e91b50",
            "7fcb90f68529cbfab49f471b54719ded7528d0ef",
            "b6b1d641a832d54144653493e3f364fbec040c25",
            "d1b9a3b11e6c9571a1553556f82b605b2b4baec3",
            "88857e68305c4845c5744aafb5be60c1117e17ea",
            "70fda5147aedd42c64143a464117b5ffde18a2e4",
            "49bdeb07b045dd77f0bfe2b44436608770235a23"
        ],
        "related_topics": [
            "Inductive Learning",
            "Untrusted Server",
            "Feature Extractor",
            "Local Differential Privacy",
            "Cloud Computing"
        ],
        "reference_count": "0",
        "citation_count": "41"
    },
    {
        "Id": "c13cc5b858b62ebb689a11e4b60cb7e745c465a5",
        "title": "Hybrid Deep Learning Framework for Privacy Preservation in Geo-Distributed Data Centre",
        "authors": [
            "S. Nithyanantham",
            "G. Singaravel"
        ],
        "date": "2022",
        "abstract": "A hybrid deep learning framework for privacy preservation in distributed DCs using Deep Neural Network for the feature extractor and classifier operations and Glow-worm Swarm Optimization algorithm is utilized to fine tune the hyperparameters of the DNN model to improve the overall efficiency. In recent times, a huge amount of data is being created from different sources and the size of the data generated on the Internet has already surpassed two Exabytes. Big Data processing and analysis can be employed in many disciplines which can aid the decision-making process with privacy preservation of users\u2019 private data. To store large quantity of data, Geo-Distributed Data Centres (GDDC) are developed. In recent times, several applications comprising data analytics and machine learning have been designed for GDDC. In this view, this paper presents a hybrid deep learning framework for privacy preservation in distributed DCs. The proposed model uses Deep Neural Network (DNN) for the feature extractor and classifier operations. In addition, Siamese training method is applied to fine-tune the prevention of secondary inference on the data. Moreover, gradient descent approach is employed to reduce the loss function of the DNN model. Furthermore, Glow-worm Swarm Optimization (GSO) algorithm is utilized to fine tune the hyperparameters of the DNN model to improve the overall efficiency. The proposed model is executed on a Hadoop based environment, i.e., Hadoop Distributed File System (HDFS), which has two nodes namely master node and slave nodes. The master node is considered as the main user node to get the services from the service provider. Every slave node behaves as per master node\u2019s instruction for data storage. In order to validate the enhanced performance of the proposed model, a series of simulations take place and the experimental results demonstrate the promising performance of the proposed model. The simple technique has reached a maximum gender recognition accuracy of 95, 90 and 79 on the applied data 1, 2 and 3 respectively. Also, the reduced simple approach has attained reduced gender recognition with the accuracy of 91, 84 and 74 on the applied data 1, 2 and 3 respectively.",
        "references": [
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "a2a3658cc9d890f4aec63722fe3f93d7ccd6ae2f",
            "a91e90d3fb60b575b0b5772e3a7fc26115d08d6e",
            "0976e8878981e28b6f657c5bb9966c972684de30",
            "79152897350079faae3b65ac15000f38bab7e209",
            "9bbb61d9bcfa1a2b63efbdb8a521af8c8a2e94ec",
            "c5cec0ef2a248456742a70bb00b8be7af09500a5",
            "3dd2140a4a74236adbeb316d574b4cd7df239f7f",
            "b02986d285bf7ac4c6e316f853244b49db62126b",
            "405006da005398279bdf7c3423d47aa0951c5391"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "23"
    },
    {
        "Id": "06b79de003c09a6adf7980dea13ae0b8638d97cb",
        "title": "Differentially Private Collaborative Learning for the IoT Edge",
        "authors": [
            "Linshan Jiang",
            "Xin Lou",
            "Rui Tan",
            "Jun Zhao"
        ],
        "date": "25 February 2019",
        "abstract": "The design of a privacy-preserving collaborative learning approach, in which the edge devices and the cloud train different stages of a deep neural network, and the data transmitted from an edge device to the honest-but-curious cloud is perturbed by Laplacian random noises to achieve e-differential privacy is presented. Collaborative learning based on training data contributed by many edge devices is a promising paradigm for implementing crowd intelligence. The collaboratively trained model generally provides superior classification performance due to the increased volume and expanded coverage of the training data. However, the data contribution may incur the concern of privacy breach. This paper presents the design of a privacy-preserving collaborative learning approach, in which the edge devices and the cloud train different stages of a deep neural network, and the data transmitted from an edge device to the honest-but-curious cloud is perturbed by Laplacian random noises to achieve e-differential privacy. We apply the proposed approach to a case study of collaboratively training a convolutional neural network for handwritten digit recognition. The results show that our approach maintains 99% and 96% classification accuracy in implementing privacy loss levels of e = 5 and e = 2, respectively.",
        "references": [
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "51b4bde0f3e381ae75dee5e41a43a32c71c61f71",
            "dc289b7889bd48962e5ab8e07981491056755ad7",
            "07d3dddb363870cfd980ca8d748c8b1418aad863",
            "44a97f4eaaefaf5338f8aed2913d5debb2459f7e",
            "8112972b8a6e0c7f9443dbcdfb4ed65c7484f8c2",
            "d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "a5e42129623f41c9f1657217e2b2c90da6c0eb4d",
            "530a4ab0308bc98995ffd64207135ca0ae36db7f"
        ],
        "related_topics": [
            "Deep Neural Networks",
            "Classification Accuracy",
            "Privacy Breach",
            "Convolutional Neural Network"
        ],
        "reference_count": "22",
        "citation_count": "20"
    },
    {
        "Id": "1206ccdce4f721462b5e185c9b2414b5f8f13116",
        "title": "Efficient Acceleration of Deep Learning Inference on Resource-Constrained Edge Devices: A Review",
        "authors": [
            "Md. Maruf Hossain Shuvo",
            "Syed Kamrul Islam",
            "Jianlin Cheng",
            "Bashir I. Morshed"
        ],
        "date": "1 January 2023",
        "abstract": "This article focuses on surveying each of the four research directions, providing a comprehensive review of the state-of-the-art tools and techniques for efficient edge inference of deep neural networks. Successful integration of deep neural networks (DNNs) or deep learning (DL) has resulted in breakthroughs in many areas. However, deploying these highly accurate models for data-driven, learned, automatic, and practical machine learning (ML) solutions to end-user applications remains challenging. DL algorithms are often computationally expensive, power-hungry, and require large memory to process complex and iterative operations of millions of parameters. Hence, training and inference of DL models are typically performed on high-performance computing (HPC) clusters in the cloud. Data transmission to the cloud results in high latency, round-trip delay, security and privacy concerns, and the inability of real-time decisions. Thus, processing on edge devices can significantly reduce cloud transmission cost. Edge devices are end devices closest to the user, such as mobile phones, cyber\u2013physical systems (CPSs), wearables, the Internet of Things (IoT), embedded and autonomous systems, and intelligent sensors. These devices have limited memory, computing resources, and power-handling capability. Therefore, optimization techniques at both the hardware and software levels have been developed to handle the DL deployment efficiently on the edge. Understanding the existing research, challenges, and opportunities is fundamental to leveraging the next generation of edge devices with artificial intelligence (AI) capability. Mainly, four research directions have been pursued for efficient DL inference on edge devices: 1) novel DL architecture and algorithm design; 2) optimization of existing DL methods; 3) development of algorithm\u2013hardware codesign; and 4) efficient accelerator design for DL deployment. This article focuses on surveying each of the four research directions, providing a comprehensive review of the state-of-the-art tools and techniques for efficient edge inference.",
        "references": [
            "e34825220509aa620fcee5d467ae599522747a67",
            "cdfc1f79656bb430e24326f89374952203cd0699",
            "e403972034de384a438e737a1b657de8d0de2500",
            "4f2d4e821dd03ac5df7d5448948bc738aefdd6db",
            "c76559037bdafef208da9e3fc38eb68a08cdfa2f",
            "a3b4ffd121b0a3728d1cdea031fc9f9faa7fa343",
            "4b8af3cbf35818d4ae78facf00e717201037c314",
            "496fa8e62f444c62a1e37b5f8fe3225a12fbf136",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "6caa5095983777c42eea0163e155425e24ff4166"
        ],
        "related_topics": [
            "Inference",
            "Deep Learning",
            "Artificial Intelligence",
            "Accelerator Design",
            "Machine Learning",
            "Hardware Performance Counters",
            "Cyber Physical Systems",
            "Introduction Internet"
        ],
        "reference_count": "401",
        "citation_count": "15"
    },
    {
        "Id": "f82daa97825ddf8c9021099e37b949910218755c",
        "title": "Abnormal Behavior Detection in Crowded Scenes Using Density Heatmaps and Optical Flow",
        "authors": [
            "Lazaros Lazaridis",
            "Anastasios Dimou",
            "Petros Daras"
        ],
        "date": "1 September 2018",
        "abstract": "A new synthetic dataset has been created using the Grand Theft Auto V engine which offers highly detailed simulated crowd abnormal behaviors and a two-stream network is proposed that uses crowd density heat-maps and optical flow information to classify abnormal events. Crowd behavior analysis is an arduous task due to scale, light and crowd density variations. This paper aims to develop a new method that can precisely detect and classify abnormal behavior in dense crowds. A two-stream network is proposed that uses crowd density heat-maps and optical flow information to classify abnormal events. Work on this network has highlighted the lack of large scale relevant datasets due to the fact that dealing and annotating such kind of data is a highly time consuming and demanding task. Therefore, a new synthetic dataset has been created using the Grand Theft Auto V engine which offers highly detailed simulated crowd abnormal behaviors.",
        "references": [
            "c626a9d75dfd73e26cf30793d5ef71527cd9fa95",
            "2fca18207fc35c32da45e0ae0f6786406abb86a7",
            "e6761ec9557f3b231688d3c491f1104cc0eeb2b0",
            "c3113eaad326a955ba96c11b7b65d0c065fb2054",
            "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf",
            "e4ea1ab19747986cc93a676734dab84cedaee4b0",
            "5194cbd51f9769ab25260446b4fa17204752e799",
            "869b17632ed4f19f93b3b58dcaa9f0b8e92108f3",
            "a605a375d0803794adee9eac225011d294dfbada",
            "2dc3b3eff8ded8914c8b536d05ee713ff0cdf3cd"
        ],
        "related_topics": [
            "Two Stream Networks",
            "Dense Crowds",
            "Crowded Scenes",
            "Optical Flow",
            "Crowd Behavior Analysis",
            "Abnormal Event",
            "Crowd Density"
        ],
        "reference_count": "20",
        "citation_count": "22"
    },
    {
        "Id": "9bd3b15944ac28aa7021db126e4344a478bdabf4",
        "title": "Crowd-11: A Dataset for Fine Grained Crowd Behaviour Analysis",
        "authors": [
            "Camille Dupont",
            "Luis Tobias",
            "Bertrand Luvison"
        ],
        "date": "1 July 2017",
        "abstract": "A new deep architecture for crowd characterisation is presented and its application in the context of anomaly classification is demonstrated and expected to be useful in multiple crowd analysis circumstances. Crowd behaviour analysis is a challenging task in computer vision, mainly due to the high complexity of the interactions between groups and individuals. This task is particularly crucial given the magnitude of manual monitoring required for effective crowd management. Within this context, a key challenge is to conceive a highly generic, fine and context-independent characterisation of crowd behaviours. Since current datasets answer only partially to this problem, a new dataset is generated, with a total of 11 crowd motion patterns and over 6000 video clips with an average length of 100 frames per sequence. We establish the first baseline of crowd characterisation with an extensive evaluation on shallow and deep methods. This characterisation is expected to be useful in multiple crowd analysis circumstances, we present a new deep architecture for crowd characterisation and demonstrate its application in the context of anomaly classification.",
        "references": [
            "c626a9d75dfd73e26cf30793d5ef71527cd9fa95",
            "902794cdcc6d908a2955f4c7361a881fa76afc98",
            "b0e52226bc29275698f35283060a97689b373490",
            "f8215adca01bc207147085c6091ff7901fab26a5",
            "93ec356c56b3d84fc994a504a6781145d6b68299",
            "fbc57dd944859ef12c3a244d87235b75b2f6c0db",
            "9bf61fba36d6255e3bc226894a255018c1d57963",
            "2dc3b3eff8ded8914c8b536d05ee713ff0cdf3cd",
            "295895e5bd013c33ef0a62b89d41397e3238d8fa",
            "5194cbd51f9769ab25260446b4fa17204752e799"
        ],
        "related_topics": [
            "Crowd Behaviour Analysis",
            "Crowd Motion Patterns",
            "Deep Architectures",
            "Computer Vision"
        ],
        "reference_count": "23",
        "citation_count": "24"
    },
    {
        "Id": "34424e701824a70d7be5d668f3de06b809b3fe99",
        "title": "Deep Learning-Based Crowd Scene Analysis Survey",
        "authors": [
            "Sherif Elbishlawi",
            "Mohamed H. Abdelpakey",
            "Agwad Eltantawy",
            "Mohamed S. Shehata",
            "Mostafa M. Mohamed"
        ],
        "date": "1 September 2020",
        "abstract": "This paper surveys deep learning-based methods for analyzing crowded scenes and proposes an evaluation metric for crowd scene analysis methods, which estimates the difference between calculated crowed count and actual count in crowd scene videos. Recently, our world witnessed major events that attracted a lot of attention towards the importance of automatic crowd scene analysis. For example, the COVID-19 breakout and public events require an automatic system to manage, count, secure, and track a crowd that shares the same area. However, analyzing crowd scenes is very challenging due to heavy occlusion, complex behaviors, and posture changes. This paper surveys deep learning-based methods for analyzing crowded scenes. The reviewed methods are categorized as (1) crowd counting and (2) crowd actions recognition. Moreover, crowd scene datasets are surveyed. In additional to the above surveys, this paper proposes an evaluation metric for crowd scene analysis methods. This metric estimates the difference between calculated crowed count and actual count in crowd scene videos.",
        "references": [
            "b0e52226bc29275698f35283060a97689b373490",
            "0d9d1c34852a2eb059feffa81a6fa77e5db23606",
            "469c66794a24a3687a3e5cfb18216f6a3acebc09",
            "9adcf858bda2991627951b68b75c99fc1ebd0f76",
            "d3c938b9982c0ced2fc6048fe8d2a46b24c4ced0",
            "133d9795a89a681c9f6db6a0244e8975992d968a",
            "b448d0d86de2c3cb727bb8823b388c650425a74b",
            "834e738ade61dbf19bf8a7059921da345e9d5529",
            "689cc4baa26acf0499983dfaca120f60c99c0126",
            "1cb1bfd9af5bda1f712605695e47d37c03522652"
        ],
        "related_topics": [
            "Deep Learning",
            "Crowd Scenes Analysis",
            "Crowd Counting"
        ],
        "reference_count": "103",
        "citation_count": "21"
    },
    {
        "Id": "50a58e66397b3f22955915d16bacf151fbb532f8",
        "title": "Fast but Not Deep: Efficient Crowd Abnormality Detection with Local Binary Tracklets",
        "authors": [
            "Mahdyar Ravanbakhsh",
            "Hossein Mousavi",
            "Moin Nabi",
            "Lucio Marcenaro",
            "Carlo S. Regazzoni"
        ],
        "date": "1 November 2018",
        "abstract": "A simple yet effective descriptor based on binary tracklets, containing both orientation and magnitude information in a single feature is proposed, which is competitive with the state-of-the-art methods in abnormality detection. In this paper, an efficient method for crowd abnormal behavior detection and localization is introduced. Despite the significant improvements of deep-learning-based methods in this field, but still, they are not fully applicable for the real-time applications. We propose a simple yet effective descriptor based on binary tracklets, containing both orientation and magnitude information in a single feature. The results of the proposed method are comparable with deep-based methods while it performs more efficiently. The evaluation of our descriptors on three different datasets yields a promising result in abnormality detection, which is competitive with the state-of-the-art methods.",
        "references": [
            "0b573c51f04ae5c1bdd0e7e3bf85c69ec62b7649",
            "655b1f83ef218ee6a030b5541d2865bc6599e6d9",
            "84af83ff6412a756df58b6436f0d2e3c049e1f12",
            "7d8755284169f6f721e046798df1eeb1170ebdd0",
            "fd52349a019d928cd9b09c2f6a8a689f174bbbf2",
            "79dbcf5f44563d27490a63c7e5b9bb5bc57fa718",
            "9d5290fadb7625862a966e0330bd0f9e111fc99d",
            "e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "9d3f0d47449c7db37d1bae3b70db2928610a8db7",
            "c626a9d75dfd73e26cf30793d5ef71527cd9fa95"
        ],
        "related_topics": [
            "Descriptor",
            "Crowd Abnormality Detection"
        ],
        "reference_count": "40",
        "citation_count": "5"
    },
    {
        "Id": "61aab7c7e3725b7af13649be2fdec2e0ba54bb78",
        "title": "Video based human crowd analysis using machine learning: a survey",
        "authors": [
            "Deevesh Chaudhary",
            "Sunil Kumar",
            "Vijaypal Singh Dhaka"
        ],
        "date": "15 October 2021",
        "abstract": "This article aims to provide a comprehensive overview of the research from different aspects of crowd analysis like crowd count, human detection, anomaly detection, human behaviour, the importance of crowdAnalysis, and recent developments in this field. ABSTRACT World population has increased manifolds in the last ten years. With the increase in population at this alarming rate, studying and understanding crowd patterns and their collective behaviour is very important. Researchers from various domains like artificial intelligence, machine learning, social science have shown their interest in understanding crowd phenomena from the social, psychological, and technical points of view. Computer vision techniques play a vital role in developing methods that help in understanding and analysing crowd behaviour automatically. In this article, we have surveyed many models related to crowd analysis developed and employed in computer vision. We aim to provide a comprehensive overview of the research from different aspects of crowd analysis like crowd count, human detection, anomaly detection, human behaviour, the importance of crowd analysis, and recent developments in this field. Major contributions have been included, along with their strengths and limitations.",
        "references": [
            "e65ec773059770c45da16bb9ce638d24870b1adf",
            "902794cdcc6d908a2955f4c7361a881fa76afc98",
            "5b95d0b8838979fea86552593c0b447b735ad54a",
            "f34df8090f6a24b37ee1bda15d743502ff03edab",
            "c3113eaad326a955ba96c11b7b65d0c065fb2054",
            "6655aebc1ba3e0fada0a05069e84548deee50e7e",
            "c2f3b51776f174100efdd21ba8f02c906bfdf4e8",
            "2bf53442826052dcf1f3e8f2b231eaf164ddfe3c",
            "c626a9d75dfd73e26cf30793d5ef71527cd9fa95",
            "469c66794a24a3687a3e5cfb18216f6a3acebc09"
        ],
        "related_topics": [
            "Crowd Analysis",
            "Machine Learning",
            "Artificial Intelligence",
            "Crowd Count",
            "Video-Based",
            "Anomaly Detection",
            "Human Detection"
        ],
        "reference_count": "127",
        "citation_count": "9"
    },
    {
        "Id": "9fb7a23910f6464902f1b653025f3aeaa20b90dd",
        "title": "CNN-Based cascaded multi-task learning of high-level prior and density estimation for crowd counting",
        "authors": [
            "Vishwanath A. Sindagi",
            "Vishal M. Patel"
        ],
        "date": "30 July 2017",
        "abstract": "A novel end-to-end cascaded network of CNNs to jointly learn crowd count classification and density map estimation achieves lower count error and better quality density maps as compared to the recent state-of-the-art methods. Estimating crowd count in densely crowded scenes is an extremely challenging task due to non-uniform scale variations. In this paper, we propose a novel end-to-end cascaded network of CNNs to jointly learn crowd count classification and density map estimation. Classifying crowd count into various groups is tantamount to coarsely estimating the total count in the image thereby incorporating a high-level prior into the density estimation network. This enables the layers in the network to learn globally relevant discriminative features which aid in estimating highly refined density maps with lower count error. The joint training is performed in an end-to-end fashion. Extensive experiments on highly challenging publicly available datasets show that the proposed method achieves lower count error and better quality density maps as compared to the recent state-of-the-art methods.",
        "references": [
            "834e738ade61dbf19bf8a7059921da345e9d5529",
            "133d9795a89a681c9f6db6a0244e8975992d968a",
            "2dc3b3eff8ded8914c8b536d05ee713ff0cdf3cd",
            "b0e52226bc29275698f35283060a97689b373490",
            "0d9d1c34852a2eb059feffa81a6fa77e5db23606",
            "2e6c3557cb90f472e6798fcaa8ecc9dff3557f11",
            "8b793918bdf8e20e218d64cbe9f1657b47bb9ac0",
            "dce3ad443e524afc291d43d72892ca6724e925c5",
            "806d7b97c3535a3c62ce243fe7008149062d14c1",
            "bf63599a05692ba4c18476f696edf98bc28a4f3d"
        ],
        "related_topics": [
            "Crowd Count",
            "Density Map Estimation",
            "Crowd Counting",
            "Density Maps",
            "High-level Priors",
            "Count Error",
            "Global Count",
            "Pixel-wise Euclidean Loss",
            "Scale-aware Counting Model",
            "Hydra CNN"
        ],
        "reference_count": "33",
        "citation_count": "461"
    },
    {
        "Id": "17d7b36443d46667a48173dcd50cbd44f2389826",
        "title": "Audio-visual Representation Learning for Anomaly Events Detection in Crowds",
        "authors": [
            "Junyu Gao",
            "Maoguo Gong",
            "Xuelong Li"
        ],
        "date": "28 October 2021",
        "abstract": "This paper designs a two-branch network to model different types of information for modeling the audio and visual signals simultaneously, and finds introducing audio signals effectively improves the performance of anomaly events detection and outperforms other state-of-the-art methods. In recent years, anomaly events detection in crowd scenes attracts many researchers' attention, because of its importance to public safety. Existing methods usually exploit visual information to analyze whether any abnormal events have occurred due to only visual sensors are generally equipped in public places. However, when an abnormal event in crowds occurs, sound information may be discriminative to assist the crowd analysis system to determine whether there is an abnormality. Compare with vision information that is easily occluded, audio signals have a certain degree of penetration. Thus, this paper attempt to exploit multi-modal learning for modeling the audio and visual signals simultaneously. To be specific, we design a two-branch network to model different types of information. The first is a typical 3D CNN model to extract temporal appearance features from video clips. The second is an audio CNN for encoding Log Mel-Spectrogram of audio signals. Finally, by fusing the above features, a more accurate prediction will be produced. We conduct the experiments on SHADE dataset, a synthetic audio-visual dataset in surveillance scenes, and find introducing audio signals effectively improves the performance of anomaly events detection and outperforms other state-of-the-art methods. Furthermore, we will release the code and the pre-trained models as soon as possible.",
        "references": [
            "bd0438b43d63605356bf5bcfedb8bd1e99803cdc",
            "96ed8ce9ef9fc475db9e02c79f984dc110409b62",
            "c4f7596a75ca5dc433ebe66e402d9ff02e557360",
            "9838ba7a31a096503def7b69bf48e5d327f95caa",
            "8abc9fc312fc6916725ec94816ab26c582cf1a90",
            "20cd83f486dca9e5da8ad27742cf4110f997a276",
            "05c846b122dc64b6900c09b9210912615a3febb6",
            "046111bd2dfc057182e0b995110a5705b572c819",
            "410ad524c2d9b0f833e2aee87a35dc2efc9c8b01",
            "fdb97f104c3ba32fcd409c07922c3e83d70721b4"
        ],
        "related_topics": [
            "Audio-Visual Representation",
            "Pre-trained Models",
            "3D CNN Model",
            "Crowd Scene",
            "Log Mel Spectrogram",
            "Abnormal Event",
            "Temporal Appearance Features"
        ],
        "reference_count": "56",
        "citation_count": "4"
    },
    {
        "Id": "791ddd71237e7bfa648ecc69bb778e3e5f2912d6",
        "title": "A survey on deep learning-based real-time crowd anomaly detection for secure distributed video surveillance",
        "authors": [
            "Khosro Rezaee",
            "Sara Mohammad Rezakhani",
            "Mohammad Reza Khosravi",
            "Mohammad Kazem Moghimi"
        ],
        "date": "25 June 2021",
        "abstract": "This paper addresses various automatic and real-time surveillance methods for abnormal event detection to recognize the dynamic crowd behavior in security applications and broadly classified methods into different categories such as tracking, classification based on handcrafted extracted features, classificationbased on deep learning, and hybrid approaches. Fast and automated recognizing of abnormal behaviors in crowded scenes is significantly effective in increasing public security. The traditional procedure of recognizing abnormalities in the Web of Thing (WoT) platform comprises monitoring the activities and describing the crowd properties such as density, trajectory, and motion pattern from the visual frames. Accordingly, incorporating real-time security monitoring based on the WoT platform and machine learning algorithms would significantly enhance the influential detection of abnormal behaviors in the crowds. This paper addresses various automatic and real-time surveillance methods for abnormal event detection to recognize the dynamic crowd behavior in security applications. The critical aspect of security and protection of public places is that we cannot manually monitor the unpredictable and complex crowded environments. The abnormal behavior algorithms have attempted to improve efficiency, robustness against pixel occlusion, generalizability, computational complexity, and execution time. Similar to the state-of-the-art abnormal behavior detection of crowded scenes, we broadly classified methods into different categories such as tracking, classification based on handcrafted extracted features, classification based on deep learning, and hybrid approaches. Hybrid and deep learning methods have been found to have more satisfactory results in the classification stage. A set of video frames called Motion Emotion Dataset (MED) is employed in this study to examine the various conditions governing these methods. Incorporating an appropriate real-time approach with considering WoT platform can facilitate the analysis of crowd and individuals\u2019 behavior for security screening of abnormal events.",
        "references": [
            "08a9a1a52ff8744b4bec371c71d23d86c223a803",
            "2b5bc76044e5c36c1911fc14c73f2618ccdb97d9",
            "e6761ec9557f3b231688d3c491f1104cc0eeb2b0",
            "fb9da8a0472ac28e6ba8523e40d2ab1a789270e7",
            "6a4798af7b36241f6d3a7ce96f81540c11a8bea5",
            "13ae3c8afef5a0d6f4c9e684da9fc1fa96caaeb6",
            "cfb155b50fb6ff284edce9705c7685fc945297f3",
            "9777438d4645aa64b2ff41f249e0daf2939b43bc",
            "2e9aaead4d9080ac9ae989d4a05a785992254a63",
            "3f307cc13a5ccfe9ffe1a81ee23325786f6a7987"
        ],
        "related_topics": [
            "Web Of Things",
            "Deep Learning",
            "Classification",
            "Crowded Scenes",
            "Abnormal Event Detection",
            "Crowd Anomaly Detection",
            "Motion Emotion Dataset",
            "Abnormal Event",
            "Computational Complexity",
            "Multimedia Event Detection"
        ],
        "reference_count": "120",
        "citation_count": "50"
    },
    {
        "Id": "454cf822c52909e3662f50ef4c0b3b1a717a0e3f",
        "title": "A Novel Deep Architecture for Multi-Task Crowd Analysis",
        "authors": [
            "Santosh Kumar Tripathy",
            "Rajeev Srivastava"
        ],
        "date": "8 July 2022",
        "abstract": "This paper created a multitask crowd analysis dataset using two publicly available crowd behavior datasets (MED, GTA) and proposed a novel deep architecture for multitasking crowd analysis, which is compared with state-of-the-art and shown its effectiveness in multitaskingrowd analysis. Recently, crowd analysis has become an essential tool for crowd disaster management. The crowd analysis is not a single task but is a collective implication of several related tasks like crowd behavior analysis, crowd counting, and crowd flow analysis. Although different models for individual tasks have been proposed in the literature, there is a lack of a multitasking framework for crowd analysis. One of the main reasons could be the availability of the multitasking crowd analysis dataset. To this end, this paper created a multitask crowd analysis dataset using two publicly available crowd behavior datasets (MED, GTA) and proposed a novel deep architecture for multitasking crowd analysis. Two different crowd analysis tasks are considered, i.e., crowd behavior (normal and panic) and crowd counting. Around 89,000 frames were annotated for obtaining ground-truth crowd counts. In addition to this, a two-stage learning mechanism is proposed. In the first stage, a novel deep model is proposed that extracts high-level spatial-temporal features from the multiscale low-level spatial-temporal features and is used to learn normal crowd behavior and counting. The second stage utilized the features of the deep model and inputted them to the one-class support vector machine (OC-SVM) for crowd panic detection. The obtained results are compared with state-of-the-art and show its effectiveness in multitasking crowd analysis.",
        "references": [
            "249f619f9c4825baa1b9293437abbe95212e400e",
            "a273473c09e386ed9ae3e96721eec8181f768ade",
            "44fc28a4c9c45310fd58f5dd652211f9de7e6247",
            "6fc8c988dd841c6c4f5e96b1b1458b6aa564b2de",
            "e7f7d48256f16fee592b78697f98bdab316d8fcc",
            "5302596bc8c84584a3531f2048bd7bf8e9507042",
            "ab0e780cfd103e0e5f1622e1e67e4baa57d6ed6e",
            "c626a9d75dfd73e26cf30793d5ef71527cd9fa95",
            "39539e9f0a99475ed8f5f3b788a406c4e34c2be6",
            "95ea860b34ec30933ce9864bc29721e265f80c85"
        ],
        "related_topics": [],
        "reference_count": "39",
        "citation_count": "2"
    },
    {
        "Id": "0b573c51f04ae5c1bdd0e7e3bf85c69ec62b7649",
        "title": "Detection and localization of crowd behavior using a novel tracklet-based model",
        "authors": [
            "Hamid R. Rabiee",
            "Hossein Mousavi",
            "Moin Nabi",
            "Mahdyar Ravanbakhsh"
        ],
        "date": "1 December 2018",
        "abstract": "This paper proposes a second framework which is able to localize the abnormal behavior areas in video sequences and employs a novel simplified Histogram of Oriented Tracklets (sHOT), which is shown to be very effective in the task of crowd abnormal behavior detection. In this paper, two novel descriptors are introduced to detect and localize abnormal behaviors in crowded scenes. The first proposed descriptor is based on the orientation and magnitude of short trajectories extracted by tracking interest points in spatio-temporal 3D patches. The proposed descriptor employs a novel simplified Histogram of Oriented Tracklets (sHOT), which is shown to be very effective in the task of crowd abnormal behavior detection. In this scheme, abnormal behaviors are detected at different levels, namely spatio-temporal level and frame level. By combining the first proposed descriptor and the dense optical flow model, we propose our second framework which is able to localize the abnormal behavior areas in video sequences. The evaluation of our simple but yet effective descriptors on different state-of-the-art datasets, namely UCSD, UMN and Violence in Crowds yields very promising results in abnormality detection and outperforming different former state-of-the-art descriptors.",
        "references": [
            "655b1f83ef218ee6a030b5541d2865bc6599e6d9",
            "84af83ff6412a756df58b6436f0d2e3c049e1f12",
            "27839232387db332bdc9024d014a6d1bc47c35eb",
            "851ff5f13fbff7023717c3913f2df4a7551a374a",
            "aae932cf9c2434f52b03991fcab050a61a960d48",
            "e6761ec9557f3b231688d3c491f1104cc0eeb2b0",
            "dc63e89e014beabe084c1dc72838c473d8c7ccfe",
            "9d3f0d47449c7db37d1bae3b70db2928610a8db7",
            "aba7b76c300db4159592ee2933d8796176d1e737",
            "7d8755284169f6f721e046798df1eeb1170ebdd0"
        ],
        "related_topics": [
            "Descriptor",
            "Localize",
            "Crowded Scenes",
            "Interest Points",
            "University Of California At San Diego",
            "Violence In Crowds"
        ],
        "reference_count": "50",
        "citation_count": "37"
    },
    {
        "Id": "0a6935a89fc51bb0a9085a58de387226287bd8d3",
        "title": "DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for deep neural networks",
        "authors": [
            "Abhishek Singh",
            "Ayush Chopra",
            "Vivek Sharma",
            "Ethan Garza",
            "Emily Zhang",
            "Praneeth Vepakomma",
            "Ramesh Raskar"
        ],
        "date": "20 December 2020",
        "abstract": "This work proposes DISCO which learns a dynamic and data driven pruning filter to selectively obfuscate sensitive information in the feature space and demonstrates the effectiveness of DISCO against state-of-the-art methods through quantitative and qualitative evaluation. Recent deep learning models have shown remarkable performance in image classification. While these deep learning systems are getting closer to practical deployment, the common assumption made about data is that it does not carry any sensitive information. This assumption may not hold for many practical cases, especially in the domain where an individual\u2019s personal information is involved, like healthcare and facial recognition systems. We posit that selectively removing features in this latent space can protect the sensitive information and provide better privacy-utility trade-off. Consequently, we propose DISCO which learns a dynamic and data driven pruning filter to selectively obfuscate sensitive information in the feature space. We propose diverse attack schemes for sensitive inputs & attributes and demonstrate the effectiveness of DISCO against state-of-the-art methods through quantitative and qualitative evaluation. Finally, we also release an evaluation benchmark dataset of 1 million sensitive representations to encourage rigorous exploration of novel attack and defense schemes at https://github.com/splitlearning/InferenceBenchmark.",
        "references": [
            "1d4f087217b816691254ef0d4377094ce16eea95",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "fa52f9f38259169cf4eff707eaa4552854621cc6",
            "d1b9a3b11e6c9571a1553556f82b605b2b4baec3",
            "3abd7683ed510ca46fcdfca47ab4ae2c01e0f864",
            "844f549adcf158883e06cd04a70c48cba18c8584",
            "d7738ddffa74ae9194911c05ab8bf19a5b5b8308",
            "542fcc66539ea974f15e22401075742afa684b15",
            "17d50efa0d5ad863f5939eb586bb0a5436b0adf7",
            "d5629135ec1f29c6dc1ffd5cc5a65fe67445eee0"
        ],
        "related_topics": [
            "Sensitive Information",
            "Deep Learning",
            "Pruning Filters",
            "Latent Space"
        ],
        "reference_count": "68",
        "citation_count": "23"
    },
    {
        "Id": "187e13df657c67e9d2287959ee39835f70331b1a",
        "title": "Privacy-Preserving Image Template Sharing Using Contrastive Learning",
        "authors": [
            "Shideh Rezaeifar",
            "Slava Voloshynovskiy",
            "Meisam Asgari Jirhandeh",
            "Vitaliy Kinakh"
        ],
        "date": "1 May 2022",
        "abstract": "In both frameworks, an encoder is trained with contrastive loss, providing a superior utility-privacy trade-off, and an obfuscator module is trained in an adversarial manner to preserve the privacy of sensitive attributes while maintaining the classification performance on the target attribute. With the recent developments of Machine Learning as a Service (MLaaS), various privacy concerns have been raised. Having access to the user\u2019s data, an adversary can design attacks with different objectives, namely, reconstruction or attribute inference attacks. In this paper, we propose two different training frameworks for an image classification task while preserving user data privacy against the two aforementioned attacks. In both frameworks, an encoder is trained with contrastive loss, providing a superior utility-privacy trade-off. In the reconstruction attack scenario, a supervised contrastive loss was employed to provide maximal discrimination for the targeted classification task. The encoded features are further perturbed using the obfuscator module to remove all redundant information. Moreover, the obfuscator module is jointly trained with a classifier to minimize the correlation between private feature representation and original data while retaining the model utility for the classification. For the attribute inference attack, we aim to provide a representation of data that is independent of the sensitive attribute. Therefore, the encoder is trained with supervised and private contrastive loss. Furthermore, an obfuscator module is trained in an adversarial manner to preserve the privacy of sensitive attributes while maintaining the classification performance on the target attribute. The reported results on the CelebA dataset validate the effectiveness of the proposed frameworks.",
        "references": [
            "a21ea13836b63ac9e6caa01ab0a001eafc608e24",
            "1dd1fa8eca97f65de0db6dd8d248fd40737fed8f",
            "7351ac6dabf267f708b3a638765825effb9cb1ee",
            "15b044b83323bba5d5bb94c16c6661f224d79e8d",
            "0a6278324c6216a789ed0ccd8ee055c612607db3",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "09feef8eec4b39da44aa9d33f723a8651d4fa647",
            "1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211",
            "b7b6437f883148ef56351d8b68466650e3b9f4d5",
            "a81f1abc25596361a0583617b4da784f4b559e9c"
        ],
        "related_topics": [
            "Sensitive Attributes",
            "Contrastive Loss",
            "Model Utility",
            "Attribute Inference Attacks",
            "Classifier",
            "Adversary",
            "Supervised Contrastive Loss",
            "Contrastive Learning",
            "Machine Learning As A Service",
            "Image Classification Task"
        ],
        "reference_count": "36",
        "citation_count": "3"
    },
    {
        "Id": "fa52f9f38259169cf4eff707eaa4552854621cc6",
        "title": "DeepObfuscator: Adversarial Training Framework for Privacy-Preserving Image Classification",
        "authors": [
            "Ang Li",
            "Jiayi Guo",
            "Huanrui Yang",
            "Yiran Chen"
        ],
        "date": "9 September 2019",
        "abstract": "An adversarial training framework DeepObfuscator is proposed that can prevent extracted features from being utilized to reconstruct raw images and infer private attributes, while retaining the useful information for the intended cloud service (i.e., image classification). Deep learning has been widely utilized in many computer vision applications and achieved remarkable commercial success. However, running deep learning models on mobile devices is generally challenging due to limitation of the available computing resources. It is common to let the users send their service requests to cloud servers that run the large-scale deep learning models to process. Sending the data associated with the service requests to the cloud, however, impose risks on the user data privacy. Some prior arts proposed sending the features extracted from raw data (e.g., images) to the cloud. Unfortunately, these extracted features can still be exploited by attackers to recover raw images and to infer embedded private attributes (e.g., age, gender, etc.). In this paper, we propose an adversarial training framework DeepObfuscator that can prevent extracted features from being utilized to reconstruct raw images and infer private attributes, while retaining the useful information for the intended cloud service (i.e., image classification). DeepObfuscator includes a learnable encoder, namely, obfuscator that is designed to hide privacy-related sensitive information from the features by performingour proposed adversarial training algorithm. Our experiments on CelebAdataset show that the quality of the reconstructed images fromthe obfuscated features of the raw image is dramatically decreased from 0.9458 to 0.3175 in terms of multi-scale structural similarity (MS-SSIM). The person in the reconstructed image, hence, becomes hardly to be re-identified. The classification accuracy of the inferred private attributes that can be achieved by the attacker drops down to a random-guessing level, e.g., the accuracy of gender is reduced from 97.36% to 58.85%. As a comparison, the accuracy of the intended classification tasks performed via the cloud service drops by only 2%",
        "references": [
            "8c2d2b5bb781254a45265bc636b3f24a2fac4126",
            "8974968bdd99f5ca4755a501c577e1416fc3224a",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "6cefb70f4668ee6c0bf0c18ea36fd49dd60e8365",
            "845865040cda3851459a1ed92eb58ca9ad484f06",
            "80379210f59298fb65f1c49014338143b04d735f",
            "6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4",
            "f393c5a809fac223461e764495d933c7f18e6ec0",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "eb42cf88027de515750f230b23b1a057dc782108"
        ],
        "related_topics": [
            "DeepObfuscator",
            "Deep Learning",
            "Private Attributes",
            "MULTI-SCALE STRUCTURAL SIMILARITY",
            "Privacy-preserving Image Classification",
            "Computer Vision",
            "Adversarial Training",
            "MS-SSIM",
            "Classification Accuracy"
        ],
        "reference_count": "22",
        "citation_count": "39"
    },
    {
        "Id": "245093f0ec61b9c18e68dd4b1f0a492239b31c1b",
        "title": "Feature Maps Image Classification With Obfuscator : Privacy Attack : Step 1 : Adversarial Training Step 2 : Users",
        "authors": [
            ""
        ],
        "date": "2018",
        "abstract": "Through extensive evaluations on real world datasets, both the numerical metrics and the visualization results demonstrate that the proposed privacy-preserving deep learning framework is qualified to protect users\u2019 privacy and achieve a relatively high accuracy on the image classification task. Real world images often contain large amounts of private / sensitive information that should be carefully protected without reducing their utilities. In this paper, we propose a privacy-preserving deep learning framework with a learnable obfuscator for the image classification task. Our framework consists of three models: learnable obfuscator, classifier and reconstructor. The learnable obfuscator is used to remove the sensitive information in the images and extract the feature maps from them. The reconstructor plays the role as an attacker, which tries to recover the image from the feature maps extracted by the obfuscator. In order to best protect users\u2019 privacy in images, we design an adversarial training methodology for our framework to optimize the obfuscator. Through extensive evaluations on real world datasets, both the numerical metrics and the visualization results demonstrate that our framework is qualified to protect users\u2019 privacy and achieve a relatively high accuracy on the image classification task.",
        "references": [
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "0a6278324c6216a789ed0ccd8ee055c612607db3",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "cc89bc832af9b42e9a00a0fafe6a76f3d9ed6209",
            "8acbe90d5b852dadea7810345451a99608ee54c7",
            "eb7ee0bc355652654990bcf9f92f124688fde493",
            "6cefb70f4668ee6c0bf0c18ea36fd49dd60e8365",
            "e9a986c8ff6c2f381d026fe014f6aaa865f34da7",
            "01acc57b5d995f313633d65ab57e801cb3d9dc28",
            "3625202d710db29ee117f7502d86901f50f92e1c"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "27"
    },
    {
        "Id": "e0136615f33cb89103f3622acf78e5fef51897f0",
        "title": "Noisy adversarial representation learning for effective and efficient image obfuscation",
        "authors": [
            "Jong Myoon Jeong",
            "Minyong Cho",
            "Philipp Benz",
            "Tae-Hoon Kim"
        ],
        "date": "2023",
        "abstract": "An effective and ef-\ufb01cient ARL method that incorporates feature noise into the ARL pipeline that achieves better accuracy, lower computation and memory overheads, and improved resistance to information leakage and reconstruction attacks is proposed. Recent real-world applications of deep learning have led to the development of machine learning as a service (MLaaS). However, the scenario of client-server inference presents privacy concerns, where the server processes raw data sent from the user\u2019s client device. One solution to this issue is to provide an obfuscator function to the client device using Adversarial Representation Learning (ARL). Prior works have primarily focused on the privacy-utility trade-off while overlooking the computational cost and memory burden on the client side. In this paper, we propose an effective and ef-\ufb01cient ARL method that incorporates feature noise into the ARL pipeline. We evaluated our approach on various datasets, comparing it with state-of-the-art ARL techniques. Our experimental results indicate that our method achieves better accuracy, lower computation and memory overheads, and improved resistance to information leakage and reconstruction attacks.",
        "references": [
            "1dd1fa8eca97f65de0db6dd8d248fd40737fed8f",
            "70edce88f8bfa001f701f8a044e4dc5fe32c1bd5",
            "1d4f087217b816691254ef0d4377094ce16eea95",
            "2669054ca98a34eeaab12e8c1f59ad67122d3e24",
            "a21ea13836b63ac9e6caa01ab0a001eafc608e24",
            "844f549adcf158883e06cd04a70c48cba18c8584",
            "0a6935a89fc51bb0a9085a58de387226287bd8d3",
            "23918ed366c60ae0ef85b0c80def63127f035e02",
            "f856e2cc4bff8f8b8bdb13501b23a91137f62f38",
            "8974968bdd99f5ca4755a501c577e1416fc3224a"
        ],
        "related_topics": [
            "Adversarial Representation Learning",
            "Client Device",
            "Average Run Length",
            "Deep Learning",
            "Feature Noise",
            "Image Obfuscation",
            "Reconstruction Attacks",
            "Computational Cost",
            "Machine Learning As A Service"
        ],
        "reference_count": "0",
        "citation_count": "51"
    },
    {
        "Id": "1dd1fa8eca97f65de0db6dd8d248fd40737fed8f",
        "title": "DeepObfuscator: Obfuscating Intermediate Representations with Privacy-Preserving Adversarial Learning on Smartphones",
        "authors": [
            "Ang Li",
            "Jiayi Guo",
            "Huanrui Yang",
            "Flora Dilys Salim",
            "Yiran Chen"
        ],
        "date": "9 September 2019",
        "abstract": "An adversarial training framework, DeepObfuscator, which prevents the usage of the features for reconstruction of the raw images and inference of private attributes, and includes a learnable encoder that is designed to hide privacy-related sensitive information from the features by performing the proposed adversarialTraining algorithm. Deep learning has been widely applied in many computer vision applications, with remarkable success. However, running deep learning models on mobile devices is generally challenging due to the limitation of computing resources. A popular alternative is to use cloud services to run deep learning models to process raw data. This, however, imposes privacy risks. Some prior arts proposed sending the features extracted from raw data (e.g., images) to the cloud. Unfortunately, these extracted features can still be exploited by attackers to recover raw images and to infer embedded private attributes (e.g., age, gender, etc.). In this paper, we propose an adversarial training framework, DeepObfuscator, which prevents the usage of the features for reconstruction of the raw images and inference of private attributes. This is done while retaining useful information for the intended cloud service (i.e., image classification). DeepObfuscator includes a learnable encoder, namely, obfuscator that is designed to hide privacy-related sensitive information from the features by performing our proposed adversarial training algorithm. The proposed algorithm is designed by simulating the game between an attacker who makes efforts to reconstruct raw image and infer private attributes from the extracted features and a defender who aims to protect user privacy. By deploying the trained obfuscator on the smartphone, features can be locally extracted and then sent to the cloud. Our experiments on CelebA and LFW datasets show that the quality of the reconstructed images from the obfuscated features of the raw image is dramatically decreased from 0.9458 to 0.3175 in terms of multi-scale structural similarity (MS-SSIM). The person in the reconstructed image, hence, becomes hardly to be re-identified. The classification accuracy of the inferred private attributes that can be achieved by the attacker is significantly reduced to a random-guessing level, e.g., the accuracy of gender is reduced from 97.36% to 58.85%. As a comparison, the accuracy of the intended classification tasks performed via the cloud service is only reduced by 2%. We also demonstrate the efficiency of DeepObfuscator, showcasing real-time performance of the deployed models on smartphones.",
        "references": [
            "d3046251ec5d6e7f90ef5ef2b0ac885c01138555",
            "a17b9803d23f8975b74269557eff0892192fd491",
            "554cb0e8a604701ca78f2d782f2a26119eadaa81",
            "7d15a04085a80558f4c6bab25040c987023069c9",
            "67498fdf77fd036a09a4593c37b012d6cf34f3f6",
            "c9b1d5f5c376f35423e0af2be24394cce54b00f4",
            "8974968bdd99f5ca4755a501c577e1416fc3224a",
            "80379210f59298fb65f1c49014338143b04d735f",
            "44058a625cb64c311043145655645d8206e272c2"
        ],
        "related_topics": [
            "DeepObfuscator",
            "Deep Learning",
            "CelebA",
            "MULTI-SCALE STRUCTURAL SIMILARITY",
            "LFW Dataset",
            "Computer Vision",
            "Adversarial Training",
            "Private Attributes",
            "Classification Accuracy"
        ],
        "reference_count": "44",
        "citation_count": "24"
    },
    {
        "Id": "e69895e121de4e7c2812d6a0513decc4ec3525d3",
        "title": "Adjustable Privacy using Autoencoder-based Learning Structure",
        "authors": [
            "Mohammad-ali Jamshidi",
            "Hadi Veisi",
            "Mohammad Mahdi Mojahedian",
            "Mohammad Reza Aref"
        ],
        "date": "7 April 2023",
        "abstract": "By modifying the structure of the autoencoder, this paper presents a method that manages the utility-privacy trade-off well and allows data providers to set the level of privacy required for confidential features. Inference centers need more data to have a more comprehensive and beneficial learning model, and for this purpose, they need to collect data from data providers. On the other hand, data providers are cautious about delivering their datasets to inference centers in terms of privacy considerations. In this paper, by modifying the structure of the autoencoder, we present a method that manages the utility-privacy trade-off well. To be more precise, the data is first compressed using the encoder, then confidential and non-confidential features are separated and uncorrelated using the classifier. The confidential feature is appropriately combined with noise, and the non-confidential feature is enhanced, and at the end, data with the original data format is produced by the decoder. The proposed architecture also allows data providers to set the level of privacy required for confidential features. The proposed method has been examined for both image and categorical databases, and the results show a significant performance improvement compared to previous methods.",
        "references": [
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "acb87cbd31ab90e4aa3e2905ae0477363038e53d",
            "54627c901252cfd8c892551a0e45384fd0d5d9cb",
            "6c564c97a403321de32317d93f047d41578be6e4",
            "e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9",
            "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "080bc0cf4033e779a9fa1a03d16bb488224fb070",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "afa778ba0ba6333e25671cfb691a4bdda13b2868",
            "fa52f9f38259169cf4eff707eaa4552854621cc6"
        ],
        "related_topics": [
            "Autoencoders",
            "Classifier",
            "Categorical Databases",
            "Architecture"
        ],
        "reference_count": "0",
        "citation_count": "45"
    },
    {
        "Id": "4b6a31a92674a7d700c669336295ab8503b01689",
        "title": "Privacy for Rescue: A New Testimony Why Privacy is Vulnerable In Deep Models",
        "authors": [
            "Ruiyuan Gao",
            "Ming Dun",
            "Hailong Yang",
            "Zhongzhi Luan",
            "Depei Qian"
        ],
        "date": "31 December 2019",
        "abstract": "This paper presents a formal definition of the privacy protection problem in the edge-cloud system running DNN models, analyzed the-state-of-the-art methods and point out the drawbacks of their methods, especially the evaluation metrics such as the Mutual Information. The huge computation demand of deep learning models and limited computation resources on the edge devices calls for the cooperation between edge device and cloud service by splitting the deep models into two halves. However, transferring the intermediates results from the partial models between edge device and cloud service makes the user privacy vulnerable since the attacker can intercept the intermediate results and extract privacy information from them. Existing research works rely on metrics that are either impractical or insufficient to measure the effectiveness of privacy protection methods in the above scenario, especially from the aspect of a single user. In this paper, we first present a formal definition of the privacy protection problem in the edge-cloud system running DNN models. Then, we analyze the-state-of-the-art methods and point out the drawbacks of their methods, especially the evaluation metrics such as the Mutual Information (MI). In addition, we perform several experiments to demonstrate that although existing methods perform well under MI, they are not effective enough to protect the privacy of a single user. To address the drawbacks of the evaluation metrics, we propose two new metrics that are more accurate to measure the effectiveness of privacy protection methods. Finally, we highlight several potential research directions to encourage future efforts addressing the privacy protection problem.",
        "references": [
            "23918ed366c60ae0ef85b0c80def63127f035e02",
            "db0cc2f21b20cbc0ab8946090967399c25709614",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "4545f59bf5914695d2742562838ab4b063dc279d",
            "29b14b6f0aee8cb3ea6da4a5b08a21aaa868bba1",
            "c80d112ce59c72f943dc7b3e56e4c77dc3af1146",
            "e62ab6416643e49245f997b203f97e072e053016",
            "52a166a9952c06af044afe4c98475e91ee0ad0a5",
            "267980e417f1d01a897e87fa409f64e2a76b96cd"
        ],
        "related_topics": [
            "Deep Model",
            "Deep Learning",
            "Mutual Information"
        ],
        "reference_count": "25",
        "citation_count": "One"
    },
    {
        "Id": "d2e70c94f7118b4a5762a99bd272db6a5fd71e94",
        "title": "Privacy-Preserving Collaborative Learning Through Feature Extraction",
        "authors": [
            "Alireza Sarmadi",
            "Hao Fu",
            "Prashanth Krishnamurthy",
            "Siddharth Garg",
            "Farshad Khorrami"
        ],
        "date": "13 December 2022",
        "abstract": "This work proposes a framework in which multiple entities collaborate to build a machine learning model while preserving privacy of their data and investigates the trade-offs among SFE, LTFE, and CTFE in regard to performance, privacy leakage, and computational cost. We propose a framework in which multiple entities collaborate to build a machine learning model while preserving privacy of their data. The approach utilizes feature embeddings from shared/per-entity feature extractors transforming data into a feature space for cooperation between entities. We propose two specific methods and compare them with a baseline method. In Shared Feature Extractor (SFE) Learning, the entities use a shared feature extractor to compute feature embeddings of samples. In Locally Trained Feature Extractor (LTFE) Learning, each entity uses a separate feature extractor, and models are trained using concatenated features from all entities. As a baseline, in Cooperatively Trained Feature Extractor (CTFE) Learning, the entities train models by sharing raw data. Secure multi-party algorithms are utilized to train models without revealing data or features in plain text. We investigate the trade-offs among SFE, LTFE, and CTFE in regard to performance, privacy leakage (using an off-the-shelf membership inference attack), and computational cost. LTFE provides the most privacy, followed by SFE, and then CTFE. Computational cost is lowest for SFE and the relative speed of CTFE and LTFE depends on network architecture. CTFE and LTFE provide the best accuracy. We use three different datasets for evaluations.",
        "references": [
            "8b070b70f18b387a64b814e7c237e9b596f2a2d6",
            "33c3f816bde8ee63ee9f2e60d4387b9390696371",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "6556d6399b3a75745537f1d90edf0b53bc1042c0",
            "76c6d39edecdb943ce0f68f5a44e6608db96e383",
            "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
            "8a0d523ea2e0ed8b3b971d2d1f61d838a3b5e713",
            "3947e0bd3eb33b64d3b2b3053d25aaadd19be4fb",
            "e7f146c3a76b3828098e2024f9227eec4afc1505",
            "4bf4b646ec87fa6048d2a563bc22e92030c0b742"
        ],
        "related_topics": [
            "Secure Function Evaluation",
            "Computational Cost",
            "Feature Embeddings",
            "Membership Inference Attack",
            "Machine Learning",
            "Modified National Institute Of Standard And Technology"
        ],
        "reference_count": "69",
        "citation_count": "One"
    },
    {
        "Id": "e3728eedfeaedf27a2dc2e6a5bb9d096a643a41e",
        "title": "Privacy-Preserving Image Acquisition for Neural Vision Systems",
        "authors": [
            "Yamin Sepehri",
            "Pedram Pad",
            "Cl{\\&#x27;e}ment K{\\&quot;u}ndig",
            "Pascal Frossard",
            "L. Andrea Dunbar"
        ],
        "date": "2023",
        "abstract": "A trainable image acquisition method that removes the sensitive information in the optical domain before it reaches the image sensor, making it irretrievable against different privacy attacks in the digital domain and can be used in conjunction with other privacy-preserving techniques in thedigital domain. Preserving privacy is a growing concern in our society where cameras are ubiquitous. In this work, we propose a trainable image acquisition method that removes the sensitive information in the optical domain before it reaches the image sensor. The method benefits from a trainable optical convolution kernel, which transmits the desired information whilst filtering out the sensitive information, making it irretrievable against different privacy attacks in the digital domain. This is in contrast with the current digital privacy-preserving methods that are all vulnerable to direct access attacks. Also, in contrast with most of the previous optical privacy-preserving methods that cannot be trained, our method is data-driven and optimized for the specific application at hand. Moreover, there is no additional computation or power burden on the acquisition system since it works passively in the optical domain and can be even used in conjunction with other privacy-preserving techniques in the digital domain. We demonstrate our new, generic method in several scenarios such as smile or open-mouth detection as the desired attribute while the gender or wearing make-up is filtered out as the sensitive content. Through several experiments, we show that this method is able to reduce around $\\mathbf {65}\\%$ of sensitive content while causing a negligible reduction in the desired information. Moreover, we tested our method by deep reconstruction attack and confirmed the ineffectiveness of this attack to reconstruct the original sensitive content. This new method has different use cases such as feedback systems for smart TV content or outdoor advertising.",
        "references": [
            "d4c5f43f3881661ae40d5ca46cb52cca8d5e19a3",
            "149328470c9a66b9cc6f7f4f4072e99267d28e6b",
            "99024ed1b4ecbd26307faf8b895c9a9e7da798b9",
            "e1dcd7fd049ae2ae3b93295d8ea360cafc00f9da",
            "311ec654129eb2cd16a8e78eca12b0f5046b2c78",
            "219de01358f46f569e122cd6f3639d92be9f9014",
            "3e2224ceb8df1560f0694b89c58d082f5fcd56da",
            "b7b6437f883148ef56351d8b68466650e3b9f4d5",
            "42790203069154a0ed77955a2c5059d972969fd4",
            "6556d6399b3a75745537f1d90edf0b53bc1042c0"
        ],
        "related_topics": [],
        "reference_count": "32",
        "citation_count": "4"
    },
    {
        "Id": "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
        "title": "Spectral\u2013Spatial Classification of Hyperspectral Images With a Superpixel-Based Discriminative Sparse Model",
        "authors": [
            "Leyuan Fang",
            "Shutao Li",
            "Xudong Kang",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "17 February 2015",
        "abstract": "Experimental results on four real HSI datasets demonstrate the superiority of the proposed SBDSM algorithm over several well-known classification approaches in terms of both classification accuracies and computational speed. A novel superpixel-based discriminative sparse model (SBDSM) for spectral-spatial classification of hyperspectral images (HSIs) is proposed. Here, a superpixel in a HSI is considered as a small spatial region whose size and shape can be adaptively adjusted for different spatial structures. In the proposed approach, the SBDSM first clusters the HSI into many superpixels using an efficient oversegmentation method. Then, pixels within each superpixel are jointly represented by a set of common atoms from a dictionary via a joint sparse regularization. The recovered sparse coefficients are utilized to determine the class label of the superpixel. In addition, instead of directly using a large number of sampled pixels as dictionary atoms, the SBDSM applies a discriminative K-SVD learning algorithm to simultaneously train a compact representation dictionary, as well as a discriminative classifier. Furthermore, by utilizing the class label information of training pixels and dictionary atoms, a class-labeled orthogonal matching pursuit is proposed to accelerate the K-SVD algorithm while still enforcing high discriminability on sparse coefficients when training the classifier. Experimental results on four real HSI datasets demonstrate the superiority of the proposed SBDSM algorithm over several well-known classification approaches in terms of both classification accuracies and computational speed.",
        "references": [
            "e860267bdaba7eba2fbfbdbb9974d6fd574d522b",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "a1a183c1e263526465c8d3097d13b3e2be273ea8",
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "b994ba36364e8e61514d1a87002442ce9ab03d33",
            "567ff70b2a580cc04be9c695f8cc5153bf6da758",
            "1301138fd1df0e08c994f9eb6fe41b75fe8b7f06"
        ],
        "related_topics": [
            "Superpixel-based Discriminative Sparse Model",
            "Discriminative Sparse Model",
            "Superpixels",
            "Dictionary",
            "Class Labels",
            "Spectral-Spatial Classification",
            "HSIs",
            "Classification Accuracy"
        ],
        "reference_count": "64",
        "citation_count": "223"
    },
    {
        "Id": "0088d6433a9715b7e74a623920925f2bfb04c920",
        "title": "Probabilistic Fusion of Pixel-Level and Superpixel-Level Hyperspectral Image Classification",
        "authors": [
            "Shutao Li",
            "Ting Lu",
            "Leyuan Fang",
            "Xiuping Jia",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "13 September 2016",
        "abstract": "A novel hyperspectral image (HSI) classification method by the probabilistic fusion of pixel-level and superpixel-level classifiers, to improve the classification performance in both homogenous and structural areas is proposed. A novel hyperspectral image (HSI) classification method by the probabilistic fusion of pixel-level and superpixel-level classifiers is proposed. Generally, pixel-level classifiers based on spectral information only may generate \u201csalt and pepper\u201d result in the classification map since spatial correlation is not considered. By incorporating spatial information in homogeneous regions, the superpixel-level classifiers can effectively eliminate the noisy appearance. However, the classification accuracy will be deteriorated if undersegmentation cannot be fully avoided in superpixel-based approaches. Therefore, it is proposed to adaptively combine both the pixel-level and superpixel-level classifiers, to improve the classification performance in both homogenous and structural areas. In the proposed method, a support vector machine classifier is first applied to estimate the pixel-level class probabilities. Then, superpixel-level class probabilities are estimated based on a joint sparse representation. Finally, the two levels of class probabilities are adaptively combined in a maximum a posteriori estimation model, and the classification map is obtained by solving the maximum optimization problem. Experimental results on real HSI images demonstrate the superiority of the proposed method over several well-known classification approaches in terms of classification accuracy.",
        "references": [
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "d70437950a66ba018a5656f8c35341869417e444",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "fff45cbbb315fffb4c72d8459fcd9fe28a87519c",
            "f1c06eff47412b5b79cdf5afda9312d089a8b74d",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "0e2b808a4be6bafac27a5679043c7710fbe5b4f2",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "5f5aaf6eb86967a67754a1cf6f286d80597e22fd",
            "d37e6317e59911e345bdef50f56998ef5b1c894c"
        ],
        "related_topics": [
            "Classification Accuracy",
            "Classification Map",
            "Pixel Level",
            "Hyperspectral Image Classification",
            "Hyperspectral Imagery"
        ],
        "reference_count": "53",
        "citation_count": "71"
    },
    {
        "Id": "ede30b1b265e62b12410bbf796a23437a64619a6",
        "title": "Task-Driven Dictionary Learning",
        "authors": [
            "Julien Mairal",
            "Francis R. Bach",
            "Jean Ponce"
        ],
        "date": "27 September 2010",
        "abstract": "This paper presents a general formulation for supervised dictionary learning adapted to a wide variety of tasks, and presents an efficient algorithm for solving the corresponding optimization problem. Modeling data with linear combinations of a few elements from a learned dictionary has been the focus of much recent research in machine learning, neuroscience, and signal processing. For signals such as natural images that admit such sparse representations, it is now well established that these models are well suited to restoration tasks. In this context, learning the dictionary amounts to solving a large-scale matrix factorization problem, which can be done efficiently with classical optimization tools. The same approach has also been used for learning features from data for other purposes, e.g., image classification, but tuning the dictionary in a supervised way for these tasks has proven to be more difficult. In this paper, we present a general formulation for supervised dictionary learning adapted to a wide variety of tasks, and present an efficient algorithm for solving the corresponding optimization problem. Experiments on handwritten digit classification, digital art identification, nonlinear inverse image problems, and compressed sensing demonstrate that our approach is effective in large-scale settings, and is well suited to supervised and semi-supervised classification, as well as regression tasks for data that admit sparse representations.",
        "references": [
            "f6e0fb4c77906bc23fe59a8f848ce62ba9687181",
            "83b522f4bfa5db7f7d34f839475af7d078107634",
            "ccd1282aea3cc7c3d40300d82472fc5f9f54cb8e",
            "e7a29a6a8b25c59c87ae87fb06cdcc34d62538b5",
            "9d65ba8bb20ae6dd001b9833c525c279dfe18916",
            "a8b515f2e5d065ed9e8c25710356014262dc0c6e",
            "92281d5002178003bd7060fc66677a3471cdaa4b",
            "9e7b0395d7b34e9d34cca779afd0c10da6e135b5",
            "932c2a02d462abd75af018125413b1ceaa1ee3f4",
            "e07416eabd4ba6c69fa473756bb04ae7161177be"
        ],
        "related_topics": [],
        "reference_count": "62",
        "citation_count": "887"
    },
    {
        "Id": "cf80cc34528273d8fbe17783efe802a6509e1562",
        "title": "Online dictionary learning for sparse coding",
        "authors": [
            "Julien Mairal",
            "Francis R. Bach",
            "Jean Ponce",
            "Guillermo Sapiro"
        ],
        "date": "14 June 2009",
        "abstract": "A new online optimization algorithm for dictionary learning is proposed, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples, and leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets. Sparse coding---that is, modelling data vectors as sparse linear combinations of basis elements---is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on learning the basis set, also called dictionary, to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.",
        "references": [
            "f6e0fb4c77906bc23fe59a8f848ce62ba9687181",
            "83b522f4bfa5db7f7d34f839475af7d078107634",
            "e64a9960734215e2b1866ea3cb723ffa5585ac14",
            "9d65ba8bb20ae6dd001b9833c525c279dfe18916",
            "92281d5002178003bd7060fc66677a3471cdaa4b",
            "e07416eabd4ba6c69fa473756bb04ae7161177be",
            "08253ca281c3603e0eaf3a4955fa468d42d165b6",
            "19de9e4850a208800db50615afec2b08b25d4f99",
            "9af121fbed84c3484ab86df8f17f1f198ed790a0",
            "2942c20f111d6fd38ef6dd53bb6eeb3b880e3d5f"
        ],
        "related_topics": [
            "Online Dictionary Learning",
            "Sparse Coding",
            "Dictionary Learning",
            "LARS-Lasso Algorithm",
            "Learned Dictionaries",
            "Dynamic Training Data",
            "Dictionary Update Steps",
            "Off-the-shelf Bases",
            "Dictionary Learning Problem",
            "Batch Alternatives"
        ],
        "reference_count": "29",
        "citation_count": "2,284"
    },
    {
        "Id": "83b522f4bfa5db7f7d34f839475af7d078107634",
        "title": "$rm K$-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation",
        "authors": [
            "Michal Aharon",
            "Michael Elad",
            "Alfred Marcel Bruckstein"
        ],
        "date": "1 November 2006",
        "abstract": "A novel algorithm for adapting dictionaries in order to achieve sparse signal representations, the K-SVD algorithm, an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data",
        "references": [
            "f6e0fb4c77906bc23fe59a8f848ce62ba9687181",
            "306de9c553695822ae9e6de044b6856baf0cce7d",
            "5a09a81393b824bf7b2efe38e2049c3dc9941293",
            "17e7cca7e795d8ba1fa9d2c88bf2675c2d6ddfe8",
            "7236864d8c2f62defea559465462c43a4b4b6b47",
            "1d9ef403969035e022b1b61c7dc513ffe189f031",
            "46ee0292a71fa86a9e2f9d691da5f0f1cf281f83",
            "42d906c733f273109c0ed716a5ef6e2a379beb26",
            "4ed0700119ed281d210897117863fa290d383cd0",
            "6cf9b027aa09d042dd13fd9ae848d902240b3d34"
        ],
        "related_topics": [
            "K-SVD Algorithm",
            "Dictionary",
            "Overcomplete Dictionaries",
            "Dictionary Atoms",
            "Sparse Representation",
            "Sparse Coding",
            "Prototype Signal-atoms",
            "Pursuit Algorithms",
            "Dictionary Columns",
            "K-means Clustering Process"
        ],
        "reference_count": "49",
        "citation_count": "7,686"
    },
    {
        "Id": "0baa66007d2cfe8e98720310ad0ed7bdee7a873d",
        "title": "Entropy rate superpixel segmentation",
        "authors": [
            "Ming-Yu Liu",
            "Oncel Tuzel",
            "Srikumar Ramalingam",
            "Rama Chellappa"
        ],
        "date": "1 June 2011",
        "abstract": "An efficient greedy algorithm for superpixel segmentation is developed by exploiting submodular and mono-tonic properties of the objective function and proving an approximation bound of \u00bd for the optimality of the solution. We propose a new objective function for superpixel segmentation. This objective function consists of two components: entropy rate of a random walk on a graph and a balancing term. The entropy rate favors formation of compact and homogeneous clusters, while the balancing function encourages clusters with similar sizes. We present a novel graph construction for images and show that this construction induces a matroid \u2014 a combinatorial structure that generalizes the concept of linear independence in vector spaces. The segmentation is then given by the graph topology that maximizes the objective function under the matroid constraint. By exploiting submodular and mono-tonic properties of the objective function, we develop an efficient greedy algorithm. Furthermore, we prove an approximation bound of \u00bd for the optimality of the solution. Extensive experiments on the Berkeley segmentation benchmark show that the proposed algorithm outperforms the state of the art in all the standard evaluation metrics.",
        "references": [
            "1328880541640d3c9aa1ce7b5201f90d6c4e0925",
            "50218bed9da6d291262590e2a1c7bfa7aaa13e4a",
            "ddd36382c3034cd9eebe18a61e8bedd2d1a40601",
            "a3269505b943d3549a82c4eef23d9e29cea3be11",
            "aeeffe327e6c93e9010c7b1e401caa9113723851",
            "87073fd45685b78cb5a68e5eae331d88f2a2be63",
            "3120324069ec20eed853d3f9bbbceb32e4173b93",
            "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "0eb464791ac91e8db4e284f48efef5b9e320701c",
            "9a9049a50dfe94fa4473880a9b60c99333ade685"
        ],
        "related_topics": [
            "Superpixel Segmentation",
            "Balancing Term",
            "Matroid",
            "Vector Space",
            "Random Walks",
            "Greedy Algorithm",
            "Graphs",
            "Balancing Functions",
            "Submodular"
        ],
        "reference_count": "22",
        "citation_count": "888"
    },
    {
        "Id": "684732677d91a93b115f57e8d671ef7f5f13ee14",
        "title": "Method of optimal directions for frame design",
        "authors": [
            "Kjersti Engan",
            "Sven Ole Aase",
            "John H{\\aa}kon Hus{\\o}y"
        ],
        "date": "15 March 1999",
        "abstract": "Experiments demonstrate that the approximation capabilities, in terms of mean squared error (MSE), of the optimized frames are significantly better than those obtained using frames designed by the algorithm of Engan et. A frame design technique for use with vector selection algorithms, for example matching pursuits (MP), is presented. The design algorithm is iterative and requires a training set of signal vectors. The algorithm, called method of optimal directions (MOD), is an improvement of the algorithm presented by Engan, Aase and Husoy see (Proc. ICASSP '98, Seattle, USA, p.1817-20, 1998). The MOD is applied to speech and electrocardiogram (ECG) signals, and the designed frames are tested on signals outside the training sets. Experiments demonstrate that the approximation capabilities, in terms of mean squared error (MSE), of the optimized frames are significantly better than those obtained using frames designed by the algorithm of Engan et. al. Experiments show typical reduction in MSE by 20-50%.",
        "references": [
            "3c5579e9c2f83552ab1dc97538f0d30f0ee12f6f",
            "0246712ba71d2fa53c24f63b5b8aacd3579527bf",
            "0beb79c74eaae6aed50e4acd672f229230637242",
            "5b7dbccf8ca8e7cf11b9115325edf40aa0e94028",
            "832516cbbc4898449f9e2bbe6cb5fcf68fbe8160",
            "490a6505da67d0f28d92bfeff418fa317fab7abf",
            "cf151c23808916f7f3d3b294480fce2dfddcb04c",
            "c564aa7639a08c280423489e52b6e32055c9aa7f",
            "bf48b3256918db40dacc094fca75707ca3a4a4ef",
            "f6295fd69d76d606f66cc15f58767a8161d60335"
        ],
        "related_topics": [
            "Method Of Optimal Directions",
            "Vector Selection Algorithms",
            "Mean Squared Error",
            "Training Set",
            "Moving Object Detection",
            "Mean Square Error",
            "pROC",
            "Approximation Capabilities",
            "Electro-cardiogram",
            "Matching Pursuits"
        ],
        "reference_count": "11",
        "citation_count": "1,306"
    },
    {
        "Id": "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
        "title": "Hyperspectral Image Classification Using Dictionary-Based Sparse Representation",
        "authors": [
            "Yi Chen",
            "Nasser M. Nasrabadi",
            "Trac D. Tran"
        ],
        "date": "12 May 2011",
        "abstract": "Experimental results show that the proposed sparsity-based algorithm for the classification of hyperspectral imagery outperforms the classical supervised classifier support vector machines in most cases. A new sparsity-based algorithm for the classification of hyperspectral imagery is proposed in this paper. The proposed algorithm relies on the observation that a hyperspectral pixel can be sparsely represented by a linear combination of a few training samples from a structured dictionary. The sparse representation of an unknown pixel is expressed as a sparse vector whose nonzero entries correspond to the weights of the selected training samples. The sparse vector is recovered by solving a sparsity-constrained optimization problem, and it can directly determine the class label of the test sample. Two different approaches are proposed to incorporate the contextual information into the sparse recovery optimization problem in order to improve the classification performance. In the first approach, an explicit smoothing constraint is imposed on the problem formulation by forcing the vector Laplacian of the reconstructed image to become zero. In this approach, the reconstructed pixel of interest has similar spectral characteristics to its four nearest neighbors. The second approach is via a joint sparsity model where hyperspectral pixels in a small neighborhood around the test pixel are simultaneously represented by linear combinations of a few common training samples, which are weighted with a different set of coefficients for each pixel. The proposed sparsity-based algorithm is applied to several real hyperspectral images for classification. Experimental results show that our algorithm outperforms the classical supervised classifier support vector machines in most cases.",
        "references": [
            "f19122b082188e626ff8355cfcaa432e68509272",
            "0e31d9acb94cdffcefa30b2b09b40e9b8457941c",
            "5d704c3908b11666904467970e6dd5bf59fbfecf",
            "4e0f49c4b23b32b1c0c278fa8eecbfee01b6aeda",
            "b0fe9323b9e74f9473f5b97cccf53a689f64bf60",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "344360c84ae36ab2e4a0bb3ffb6ac65f47fc7722",
            "c86abfc2d6c5ad3ed80b133ea736529301f2e500",
            "6fb4840ed454daf0b56ca9b40aced6fc43e569f4",
            "50b596dd0dc5c59912ef747d854c72d891be40b1"
        ],
        "related_topics": [],
        "reference_count": "66",
        "citation_count": "943"
    },
    {
        "Id": "692541a740b2b3c5c82a47390a7cbb40872efec5",
        "title": "Contextual Online Dictionary Learning for Hyperspectral Image Classification",
        "authors": [
            "Wei Fu",
            "Shutao Li",
            "Leyuan Fang",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "1 March 2018",
        "abstract": "A contextual online dictionary learning (DL) method for HSIs classification is proposed, which learns a dictionary over the whole image rather than few labeled pixels, and can effectively and efficiently improve the adaptive representation capability of different pixels with an online learning mechanism. Sparse representation (SR) has been successfully used in the classification of hyperspectral images (HSIs) by representing HSI pixels over a dictionary and yielding discriminative sparse coefficients. Most of SR-based classification methods construct the dictionary by directly using some labeled pixels as atoms. Such dictionary can lead to inefficient SR for large-sized HSIs, and may be incomplete when the number of labeled pixels is less than the number of spectral bands. This paper proposes a contextual online dictionary learning (DL) method for HSIs classification, which learns a dictionary over the whole image rather than few labeled pixels. The proposed method can effectively and efficiently improve the adaptive representation capability of different pixels with an online learning mechanism. Specifically, the contextual characteristics of the HSI are integrated with discriminative spectral information for online DL, i.e., pushing similar pixels in neighborhood to share similar sparse coefficients with respect to the well-learned dictionary. By this way, the obtained sparse coefficients are structured and discriminative. Finally, a traditional classifier, i.e., the linear support vector machine, is applied to the sparse coefficients, and the final classification results are obtained. Experimental results on real HSIs show the effectiveness of the proposed method.",
        "references": [
            "e860267bdaba7eba2fbfbdbb9974d6fd574d522b",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "15f7662fadf686beae8ce704ee9b48262ac62237",
            "083b3a4d102c08c9553ad4db4afd6dd37a5ca448",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "cdd338408ce5b93dc78609af10fee43d5a45fab9",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "28370ac959ea8a46fdf05d1092ee476ace3afe3d"
        ],
        "related_topics": [
            "Dictionary",
            "HSIs",
            "Classification",
            "Online Dictionary Learning",
            "Sparse Representation",
            "Hyperspectral Image Classification",
            "Linear Support Vector Machines",
            "Neighborhood"
        ],
        "reference_count": "50",
        "citation_count": "21"
    },
    {
        "Id": "22ae9bc79e07285144adef621b09d4f0ddd2f757",
        "title": "Hyperspectral Image Denoising using Dictionary Learning",
        "authors": [
            "C{\\&#x27;a}ssio Fraga Dantas",
            "J{\\&#x27;e}r{\\&#x27;e}my E. Cohen",
            "R{\\&#x27;e}mi Gribonval"
        ],
        "date": "1 September 2019",
        "abstract": "This work shows that the dictionary learning approach is more efficient to denoise hyperspectral images than state-of-the-art methods with fixed dictionaries, at the cost of a larger computation time. Hyperspectral images are corrupted by noise during their acquisition. In this work, we propose to efficiently denoise hyperspectral images under two assumptions: (i) noiseless hyperspectral images in matrix form are low-rank, and (ii) image patches are sparse in a proper representation domain defined through a dictionary. These two assumptions have already led to state-of-the-art denoising methods using fixed Wavelet transforms. We propose to rather learn the dictionary from hyperspectral images, a task commonly known as dictionary learning. We show that the dictionary learning approach is more efficient to denoise hyperspectral images than state-of-the-art methods with fixed dictionaries, at the cost of a larger computation time.",
        "references": [
            "e148a963582e2cfeb65c2e39c8c6d4a60aac0e0d",
            "b8318be888ff135851b62a8015e89fc38828ede9",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "124db146d4bf80f1b1963307d4e949588c25019c",
            "e07416eabd4ba6c69fa473756bb04ae7161177be",
            "99a98ea99a1f6946341c349cf8ccf2c58ba9afdb",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "e1fec22da5aebc4d76466a49640b193ffc65bb0c",
            "32b76ed3a13f3721298866b5333da06305bac040",
            "a1717abbe5e48a51f583859576b842a78353a83f"
        ],
        "related_topics": [
            "Dictionary",
            "Dictionary Learning",
            "Image Patches",
            "Hyperspectral Image Denoising",
            "Denoising Method",
            "Low-rank"
        ],
        "reference_count": "19",
        "citation_count": "6"
    },
    {
        "Id": "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
        "title": "Learning Discriminative Sparse Representations for Modeling, Source Separation, and Mapping of Hyperspectral Imagery",
        "authors": [
            "Alexey Castrodad",
            "Zhengming Xing",
            "John B. Greer",
            "Edward Bosch",
            "Lawrence Carin",
            "Guillermo Sapiro"
        ],
        "date": "26 September 2011",
        "abstract": "Results when the data have been significantly undersampled and then reconstructed are presented, still retaining high-performance classification, showing the potential role of compressive sensing and sparse modeling techniques in efficient acquisition/transmission missions for hyperspectral imagery. A method is presented for subpixel modeling, mapping, and classification in hyperspectral imagery using learned block-structured discriminative dictionaries, where each block is adapted and optimized to represent a material in a compact and sparse manner. The spectral pixels are modeled by linear combinations of subspaces defined by the learned dictionary atoms, allowing for linear mixture analysis. This model provides flexibility in source representation and selection, thus accounting for spectral variability, small-magnitude errors, and noise. A spatial-spectral coherence regularizer in the optimization allows pixel classification to be influenced by similar neighbors. We extend the proposed approach for cases for which there is no knowledge of the materials in the scene, unsupervised classification, and provide experiments and comparisons with simulated and real data. We also present results when the data have been significantly undersampled and then reconstructed, still retaining high-performance classification, showing the potential role of compressive sensing and sparse modeling techniques in efficient acquisition/transmission missions for hyperspectral imagery.",
        "references": [
            "41f426e2dc5b4944148014d9c86d20fdd21dc968",
            "ec892e36c16feffdea169dbec97ecdc412778a02",
            "074354a7d114c43dfba60663a536cec947f8ff08",
            "dbd75566afe8034c8d1db0cad623f3730d1c5e97",
            "0337e7041779082330ac74cf74aebe79fddb38d2",
            "79ff2db16cb2c64883a581bf7f6641795263ae8c",
            "e616132691824d6eec92b0eb4560b286d732582b",
            "46f447a8dbb68ea4d2793a8c5d9abfd3c622c144",
            "47d15dfd9d4e06fdb596803bf1c5e9a7661183a3",
            "4a1042d7a216008eaae4d17d478f93029ef69a4f"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Classification",
            "Compressive Sensing",
            "Spectral Pixels",
            "Dictionary Atoms",
            "Linear Mixture Analysis",
            "Undersampled",
            "Source Separation",
            "Sparse Representation",
            "Spectral Variability"
        ],
        "reference_count": "69",
        "citation_count": "129"
    },
    {
        "Id": "58c239e6c2c38dea061310ed5d719c3221d4428f",
        "title": "Semisupervised Neural Networks for Efficient Hyperspectral Image Classification",
        "authors": [
            "Fr{\\&#x27;e}d{\\&#x27;e}ric Ratle",
            "Gustau Camps-Valls",
            "Jason Weston"
        ],
        "date": "17 February 2010",
        "abstract": "The proposed approach gives rise to an operational classifier, as opposed to previously presented transductive or Laplacian support vector machines (TSVM or LapSVM, respectively), which constitutes a general framework for building computationally efficient semisupervised methods. A framework for semisupervised remote sensing image classification based on neural networks is presented. The methodology consists of adding a flexible embedding regularizer to the loss function used for training neural networks. Training is done using stochastic gradient descent with additional balancing constraints to avoid falling into local minima. The method constitutes a generalization of both supervised and unsupervised methods and can handle millions of unlabeled samples. Therefore, the proposed approach gives rise to an operational classifier, as opposed to previously presented transductive or Laplacian support vector machines (TSVM or LapSVM, respectively). The proposed methodology constitutes a general framework for building computationally efficient semisupervised methods. The method is compared with LapSVM and TSVM in semisupervised scenarios, to SVM in supervised settings, and to online and batch k-means for unsupervised learning. Results demonstrate the improved classification accuracy and scalability of this approach on several hyperspectral image classification problems.",
        "references": [
            "e8e87430f7c76abf80081c73ee3dd95e2770c9d9",
            "7c997a648976fb9df320c6ca332c9dc155820454",
            "558593f2ba9a6c921dcef904d4f2b1e87b9084f7",
            "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6",
            "3e32b4775f3aeff0e1eaf37cc46771376a0c8d08",
            "408c49cea4dbf3f793b8d29a54febf49a8db50cb",
            "3e0d40153bde82d1f2f1cd2b2e05bf75a2de773b",
            "c57a50f79bf2e8174b76aed1ccabc53e9e966256",
            "6fa08993cbbfb19bcb9124dce3d2520312689d2e",
            "14b64bb5af95367883abd2b95d95979f87bcd5f0"
        ],
        "related_topics": [
            "Laplacian SVMs",
            "Hyperspectral Image Classification",
            "Laplacian Support Vector Machines",
            "Transductive Support Vector Machines",
            "Neural Network",
            "Support Vector Machines",
            "Embedding Regularizer",
            "Transductive",
            "Stochastic Gradient Descent",
            "Loss Function"
        ],
        "reference_count": "50",
        "citation_count": "311"
    },
    {
        "Id": "ec9aa46ebc50a03ea9d7d20d80a232e6bd4293de",
        "title": "Convolutional neural networks for hyperspectral image classification",
        "authors": [
            "Shiqi Yu",
            "Sen Jia",
            "Chunyan Xu"
        ],
        "date": "5 January 2017",
        "abstract": "Semantic Scholar extracted view of \"Convolutional neural networks for hyperspectral image classification\" by Shiqi Yu et al.",
        "references": [
            "2369db9921078c4bb76072ef7d6426e9f1dbfdb5",
            "ef8ae1effca9cd45677086034d8c7b06a69c03e5",
            "f20048cb8172a528a292dd5a9154ce2f59e116d1",
            "f9b6242f8e9d5f7f9e31214444290f812889f946",
            "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "e1cf0d241c6214d772b7f882183c3dfbe4a7f3eb",
            "4cc353aab3342dca24394e48c5143a8fd4f34523",
            "c5389f0d9751ce9cd39160320ef17ae968a79edf",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "5355e8c7359b8dadb970099dcd6fa951fa5ef3b7"
        ],
        "related_topics": [
            "Convolutional Neural Network",
            "Hyperspectral Image Classification",
            "Average Pooling Layer",
            "Dropout Rate",
            "Neural Network"
        ],
        "reference_count": "47",
        "citation_count": "451"
    },
    {
        "Id": "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6",
        "title": "Kernel-based methods for hyperspectral image classification",
        "authors": [
            "Gustau Camps-Valls",
            "Lorenzo Bruzzone"
        ],
        "date": "23 May 2005",
        "abstract": "This paper assesses performance of regularized radial basis function neural networks (Reg-RBFNN), standard support vector machines (SVMs), kernel Fisher discriminant (KFD) analysis, and regularized AdaBoost (reg-AB) in the context of hyperspectral image classification. This paper presents the framework of kernel-based methods in the context of hyperspectral image classification, illustrating from a general viewpoint the main characteristics of different kernel-based approaches and analyzing their properties in the hyperspectral domain. In particular, we assess performance of regularized radial basis function neural networks (Reg-RBFNN), standard support vector machines (SVMs), kernel Fisher discriminant (KFD) analysis, and regularized AdaBoost (Reg-AB). The novelty of this work consists in: 1) introducing Reg-RBFNN and Reg-AB for hyperspectral image classification; 2) comparing kernel-based methods by taking into account the peculiarities of hyperspectral images; and 3) clarifying their theoretical relationships. To these purposes, we focus on the accuracy of methods when working in noisy environments, high input dimension, and limited training sets. In addition, some other important issues are discussed, such as the sparsity of the solutions, the computational burden, and the capability of the methods to provide outputs that can be directly interpreted as probabilities.",
        "references": [
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "c57a50f79bf2e8174b76aed1ccabc53e9e966256",
            "58a4e754d333b2feafce58b7ec13dc818635099f",
            "5b92c12e80e82e2302c6f2570f415bbc26f966b0",
            "beaf082a29bc5e9721de478457cfce30a2047d4a",
            "0cfcfd98106a63a0b35021a3a1910ec53c62fc3a",
            "72d9f02f78570d680b9242866f925114061bb8da",
            "f76bb99b4e9f247d49dc46266f6351267c8db69f",
            "5260df181b79a5c91622d4c2da6d2c618852d6ff",
            "7547fd7c5e4bc3b8b8bf714583684ff187e8a382"
        ],
        "related_topics": [
            "Hyperspectral Image Classification",
            "Kernel Fisher Discriminant",
            "Support Vector Machines",
            "Training Set"
        ],
        "reference_count": "50",
        "citation_count": "1,418"
    },
    {
        "Id": "2badd8953397d757693859918cf9318fe7ec5e3b",
        "title": "Classification of hyperspectral remote sensing images with support vector machines",
        "authors": [
            "Farid Melgani",
            "Lorenzo Bruzzone"
        ],
        "date": "16 August 2004",
        "abstract": "This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines by understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces and concludes that SVMs are a valid and effective alternative to conventional pattern recognition approaches. This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines (SVMs). First, we propose a theoretical discussion and experimental analysis aimed at understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces. Then, we assess the effectiveness of SVMs with respect to conventional feature-reduction-based approaches and their performances in hypersubspaces of various dimensionalities. To sustain such an analysis, the performances of SVMs are compared with those of two other nonparametric classifiers (i.e., radial basis function neural networks and the K-nearest neighbor classifier). Finally, we study the potentially critical issue of applying binary SVMs to multiclass problems in hyperspectral data. In particular, four different multiclass strategies are analyzed and compared: the one-against-all, the one-against-one, and two hierarchical tree-based strategies. Different performance indicators have been used to support our experimental studies in a detailed and accurate way, i.e., the classification accuracy, the computational time, the stability to parameter setting, and the complexity of the multiclass architecture. The results obtained on a real Airborne Visible/Infrared Imaging Spectroradiometer hyperspectral dataset allow to conclude that, whatever the multiclass strategy adopted, SVMs are a valid and effective alternative to conventional pattern recognition approaches (feature-reduction procedures combined with a classification method) for the classification of hyperspectral remote sensing data.",
        "references": [
            "a240da170041b9aa798b512160ba9712bf82a56e",
            "5b92c12e80e82e2302c6f2570f415bbc26f966b0",
            "b821c3afbb404766ff2c768fa363803b8d256434",
            "b9ddc16cd2449e93d44c1c5360dcf765b91de099",
            "f83b85d8daa4ee370982842a809b5c8dba63b645",
            "75a963eff4fd7809694d2225b62db7569f1e1b93",
            "5355e8c7359b8dadb970099dcd6fa951fa5ef3b7",
            "c94dec3fc99c4a653afb935d00246f788689c341",
            "ea82a3b3f8940c7e8f949d78639792ac345d09fd",
            "7dd9820b13754f05ae3f7f771fc8b2d7f4691c06"
        ],
        "related_topics": [],
        "reference_count": "52",
        "citation_count": "3,550"
    },
    {
        "Id": "5a391667242b4a631acdd5917681b16a86523987",
        "title": "Deep Recurrent Neural Networks for Hyperspectral Image Classification",
        "authors": [
            "Lichao Mou",
            "Pedram Ghamisi",
            "Xiaoxiang Zhu"
        ],
        "date": "2017",
        "abstract": "This paper proposes a novel RNN model that can effectively analyze hyperspectral pixels as sequential data and then determine information categories via network reasoning, and makes use of a newly proposed activation function, parametric rectified tanh (PRetanh), for hyperspectrals sequential data analysis. In recent years, vector-based machine learning algorithms, such as random forests, support vector machines, and 1-D convolutional neural networks, have shown promising results in hyperspectral image classification. Such methodologies, nevertheless, can lead to information loss in representing hyperspectral pixels, which intrinsically have a sequence-based data structure. A recurrent neural network (RNN), an important branch of the deep learning family, is mainly designed to handle sequential data. Can sequence-based RNN be an effective method of hyperspectral image classification? In this paper, we propose a novel RNN model that can effectively analyze hyperspectral pixels as sequential data and then determine information categories via network reasoning. As far as we know, this is the first time that an RNN framework has been proposed for hyperspectral image classification. Specifically, our RNN makes use of a newly proposed activation function, parametric rectified tanh (PRetanh), for hyperspectral sequential data analysis instead of the popular tanh or rectified linear unit. The proposed activation function makes it possible to use fairly high learning rates without the risk of divergence during the training procedure. Moreover, a modified gated recurrent unit, which uses PRetanh for hidden representation, is adopted to construct the recurrent layer in our network to efficiently process hyperspectral data and reduce the total number of parameters. Experimental results on three airborne hyperspectral images suggest competitive performance in the proposed mode. In addition, the proposed network architecture opens a new window for future research, showcasing the huge potential of deep recurrent networks for hyperspectral data analysis.",
        "references": [
            "ef8ae1effca9cd45677086034d8c7b06a69c03e5",
            "10fb16414324a5db44f5d830adcb4810af59eed0",
            "8027c90cad2c41275c96ed058e4c90c7426ace0b",
            "2369db9921078c4bb76072ef7d6426e9f1dbfdb5",
            "8e80671105bae1e65abe0b6f80aa9843403a7c24",
            "842ca93d770edef147e9ca117e1c0294a596cb82",
            "3fd878a2b116be8088483c1d7755763bb50599af",
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "be055383ba9e17fe9898a2e1a084e7e7652fbbf9"
        ],
        "related_topics": [
            "Parametric Rectified Tanh",
            "Network Reasoning",
            "Hyperspectral Image Classification",
            "Recurrent Neural Networks",
            "Sequential Data",
            "Activation Function",
            "Gated Recurrent Unit",
            "Learning Rates",
            "Hidden Representations"
        ],
        "reference_count": "47",
        "citation_count": "841"
    },
    {
        "Id": "bbfd00eb29c3f18d4dd997ac8331e495e56059e3",
        "title": "Hyperspectral image classification via compact-dictionary-based sparse representation",
        "authors": [
            "Chunhong Cao",
            "Liu Deng",
            "Wei Duan",
            "Fen Xiao",
            "Wan Chun Yang",
            "Kai Hu"
        ],
        "date": "22 November 2018",
        "abstract": "Experimental results demonstrate the effectiveness and superiority of the proposed compact-dictionary-based sparse representation (CDSR) method when compared with some widely used HSI classification approaches. In this paper, a compact-dictionary-based sparse representation (CDSR) method is proposed for hyperspectral image (HSI) classification. The proposed dictionary in CDSR is dynamically generated according to the spatial and spectral context of each pixel. It can effectively shrink the decision range for classification, and reduce the computational burden since the compact dictionary is composed of the classes correlated with the target pixel in terms of spatial location and spectral information. In order to obtain better spatial context information, a spatial location expanding strategy is designed for spreading local explicit label information to a wider region. Experimental results demonstrate the effectiveness and superiority of the proposed method when compared with some widely used HSI classification approaches.",
        "references": [
            "33f91879e50d6217aab30cad86eb259f0ca2c8cd",
            "e30fcfa9e0e8c7d03315848e823781b7a72203ef",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "f206be139e71051e3bab8588854728cc07c20988",
            "98c03d81310650f3013a163afdda7f7e1e9d64db",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "e860267bdaba7eba2fbfbdbb9974d6fd574d522b",
            "3bbafaa25837bc4c8a69136fab551dbf86bc5941"
        ],
        "related_topics": [],
        "reference_count": "46",
        "citation_count": "6"
    },
    {
        "Id": "e7259f0a9afcc9a8314a9a2ce6c5017fda01edc5",
        "title": "Hyperspectral Image Classification with Spatial Filtering and \u21132,1 Norm",
        "authors": [
            "Hao Li",
            "Chang Li",
            "Cong Zhang",
            "Zhe Liu",
            "Chengyin Liu"
        ],
        "date": "1 February 2017",
        "abstract": "A hyperspectral classification method with spatial filtering and \u21132,1 norm (SFL) that can deal with all the test pixels simultaneously and can obtain better classification performance than some other popular classifiers is proposed. Recently, the sparse representation based classification methods have received particular attention in the classification of hyperspectral imagery. However, current sparse representation based classification models have not considered all the test pixels simultaneously. In this paper, we propose a hyperspectral classification method with spatial filtering and \u21132,1 norm (SFL) that can deal with all the test pixels simultaneously. The \u21132,1 norm regularization is used to extract relevant training samples among the whole training data set with joint sparsity. In addition, the \u21132,1 norm loss function is adopted to make it robust for samples that deviate significantly from the rest of the samples. Moreover, to take the spatial information into consideration, a spatial filtering step is implemented where all the training and testing samples are spatially averaged with its nearest neighbors. Furthermore, the non-negative constraint is added to the sparse representation matrix motivated by hyperspectral unmixing. Finally, the alternating direction method of multipliers is used to solve SFL. Experiments on real hyperspectral images demonstrate that the proposed SFL method can obtain better classification performance than some other popular classifiers.",
        "references": [
            "4ab0d77862353cfc1c5d39d4a85fc12c5764843b",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "9f2f1a5d4f6e582d4afd857915802805a7f4185e",
            "87402a58586ed750d3c43e4c7062a3a6a867bf42",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "135aa328a788c02cecfed79291f11f2bbb20603e",
            "28370ac959ea8a46fdf05d1092ee476ace3afe3d",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "10fb16414324a5db44f5d830adcb4810af59eed0"
        ],
        "related_topics": [
            "Test Pixel",
            "L2,1-norm Regularization",
            "Hyperspectral Unmixing",
            "Hyperspectral Imagery",
            "Classifier",
            "Sparse Representation Based Classification",
            "Sparse Representation",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "69",
        "citation_count": "16"
    },
    {
        "Id": "2249c7c89e3178ff7629a8e684232e7c47e2b629",
        "title": "Multiscale Feature Extraction Based on Convolutional Sparse Decomposition for Hyperspectral Image Classification",
        "authors": [
            "Chongxiao Zhong",
            "Junping Zhang",
            "Ye Zhang"
        ],
        "date": "2020",
        "abstract": "A convolutional sparse decomposition (CSD) model is introduced to characterize the significant spatial structures of hyperspectral data while removing the irrelevant noise and local textures at the specific scale and leads to better classification results than several state-of-the-art methods. Due to the different spatial properties presented by various ground objects in hyperspectral image (HSI), multiscale-based feature extraction approaches have been developed for HSI classification in recent years. However, the spatial features of different scales are usually acquired at the cost of obscuring the structural information of input image, which severely limits the effectiveness of multiscale strategy. In this article, a convolutional sparse decomposition (CSD) model is introduced to characterize the significant spatial structures of hyperspectral data while removing the irrelevant noise and local textures at the specific scale. Based on the CSD model, a multiscale spectral-spatial feature extraction framework is generated, which consists of the following steps. First, the spectral dimensionality of the original HSI is reduced through a segmented averaging approach. Second, spatial features at different scales are separated from the dimension-reduced data by solving the CSD model with different regularization parameters. Finally, principal component analysis is performed and the obtained multiscale spectral-spatial features are stacked together for classification. Experiments conducted on three widely used hyperspectral datasets demonstrate that the proposed method is robust in capturing effective features of ground objects at different scales and leads to better classification results than several state-of-the-art methods.",
        "references": [
            "fcb3ed16fcd372079570843fe2f462d16f8890c5",
            "beb88611231c630805a1839e49e421852abf65ce",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "0ac9bce2a1168a1b3f39199a8317dfc65c59262a",
            "c886eebf361b5de07bc487641b3b5df4941e28db",
            "1301138fd1df0e08c994f9eb6fe41b75fe8b7f06",
            "5a086f083b1c1bbbb1050b7a493eee2768093e63",
            "5c2522857904708b6d7a03c4299bbd1935f8705f",
            "72badba8563a0542b12db5d843494d430fa6a7df",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1"
        ],
        "related_topics": [
            "Classification",
            "Canonical Signed Digit",
            "Hyperspectral Imagery",
            "Spectral Dimensionality",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "59",
        "citation_count": "6"
    },
    {
        "Id": "d9b3d824cee776a3e325dd33c6e69e6a7ef9d5bc",
        "title": "Hyperspectral image classification using distance metric based 1-dimensional manifold embedding",
        "authors": [
            "Hui-Wu Luo",
            "Yulong Wang",
            "Yuanyan Tang",
            "Chunli Li",
            "Jianzhong Wang"
        ],
        "date": "10 July 2016",
        "abstract": "A distance metric learning based 1-dimensional manifold embedding (1DME) for hyperspectral image classification is proposed and the results validate the efficiency of the proposed method. Hyperspectral remotely sensed image provides very informative information for a wide range of applications that relate to landcover classification. Many studies have shown that the spectral-spatial information is well effective for hyperspectral image (HSI) classification. However, for the spatial based methods, it may sometimes encounter many difficulties in obtaining the spatial prior of different landcovers. Moreover, the spatial prior has to be carefully tuned during each experiment. In this paper, we propose a distance metric learning based 1-dimensional manifold embedding (1DME) for hyperspectral image classification. In our approach, the Mahalanobis matric is first employed to learn an similarity metric of pairwise pixels. The measurement can well indicate proximity of different classes. Then, according to the piecewise affinity, we adopt the developed 1-dimensional manifold embedding to sort the entire data points so that pixels with similar property stay close. Since the entire data points are ordered, several regressors are applied to the ordered sequence, and the averaged results are treated as the prediction. Experiment is conducted on the well acknowledged Indian Pines benchmark data set, and the results validate the efficiency of the proposed method.",
        "references": [
            "024c6433fb4486433a9f412476b5d3d565a0794b",
            "771a9e2bb431497c04635c90d1587e9a4adbfb4c",
            "3a63667284dc8b9687ed1620406030bfe39af3c9",
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "e30fcfa9e0e8c7d03315848e823781b7a72203ef",
            "c974e3d309ac143127953a645ff8e9afa20ec69a",
            "946e836206964c31e3aefce1df54fbb542ab80ed",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "0fe45d9b944714fb1ebaa381c9dd05d82174f4f0",
            "78947497cbbffc691aac3f590d972130259af9ce"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "17"
    },
    {
        "Id": "1bce20f54f1206444f742c08e46e55b9e852c134",
        "title": "Low-Rank and Sparse Representation for Hyperspectral Image Processing: A review",
        "authors": [
            "Jiangtao Peng",
            "Weiwei Sun",
            "Hengchao Li",
            "Wei Li",
            "Xiangchao Meng",
            "Chiru Ge",
            "Qian Du"
        ],
        "date": "1 March 2022",
        "abstract": "Combining rich spectral and spatial information, a hyperspectral image (HSI) can provide a more comprehensive characterization of the Earth\u2019s surface. To better exploit HSIs, a large number of algorithms have been developed during the past few decades. Due to their very high correlation between spectral channels and spatial pixels, HSIs have intrinsically sparse and low-rank structures. The sparse representation (SR) and low-rank representation (LRR)-based methods have proven to be powerful tools for HSI processing and are widely used in different HS fields. In this article, we present a survey of low-rank and sparse-based HSI processing methods in the fields of denoising, superresolution, dimension reduction, unmixing, classification, and anomaly detection. The purpose is to provide guidelines and inspiration to practitioners for promoting the development of HSI processing. For a listing of the key terms discussed in this article, see \u201cNomenclature.\u201d",
        "references": [
            "735098a8698acb1ed6b2eb2c29c90018296c4aac",
            "37531995a09f038db1b253dea60a242810554da2",
            "75cbea9d8ba5ae1835d98f9ef65048c83edab8f5",
            "af17ed0986f11c08134426dfb46bd0496d74a3f1",
            "8dbb81ceac324975bf4c2cbc80b08ed3c91ad932",
            "ca39d6e0c6d942ae95f58d50835173560a1a022f",
            "7b58944e3b344d019f660bd2b78d3ede38f94ce6",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "29580626129d00992feac5dbbccbe5a538b3caa8",
            "a1ea3408b4131134c6c55fcaa74d94ef6347f29e"
        ],
        "related_topics": [
            "Testing Pixel",
            "Hyperspectral Imagery",
            "HSIs",
            "Sparse Representation",
            "Superresolution",
            "Unmixing",
            "Classification",
            "Denoising",
            "Anomaly Detection",
            "Low-rank"
        ],
        "reference_count": "225",
        "citation_count": "79"
    },
    {
        "Id": "613c5f43e9087995ed8fbf66be83fb98fef0b79f",
        "title": "Improved Joint Sparse Models for Hyperspectral Image Classification Based on a Novel Neighbour Selection Strategy",
        "authors": [
            "Qishuo Gao",
            "Samsung Lim",
            "Xiuping Jia"
        ],
        "date": "8 June 2018",
        "abstract": "Tests on three benchmark datasets show that the proposed adaptive local neighbour selection strategy suitable for hyperspectral image classification is superior to the conventional sparsity representation methods and the popular support vector machines. Joint sparse representation has been widely used for hyperspectral image classification in recent years, however, the equal weight assigned to each neighbouring pixel is less realistic, especially for the edge areas, and one fixed scale is not appropriate for the entire image extent. To overcome these problems, we propose an adaptive local neighbour selection strategy suitable for hyperspectral image classification. We also introduce a multi-level joint sparse model based on the proposed adaptive local neighbour selection strategy. This method can generate multiple joint sparse matrices on different levels based on the selected parameters, and the multi-level joint sparse optimization can be performed efficiently by a simultaneous orthogonal matching pursuit algorithm. Tests on three benchmark datasets show that the proposed method is superior to the conventional sparsity representation methods and the popular support vector machines.",
        "references": [
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "87402a58586ed750d3c43e4c7062a3a6a867bf42",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "49861bc0a8e290b939ff8f0e656ec7d80bef4ec0",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5aa216c9a1a0a99398c0523a7159085846916ede",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "e30fcfa9e0e8c7d03315848e823781b7a72203ef",
            "2fa41ad17da78347b5fce8cb1e8d89c1c1671f83",
            "694f9c965b82ba993fdbfb7568f45b3577524c46"
        ],
        "related_topics": [
            "Hyperspectral Image Classification",
            "Benchmark Dataset",
            "Optimization"
        ],
        "reference_count": "42",
        "citation_count": "10"
    },
    {
        "Id": "6bcf14f28813c456651dd17911d12b8c66877d5a",
        "title": "Frontiers in Spectral-Spatial Classification of Hyperspectral Images",
        "authors": [
            "Pedram Ghamisi",
            "Emmanuel Maggiori",
            "Shutao Li",
            "Roberto Souza",
            "Yuliya Tarabalka",
            "Gabriele Moser",
            "Andrea De Giorgi",
            "Leyuan Fang",
            "Yushi Chen",
            "Mingmin Chi",
            "Sebastiano Bruno Serpico",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "1 September 2018",
        "abstract": "The latest advances in spectral-spatial classification of hyperspectral data are critically reviewed and more than 25 approaches based on mathematical morphology, Markov random fields, segmentation, sparse representation, and deep learning are addressed with an emphasis on discussing their methodological foundations. Airborne and spaceborne hyperspectral imaging systems have advanced in recent years in terms of spectral and spatial resolution, which makes data sets produced by them a valuable source for land-cover classification. The availability of hyper-spectral data with fine spatial resolution has revolutionized hyperspectral image classification techniques by taking advantage of both spectral and spatial information in a single classification framework. The ECHO (Extraction and Classification of Homogeneous Objects) classifier, which was proposed in 1976, might be the first spectral-spatial classification approach of its kind in the remote sensing community. Since then and especially in the latest years, increasing attention has been dedicated to developing sophisticated spectral-spatial classification methods. There is now a rich literature on this particular topic in the remote sensing community, composing of several fast-growing branches. In this paper, the latest advances in spectral-spatial classification of hyperspectral data are critically reviewed. More than 25 approaches based on mathematical morphology, Markov random fields, segmentation, sparse representation, and deep learning are addressed with an emphasis on discussing their methodological foundations. Examples of experimental results on three benchmark hyperspectral data sets, including both well-known long-used data and a recent data set resulting from an international contest, are also presented. Moreover, the utilized training and test sets for the aforementioned data sets as well as several codes and libraries are also shared online with the community.",
        "references": [
            "bd7d537f837cd33f7b5b5d650e4850fabb8492c7",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "26cbdee3e90d700748c5cacad1b8f5be9ff83492",
            "3bd7071028c01228d1bc78532c25e719cc658fa5",
            "f1c06eff47412b5b79cdf5afda9312d089a8b74d",
            "70369818d03b0bba2f2e7b7ef401d5ba985bf84d",
            "ad509bf739ddeac0bdbc0b509222ba29c3e26a6f",
            "099e4fefdd417b73ab2147d84c965ae4bbb47a82",
            "92261e8f1ab997a33892322c3231afc76b2d3158"
        ],
        "related_topics": [
            "Remote-sensing Community",
            "Spectral-Spatial Classification",
            "Hyperspectral Data",
            "Benchmark Hyperspectral Data Sets",
            "Mathematical Morphology",
            "Markov Random Field",
            "Deep Learning",
            "Frontiers",
            "Sparse Representation",
            "IEEE Geoscience"
        ],
        "reference_count": "166",
        "citation_count": "28"
    },
    {
        "Id": "a80b169a86da15040d41033368a07ab052f4315d",
        "title": "Recent Advances on Spectral\u2013Spatial Hyperspectral Image Classification: An Overview and New Guidelines",
        "authors": [
            "Lin He",
            "Jun Yu Li",
            "Chenying Liu",
            "Shutao Li"
        ],
        "date": "1 March 2018",
        "abstract": "A concept of spatial dependency system that involves pixel dependency and label dependency, with two main factors: neighborhood covering and neighborhood importance is developed, and several representative spectral\u2013spatial classification methods are applied on real-world hyperspectral data. Imaging spectroscopy, also known as hyperspectral imaging, has been transformed in the last four decades from being a sparse research tool into a commodity product available to a broad user community. Specially, in the last 10 years, a large number of new techniques able to take into account the special properties of hyperspectral data have been introduced for hyperspectral data processing, where hyperspectral image classification, as one of the most active topics, has drawn massive attentions. Spectral\u2013spatial hyperspectral image classification can achieve better classification performance than its pixel-wise counterpart, since the former utilizes not only the information of spectral signature but also that from spatial domain. In this paper, we provide a comprehensive overview on the methods belonging to the category of spectral\u2013spatial classification in a relatively unified context. First, we develop a concept of spatial dependency system that involves pixel dependency and label dependency, with two main factors: neighborhood covering and neighborhood importance. In terms of the way that the neighborhood information is used, the spatial dependency systems can be classified into fixed, adaptive, and global systems, which can accommodate various kinds of existing spectral\u2013spatial methods. Based on such, the categorizations of single-dependency, bilayer-dependency, and multiple-dependency systems are further introduced. Second, we categorize the performings of existing spectral\u2013spatial methods into four paradigms according to the different fusion stages wherein spatial information takes effect, i.e., preprocessing-based, integrated, postprocessing-based, and hybrid classifications. Then, typical methodologies are outlined. Finally, several representative spectral\u2013spatial classification methods are applied on real-world hyperspectral data in our experiments.",
        "references": [
            "b994ba36364e8e61514d1a87002442ce9ab03d33",
            "bd7d537f837cd33f7b5b5d650e4850fabb8492c7",
            "26cbdee3e90d700748c5cacad1b8f5be9ff83492",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "70369818d03b0bba2f2e7b7ef401d5ba985bf84d",
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "e616132691824d6eec92b0eb4560b286d732582b",
            "f9d119346b0773ea83251598fa5305bc75bac8ab",
            "23399225034cdf7e1edb9c6df5ce982b838b4f24",
            "2fa3781b4123461a33cfe3cfb11a457b806b0bfc"
        ],
        "related_topics": [
            "Spectral-spatial Methods",
            "Hyperspectral Image Classification",
            "Spectral-Spatial Classification",
            "Hyperspectral Data",
            "Imaging Spectroscopy",
            "Real-world Hyperspectral Data",
            "Spectral Signatures",
            "Label Dependencies"
        ],
        "reference_count": "143",
        "citation_count": "403"
    },
    {
        "Id": "c143884854158f4af2b09d8da21679f0f8da6b9c",
        "title": "Hyperspectral Image Classification Based on Spectral and Spatial Information Using Multi-Scale ResNet",
        "authors": [
            "Zongwei Wang",
            "Qiming Xia",
            "Jingfeng Yan",
            "Shuxing Xuan",
            "Jingyi Su",
            "Cheng-Fu Yang"
        ],
        "date": "14 November 2019",
        "abstract": "To make full use of HSI information, spectral and spatial information is combined into a two-dimension image in a particular order by extracting a data cube and unfolding it by using a convolutional neural network. Hyperspectral imaging (HSI) contains abundant spectrums as well as spatial information, providing a great basis for classification in the field of remote sensing. In this paper, to make full use of HSI information, we combined spectral and spatial information into a two-dimension image in a particular order by extracting a data cube and unfolding it. Prior to the step of combining, principle component analysis (PCA) is utilized to decrease the dimensions of HSI so as to reduce computational cost. Moreover, the classification block used during the experiment is a convolutional neural network (CNN). Instead of using traditionally fixed-size kernels in CNN, we leverage a multi-scale kernel in the first convolutional layer so that it can scale to the receptive field. To attain higher classification accuracy with deeper layers, residual blocks are also applied to the network. Extensive experiments on the datasets from Pavia University and Salinas demonstrate that the proposed method significantly improves the accuracy in HSI classification.",
        "references": [
            "ba14fa8493a1919903c6b9ab047a86448f7e2559",
            "56124ac676391d1c6a94cee9d0b39155d06941ee",
            "10fb16414324a5db44f5d830adcb4810af59eed0",
            "a40d966b211f4c1b601ccbbc4ef04a8ab7ad432a",
            "8027c90cad2c41275c96ed058e4c90c7426ace0b",
            "be00ddea81933a280aaf3dda486aa12cb374f5c1",
            "b4891152b7291a204d30a4786f25ea6846635c4b",
            "1980b95cb09b8415aec873f8f9ff7a0565f84694",
            "a80b169a86da15040d41033368a07ab052f4315d",
            "9d61959a159a0007fe94d86d4d03b05f4205db47"
        ],
        "related_topics": [],
        "reference_count": "52",
        "citation_count": "13"
    },
    {
        "Id": "1c3374d6d816e8c8b205e20c08969350d4e0ac00",
        "title": "Shearlet-Based Region Map Guidance for Improving Hyperspectral Image Classification",
        "authors": [
            "Mariem Zaouali",
            "Sonia Bouzidi",
            "Ezzeddine Zagrouba"
        ],
        "date": "18 September 2017",
        "abstract": "A Shearlet-based Region Map Joint Sparse Representation (RM-JSR), where the objective is to elaborate a map of edge-surrounded partitions, each having a unique label and each referring to a single land cover. The inclusion of the spatial context in Hyperspectral Images\u2019 classification tasks has widely proved its efficiency. However, when the neighboring pixels do not represent the same land cover, considering all of them might confuse the classifier and decrease the classification accuracy. To overcome this issue, we propose a Shearlet-based Region Map Joint Sparse Representation (RM-JSR), where the objective is to elaborate a map of edge-surrounded partitions, each having a unique label and each referring to a single land cover. To do so, we first decompose the image using Shearlet Transform. Next, we select the finest scale of the obtained decomposition, where we generally find the salient information about the edges. Then, we carry out a K-means algorithm to segregate the coefficients of the kept scale into edge and not-edge clusters. Afterwards, we apply the Inverse Shearlet Transform and create an image by fusing only the reconstructed edge bands. Finally, we apply a threshold in order to get the region map where homogeneous regions are well delimited. Into the objective function of JSR, we inject the proposed Region Map via Hadamard product. This way, we guide the Simultaneous Orthogonal Matching Pursuit (SOMP), an implementation of the JSR paradigm, in an attempt to overcome its fixed window issue. Compared to other methods attempting to solve this problem, our proposed method achieves better overall classification accuracies.",
        "references": [
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "cafbdf6b8d7f38f0a6e0543dbcf20299f20e71c1",
            "e30fcfa9e0e8c7d03315848e823781b7a72203ef",
            "4db744cf8c986b57838727fe4368fbaae052ad2b",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "caf7f59b6d0f6736a0367513131a0b1ac65fbd1d",
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "ce5d552f724171b5f47476dd5325b9cd1e252a3f",
            "14b64bb5af95367883abd2b95d95979f87bcd5f0"
        ],
        "related_topics": [
            "Simultaneous Orthogonal Matching Pursuit",
            "Classification Task",
            "Classifier",
            "Hyperspectral Image Classification",
            "Classification Accuracy"
        ],
        "reference_count": "16",
        "citation_count": "2"
    },
    {
        "Id": "12f63dcca127cea8751f88f5f126d16eed6406c5",
        "title": "Hyperspectral image classification via nonlocal joint kernel sparse representation based on local covariance",
        "authors": [
            "Dan Li",
            "Fanqiang Kong",
            "Qiang Wang"
        ],
        "date": "1 March 2021",
        "abstract": "Semantic Scholar extracted view of \"Hyperspectral image classification via nonlocal joint kernel sparse representation based on local covariance\" by Dan Li et al.",
        "references": [
            "fe5d95b071523bf10f1ce7f6773756ef2140e54a",
            "097615d18c38ec8ed986a7af586d38d804eee482",
            "3fe9f6d9c3b06d3fbff82cdec63ff48be71a1922",
            "6007a8fdc7ccfc5975f7760db1a4f8831c36193a",
            "a1c1b2b789c7a43ccb415482f5b783a6831c46a3",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "c52e31f7113d8b3070b1757626970b63feb17b84",
            "55c94bc8a640477b313bd28bcf8e5585d15a53b5",
            "a9610716093b796c1241dfef6493b0881f139143",
            "6f6fab0f31e7a5116086cc29d71e42ab51059e47"
        ],
        "related_topics": [
            "Classification",
            "Hyperspectral Imagery",
            "Maximum Noise Fraction",
            "Loop-Closure Detection",
            "Local Spatial Information",
            "Superpixels",
            "Computational Complexity",
            "Sparse Representation",
            "Spectral-spatial Information",
            "Local Covariance Descriptor"
        ],
        "reference_count": "69",
        "citation_count": "6"
    },
    {
        "Id": "28f3446718da6fed450bded33576322bd8d60448",
        "title": "Hyperspectral Image Classification Based on Sparse Modeling of Spectral Blocks",
        "authors": [
            "Saeideh Ghanbari Azar",
            "Saeed Meshgini",
            "Tohid Yousefi Rezaii",
            "Soosan Beheshti"
        ],
        "date": "17 May 2020",
        "abstract": "Semantic Scholar extracted view of \"Hyperspectral Image Classification Based on Sparse Modeling of Spectral Blocks\" by Saeideh Ghanbari Azar et al.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "adfd2883433e457c7e5167121714c81247cb4e15",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "541ebe34978254e0717bd3f59087e20c861a6753",
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "10fb16414324a5db44f5d830adcb4810af59eed0"
        ],
        "related_topics": [
            "Spatial Redundancy",
            "Benchmark Dataset",
            "Computational Complexity",
            "Classification Accuracy",
            "Classification",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "38",
        "citation_count": "15"
    },
    {
        "Id": "66a3311810b032552261547c4358cf09ad9975a3",
        "title": "Spectral-Spatial Discriminant Feature Learning for Hyperspectral Image Classification",
        "authors": [
            "Chunhua Dong",
            "Masoud Naghedolfeizi",
            "Dawit Aberra",
            "Xiangyan Zeng"
        ],
        "date": "29 June 2019",
        "abstract": "A novel discriminant feature learning (DFL) method, which combines spectral and spatial information into a hypergraph Laplacian, which increases classification accuracy and outperforms the state-of-the-art HSI classification methods. Sparse representation classification (SRC) is being widely applied to target detection in hyperspectral images (HSI). However, due to the problem in HSI that high-dimensional data contain redundant information, SRC methods may fail to achieve high classification performance, even with a large number of spectral bands. Selecting a subset of predictive features in a high-dimensional space is an important and challenging problem for hyperspectral image classification. In this paper, we propose a novel discriminant feature learning (DFL) method, which combines spectral and spatial information into a hypergraph Laplacian. First, a subset of discriminative features is selected, which preserve the spectral structure of data and the inter- and intra-class constraints on labeled training samples. A feature evaluator is obtained by semi-supervised learning with the hypergraph Laplacian. Secondly, the selected features are mapped into a further lower-dimensional eigenspace through a generalized eigendecomposition of the Laplacian matrix. The finally extracted discriminative features are used in a joint sparsity-model algorithm. Experiments conducted with benchmark data sets and different experimental settings show that our proposed method increases classification accuracy and outperforms the state-of-the-art HSI classification methods.",
        "references": [
            "383a5b15bf4eee3084b21f260c97be2e23b9a5b6",
            "7491d3a4351ddbab9e86f9e37d7117f22e85d4e1",
            "f5f9dbf8b8537445adc4824d0a427c0138fba457",
            "dc04c67856452d30babac6b80e8615eefcb0df6b",
            "9d726968a3c2c2238c561cf72a4aaa625d8f1eab",
            "dc9133713408074dea75d5e9403d636a924d4174",
            "6197e7aad7aeebfcca8601162986252e07c7a1de",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "d80e7c2280caf016404ffa02469b331e755cfc7b",
            "b48173ede760f64fd3724dc44ad3f9f39c4e9aaf"
        ],
        "related_topics": [
            "Hypergraph Laplacian",
            "Sparse Representation Based Classification",
            "Hyperspectral Imagery",
            "High-dimensional Data",
            "Spectral-Spatial",
            "Semi-Supervised Learning",
            "Device-free Localization",
            "Laplacian Matrices",
            "Classification Accuracy",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "71",
        "citation_count": "6"
    },
    {
        "Id": "1bce20f54f1206444f742c08e46e55b9e852c134",
        "title": "Low-Rank and Sparse Representation for Hyperspectral Image Processing: A review",
        "authors": [
            "Jiangtao Peng",
            "Weiwei Sun",
            "Hengchao Li",
            "Wei Li",
            "Xiangchao Meng",
            "Chiru Ge",
            "Qian Du"
        ],
        "date": "1 March 2022",
        "abstract": "Combining rich spectral and spatial information, a hyperspectral image (HSI) can provide a more comprehensive characterization of the Earth\u2019s surface. To better exploit HSIs, a large number of algorithms have been developed during the past few decades. Due to their very high correlation between spectral channels and spatial pixels, HSIs have intrinsically sparse and low-rank structures. The sparse representation (SR) and low-rank representation (LRR)-based methods have proven to be powerful tools for HSI processing and are widely used in different HS fields. In this article, we present a survey of low-rank and sparse-based HSI processing methods in the fields of denoising, superresolution, dimension reduction, unmixing, classification, and anomaly detection. The purpose is to provide guidelines and inspiration to practitioners for promoting the development of HSI processing. For a listing of the key terms discussed in this article, see \u201cNomenclature.\u201d",
        "references": [
            "735098a8698acb1ed6b2eb2c29c90018296c4aac",
            "37531995a09f038db1b253dea60a242810554da2",
            "75cbea9d8ba5ae1835d98f9ef65048c83edab8f5",
            "af17ed0986f11c08134426dfb46bd0496d74a3f1",
            "8dbb81ceac324975bf4c2cbc80b08ed3c91ad932",
            "ca39d6e0c6d942ae95f58d50835173560a1a022f",
            "7b58944e3b344d019f660bd2b78d3ede38f94ce6",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "29580626129d00992feac5dbbccbe5a538b3caa8",
            "a1ea3408b4131134c6c55fcaa74d94ef6347f29e"
        ],
        "related_topics": [
            "Testing Pixel",
            "Hyperspectral Imagery",
            "HSIs",
            "Sparse Representation",
            "Superresolution",
            "Unmixing",
            "Classification",
            "Denoising",
            "Anomaly Detection",
            "Low-rank"
        ],
        "reference_count": "225",
        "citation_count": "79"
    },
    {
        "Id": "097615d18c38ec8ed986a7af586d38d804eee482",
        "title": "Adaptive kernel sparse representation based on multiple feature learning for hyperspectral image classification",
        "authors": [
            "Dan Li",
            "Qiang Wang",
            "Fanqiang Kong"
        ],
        "date": "4 August 2020",
        "abstract": "Semantic Scholar extracted view of \"Adaptive kernel sparse representation based on multiple feature learning for hyperspectral image classification\" by Dan Li et al.",
        "references": [
            "a1c1b2b789c7a43ccb415482f5b783a6831c46a3",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "5154456c5b0b82206005f3df9fc4b478174db1ff",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "f9b6242f8e9d5f7f9e31214444290f812889f946",
            "7885a3cbd0aa4f1270a282457223d4379d5f04f0",
            "fff45cbbb315fffb4c72d8459fcd9fe28a87519c",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "06ea70d7f3f6a9991e0b977069443c817f836802"
        ],
        "related_topics": [
            "Base Kernels",
            "Multiple Feature Learning",
            "Multiple Kernel Learning",
            "Pixel",
            "Hyperspectral Image Classification",
            "Composite Kernels",
            "Feature Descriptors",
            "Shape-adaptive Region",
            "Classification Accuracy"
        ],
        "reference_count": "44",
        "citation_count": "24"
    },
    {
        "Id": "b1ab763e25ebc3127042a08191ed9cdd3ebd0c12",
        "title": "Locally Homogeneous Covariance Matrix Representation for Hyperspectral Image Classification",
        "authors": [
            "Xinyu Zhang",
            "Yantao Wei",
            "Huang Yao",
            "Zhijing Ye",
            "Yicong Zhou",
            "Yue Zhao"
        ],
        "date": "2021",
        "abstract": "A new spectral\u2013spatial feature extraction method called locally homogeneous covariance matrix representation (CMR) is proposed for the fusion of spectral and spatial information and is superior to several state-of-the-art methods when the training set is very limited. Combining spectralandspatial information has been proven to be an effective way for hyperspectral image (HSI) classification. However, making full use of spectral\u2013spatial information of HSI still remains an open problem, especially when only a small number of labeled samples are available. In this article, a new spectral\u2013spatial feature extraction method called locally homogeneous covariance matrix representation (CMR) is proposed for the fusion of spectral and spatial information. Specially, to make use of neighborhood homogeneity of land covers, original HSI is first segmented into many superpixels using modified entropy rate superpixel segmentation. Then, to acquire the most similar pixels, we propose to construct neighborhoods of each pixel from the overlapping areas between the corresponding superpixels and the sliding window centered on it. Subsequently, CMRs of different pixels can be obtained. In the classification stage, we fed the obtained CMRs into SVM with Log-Euclidean-based kernel for classification. Compared to the traditional approach that utilizes neighboring information only within a fixed window, the proposed local homogeneity strategy can absorb more discriminative spectral\u2013spatial features. Experimental results from a series of available HSI datasets show that our proposed method is superior to several state-of-the-art methods, especially when the training set is very limited.",
        "references": [
            "72d23627cd6af8a972e7163846646a2124da58e4",
            "fcb3ed16fcd372079570843fe2f462d16f8890c5",
            "c1f0cccf7ee68be4e1537fc0f0bef2f80083e0c1",
            "d80e7c2280caf016404ffa02469b331e755cfc7b",
            "a9b7940102173ca5b8cf69337b579ba5fa13bfee",
            "95bad7fd2d94ff329100aa4701248b7a34b8801b",
            "a80b169a86da15040d41033368a07ab052f4315d",
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "a03865b5a3b30ea301e00ecc926761ccc23e9c0c",
            "43035d1033fe8eef6c4e81dd063bb5094010426d"
        ],
        "related_topics": [
            "Classification",
            "Hyperspectral Imagery",
            "Superpixels",
            "Support Vector Machines",
            "Training Set",
            "Spectral-Spatial Feature Extraction",
            "Discriminative Spectral-spatial Features",
            "Sliding-window",
            "Hyperspectral Image Classification",
            "Cross-modal Retrieval"
        ],
        "reference_count": "47",
        "citation_count": "4"
    },
    {
        "Id": "fe5d95b071523bf10f1ce7f6773756ef2140e54a",
        "title": "Superpixel-feature-based multiple kernel sparse representation for hyperspectral image classification",
        "authors": [
            "Dan Li",
            "Qiang Wang",
            "Fanqiang Kong"
        ],
        "date": "1 November 2020",
        "abstract": "Semantic Scholar extracted view of \"Superpixel-feature-based multiple kernel sparse representation for hyperspectral image classification\" by Dan Li et al.",
        "references": [
            "bb471c3d674203585cfa3b4c3e1b1b2c40347468",
            "f59d79f5ab81718cf5fa7bfaf2be635451d7953f",
            "a1c1b2b789c7a43ccb415482f5b783a6831c46a3",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "cbc1676c5bce7a0fc75b7e859434ccb6b44601f7",
            "7d0d0de237c25e3ef2cd81cd1216eccd00483fd5",
            "f9b6242f8e9d5f7f9e31214444290f812889f946",
            "c52e31f7113d8b3070b1757626970b63feb17b84",
            "cb28d58a24ea2cc51928d898f89ff907a16e8c17",
            "33d81ab009ffb712be8b9d025e75510a07e4c8e7"
        ],
        "related_topics": [
            "Superpixels",
            "Base Kernels",
            "SSRC",
            "Hyperspectral Imagery",
            "Computational Complexity",
            "Hyperspectral Image Classification",
            "Multiple Kernels",
            "High Dimensional Feature Space",
            "Composite Kernels",
            "Sparse Representation"
        ],
        "reference_count": "63",
        "citation_count": "18"
    },
    {
        "Id": "a6299a9749dacc84fbd0da30cbb62ad739f98e98",
        "title": "Nonlocal Correntropy Matrix Representation for Hyperspectral Image Classification",
        "authors": [
            "Guochao Zhang",
            "Xueting Hu",
            "Yantao Wei",
            "Weijia Cao",
            "Huang Yao",
            "Xueyang Zhang",
            "Keyi Song"
        ],
        "date": "2023",
        "abstract": "The results show that NLCM performs better than the state-of-the-art methods, especially when the training set size is small, and the experimental results demonstrate that the proposed method outperforms compared methods significantly when the land covers are complex and with irregular distributions. Hyperspectral image (HSI) classification is a hot topic in the remote sensing community. However, it is challenging to fully use spatial\u2013spectral information for HSI classification due to the high dimensionality of the data, high intraclass variability, and the limited availability of training samples. To deal with these issues, we propose a novel feature extraction method called nonlocal correntropy matrix (NLCM) representation in this letter. NLCM can characterize the spectral correlation and effectively extract discriminative features for HSI classification. We verify the effectiveness of the proposed method on two widely used datasets. The results show that NLCM performs better than the state-of-the-art methods, especially when the training set size is small. Furthermore, the experimental results also demonstrate that the proposed method outperforms compared methods significantly when the land covers are complex and with irregular distributions.",
        "references": [
            "96df413552e64b6d534bae8ad6941c60c72e7dae",
            "70416780b69ea348f7d08784be27af1000117601",
            "db897f7f7123a43403d0cf90a93126d64c225a73",
            "7252d0ccf410e7bc3e60a522b408ee7de073b546",
            "bdd57e49191329bac20caa48f3405ac111bf0842",
            "d80e7c2280caf016404ffa02469b331e755cfc7b",
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "fa30b07c6cf018e46e093f1901b4e9d26c1b8e95",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "fff45cbbb315fffb4c72d8459fcd9fe28a87519c"
        ],
        "related_topics": [
            "Classification",
            "Hyperspectral Imagery",
            "Hyperspectral Image Classification",
            "Spatial-spectral Information"
        ],
        "reference_count": "0",
        "citation_count": "16"
    },
    {
        "Id": "f7773291ef557d97be57ee9ad267fae1fd8d0415",
        "title": "A Hyperspectral Image Classification Method Based on Weight Wavelet Kernel Joint Sparse Representation Ensemble and \u03b2-Whale Optimization Algorithm",
        "authors": [
            "Mingwei Wang",
            "Zitong Jia",
            "Jianwei Luo",
            "Maolin Chen",
            "Shuping Wang",
            "Zhiwei Ye"
        ],
        "date": "2021",
        "abstract": "Experimental results indicate that the performance of the proposed HSI classification method is better than that of other newly proposed and corresponding approaches, the misclassification and classified noise are eliminated to some extent, and the overall classification accuracy reaches 95% for all HSIs. Joint sparse representation (JSR) is a commonly used classifier that recognizes different objects with core features extracted from images. However, the generalization ability is weak for the traditional linear kernel, and the objects with similar feature values associated with different categories are not sufficiently distinguished especially for a hyperspectral image (HSI). In this article, an HSI classification technique based on the weight wavelet kernel JSR ensemble model and the <inline-formula><tex-math notation=\"LaTeX\">$\\beta$</tex-math></inline-formula>-whale optimization algorithm is proposed to conduct pixel-level classification, where the wavelet function is acted as the kernel of JSR. Moreover, ensemble learning is used to determine the category label of each sample by comprehensive decision of some subclassifiers, and the <inline-formula><tex-math notation=\"LaTeX\">$\\beta$</tex-math></inline-formula> function is utilized to enhance the exploration phase of the whale optimization algorithm and obtain the optimal weight of subclassifiers. Experimental results indicate that the performance of the proposed HSI classification method is better than that of other newly proposed and corresponding approaches, the misclassification and classified noise are eliminated to some extent, and the overall classification accuracy reaches 95% for all HSIs.",
        "references": [
            "23a9bd498d1b3570d0d5909425e3fa1b2245fe6e",
            "41ea49891cd4c42f537daa3a7c1cd76c23e839a2",
            "c11c86f46fa1b42257ea72591792b1dd79e809e6",
            "5eedce1d237644595dfd760ede97fade512ba5f0",
            "8d49bde32781b51cc8b7d6d73a835ce41e3da8df",
            "6d3c31339a10956aa38cdd6b0c71d7b513709073",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "78f7782d6e9017d72b31907b53b4925bb4e6cde1",
            "55d5b6e8971fd7793c4a833a7bb75e92a589511e",
            "08884fbf871f5e31a71573dcc61c1492714b25f4"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Joint Spectral Radius",
            "HSIs",
            "Kernels",
            "Classifier",
            "Category Labels",
            "Hyperspectral Image Classification",
            "Classification Accuracy"
        ],
        "reference_count": "50",
        "citation_count": "4"
    },
    {
        "Id": "bc7a0142969937f68f78ed390178311bd06d08e3",
        "title": "Spatial-Aware Network for Hyperspectral Image Classification",
        "authors": [
            "Yantao Wei",
            "Yicong Zhou"
        ],
        "date": "14 August 2021",
        "abstract": "An efficient deep learning-based HSI classification method, namely, spatial-aware network (SANet), which is able not only to aware local spatial structures using side window filtering framework, but also to learn discriminative features making use of the hierarchical architecture and limited label information. Deep learning is now receiving widespread attention in hyperspectral image (HSI) classification. However, due to the imbalance between a huge number of weights and limited training samples, many problems and difficulties have arisen from the use of deep learning methods in HSI classification. To handle this issue, an efficient deep learning-based HSI classification method, namely, spatial-aware network (SANet) has been proposed in this paper. The main idea of SANet is to exploit discriminative spectral-spatial features by incorporating prior domain knowledge into the deep architecture, where edge-preserving side window filters are used as the convolution kernels. Thus, SANet has a small number of parameters to optimize. This makes it fit for small sample sizes. Furthermore, SANet is able not only to aware local spatial structures using side window filtering framework, but also to learn discriminative features making use of the hierarchical architecture and limited label information. The experimental results on four widely used HSI data sets demonstrate that our proposed SANet significantly outperforms many state-of-the-art approaches when only a small number of training samples are available.",
        "references": [
            "c02ce3f65e60ce69e039b1dd4c6f99244f74b58f",
            "4f71ab367eb37cfd145d41327f7bb14077e5e7c5",
            "16a7a491bb9194d38bfe3b2f6ce7a68b404fcf7d",
            "bdd57e49191329bac20caa48f3405ac111bf0842",
            "ba9c973ef7c3c693d7769760517cb6038f712a3d",
            "1701daaccd6a5a5ff882b64dd5534988788e32f5",
            "75f5810ba25abdaa324890a7c4857dcdc35605ea",
            "4a9bc2ef17b211ede1dc73ac9b24a31612f88735",
            "0eb1a16a4ad26f217547c65e32790d09cf3454a3",
            "f9d119346b0773ea83251598fa5305bc75bac8ab"
        ],
        "related_topics": [
            "SANet",
            "Deep Learning",
            "Classification",
            "Hyperspectral Imagery",
            "Deep Architectures",
            "Parameters",
            "Hyperspectral Image Classification",
            "Spectral-spatial Features"
        ],
        "reference_count": "62",
        "citation_count": "6"
    },
    {
        "Id": "844012b752d1ff68b800a686a9480d752239af38",
        "title": "One-Class Classification of Remote Sensing Images Using Kernel Sparse Representation",
        "authors": [
            "Benqin Song",
            "Peijun Li",
            "Jun Yu Li",
            "Antonio J. Plaza"
        ],
        "date": "26 January 2016",
        "abstract": "A novel method for one-class classification (OCC) using a kernel sparse representation model for remotely sensed imagery and results indicate that the proposed method outperforms these existing methods, particularly when using a Kernel sparse representation. Sparse representations have been widely studied in remote sensing image analysis in recent years. In this paper, we develop a novel method for one-class classification (OCC) using a kernel sparse representation model for remotely sensed imagery. Training samples taken from the target class alone are used to build a learning dictionary for the sparse representation model, which is then optimized to produce a reconstruction residual. In the proposed model, a pixel is classified as the target class if the obtained reconstruction residual for the pixel is smaller than a given threshold; otherwise, the pixel is labeled as the outlier class. To improve the data separability between the target and outliner classes, the training samples taken from the target class are mapped into a high-dimensional feature space using a kernel function to build a learning dictionary for the kernel sparse representation model. OCC is then conducted in the mapped high-dimensional feature space using the reconstruction residual threshold, following the same principle as OCC in the original feature space. The proposed OCC method is evaluated and compared with several existing OCC methods in three different case studies. The experimental results indicate that the proposed method outperforms these existing methods, particularly when using a kernel sparse representation.",
        "references": [
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "7fc0624d3161c51f03bf496065a1ccb9f05caa45",
            "a87f0358993d9d24eb9f52f8534c60be9a213503",
            "11ad2a3ed2fdd58a9b81fc334fe45ab1630f9793",
            "6f5080b0b66ccb4deedbc1c4bfc655e84d951a07",
            "a00c49eebbe4aa82cf4429954b9994a3c01631fa",
            "8c7e9d9bc9009fd5ca7028af6e37f3851af1ad6b",
            "2749d31dd2aa439546dffa26385ca7e9c1c3e5bb",
            "e99a64357a4f38063bc3206cb9266443a0d1f0b4"
        ],
        "related_topics": [
            "One-class Classification",
            "Pixel",
            "High Dimensional Feature Space",
            "Target Class",
            "Kernel Sparse Representation",
            "Sparse Representation",
            "OCC Methods"
        ],
        "reference_count": "50",
        "citation_count": "42"
    },
    {
        "Id": "58fb3a43e030080425a3449b20e39708e44c1be6",
        "title": "A comprehensive review on sparse representation for image classification in remote sensing",
        "authors": [
            "N R Bhuvaneswari",
            "V. Sivakumar"
        ],
        "date": "1 October 2016",
        "abstract": "This issue demands a detailed collection of information extraction algorithms which would be remarkably valuable for the researchers who are new to the field of high resolution remote sensing data in selecting a suitable classification technique. The main objective of this paper is to provide a comprehensive study on Sparse Representation based feature extraction techniques in the image classification domain. Sparse Representation (SR) plays a vital role in both theoretical research and practical applications. The Sparse Representation being image dependent has become a broadly used feature extraction technique that represents the signal or image under study. Considering the feature extraction techniques, this review article includes the work involving Multikernel Fusion Sparse Representation. A successful classification of remote sensing data is a huge challenge because many factors belong to the appropriate selection of remote sensing data, image pre-processing and processing methods may result in improper results. This issue demands a detailed collection of information extraction algorithms which would be remarkably valuable for the researchers who are new to the field of high resolution remote sensing data in selecting a suitable classification technique. This paper concentrates on recapitulating all the possible information extraction techniques for image classification in remote sensing images.",
        "references": [
            "a87f0358993d9d24eb9f52f8534c60be9a213503",
            "6c1dd5cd7468d05a936fa63877a035223884606a",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "0033c0015f6957123e46f10772de5228f4e3a5cf",
            "e0932bb68dbafe68b5636ccf93c6d7c03afcb4c1",
            "7fda3b7e173936bc8acbafc7f2963c10675939d8",
            "f19122b082188e626ff8355cfcaa432e68509272",
            "677dc448f1dcb487afbf6133c1f2b98a49941102",
            "3b8aec6dd10984b732562af220e4c028354ab283",
            "281db9a96aca09678f5371c4ff6ce9515b91d67f"
        ],
        "related_topics": [
            "Sparse Representation"
        ],
        "reference_count": "31",
        "citation_count": "5"
    },
    {
        "Id": "0639f5bd64e816d1bcdf56ae988080c30d79f885",
        "title": "Sparse Representation For Image Classification",
        "authors": [
            "Arockia Panimalar",
            "Thanga Balu",
            "Aswin George Willy"
        ],
        "date": "2017",
        "abstract": "This issue requests a point by point gathering of information extraction algorithms which would be strikingly valuable for the researchers who are new to the field of high resolution remote sensing data in choosing an appropriate classification technique. The primary target of this paper is to give a complete report on Sparse Representation based feature extraction techniques in the image classification domain. Sparse Representation (SR) assumes a fundamental part in both theoretical research and practical applications. The Sparse Representation being image dependent has turned into a comprehensively utilized feature extraction technique that speaks to the signal or image under study. Considering the feature extraction techniques, this article incorporates the work including Multikernel Fusion Sparse Representation. An effective grouping of remote sensing data is a colossal test on the grounds that many components have a place with the proper selection of remote sensing data, image pre-processing and processing methods may result in improper results. This issue requests a point by point gathering of information extraction algorithms which would be strikingly valuable for the researchers who are new to the field of high resolution remote sensing data in choosing an appropriate classification technique. This paper focuses on restating all the possible information extraction techniques for image classification in remote sensing images.",
        "references": [
            "a87f0358993d9d24eb9f52f8534c60be9a213503",
            "0033c0015f6957123e46f10772de5228f4e3a5cf",
            "7fda3b7e173936bc8acbafc7f2963c10675939d8",
            "8185be0689442db83813b49e215bf30870017459",
            "f4106ee9cde073f89263aa417434bea09c094e71",
            "49f366a1bdc3807efc9899ceb2a91e758f929fc3",
            "3b8aec6dd10984b732562af220e4c028354ab283",
            "3e32b4775f3aeff0e1eaf37cc46771376a0c8d08",
            "b005ec0c615e765889cf457f4f5f0be4454ea261",
            "91ead9cd5f2a51d384106b1384662ff9e61a9208"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "18"
    },
    {
        "Id": "c29ce44ff24c41cede13d4955a5e29d04bf72169",
        "title": "Spectral-spatial multi-feature classification of remote sensing big data based on a random forest classifier for land cover mapping",
        "authors": [
            "Xiaomei Zhang",
            "Guo-jin He",
            "Zhao-ming Zhang",
            "Yan Peng",
            "Tengfei Long"
        ],
        "date": "3 June 2017",
        "abstract": "The results showed that utilizing random sampling, multi-temporal spectral image and texture features, the classification of the Wuhan urban agglomeration, China, using RF performed well and demonstrated that the type of textural features was extremely important for intra-class separability. Supplementary information, such as multi-temporal spectral data and textural features, has the potential to improve land cover classification accuracy. However, given the larger volumes of remote sensing data, it is difficult to utilize all the features of remote sensing big data having different times and spatial resolutions. Inefficiency is also a large problem when dealing with large area land cover mapping. In this study, a new mode of incorporating spatial and temporal dependencies in a complex region employing the random forests (RFs) classifier was utilized. To map land covers, spring and autumn spectral images and their spectral indexes, textural features obtained from Landsat 5 were selected, and an importance measure variable was used to reduce the data\u2019s dimension. In addition to randomly selecting the variable, we used random sampling to furthest decrease the generalization error in RF. The results showed that utilizing random sampling, multi-temporal spectral image and texture features, the classification of the Wuhan urban agglomeration, China, using RF performed well. The RF algorithm yielded an overall accuracy of 89.2% and a Kappa statistic of 0.8522, indicating high model performance. In addition, the variable importance measures demonstrated that the type of textural features was extremely important for intra-class separability. The RF model has transitivity. The algorithm can be extended by choosing a set of appropriate features for signature extension over large areas or in time-series of Landsat imagery. Land cover mapping might be more economical and efficient if no-cost imagery is used.",
        "references": [
            "fc1d6787cbd6f0fb5089bbe29f402d28ce438702",
            "fc8b5280630996a90c4ca613ef1c29fed1fc0171",
            "2e37205d9d699622a505d4f02cb3a07365a73d53",
            "99b4ca6bf41bb6f3e56ce417e958fc9ed61e7442",
            "13dd43463710f0b5039fb93f7a9eda29d2d72f89",
            "8f4ede94cc61d9af2cad826d209dfc3a0521dabd",
            "b801af56e1c96ca924f553fd49ac609bdecac080",
            "fc6f99aa02d445dea082ad829c8caa966d2b24e0",
            "1603f64116c544c97e16b29c3ff7fd06f25b4ae6",
            "ccdf098fd7d0ae80895b700da36b112832015d8a"
        ],
        "related_topics": [
            "Textural Features",
            "Generalization Error",
            "Spectral-Spatial",
            "Model Performance",
            "Kappa Statistic"
        ],
        "reference_count": "45",
        "citation_count": "33"
    },
    {
        "Id": "eaa76e406fc2c7dfa12138c11a38f23e9cf0f639",
        "title": "Spectral-spatial multi-feature classification of remote sensing big data based on a random forest classifier for land cover mapping",
        "authors": [
            "X. M. Zhang",
            "Guo-jin He",
            "Z. Zhang",
            "Yan Peng",
            "Tengfei Long"
        ],
        "date": "3 June 2017",
        "abstract": "The results showed that utilizing random sampling, multi-temporal spectral image and texture features, the classification of the Wuhan urban agglomeration, China, using RF performed well and demonstrated that the type of textural features was extremely important for intra-class separability. Supplementary information, such as multi-temporal spectral data and textural features, has the potential to improve land cover classification accuracy. However, given the larger volumes of remote sensing data, it is difficult to utilize all the features of remote sensing big data having different times and spatial resolutions. Inefficiency is also a large problem when dealing with large area land cover mapping. In this study, a new mode of incorporating spatial and temporal dependencies in a complex region employing the random forests (RFs) classifier was utilized. To map land covers, spring and autumn spectral images and their spectral indexes, textural features obtained from Landsat 5 were selected, and an importance measure variable was used to reduce the data\u2019s dimension. In addition to randomly selecting the variable, we used random sampling to furthest decrease the generalization error in RF. The results showed that utilizing random sampling, multi-temporal spectral image and texture features, the classification of the Wuhan urban agglomeration, China, using RF performed well. The RF algorithm yielded an overall accuracy of 89.2% and a Kappa statistic of 0.8522, indicating high model performance. In addition, the variable importance measures demonstrated that the type of textural features was extremely important for intra-class separability. The RF model has transitivity. The algorithm can be extended by choosing a set of appropriate features for signature extension over large areas or in time-series of Landsat imagery. Land cover mapping might be more economical and efficient if no-cost imagery is used.",
        "references": [
            "fc1d6787cbd6f0fb5089bbe29f402d28ce438702",
            "fc8b5280630996a90c4ca613ef1c29fed1fc0171",
            "2e37205d9d699622a505d4f02cb3a07365a73d53",
            "99b4ca6bf41bb6f3e56ce417e958fc9ed61e7442",
            "13dd43463710f0b5039fb93f7a9eda29d2d72f89",
            "8f4ede94cc61d9af2cad826d209dfc3a0521dabd",
            "b801af56e1c96ca924f553fd49ac609bdecac080",
            "fc6f99aa02d445dea082ad829c8caa966d2b24e0",
            "ccdf098fd7d0ae80895b700da36b112832015d8a",
            "7ad785d8cd5d45ee07a82a2c0d7d4c733b1251d5"
        ],
        "related_topics": [],
        "reference_count": "44",
        "citation_count": "One"
    },
    {
        "Id": "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
        "title": "Hyperspectral image classification via kernel sparse representation",
        "authors": [
            "Yi Chen",
            "Nasser M. Nasrabadi",
            "Trac D. Tran"
        ],
        "date": "29 December 2011",
        "abstract": "Experimental results show that the proposed technique outperforms the linear sparsity-based classification technique and the classical Support Vector Machine classifiers. In this paper, a new technique for hyperspectral image classification is proposed. Our approach relies on the sparse representation of a test sample with respect to all training samples in a feature space induced by a kernel function. Projecting the samples into the feature space and kernelizing the sparse representation improves the separability of the data and thus yields higher classification accuracy compared to the more conventional linear sparsity-based classification algorithm. Moreover, the spatial coherence across neighboring pixels is also incorporated through a kernelized joint sparsity model, where all of the pixels within a small neighborhood are sparsely represented in the feature space by selecting a few common training samples. Two greedy algorithms are also provided in this paper to solve the kernel versions of the pixel-wise and jointly sparse recovery problems. Experimental results show that the proposed technique outperforms the linear sparsity-based classification technique and the classical Support Vector Machine classifiers.",
        "references": [
            "566d9be7c3ae903c6555f32fbccf551c1fc84c7b",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "a00c49eebbe4aa82cf4429954b9994a3c01631fa",
            "e99a64357a4f38063bc3206cb9266443a0d1f0b4",
            "9b416ec0b8a787ed4f0cd2dcc00cf083d47104c6",
            "6d1e846f6c3fb3aa8bb9d392e563145a840247b4",
            "5d704c3908b11666904467970e6dd5bf59fbfecf",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "f19122b082188e626ff8355cfcaa432e68509272",
            "4a974d1f6c0d4b91bc7c1a56008cbeebc40c9361"
        ],
        "related_topics": [
            "Test Pixel",
            "Sparse Representation",
            "Hyperspectral Image Classification",
            "Greedy Algorithm",
            "Kernel Sparse Representation",
            "Classification Accuracy"
        ],
        "reference_count": "52",
        "citation_count": "498"
    },
    {
        "Id": "ab754fecbca13aeb08f42de7bd3be4938e4813f8",
        "title": "Sparse representation using contextual information for hyperspectral image classification",
        "authors": [
            "Haoliang Yuan",
            "Yang Lu",
            "Lina Yang",
            "Huiwu Luo",
            "Yuanyan Tang"
        ],
        "date": "13 June 2013",
        "abstract": "This paper proposes a least square based sparse representation algorithm, which uses the weight vector obtained by the least square method from the neighbors to help improve the sparse representations. This paper analyzes the classification of hyperspectral images with the sparse representation algorithm in the presence of a minimal reconstruction error. Incorporating the contextual information into the sparse recovery process can improve the classification performance. However, previous sparse algorithms using contextual information only assume that all neighbors around a test sample make equal contributions to the classification. One disadvantage is that these neighbors located in the edge may belong to the different classes, because they are extracted by a fixed square window. Assuming equal contributions may ease the discrimination of the obtained sparse representations. In this paper, we propose a least square based sparse representation algorithm, which uses the weight vector obtained by the least square method from the neighbors to help improve the sparse representations. Through projecting the weight vector into the corresponding sparse representations, the obtained sparse representations can build a relationship between the neighbors through different weights. Comparative experimental results are shown to demonstrate the validity of our proposed algorithm.",
        "references": [
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "00582be58da554cc66c91d23924b24487912abf7",
            "558593f2ba9a6c921dcef904d4f2b1e87b9084f7",
            "946e836206964c31e3aefce1df54fbb542ab80ed",
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "14b64bb5af95367883abd2b95d95979f87bcd5f0",
            "e616132691824d6eec92b0eb4560b286d732582b",
            "46f9073f3983fd0d9ca5b364bfe8f0bfa89f343e",
            "4eb130a05b2fc9cad0bd97fd85500a71ad5cbd66",
            "74227090d23c958f601ad05369fad587e3b546f1"
        ],
        "related_topics": [
            "Classification",
            "Discrimination",
            "Sparse Representation",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "20",
        "citation_count": "6"
    },
    {
        "Id": "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
        "title": "Hyperspectral Image Classification Using Dictionary-Based Sparse Representation",
        "authors": [
            "Yi Chen",
            "Nasser M. Nasrabadi",
            "Trac D. Tran"
        ],
        "date": "12 May 2011",
        "abstract": "Experimental results show that the proposed sparsity-based algorithm for the classification of hyperspectral imagery outperforms the classical supervised classifier support vector machines in most cases. A new sparsity-based algorithm for the classification of hyperspectral imagery is proposed in this paper. The proposed algorithm relies on the observation that a hyperspectral pixel can be sparsely represented by a linear combination of a few training samples from a structured dictionary. The sparse representation of an unknown pixel is expressed as a sparse vector whose nonzero entries correspond to the weights of the selected training samples. The sparse vector is recovered by solving a sparsity-constrained optimization problem, and it can directly determine the class label of the test sample. Two different approaches are proposed to incorporate the contextual information into the sparse recovery optimization problem in order to improve the classification performance. In the first approach, an explicit smoothing constraint is imposed on the problem formulation by forcing the vector Laplacian of the reconstructed image to become zero. In this approach, the reconstructed pixel of interest has similar spectral characteristics to its four nearest neighbors. The second approach is via a joint sparsity model where hyperspectral pixels in a small neighborhood around the test pixel are simultaneously represented by linear combinations of a few common training samples, which are weighted with a different set of coefficients for each pixel. The proposed sparsity-based algorithm is applied to several real hyperspectral images for classification. Experimental results show that our algorithm outperforms the classical supervised classifier support vector machines in most cases.",
        "references": [
            "f19122b082188e626ff8355cfcaa432e68509272",
            "0e31d9acb94cdffcefa30b2b09b40e9b8457941c",
            "5d704c3908b11666904467970e6dd5bf59fbfecf",
            "4e0f49c4b23b32b1c0c278fa8eecbfee01b6aeda",
            "b0fe9323b9e74f9473f5b97cccf53a689f64bf60",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "344360c84ae36ab2e4a0bb3ffb6ac65f47fc7722",
            "c86abfc2d6c5ad3ed80b133ea736529301f2e500",
            "6fb4840ed454daf0b56ca9b40aced6fc43e569f4",
            "50b596dd0dc5c59912ef747d854c72d891be40b1"
        ],
        "related_topics": [],
        "reference_count": "66",
        "citation_count": "943"
    },
    {
        "Id": "a1a183c1e263526465c8d3097d13b3e2be273ea8",
        "title": "Exploiting Sparsity in Hyperspectral Image Classification via Graphical Models",
        "authors": [
            "Umamahesh Srinivas",
            "Yi Chen",
            "Vishal Monga",
            "Nasser M. Nasrabadi",
            "Trac D. Tran"
        ],
        "date": "1 May 2013",
        "abstract": "A probabilistic graphical model framework to explicitly mine the conditional dependences between these distinct sparse features of HSI classification, synthesized using simple tree structures which can be discriminatively learnt (even with limited training samples) for classification. A significant recent advance in hyperspectral image (HSI) classification relies on the observation that the spectral signature of a pixel can be represented by a sparse linear combination of training spectra from an overcomplete dictionary. A spatiospectral notion of sparsity is further captured by developing a joint sparsity model, wherein spectral signatures of pixels in a local spatial neighborhood (of the pixel of interest) are constrained to be represented by a common collection of training spectra, albeit with different weights. A challenging open problem is to effectively capture the class conditional correlations between these multiple sparse representations corresponding to different pixels in the spatial neighborhood. We propose a probabilistic graphical model framework to explicitly mine the conditional dependences between these distinct sparse features. Our graphical models are synthesized using simple tree structures which can be discriminatively learnt (even with limited training samples) for classification. Experiments on benchmark HSI data sets reveal significant improvements over existing approaches in classification rates as well as robustness to choice of training.",
        "references": [
            "4a974d1f6c0d4b91bc7c1a56008cbeebc40c9361",
            "48b9254f150ec91c9363301556e384f9afc996d7",
            "2badd8953397d757693859918cf9318fe7ec5e3b",
            "14b64bb5af95367883abd2b95d95979f87bcd5f0",
            "0033c0015f6957123e46f10772de5228f4e3a5cf",
            "f19122b082188e626ff8355cfcaa432e68509272",
            "76809ca966bf8d518d8e96abc131e1e5ff54962c",
            "5b92c12e80e82e2302c6f2570f415bbc26f966b0",
            "3e32b4775f3aeff0e1eaf37cc46771376a0c8d08",
            "f4106ee9cde073f89263aa417434bea09c094e71"
        ],
        "related_topics": [
            "Pixel",
            "Classification",
            "Spectral Signatures",
            "Joint Sparsity Model",
            "Sparse Features",
            "Hyperspectral Image Classification",
            "Overcomplete Dictionaries",
            "Hyperspectral Imagery"
        ],
        "reference_count": "28",
        "citation_count": "84"
    },
    {
        "Id": "348976f5aa807eb52f1b27a811ed499ca14bf7aa",
        "title": "Structured Dictionary Learning with Block Diagonal Regularization for Image Classification",
        "authors": [
            "Manman Xu",
            "Runhua Jiang",
            "Tao Wang",
            "Di Wang",
            "Xiaoju Lu"
        ],
        "date": "10 December 2020",
        "abstract": "A novel supervised dictionary learning method based on the prior of the block diagonal phenomenon, where a block diagonal regularizer is imposed on the affinity matrix to enforce the sparse representation matrix to have an approximately block diagonal structure, which makes the learned dictionary more discriminative and suitable for classification tasks. Sparse representation and dictionary learning have been successfully applied to encode dense data and facilitate image classification. Though existing dictionary learning methods achieve better performance than their counterparts, the class discriminative ability of learned dictionary is still limited. This paper proposes a novel supervised dictionary learning method based on the prior of the block diagonal phenomenon, i.e., each sample should be well reconstructed by the samples in the same class while poorly reconstructed by the samples in other class. Specifically, a block diagonal regularizer is imposed on the affinity matrix to enforce the sparse representation matrix to have an approximately block diagonal structure, which makes the learned dictionary more discriminative and suitable for classification tasks. Furthermore, we present an effective optimization strategy by combining the alternating minimization with the alternating direction method of multipliers (ADMM) for the proposed framework. Experimental results on six real-world datasets show that the proposed method is more effective than state-of-the-art dictionary learning methods.",
        "references": [
            "a73be6ea4e354c669230509754277710d1f2c169",
            "544d6cd24db5adad8453033e0cc1aa7d3d6224ab",
            "b38ac423809d5907e2d9617b4b4242f6c457221d",
            "96e626c8d03ff83b10adb45901e2e7fe247f2cd4",
            "533b2e2ba64bc7ceedc0aa863941e07f2e4ee6bf",
            "684f5166d8147b59d9e0938d627beff8c9d208dd",
            "869513e775f2e27bfba8c771118e4304589ceb85",
            "4940db01da1f5c23c7639fe581d98183451d8e3e",
            "c0ea568bd071ef5e1e9d204f162ebae3a595d715",
            "9308f9a34a0d82ab9c4bdd046e76b63800d2a29a"
        ],
        "related_topics": [
            "Dictionary Learning",
            "Sparse Representation",
            "Classification Task",
            "Alternating Minimization",
            "Supervised Dictionary Learning",
            "Affinity Matrix",
            "Alternating Direction Method Of Multipliers",
            "Block Diagonal Regularizer"
        ],
        "reference_count": "0",
        "citation_count": "49"
    },
    {
        "Id": "6afec1af7c41cc6ff17ac5c501713e90b5ed0105",
        "title": "A Novel Feature Enhancement Method Based on Improved Constraint Model of Online Dictionary Learning",
        "authors": [
            "Huaqing Wang",
            "Pengxin Wang",
            "Liuyang Song",
            "Bangyue Ren",
            "Lingli Cui"
        ],
        "date": "31 January 2019",
        "abstract": "Compared with the typical ODL method, the ICM-ODL algorithm can not only improves the anti-noise performance of the dictionary atoms, but also removes the noise compositions of the reconstructed signal significantly. Online dictionary learning (ODL) is an emerging and efficient dictionary learning algorithm, which can extract fault features information of fault signals in most occasions. However, the typical ODL algorithm fails to consider the interference of noise and the structural features of the fault signals, which leads to the fault features of weak fault signals that are difficult to extract. For that, a novel feature enhancement method based on an improved constraint model of an ODL (ICM-ODL) algorithm has been proposed in this paper. For the stage of dictionary learning, the elastic-net constraint is used to promote the anti-noise performance of the dictionary atoms. For the stage of signals sparse coding, the  $l_{2,1} $  norm constraint is added to learn the structural features of fault signals. In addition, a variational mode decomposition algorithm is used to reduce the impact of noise on the signal initially. Taking the weak fault signals of bearing as examples for analysis, the results show that the feature enhancement of the weak fault signals is fulfilled by using the ICM-ODL algorithm. Compared with the typical ODL method, the ICM-ODL algorithm can not only improves the anti-noise performance of the dictionary atoms, but also removes the noise compositions of the reconstructed signal significantly.",
        "references": [
            "2bca5342140e0d7f8a146ae22f5fabb61ce2c987",
            "9ccdaf25f2549a9c1bbbbe2c397f353528122333",
            "0086beb7ce409cb1f7d098da32d6acceda53773e",
            "76504e0f64837cc18e760dfed2f5a76740b1180c",
            "f6e0fb4c77906bc23fe59a8f848ce62ba9687181",
            "83b522f4bfa5db7f7d34f839475af7d078107634",
            "9e45d32c493cf60f470c3e21b738d0e0a2eec293",
            "ec82c215f5b5879ad7639995c7926afda3dd7f51",
            "cf80cc34528273d8fbe17783efe802a6509e1562",
            "0974a7957910de34c709e2d63411834f59323774"
        ],
        "related_topics": [
            "Online Dictionary Learning",
            "Dictionary Atoms",
            "Dictionary Learning",
            "Elastic-net Constraints"
        ],
        "reference_count": "33",
        "citation_count": "62"
    },
    {
        "Id": "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
        "title": "Hyperspectral Image Classification Using Dictionary-Based Sparse Representation",
        "authors": [
            "Yi Chen",
            "Nasser M. Nasrabadi",
            "Trac D. Tran"
        ],
        "date": "12 May 2011",
        "abstract": "Experimental results show that the proposed sparsity-based algorithm for the classification of hyperspectral imagery outperforms the classical supervised classifier support vector machines in most cases. A new sparsity-based algorithm for the classification of hyperspectral imagery is proposed in this paper. The proposed algorithm relies on the observation that a hyperspectral pixel can be sparsely represented by a linear combination of a few training samples from a structured dictionary. The sparse representation of an unknown pixel is expressed as a sparse vector whose nonzero entries correspond to the weights of the selected training samples. The sparse vector is recovered by solving a sparsity-constrained optimization problem, and it can directly determine the class label of the test sample. Two different approaches are proposed to incorporate the contextual information into the sparse recovery optimization problem in order to improve the classification performance. In the first approach, an explicit smoothing constraint is imposed on the problem formulation by forcing the vector Laplacian of the reconstructed image to become zero. In this approach, the reconstructed pixel of interest has similar spectral characteristics to its four nearest neighbors. The second approach is via a joint sparsity model where hyperspectral pixels in a small neighborhood around the test pixel are simultaneously represented by linear combinations of a few common training samples, which are weighted with a different set of coefficients for each pixel. The proposed sparsity-based algorithm is applied to several real hyperspectral images for classification. Experimental results show that our algorithm outperforms the classical supervised classifier support vector machines in most cases.",
        "references": [
            "f19122b082188e626ff8355cfcaa432e68509272",
            "0e31d9acb94cdffcefa30b2b09b40e9b8457941c",
            "5d704c3908b11666904467970e6dd5bf59fbfecf",
            "4e0f49c4b23b32b1c0c278fa8eecbfee01b6aeda",
            "b0fe9323b9e74f9473f5b97cccf53a689f64bf60",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "344360c84ae36ab2e4a0bb3ffb6ac65f47fc7722",
            "c86abfc2d6c5ad3ed80b133ea736529301f2e500",
            "6fb4840ed454daf0b56ca9b40aced6fc43e569f4",
            "50b596dd0dc5c59912ef747d854c72d891be40b1"
        ],
        "related_topics": [],
        "reference_count": "66",
        "citation_count": "943"
    },
    {
        "Id": "a7578a4673ba8e8abf084bc05cb335d255b862ea",
        "title": "Hyperspectral Image Classification Via Shape-Adaptive Joint Sparse Representation",
        "authors": [
            "Wei Fu",
            "Shutao Li",
            "Leyuan Fang",
            "Xudong Kang",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "1 February 2016",
        "abstract": "A new shape-adaptive joint sparse representation classification (SAJSRC) method for hyperspectral images (HSIs) classification adaptively explores the spatial information and incorporates it into a joint sparse representation classifier. A new shape-adaptive joint sparse representation classification (SAJSRC) method is proposed for hyperspectral images (HSIs) classification. The proposed method adaptively explores the spatial information and incorporates it into a joint sparse representation classifier. First, the HSI is transformed with the principal component analysis (PCA) algorithm. Then, the first principal component (PC), which represents the most spatial variation in the HSI, is used in the shape-adaptive algorithm to construct a shape-adaptive local smooth region for each test pixel. Unlike the fixed-sized window used in other sparse representation-based methods, the shape-adaptive regions have adaptive sizes and shapes, and conform to the spatial structure of the HSI as far as possible. Finally, the label of the test pixel is determined by applying the joint sparse representation classifier to the first several PCs of pixels within the corresponding SA region. According to the experiments performed on several HSIs, the proposed SAJSRC method outperforms some widely used HSIs classification approaches.",
        "references": [
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "fc7aceed94bd8931c8fa3a8cd43b33ecf4b130f6",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "2fa41ad17da78347b5fce8cb1e8d89c1c1671f83",
            "3a5f27e244711177872b349207bec4d64d37e986",
            "e860267bdaba7eba2fbfbdbb9974d6fd574d522b",
            "9dc0f6bb33c4b4aaf3381d22cfbb32bd1514b6f8"
        ],
        "related_topics": [
            "HSIs",
            "Test Pixel",
            "Principal Components",
            "Principal Component Analysis",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "53",
        "citation_count": "105"
    },
    {
        "Id": "d80e7c2280caf016404ffa02469b331e755cfc7b",
        "title": "Classification of Hyperspectral Images by Exploiting Spectral\u2013Spatial Information of Superpixel via Multiple Kernels",
        "authors": [
            "Leyuan Fang",
            "Shutao Li",
            "Wuhui Duan",
            "Jinchang Ren",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "2 July 2015",
        "abstract": "Experimental results on three widely used real HSIs indicate that the proposed SC-MK approach outperforms several well-known classification methods. For the classification of hyperspectral images (HSIs), this paper presents a novel framework to effectively utilize the spectral-spatial information of superpixels via multiple kernels, which is termed as superpixel-based classification via multiple kernels (SC-MK). In the HSI, each superpixel can be regarded as a shape-adaptive region, which consists of a number of spatial neighboring pixels with very similar spectral characteristics. First, the proposed SC-MK method adopts an oversegmentation algorithm to cluster the HSI into many superpixels. Then, three kernels are separately employed for the utilization of the spectral information, as well as spatial information, within and among superpixels. Finally, the three kernels are combined together and incorporated into a support vector machine classifier. Experimental results on three widely used real HSIs indicate that the proposed SC-MK approach outperforms several well-known classification methods.",
        "references": [
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "c63af04d797aa7ca287b66f824a264391e4d98a4",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "2fa41ad17da78347b5fce8cb1e8d89c1c1671f83",
            "14b64bb5af95367883abd2b95d95979f87bcd5f0",
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "b994ba36364e8e61514d1a87002442ce9ab03d33",
            "f19122b082188e626ff8355cfcaa432e68509272",
            "d8f4f6b751e49b2adca8f601cdaf940b355f226a"
        ],
        "related_topics": [
            "Superpixel-based Classification Via Multiple Kernels",
            "Shape-adaptive Region",
            "Superpixels",
            "Multiple Kernels",
            "HSIs",
            "Kernels",
            "Classification",
            "Spectral-spatial Information",
            "Oversegmentation Algorithms"
        ],
        "reference_count": "51",
        "citation_count": "324"
    },
    {
        "Id": "fff45cbbb315fffb4c72d8459fcd9fe28a87519c",
        "title": "Local Binary Patterns and Extreme Learning Machine for Hyperspectral Imagery Classification",
        "authors": [
            "Wei Li",
            "Cheng Chen",
            "Hongjun Su",
            "Qian Du"
        ],
        "date": "15 January 2015",
        "abstract": "The proposed framework employs local binary patterns to extract local image features, such as edges, corners, and spots, and employs the efficient extreme learning machine with a very simple structure as the classifier. It is of great interest in exploiting texture information for classification of hyperspectral imagery (HSI) at high spatial resolution. In this paper, a classification paradigm to exploit rich texture information of HSI is proposed. The proposed framework employs local binary patterns (LBPs) to extract local image features, such as edges, corners, and spots. Two levels of fusion (i.e., feature-level fusion and decision-level fusion) are applied to the extracted LBP features along with global Gabor features and original spectral features, where feature-level fusion involves concatenation of multiple features before the pattern classification process while decision-level fusion performs on probability outputs of each individual classification pipeline and soft-decision fusion rule is adopted to merge results from the classifier ensemble. Moreover, the efficient extreme learning machine with a very simple structure is employed as the classifier. Experimental results on several HSI data sets demonstrate that the proposed framework is superior to some traditional alternatives.",
        "references": [
            "9de574ea1293e399fb3723d44535ef2b26bc56df",
            "a2f4fddd2e56d9d3fb5cb4baa92e348311f5d646",
            "45c7a4b20ad32ef6fa7029cb15c09b3e83a1a54b",
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "92261e8f1ab997a33892322c3231afc76b2d3158",
            "f5f9dbf8b8537445adc4824d0a427c0138fba457",
            "e731b151c90aba8fcdce38e05a301b645a222315",
            "5aa216c9a1a0a99398c0523a7159085846916ede",
            "f6071eb167ac70099d357976c0a065ad685193b8",
            "89a1e42f645c657510eef13c151851f945eb3681"
        ],
        "related_topics": [
            "Linear Prediction Error",
            "HSI Classification",
            "Morphological Profiles",
            "Hyperspectral Imagery",
            "Local Binary Patterns",
            "Classification",
            "Extreme Learning Machine",
            "Local Image Features",
            "Classifier Ensembles",
            "Corner"
        ],
        "reference_count": "44",
        "citation_count": "546"
    },
    {
        "Id": "544d6cd24db5adad8453033e0cc1aa7d3d6224ab",
        "title": "Fisher Discrimination Dictionary Learning for sparse representation",
        "authors": [
            "Meng Yang",
            "Lei Zhang",
            "Xiangchu Feng",
            "David Dian Zhang"
        ],
        "date": "6 November 2011",
        "abstract": "A novel dictionary learning (DL) method based on the Fisher discrimination criterion, whose dictionary atoms have correspondence to the class labels is learned so that the reconstruction error after sparse coding can be used for pattern classification. Sparse representation based classification has led to interesting image recognition results, while the dictionary used for sparse coding plays a key role in it. This paper presents a novel dictionary learning (DL) method to improve the pattern classification performance. Based on the Fisher discrimination criterion, a structured dictionary, whose dictionary atoms have correspondence to the class labels, is learned so that the reconstruction error after sparse coding can be used for pattern classification. Meanwhile, the Fisher discrimination criterion is imposed on the coding coefficients so that they have small within-class scatter but big between-class scatter. A new classification scheme associated with the proposed Fisher discrimination DL (FDDL) method is then presented by using both the discriminative information in the reconstruction error and sparse coding coefficients. The proposed FDDL is extensively evaluated on benchmark image databases in comparison with existing sparse representation and DL based classification methods.",
        "references": [
            "15f53de0a5ee2ef9015e218cb179165df1ed1298",
            "cea50611ba73b5775cc2fe1e9c27990a0bb20cf8",
            "11de4195ecf7b24568b0c893125cd6b8b469f0a6",
            "63140301f88a0c5223f92afbf2acfec9e537f6be",
            "9f70088ae0c839455f4da91f44a1783f6d3c6c9e",
            "a616bd79c26b0390a0c5d349acd3454d5f579d22",
            "df15ab894ab518e97f361e85122fffb6349fc9b6",
            "c65be1f97642510843667d36e399de58837d3419",
            "1a1a60fd4dc88a14c016b95789385801c6b80574",
            "9d65ba8bb20ae6dd001b9833c525c279dfe18916"
        ],
        "related_topics": [
            "Fisher Discrimination Dl",
            "Fisher Discrimination Criterion",
            "Structured Dictionary",
            "Coding Coefficients",
            "Sparse Coding",
            "Dictionary",
            "Classification",
            "Sparse Representation",
            "Fisher Discrimination Dictionary Learning",
            "Image Recognition"
        ],
        "reference_count": "34",
        "citation_count": "974"
    },
    {
        "Id": "0088d6433a9715b7e74a623920925f2bfb04c920",
        "title": "Probabilistic Fusion of Pixel-Level and Superpixel-Level Hyperspectral Image Classification",
        "authors": [
            "Shutao Li",
            "Ting Lu",
            "Leyuan Fang",
            "Xiuping Jia",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "13 September 2016",
        "abstract": "A novel hyperspectral image (HSI) classification method by the probabilistic fusion of pixel-level and superpixel-level classifiers, to improve the classification performance in both homogenous and structural areas is proposed. A novel hyperspectral image (HSI) classification method by the probabilistic fusion of pixel-level and superpixel-level classifiers is proposed. Generally, pixel-level classifiers based on spectral information only may generate \u201csalt and pepper\u201d result in the classification map since spatial correlation is not considered. By incorporating spatial information in homogeneous regions, the superpixel-level classifiers can effectively eliminate the noisy appearance. However, the classification accuracy will be deteriorated if undersegmentation cannot be fully avoided in superpixel-based approaches. Therefore, it is proposed to adaptively combine both the pixel-level and superpixel-level classifiers, to improve the classification performance in both homogenous and structural areas. In the proposed method, a support vector machine classifier is first applied to estimate the pixel-level class probabilities. Then, superpixel-level class probabilities are estimated based on a joint sparse representation. Finally, the two levels of class probabilities are adaptively combined in a maximum a posteriori estimation model, and the classification map is obtained by solving the maximum optimization problem. Experimental results on real HSI images demonstrate the superiority of the proposed method over several well-known classification approaches in terms of classification accuracy.",
        "references": [
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "d70437950a66ba018a5656f8c35341869417e444",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "fff45cbbb315fffb4c72d8459fcd9fe28a87519c",
            "f1c06eff47412b5b79cdf5afda9312d089a8b74d",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "0e2b808a4be6bafac27a5679043c7710fbe5b4f2",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "5f5aaf6eb86967a67754a1cf6f286d80597e22fd",
            "d37e6317e59911e345bdef50f56998ef5b1c894c"
        ],
        "related_topics": [
            "Classification Accuracy",
            "Classification Map",
            "Pixel Level",
            "Hyperspectral Image Classification",
            "Hyperspectral Imagery"
        ],
        "reference_count": "53",
        "citation_count": "71"
    },
    {
        "Id": "2badd8953397d757693859918cf9318fe7ec5e3b",
        "title": "Classification of hyperspectral remote sensing images with support vector machines",
        "authors": [
            "Farid Melgani",
            "Lorenzo Bruzzone"
        ],
        "date": "16 August 2004",
        "abstract": "This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines by understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces and concludes that SVMs are a valid and effective alternative to conventional pattern recognition approaches. This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines (SVMs). First, we propose a theoretical discussion and experimental analysis aimed at understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces. Then, we assess the effectiveness of SVMs with respect to conventional feature-reduction-based approaches and their performances in hypersubspaces of various dimensionalities. To sustain such an analysis, the performances of SVMs are compared with those of two other nonparametric classifiers (i.e., radial basis function neural networks and the K-nearest neighbor classifier). Finally, we study the potentially critical issue of applying binary SVMs to multiclass problems in hyperspectral data. In particular, four different multiclass strategies are analyzed and compared: the one-against-all, the one-against-one, and two hierarchical tree-based strategies. Different performance indicators have been used to support our experimental studies in a detailed and accurate way, i.e., the classification accuracy, the computational time, the stability to parameter setting, and the complexity of the multiclass architecture. The results obtained on a real Airborne Visible/Infrared Imaging Spectroradiometer hyperspectral dataset allow to conclude that, whatever the multiclass strategy adopted, SVMs are a valid and effective alternative to conventional pattern recognition approaches (feature-reduction procedures combined with a classification method) for the classification of hyperspectral remote sensing data.",
        "references": [
            "a240da170041b9aa798b512160ba9712bf82a56e",
            "5b92c12e80e82e2302c6f2570f415bbc26f966b0",
            "b821c3afbb404766ff2c768fa363803b8d256434",
            "b9ddc16cd2449e93d44c1c5360dcf765b91de099",
            "f83b85d8daa4ee370982842a809b5c8dba63b645",
            "75a963eff4fd7809694d2225b62db7569f1e1b93",
            "5355e8c7359b8dadb970099dcd6fa951fa5ef3b7",
            "c94dec3fc99c4a653afb935d00246f788689c341",
            "ea82a3b3f8940c7e8f949d78639792ac345d09fd",
            "7dd9820b13754f05ae3f7f771fc8b2d7f4691c06"
        ],
        "related_topics": [],
        "reference_count": "52",
        "citation_count": "3,550"
    },
    {
        "Id": "f810b28ef87035220ea31de794b2e7153f62a815",
        "title": "Context-Aware Compressed Sensing of Hyperspectral Image",
        "authors": [
            "Wei Fu",
            "Ting Lu",
            "Shutao Li"
        ],
        "date": "1 January 2020",
        "abstract": "A novel context-aware CS (CACS) method for HSIs is proposed by incorporating contextual prior to the dictionary learning and the sparse reconstruction, which demonstrates the superiority of the proposed method over some state-of-the-art hyperspectral compressive imaging methods. Traditional hyperspectral imaging technique obtains numerous hyperspectral images (HSIs) with hundreds of spectral bands, leading to high cost in data acquisition, transmission, and storage. Compressed sensing (CS) theory provides a new imaging mechanism, which relies on the assumption that signals can be sparsely represented over a dictionary. By the CS imaging technique, original HSIs can be approximately reconstructed from only a few sampled measurements. In this article, a novel context-aware CS (CACS) method for HSIs is proposed by incorporating contextual prior to the dictionary learning and the sparse reconstruction. First, a patch-based online dictionary learning (ODL) algorithm is developed by introducing a joint sparse constraint. On the one hand, the online dictionary learning mechanism enables a more adaptive representation of HSIs with different scenes than using fixed-basis-based dictionaries, e.g., the discrete cosine transform (DCT) and the discrete wavelet transform dictionaries. On the other hand, the introduced joint sparse constraint promotes the learned dictionary to more sparsely and structurally represent spectral pixels. Then, with the well-learned dictionary, a weighted smoothing regularization is introduced to develop a new sparse reconstruction model. Considering the high spectral\u2013spatial similarity of pixels in a neighborhood, the new sparse reconstruction model will encourage a locally smoothing reconstruction result. In this way, the spectral\u2013spatial structures of the HSI can be well preserved, while possible artifacts can be effectively reduced. Experimental results demonstrate the superiority of the proposed method over some state-of-the-art hyperspectral compressive imaging methods.",
        "references": [
            "c8050a113ac01dee92c6b303c506be710561491a",
            "4942dceebd33ac6feb8fb2ca457caab3262a9382",
            "bd91ecaf8421f83885b35803f15688b50c2ae965",
            "e2c2e7f4fe194da5039b7d6b0612834e846f3a33",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "ee3d02a5a5d39d36d66fd416e6af204b44d7ba1a",
            "083b3a4d102c08c9553ad4db4afd6dd37a5ca448",
            "c8b6d65eb0dce36d9013ab10b1764adfca61edfd",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "42c41a849b9c439371b93ea0b7e44230f668679f"
        ],
        "related_topics": [
            "Dictionary",
            "HSIs",
            "Compressed Sensing",
            "Discrete Cosine Transform",
            "Sparse Reconstruction",
            "Dictionary Learning",
            "Spectral Pixels",
            "Spectral-spatial Structure"
        ],
        "reference_count": "49",
        "citation_count": "4"
    },
    {
        "Id": "e154f59d0dfcae7f51d4582ca35e21a0d11be929",
        "title": "Hyperspectral image classification using cluster based graph regularized low rank representation and dictionary learning",
        "authors": [
            "Fatemeh Hajiani",
            "Naser Parhizgar",
            "Ahmad Keshavarz"
        ],
        "date": "28 October 2021",
        "abstract": "Semantic Scholar extracted view of \"Hyperspectral image classification using cluster based graph regularized low rank representation and dictionary learning\" by Fatemeh Hajiani et al.",
        "references": [
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea",
            "e7c489e6fdbc5086522166fda86fce16288b1a43",
            "035e979321f5a04bcaf5e92d568504077db6be03",
            "70add4d30d1aaa09ef7b05456c8291781e174588",
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "27eb47d75a624cda9e17e2f9df03b8f3fd99284d",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "7e9228b914556cc84b2705bacb121df353c57e43",
            "7c997a648976fb9df320c6ca332c9dc155820454",
            "2b87492840948d7506e2e6cfba3c3b1e814deb18"
        ],
        "related_topics": [
            "Low-Rank Representation",
            "Classification",
            "Pixel",
            "Dictionary Learning",
            "Hyperspectral Imagery",
            "Hyperspectral Image Classification",
            "Manifold Regularization"
        ],
        "reference_count": "56",
        "citation_count": "5"
    },
    {
        "Id": "c03d64bbdd0d1ea9d47e1fc1ec43a1774f2cc10d",
        "title": "Subspace Clustering for Hyperspectral Images via Dictionary Learning With Adaptive Regularization",
        "authors": [
            "Shaoguang Huang",
            "Hongyan Zhang",
            "Aleksandra Pi{\\vz}urica"
        ],
        "date": "2022",
        "abstract": "This article proposes a scalable subspace clustering method, which integrates the learning of a concise dictionary and robust subspace representation in a unified model and derives an effective solver based on alternating minimization and alternating direction method of multipliers (ADMMs) to solve the resulting optimization problem. Sparse subspace clustering (SSC) has emerged as an effective approach for the automatic analysis of hyperspectral images (HSI). Traditional SSC-based approaches employ the input HSI data as a dictionary of atoms, in terms of which all the data samples are linearly represented. This leads to highly redundant dictionaries of huge size, and the computational complexity of the resulting optimization problems becomes prohibitive for large-scale data. In this article, we propose a scalable subspace clustering method, which integrates the learning of a concise dictionary and robust subspace representation in a unified model. This reduces significantly the size of the involved optimization problems. We introduce a new adaptive spatial regularization for the representation coefficients, which incorporates spatial information of HSI and improves the robustness of the model to noise. We derive an effective solver based on alternating minimization and alternating direction method of multipliers (ADMMs) to solve the resulting optimization problem. Experimental results on four representative hyperspectral images show the effectiveness of the proposed method and excellent clustering performance relative to the state of the art.",
        "references": [
            "ce9cbcd976a897cbd37bf90905d5ffbaced01c9b",
            "9751ed37be9ed7ec7a6c4a97425dfaf5bb55596f",
            "7ab056a660291e56c7d8015877f6e2b0d8eca358",
            "0a396297c06f94fca565464fa988a8462b15549c",
            "f9c3f6e2fd3152abc96c27465635caa0f3f79c82",
            "9e36c66a43c23c90f5ab9cead87811f95b930651",
            "3dad5bbdddd7cc7fa73198fd1de74a8ca32a6644",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "6fc13df30cae06a95aa549ba59b1c4b272f5ef47",
            "09e54bdb98c2d2eb5dddec04a8e7e9106e0a0116"
        ],
        "related_topics": [
            "Sparse Subspace Clustering",
            "Hyperspectral Imagery",
            "Adaptive Spatial Regularization",
            "Redundant Dictionaries",
            "Dictionary Learning",
            "Subspace Clustering",
            "Alternating Minimization",
            "Representation Coefficients",
            "Clustering Performance",
            "Dictionary"
        ],
        "reference_count": "62",
        "citation_count": "32"
    },
    {
        "Id": "28f3446718da6fed450bded33576322bd8d60448",
        "title": "Hyperspectral Image Classification Based on Sparse Modeling of Spectral Blocks",
        "authors": [
            "Saeideh Ghanbari Azar",
            "Saeed Meshgini",
            "Tohid Yousefi Rezaii",
            "Soosan Beheshti"
        ],
        "date": "17 May 2020",
        "abstract": "Semantic Scholar extracted view of \"Hyperspectral Image Classification Based on Sparse Modeling of Spectral Blocks\" by Saeideh Ghanbari Azar et al.",
        "references": [
            "5ca94050fcf3382b50ec44629c0dda80c8843558",
            "adfd2883433e457c7e5167121714c81247cb4e15",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5ef1bc90ee5ca4e474972bf6f43eb0751e09093b",
            "67bcbb8ffd79c385edd734b9c9cf528ecc8ea343",
            "541ebe34978254e0717bd3f59087e20c861a6753",
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea",
            "692541a740b2b3c5c82a47390a7cbb40872efec5",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "10fb16414324a5db44f5d830adcb4810af59eed0"
        ],
        "related_topics": [
            "Spatial Redundancy",
            "Benchmark Dataset",
            "Computational Complexity",
            "Classification Accuracy",
            "Classification",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "38",
        "citation_count": "15"
    },
    {
        "Id": "e7e349926095d397c06718320222b5990ce0c105",
        "title": "Spectral-Difference Low-Rank Representation Learning for Hyperspectral Anomaly Detection",
        "authors": [
            "Xiangrong Zhang",
            "Xiaoxiao Ma",
            "Ning Huyan",
            "Jing Gu",
            "Xu Tang",
            "Licheng Jiao"
        ],
        "date": "1 December 2021",
        "abstract": "The proposed model can simultaneously learn the dictionary and separate anomaly by iterative learning and demonstrates the superior performance of the proposed method for hyperspectral anomaly detection compared with other state-of-the-art algorithms. Anomaly detection of a hyperspectral image without any prior information has attracted much more attention in remote sensing image understanding and interpretation, which aims at determining whether a sample belongs to background or anomaly. Low-rank dictionary learning plays an important role in exploiting the low-rank prior of background for hyperspectral image (HSI) anomaly detection. In this article, the low-rank dictionary learning is introduced to learn a dictionary which can reconstruct the background positively, while anomaly cannot. Considering the high correlation of data especially between the adjacent bands, we resort to spectral-difference low-rank dictionary representation learning for global background modeling which can fully exploit the low-rank prior of background. Then, the residual matrix is used to distinguish anomaly. Different from the existing anomaly detection methods based on dictionary which is constructed or learned in a separated step, our proposed model can simultaneously learn the dictionary and separate anomaly by iterative learning. The experimental results on five real data sets demonstrate the superior performance of the proposed method for hyperspectral anomaly detection compared with other state-of-the-art algorithms.",
        "references": [
            "83e7d75cd5e0f93508c8ca09a46584bc04fc2fa8",
            "29580626129d00992feac5dbbccbe5a538b3caa8",
            "4c9e2d100dd2104a916bdd979cb42527320d09e8",
            "9b4a3411e163607bb30ae85fa14a6905da7151a5",
            "ab597c7795d0e20c2a00183f349f874064a5e9cb",
            "6660c33e26c7ae1be071af35fcf8fba5058f144a",
            "5a7608d0ab7147bb91a0b90827d3635ea8a1ff6f",
            "93c9f1ea1dfb06672207711a5b2e2eec5b623665",
            "490cdc0bc116774d19589cf8bf216ba87e8cd76e",
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea"
        ],
        "related_topics": [
            "Anomaly Detection",
            "Low-rank Dictionary Learning",
            "Hyperspectral Anomaly Detection",
            "Image Understanding",
            "Iterative Learning",
            "Low-Rank Representation"
        ],
        "reference_count": "49",
        "citation_count": "17"
    },
    {
        "Id": "8df3329d8e1b10f88943c5119fb7b5f83a33e74d",
        "title": "From Model-Based Optimization Algorithms to Deep Learning Models for Clustering Hyperspectral Images",
        "authors": [
            "Shaoguang Huang",
            "Hongyan Zhang",
            "Haijin Zeng",
            "Aleksandra Pi{\\vz}urica"
        ],
        "date": "2023",
        "abstract": "A systematic performance comparison between different clustering methods of HSI is provided by conducting extensive experiments on real HSIs and a toolbox that contains implementations of representative clustering algorithms is provided to help researchers to develop their own models is provided. : Hyperspectral images (HSIs), captured by different Earth observation airborne and space-borne systems, provide rich spectral information in hundreds of bands, enabling far better discrimination between ground materials that are often indistinguishable in visible and multi-spectral images. Clustering of HSIs, which aims to unveil class patterns in an unsupervised way, is highly important in the interpretation of HSI, especially when labelled data is not available. A number of HSI clustering methods have been proposed. Among them, model-based optimization algorithms, which learn cluster structure of data by solving convex/non-convex optimization problems, have achieved the current state-of-the-art performance. Recent works extend the model-based algorithms to deep versions with deep neural networks, obtaining huge breakthroughs of clustering performance. However, a systematic survey on the topic is absent. This article provides a comprehensive overview of clustering methods of HSI and tracks the latest techniques and breakthroughs in the domain, including the traditional model-based optimization algorithms and the emerging deep learning based clustering methods. With a new taxonomy, we elaborate on the main ideas, technical details, advantages and disadvantages of different types of clustering methods of HSIs. We provide a systematic performance comparison between different clustering methods by conducting extensive experiments on real HSIs. Unsolved problems and future research trends in the domain are pointed out. Moreover, we provide a toolbox that contains implementations of representative clustering algorithms to help researchers to develop their own models.",
        "references": [
            "5e6b6caaff4304506f1637ca90db765a99d8733d",
            "411821e4a108180bdf466b6f88f1963502809962",
            "5dd3e0e7f1da307d5a7c8cda460f3aa3845e1b3c",
            "c962d048c1b01297da79cfa7f7b153e237aff9eb",
            "7ab056a660291e56c7d8015877f6e2b0d8eca358",
            "f09578467e5eccf0588e02b6333710fb3ed35e32",
            "a60fafdb261628300da410c7993cd97216a48e30",
            "c0f8996e641300da87b6b563663efb71b9f340c2",
            "6d108d197b001ed2a128c1ee0febe58b6f496e37",
            "8892adbb2e36a836a5ad52bb19e424d8d4624885"
        ],
        "related_topics": [
            "HSIs",
            "Clustering Performance",
            "Labelled Data"
        ],
        "reference_count": "0",
        "citation_count": "189"
    },
    {
        "Id": "dbc63911d4e23bb0d21c62a5f7a1a21b094150bc",
        "title": "Capsulenet-Based Spatial\u2013Spectral Classifier for Hyperspectral Images",
        "authors": [
            "Arun Pv",
            "Krishna Mohan Buddhiraju",
            "Alok Porwal"
        ],
        "date": "15 May 2019",
        "abstract": "The proposed Capsulenet-based framework for extracting spectral and spatial features for improving hyperspectral image classification is found to be less sensitive to the network parameters and achieves better accuracy even with lesser network depth. In this paper, a Capsulenet-based framework is proposed for extracting spectral and spatial features for improving hyperspectral image classification. Unlike conventional strategies, the proposed framework simultaneously optimizes both feature extraction and classification. The spectral features/patterns derived at different levels of hierarchies are remodeled as spectral-feature capsules. Consequently, unlike conventional convolutional neural network-based approaches, the relative locations as well as other properties such as depth, width, and position of the spectral patterns are taken into consideration. In addition to learning spectral features/patterns, a convolutional long short-term memory (conv-LSTM) is employed for sequentially integrating the spatial features learned from each band. The integrated spatial-feature representation, thus obtained from the final hidden state of conv-LSTM, forms spatial-feature capsules. The capsule-level integration of spatial and spectral features/patterns yields better convergence and accuracy as compared to both ensemble-based and kernel-level integrations. Along with the margin loss, a spectral-angle-based reconstruction loss is also minimized to regularize the learning of network weights. Experiments over different standard datasets indicate that the proposed approach performs better than other prominent hyperspectral classifiers. Furthermore, in comparison with the recent deep learning models, our approach is found to be less sensitive to the network parameters and achieves better accuracy even with lesser network depth.",
        "references": [
            "4cf28fc05744d9cfd3206b6b6e8a81c823e740f6",
            "18056fcac6fc744b940a8d10ff36d42269006f3c",
            "e3ab2c2277f77ffd49bbd1392cb3b5b576a70f48",
            "3812751e7d0fe02d19cdc12bbe53a7c683072e28",
            "0f990cb8bbd3767350842b0975b4b32a600f41e1",
            "914e2f0bb6d5d4fb25e2940dbf4ebb3660710f31",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "1b550f491808fba5285c1ffc4067f1cc1431d5f6",
            "33f2761d08da1c5b1b6a8f65ee6930075cf9927e",
            "def683aaaa6fd1145b9ae22c6b200fc579f43c0e"
        ],
        "related_topics": [
            "Margin Loss",
            "Network Depth",
            "Ensemble",
            "Network Weights",
            "Convolutional Neural Network",
            "CapsuleNet",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "67",
        "citation_count": "22"
    },
    {
        "Id": "14b88d0b1234f64f7a66298695a589b5f54c0d1f",
        "title": "Unsupervised Feature Extraction in Hyperspectral Images Based on Wasserstein Generative Adversarial Network",
        "authors": [
            "Mingyang Zhang",
            "Maoguo Gong",
            "Yishun Mao",
            "Jun Yu Li",
            "Yue Wu"
        ],
        "date": "1 May 2019",
        "abstract": "A novel modified generative adversarial network (GAN) is proposed to train a DL-based feature extractor without supervision, and replaces the original Jensen\u2013Shannon divergence with the Wasserstein distance, aiming to mitigate the unstability and difficulty of the training of GAN frameworks. Feature extraction (FE) is a crucial research area in hyperspectral image (HSI) processing. Recently, due to the powerful ability of deep learning (DL) to extract spatial and spectral features, DL-based FE methods have shown great potentials for HSI processing. However, most of the DL-based FE methods are supervised, and the training of them suffers from the absence of labeled samples in HSIs severely. The training issue of supervised DL-based FE methods limits their application on HSI processing. To address this issue, in this paper, a novel modified generative adversarial network (GAN) is proposed to train a DL-based feature extractor without supervision. The designed GAN consists of two components, which are a generator and a discriminator. The generator can focus on the learning of real probability distributions of data sets and the discriminator can extract spatial\u2013spectral features with superior invariance effectively. In order to learn upsampling and downsampling strategies adaptively during FE, the proposed generator and discriminator are designed based on a fully deconvolutional subnetwork and a fully convolutional subnetwork, respectively. Moreover, a novel min\u2013max cost function is designed for training the proposed GAN in an end-to-end fashion without supervision, by utilizing the zero-sum game relationship between the generator and discriminator. Besides, the proposed modified GAN replaces the original Jensen\u2013Shannon divergence with the Wasserstein distance, aiming to mitigate the unstability and difficulty of the training of GAN frameworks. Experimental results on three real data sets validate the effectiveness of the proposed method.",
        "references": [
            "10fb16414324a5db44f5d830adcb4810af59eed0",
            "fe9b4efdf5ebba7865f920b4b94409047fc98ca3",
            "1df49ddb9460f302ff9692f4b93c9f3d68693a17",
            "ab5696f4a3e243abc8689f0dff2c7ee185387225",
            "4630341279a01d25f06a614ca8f3eb7f92903b47",
            "9ed92e11c78d1f96bf364ced84ae8a07b56ac321",
            "f9d119346b0773ea83251598fa5305bc75bac8ab",
            "ef8ae1effca9cd45677086034d8c7b06a69c03e5",
            "0e7e22fe094b0e4b0aa67d4915072c598512da35",
            "022dfa7a38fc43856f83f79e07a2b1f08709c962"
        ],
        "related_topics": [
            "Generative Adversarial Networks",
            "Discriminator",
            "Hyperspectral Imagery",
            "Supervision",
            "Supervised",
            "Wasserstein Distance",
            "HSIs",
            "Downsampling",
            "Spatial-spectral Features",
            "Deep Learning"
        ],
        "reference_count": "86",
        "citation_count": "80"
    },
    {
        "Id": "f0a205ee2656d8adc2d0659f0c9180fc3d0fee4d",
        "title": "Histopathological image classification through discriminative feature learning and mutual information-based multi-channel joint sparse representation",
        "authors": [
            "Xiao Li",
            "Hongzhong Tang",
            "Dongbo Zhang",
            "Ting Liu",
            "Lizhen Mao",
            "Tianyu Chen"
        ],
        "date": "1 July 2020",
        "abstract": "Semantic Scholar extracted view of \"Histopathological image classification through discriminative feature learning and mutual information-based multi-channel joint sparse representation\" by Xiao Li et al.",
        "references": [
            "32ce875b1eeda8215e3dfb9ad05ff94eb656c41e",
            "2704d1d304fb0e39b416662bd721482dc922cbbb",
            "747c75bffc0017f6be0bb6cd81330f27e759b0d4",
            "8745233f937e98c30c46965732993df3d2ae0337",
            "8b0f43a9eb75d97fc7d9d78bdf983813fb07bd1e",
            "b8646378abd6831ed5548fa20d1db03c66d92eaa",
            "701d5bb35021920410f4a4c3382d3dcf5b41cc64",
            "ec83b10372b4f1c5d9d549f9753959a3f8eaf2fe",
            "544d6cd24db5adad8453033e0cc1aa7d3d6224ab",
            "692541a740b2b3c5c82a47390a7cbb40872efec5"
        ],
        "related_topics": [
            "Histopathological Image Classification",
            "Discriminative Feature Learning",
            "Support Vector Machines",
            "Class Labels",
            "Classifier",
            "BreakHis Dataset",
            "Mutual Information",
            "Linear Support Vector Machines",
            "Architecture Description Languages",
            "Multi-channel Features"
        ],
        "reference_count": "57",
        "citation_count": "7"
    },
    {
        "Id": "f59d79f5ab81718cf5fa7bfaf2be635451d7953f",
        "title": "Superpixel Guided Deep-Sparse-Representation Learning for Hyperspectral Image Classification",
        "authors": [
            "Jiayuan Fan",
            "Tao Chen",
            "Shijian Lu"
        ],
        "date": "1 November 2018",
        "abstract": "This paper presents a new technique for hyperspectral image (HSI) classification by using superpixel guided deep-sparse-representation learning, which constructs a hierarchical architecture by exploiting the sparse coding to learn the HSI representation. This paper presents a new technique for hyperspectral image (HSI) classification by using superpixel guided deep-sparse-representation learning. The proposed technique constructs a hierarchical architecture by exploiting the sparse coding to learn the HSI representation. Specifically, a multiple-layer architecture using different superpixel maps is designed, where each superpixel map is generated by downsampling the superpixels gradually along with enlarged spatial regions for labeled samples. In each layer, sparse representation of pixels within every spatial region is computed to construct a histogram via the sum-pooling with  $l_{1}$  normalization. Finally, the representations (features) learned from the multiple-layer network are aggregated and trained by a support vector machine classifier. The proposed technique has been evaluated over three public HSI data sets, including the Indian Pines image set, the Salinas image set, and the University of Pavia image set. Experiments show superior performance compared with the state-of-the-art methods.",
        "references": [
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "9f2f1a5d4f6e582d4afd857915802805a7f4185e",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "b994ba36364e8e61514d1a87002442ce9ab03d33",
            "a1a183c1e263526465c8d3097d13b3e2be273ea8",
            "6f5080b0b66ccb4deedbc1c4bfc655e84d951a07",
            "82e1680535b90e5e43cedc130da7b61ef04cbbd2"
        ],
        "related_topics": [
            "Superpixels",
            "Hyperspectral Imagery",
            "Histograms",
            "Downsampling",
            "Sparse Coding",
            "Sum Pooling",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "48",
        "citation_count": "32"
    },
    {
        "Id": "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
        "title": "Hyperspectral Image Classification Using Dictionary-Based Sparse Representation",
        "authors": [
            "Yi Chen",
            "Nasser M. Nasrabadi",
            "Trac D. Tran"
        ],
        "date": "12 May 2011",
        "abstract": "Experimental results show that the proposed sparsity-based algorithm for the classification of hyperspectral imagery outperforms the classical supervised classifier support vector machines in most cases. A new sparsity-based algorithm for the classification of hyperspectral imagery is proposed in this paper. The proposed algorithm relies on the observation that a hyperspectral pixel can be sparsely represented by a linear combination of a few training samples from a structured dictionary. The sparse representation of an unknown pixel is expressed as a sparse vector whose nonzero entries correspond to the weights of the selected training samples. The sparse vector is recovered by solving a sparsity-constrained optimization problem, and it can directly determine the class label of the test sample. Two different approaches are proposed to incorporate the contextual information into the sparse recovery optimization problem in order to improve the classification performance. In the first approach, an explicit smoothing constraint is imposed on the problem formulation by forcing the vector Laplacian of the reconstructed image to become zero. In this approach, the reconstructed pixel of interest has similar spectral characteristics to its four nearest neighbors. The second approach is via a joint sparsity model where hyperspectral pixels in a small neighborhood around the test pixel are simultaneously represented by linear combinations of a few common training samples, which are weighted with a different set of coefficients for each pixel. The proposed sparsity-based algorithm is applied to several real hyperspectral images for classification. Experimental results show that our algorithm outperforms the classical supervised classifier support vector machines in most cases.",
        "references": [
            "f19122b082188e626ff8355cfcaa432e68509272",
            "0e31d9acb94cdffcefa30b2b09b40e9b8457941c",
            "5d704c3908b11666904467970e6dd5bf59fbfecf",
            "4e0f49c4b23b32b1c0c278fa8eecbfee01b6aeda",
            "b0fe9323b9e74f9473f5b97cccf53a689f64bf60",
            "4aadb3a73a0d753b1e5a7c53ad27b81418ef02d5",
            "344360c84ae36ab2e4a0bb3ffb6ac65f47fc7722",
            "c86abfc2d6c5ad3ed80b133ea736529301f2e500",
            "6fb4840ed454daf0b56ca9b40aced6fc43e569f4",
            "50b596dd0dc5c59912ef747d854c72d891be40b1"
        ],
        "related_topics": [],
        "reference_count": "66",
        "citation_count": "943"
    },
    {
        "Id": "4ab0d77862353cfc1c5d39d4a85fc12c5764843b",
        "title": "Hyperspectral Image Classification With Robust Sparse Representation",
        "authors": [
            "Chang Li",
            "Yong Ma",
            "Xiaoguang Mei",
            "Chengyin Liu",
            "Jiayi Ma"
        ],
        "date": "15 March 2016",
        "abstract": "This work proposes a robust SRC (RSRC) method which can handle outliers in hyperspectral classification and extends the RSRC to the joint robust sparsity model named JRSRC, where pixels in a small neighborhood around the test pixel are simultaneously represented by linear combinations of a few training samples and outliers. Recently, the sparse representation-based classification (SRC) methods have been successfully used for the classification of hyperspectral imagery, which relies on the underlying assumption that a hyperspectral pixel can be sparsely represented by a linear combination of a few training samples among the whole training dictionary. However, the SRC-based methods ignore the sparse representation residuals (i.e., outliers), which may make the SRC not robust for outliers in practice. To overcome this problem, we propose a robust SRC (RSRC) method which can handle outliers. Moreover, we extend the RSRC to the joint robust sparsity model named JRSRC, where pixels in a small neighborhood around the test pixel are simultaneously represented by linear combinations of a few training samples and outliers. The JRSRC can also deal with outliers in hyperspectral classification. Experiments on real hyperspectral images demonstrate that the proposed RSC and JRSRC have better performances than the orthogonal matching pursuit (OMP) and simultaneous OMP, respectively. Moreover, the JRSRC outperforms some other popular classifiers.",
        "references": [
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "5c8f91f7ead043544e2606d1997f9ce15a421107",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "383a5b15bf4eee3084b21f260c97be2e23b9a5b6",
            "2fa41ad17da78347b5fce8cb1e8d89c1c1671f83",
            "f65a1b40d611929c322d2b19cac4c069583b06c4",
            "9dc0f6bb33c4b4aaf3381d22cfbb32bd1514b6f8",
            "8d4a9b9bd9af04598adeadc07c01489ce532d509",
            "a616bd79c26b0390a0c5d349acd3454d5f579d22",
            "05ff227925b538798fe2b56a074a0c96cb79143b"
        ],
        "related_topics": [
            "Sparse Representation Based Classification",
            "Orthogonal Matching Pursuit",
            "Hyperspectral Imagery",
            "Robust Sparse Coding",
            "Test Pixel",
            "Training Dictionary",
            "Classifier",
            "Sparse Representation",
            "Hyperspectral Image Classification",
            "Retrosplenial Cortex"
        ],
        "reference_count": "23",
        "citation_count": "78"
    },
    {
        "Id": "85efd6887be908584bd85e8004dcad3bd53f51aa",
        "title": "Hyperspectral Image Classification With Discriminative Kernel Collaborative Representation and Tikhonov Regularization",
        "authors": [
            "Yong Ma",
            "Chang Li",
            "Hao Li",
            "Xiaoguang Mei",
            "Jiayi Ma"
        ],
        "date": "14 February 2018",
        "abstract": "This work proposes a discriminative kernel collaborative representation and Tikhonov regularization method (DKCRT) for HSI classification, which can make the Kernel collaborative representation of different classes to be more discrim inative. Recently, collaborative representation has received much attention in the hyperspectral image (HSI) classification due to its simplicity and effectiveness. However, the existing collaborative representation-based HSI classification methods ignore the correlation among different classes. To overcome this problem, we propose a discriminative kernel collaborative representation and Tikhonov regularization method (DKCRT) for HSI classification, which can make the kernel collaborative representation of different classes to be more discriminative. Specifically, the kernel trick is adopted to map the original HSI into a high space to improve the class separability. Besides, distance-weighted kernel Tikhonov regularization is adopted to enforce these training samples to have large representation coefficients, which are similar to the test sample in the high-dimensional feature space. Moreover, we add a discriminative regularization term to further enhance the separability of different classes, which can take the correlation among different classes into consideration. Furthermore, to take the spatial information of HSI into consideration, we extend the DKCRT to a joint version named JDKCRT. Experiments on real HSIs demonstrate the efficiency of the proposed DKCRT and JDKCRT.",
        "references": [
            "b36477a7fecd35685ad932f79752ed81564782ce",
            "a19e9ddf42ef935ba417f0f65ed747a4627fb1e2",
            "af617b2b33cb6755d0b642a9a796462e6b56fcf1",
            "e7259f0a9afcc9a8314a9a2ce6c5017fda01edc5",
            "ea50eee59e433f48efe6617bba947f0796c52db4",
            "6f931e84bc5f750586bb39fd3da1fa1213eaa238",
            "2fa3781b4123461a33cfe3cfb11a457b806b0bfc",
            "e6f8971372ebbbfa4d69d792ea282c72e1d2d744",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "87fa9b8d8a49a9ee54b9c55228a6531ee8e8dd3b"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Collaborative Representation",
            "Classification",
            "High Dimensional Feature Space",
            "HSIs",
            "Representation Coefficients",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "31",
        "citation_count": "26"
    },
    {
        "Id": "5154456c5b0b82206005f3df9fc4b478174db1ff",
        "title": "Hyperspectral Image Classification via Multiple-Feature-Based Adaptive Sparse Representation",
        "authors": [
            "Leyuan Fang",
            "Cheng Wang",
            "Shutao Li",
            "J{\\&#x27;o}n Atli Benediktsson"
        ],
        "date": "17 March 2017",
        "abstract": "Experimental results demonstrated that the proposed MFASR method can outperform several well-known classifiers in terms of both qualitative and quantitative results. A multiple-feature-based adaptive sparse representation (MFASR) method is proposed for the classification of hyperspectral images (HSIs). The proposed method mainly includes the following steps. First, four different features are separately extracted from the original HSI and they reflect different kinds of spectral and spatial information. Second, for each pixel, a shape adaptive (SA) spatial region is extracted. Third, an adaptive sparse representation algorithm is introduced to obtain the sparse coefficients for the multiple-feature matrix set of pixels in each SA region. Finally, these obtained coefficients are jointly used to determine the class label of each test pixel. Experimental results demonstrated that the proposed MFASR method can outperform several well-known classifiers in terms of both qualitative and quantitative results.",
        "references": [
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "24a759e723ef8f03326c91f671f3996f05bab9da",
            "d80e7c2280caf016404ffa02469b331e755cfc7b",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc",
            "f2c0f3ff86336d1476432add110bbdf6c8a134d8",
            "6caa2718e85f8cda7d75342ab36821bf0f681b87",
            "4cc353aab3342dca24394e48c5143a8fd4f34523",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "1d67778acccc26a1c42682df32e6d5404b551045",
            "6353266413c38fa9288d82decaf08853b537c1db"
        ],
        "related_topics": [
            "Multiple-feature-based Adaptive Sparse Representation",
            "Multiscale Adaptive Sparse Representation",
            "Shape-adaptive Region",
            "Test Pixel",
            "HSIs",
            "Pixel",
            "Class Labels",
            "Classifier",
            "Classification",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "48",
        "citation_count": "135"
    },
    {
        "Id": "3a5f27e244711177872b349207bec4d64d37e986",
        "title": "Collaborative-Representation-Based Nearest Neighbor Classifier for Hyperspectral Imagery",
        "authors": [
            "Wei Li",
            "Qian Du",
            "Fan Zhang",
            "Wei Hu"
        ],
        "date": "1 February 2015",
        "abstract": "Novel collaborative representation (CR)-based nearest neighbor (NN) algorithms are proposed for hyperspectral image classification based on a CR computed by an \u21132-norm minimization-derived closed-form solution with a Tikhonov regularization matrix. Novel collaborative representation (CR)-based nearest neighbor (NN) algorithms are proposed for hyperspectral image classification. The proposed methods are based on a CR computed by an \u21132-norm minimization with a Tikhonov regularization matrix. More specific, a testing sample is represented as a linear combination of all the training samples, and the weights for representation are estimated by an \u21132-norm minimization-derived closed-form solution. In the first strategy, the label of a testing sample is determined by majority voting of those with k largest representation weights. In the second strategy, local within-class CR is considered as an alternative, and the testing sample is assigned to the class producing the minimum representation residual. The experimental results show that the proposed algorithms achieve better performance than several previous algorithms, such as the original k-NN classifier and the local mean-based NN classifier.",
        "references": [
            "0fe45d9b944714fb1ebaa381c9dd05d82174f4f0",
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "39388e5d39d119be7c1617426259c60b9bd0eca6",
            "45c7a4b20ad32ef6fa7029cb15c09b3e83a1a54b",
            "c86abfc2d6c5ad3ed80b133ea736529301f2e500",
            "83041ca2a123031af18bec0c5684c85ced0daea5",
            "46f9073f3983fd0d9ca5b364bfe8f0bfa89f343e",
            "f5f9dbf8b8537445adc4824d0a427c0138fba457",
            "7736e5662bd8702d2d76640885ad1712357c7b9d"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Collaborative Representation",
            "Representation Residual",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "13",
        "citation_count": "97"
    },
    {
        "Id": "a80b169a86da15040d41033368a07ab052f4315d",
        "title": "Recent Advances on Spectral\u2013Spatial Hyperspectral Image Classification: An Overview and New Guidelines",
        "authors": [
            "Lin He",
            "Jun Yu Li",
            "Chenying Liu",
            "Shutao Li"
        ],
        "date": "1 March 2018",
        "abstract": "A concept of spatial dependency system that involves pixel dependency and label dependency, with two main factors: neighborhood covering and neighborhood importance is developed, and several representative spectral\u2013spatial classification methods are applied on real-world hyperspectral data. Imaging spectroscopy, also known as hyperspectral imaging, has been transformed in the last four decades from being a sparse research tool into a commodity product available to a broad user community. Specially, in the last 10 years, a large number of new techniques able to take into account the special properties of hyperspectral data have been introduced for hyperspectral data processing, where hyperspectral image classification, as one of the most active topics, has drawn massive attentions. Spectral\u2013spatial hyperspectral image classification can achieve better classification performance than its pixel-wise counterpart, since the former utilizes not only the information of spectral signature but also that from spatial domain. In this paper, we provide a comprehensive overview on the methods belonging to the category of spectral\u2013spatial classification in a relatively unified context. First, we develop a concept of spatial dependency system that involves pixel dependency and label dependency, with two main factors: neighborhood covering and neighborhood importance. In terms of the way that the neighborhood information is used, the spatial dependency systems can be classified into fixed, adaptive, and global systems, which can accommodate various kinds of existing spectral\u2013spatial methods. Based on such, the categorizations of single-dependency, bilayer-dependency, and multiple-dependency systems are further introduced. Second, we categorize the performings of existing spectral\u2013spatial methods into four paradigms according to the different fusion stages wherein spatial information takes effect, i.e., preprocessing-based, integrated, postprocessing-based, and hybrid classifications. Then, typical methodologies are outlined. Finally, several representative spectral\u2013spatial classification methods are applied on real-world hyperspectral data in our experiments.",
        "references": [
            "b994ba36364e8e61514d1a87002442ce9ab03d33",
            "bd7d537f837cd33f7b5b5d650e4850fabb8492c7",
            "26cbdee3e90d700748c5cacad1b8f5be9ff83492",
            "b5c3adb715117cacfceaccb3bdef8a6b57b9b5d1",
            "70369818d03b0bba2f2e7b7ef401d5ba985bf84d",
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "e616132691824d6eec92b0eb4560b286d732582b",
            "f9d119346b0773ea83251598fa5305bc75bac8ab",
            "23399225034cdf7e1edb9c6df5ce982b838b4f24",
            "2fa3781b4123461a33cfe3cfb11a457b806b0bfc"
        ],
        "related_topics": [
            "Spectral-spatial Methods",
            "Hyperspectral Image Classification",
            "Spectral-Spatial Classification",
            "Hyperspectral Data",
            "Imaging Spectroscopy",
            "Real-world Hyperspectral Data",
            "Spectral Signatures",
            "Label Dependencies"
        ],
        "reference_count": "143",
        "citation_count": "403"
    },
    {
        "Id": "c11c86f46fa1b42257ea72591792b1dd79e809e6",
        "title": "Hyperspectral Image Classification via Multitask Joint Sparse Representation and Stepwise MRF Optimization",
        "authors": [
            "Yuan Yuan",
            "Jian Zhong Lin",
            "Qi Wang"
        ],
        "date": "1 December 2016",
        "abstract": "The proposed method mainly focuses on multitask joint sparse representation (MJSR) and a stepwise Markov random filed framework and retains necessary correlation in spectral field during classification, which significantly enhances the classification accuracy and robustness. Hyperspectral image (HSI) classification is a crucial issue in remote sensing. Accurate classification benefits a large number of applications such as land use analysis and marine resource utilization. But high data correlation brings difficulty to reliable classification, especially for HSI with abundant spectral information. Furthermore, the traditional methods often fail to well consider the spatial coherency of HSI that also limits the classification performance. To address these inherent obstacles, a novel spectral-spatial classification scheme is proposed in this paper. The proposed method mainly focuses on multitask joint sparse representation (MJSR) and a stepwise Markov random filed framework, which are claimed to be two main contributions in this procedure. First, the MJSR not only reduces the spectral redundancy, but also retains necessary correlation in spectral field during classification. Second, the stepwise optimization further explores the spatial correlation that significantly enhances the classification accuracy and robustness. As far as several universal quality evaluation indexes are concerned, the experimental results on Indian Pines and Pavia University demonstrate the superiority of our method compared with the state-of-the-art competitors.",
        "references": [
            "35f56c64ed29bde773c6fba2e628d2e2875f9f86",
            "21772d71b38ea2a39f18e94f0da83317f588ee1b",
            "510c216b4b089623642ab557f8d5de733202ed13",
            "5f346dc3df2a256003fd037cd770ea3838d781a4",
            "c8b50b0346851a94b5b06f8c790340420aba575b",
            "b994ba36364e8e61514d1a87002442ce9ab03d33",
            "4db744cf8c986b57838727fe4368fbaae052ad2b",
            "82e1680535b90e5e43cedc130da7b61ef04cbbd2",
            "b010cd189d34af561aa74c675330f536c74bad6c",
            "946e836206964c31e3aefce1df54fbb542ab80ed"
        ],
        "related_topics": [
            "Multitask Joint Sparse Representation",
            "Classification",
            "Hyperspectral Imagery",
            "Spectral-spatial Classification Scheme",
            "Hyperspectral Image Classification",
            "Classification Accuracy"
        ],
        "reference_count": "55",
        "citation_count": "182"
    },
    {
        "Id": "87fa9b8d8a49a9ee54b9c55228a6531ee8e8dd3b",
        "title": "Joint Within-Class Collaborative Representation for Hyperspectral Image Classification",
        "authors": [
            "Wei Li",
            "Qian Du"
        ],
        "date": "27 March 2014",
        "abstract": "Experimental results confirm that the proposed joint within-class collaborative representation outperforms other state-of-the-art techniques, such as joint sparse representation and support vector machines with composite kernels. Representation-based classification has gained great interest recently. In this paper, we extend our previous work in collaborative representation-based classification to spatially joint versions. This is due to the fact that neighboring pixels tend to belong to the same class with high probability. Specifically, neighboring pixels near the test pixel are simultaneously represented via a joint collaborative model of linear combinations of labeled samples, and the weights for representation are estimated by an \u21132-minimization derived closed-form solution. Experimental results confirm that the proposed joint within-class collaborative representation outperforms other state-of-the-art techniques, such as joint sparse representation and support vector machines with composite kernels.",
        "references": [
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "0fe45d9b944714fb1ebaa381c9dd05d82174f4f0",
            "9dc0f6bb33c4b4aaf3381d22cfbb32bd1514b6f8",
            "14b64bb5af95367883abd2b95d95979f87bcd5f0",
            "4db744cf8c986b57838727fe4368fbaae052ad2b",
            "2d8afc5e6e992eeb9096a16407926aa88af6e9f2",
            "a00c49eebbe4aa82cf4429954b9994a3c01631fa",
            "f5f9dbf8b8537445adc4824d0a427c0138fba457",
            "6663962405f01593e9c5334ea295f031e70468db",
            "4cc353aab3342dca24394e48c5143a8fd4f34523"
        ],
        "related_topics": [
            "Composite Kernels",
            "Collaborative Representation Based Classification",
            "Collaborative Representation",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "26",
        "citation_count": "165"
    },
    {
        "Id": "386ac22671ecca7698ea6327b4cb184e1a689e63",
        "title": "A three layer spatial-spectral hyperspectral image classification model using guided median filters",
        "authors": [
            "Semih Din\u00e7",
            "Luis Alberto Cueva Parra"
        ],
        "date": "15 April 2021",
        "abstract": "An efficient, three-layer hyperspectral image classification model by utilizing spectral/spatial features and a new proximity-based 2D edge preserving order-statistic filtering called Guided Median Filter (GMF) is introduced with weights assigned to each neighboring pixel. Hyperspectral images (HSI) contain rich spectral information from a large portion of the electromagnetic spectrum. Using these images, it is possible to make pixel-level classification as each pixel holds hundreds of features. In this paper, we propose an efficient, three-layer hyperspectral image classification model by utilizing spectral/spatial features. The first layer of the system includes two classifiers that work in parallel. These classifiers generate probability scores that form the \"new feature set\" of the original dataset. The second layer is an ensemble classifier that combines the new features to generate the initial region classification. The third layer introduces a novel approach for enhancing the initial region classification's accuracy from the second layer by utilizing the spatial characteristics of the dataset. A new proximity-based 2D edge preserving order-statistic filtering called Guided Median Filter (GMF) is introduced with weights assigned to each neighboring pixel. Experimental results show that the proposed system improves our previously published results and reaches over 96% overall accuracy on Indian Pines dataset by exceeding some well-known traditional classifiers. Moreover, our GMF based system produced comparable results with the state-of-the-art neural network based methodologies without complex training stage and lack of interpretability of classification model.",
        "references": [
            "ee5812b92f4159fda10dba701b17c34e245cf985",
            "6fda19531dc703dae4501af2bfb5cb8b51c522c0",
            "f19771251aaf74002f8a8dbc3b47bb3fe3700e21",
            "28f3446718da6fed450bded33576322bd8d60448",
            "ba14fa8493a1919903c6b9ab047a86448f7e2559",
            "eb3d0f7607c4492dd89d3a25f7d1c5aaadef6b7e",
            "d627c249d828d96c0ef91d7fa6605a3854f6972a",
            "2a6ec10b3539a4285f43e846404eb18c01ad0a32",
            "61ddadb63e64bd1a281c7462eb92a3a844198593",
            "e8df07c0722b2116e5a0ad3bddc9ccdf7aef4e20"
        ],
        "related_topics": [
            "Classifier",
            "Geophysical Model Function",
            "Region Classification",
            "Interpretability",
            "Indian Pines Dataset",
            "Hyperspectral Imagery",
            "Classification",
            "Neural Network"
        ],
        "reference_count": "36",
        "citation_count": "3"
    },
    {
        "Id": "c8afb6dd879c154becf2c1218da788aa0e953e85",
        "title": "FHIC: Fast Hyperspectral Image Classification Model Using ETR Dimensionality Reduction and ELU Activation Function",
        "authors": [
            "Dalal Al-Alimi",
            "Zhihua Cai",
            "Mohammed Abdulaziz Aide Al-qaness"
        ],
        "date": "2023",
        "abstract": "The fast hyperspectral image classification (FHIC) model is introduced, a rapid model for classifying HSIs and resolving their associated challenges that uses the enhancing transformation reduction (ETR) method to address the HSI difficulties and enhance classes\u2019 differentiation. Hyperspectral images (HSIs) are typically utilized in a wide variety of practical applications. HSI is replete with spatial and spectral information, which provides precise data for material detection. HSIs are characterized by a high degree of variations and undesirable pixel distributions, providing major processing challenges. This article introduces the fast hyperspectral image classification (FHIC) model, a rapid model for classifying HSIs and resolving their associated challenges. It uses the enhancing transformation reduction (ETR) method to address the HSI difficulties and enhance classes\u2019 differentiation. It also uses exponential linear units (ELUs) to smooth and speed the classification processing. The structure of the FHIC model is designed to be very flexible and suitable for a range of HSIs. The model reduced execution time and RAM consumption, and provided superior performance compared to seven of the most advanced analysis models for three well-known HSIs. In some cases, it was 60% faster than other models. In addition, this work presents a new and highly effective method for measuring the performance of the compared models in terms of their accuracy and processing speed to provide an easy evaluation method. The code of the FHIC model is available at this link: https://github.com/DalalAL-Alimi/FHIC.",
        "references": [
            "0913f85051cb0d4d83499679d04cb3e7d9be1c09",
            "1e5e55c6c00fd7b2a48af9307d6aa738db7c7742",
            "ead1963f4963d6a75b189058b4490deacbfc7212",
            "16aeed4da8b6655b9e050f79d9f0c4bb0e1ab417",
            "3be5f12a68822f612de303ccece45bce9d8b2afe",
            "28f3446718da6fed450bded33576322bd8d60448",
            "c8cdd589603347088d61f64a4d845bf11dbb6804",
            "a8fdc7a276c1576f3f2145edb6e155a2b505db71",
            "dc6d5d7e3a9f0a71f781e6eb9116d41d4c13d433",
            "2f875a3e2c9933d6f09c5434af73f967d11a6e19"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "63"
    },
    {
        "Id": "9c5a7beb1fb3471cead2188dc753fea72a0d1db3",
        "title": "Dual-Concentrated Network With Morphological Features for Tree Species Classification Using Hyperspectral Image",
        "authors": [
            "Zhengqi Guo",
            "Mengmeng Zhang",
            "Wen Jia",
            "Jinxin Zhang",
            "Wei Li"
        ],
        "date": "2022",
        "abstract": "A dual-concentrated network with morphological features (DNMF) is proposed to solve the dilemma of forest tree species classification and achieves clearly better classification performance over other competitive baselines. At present, deep learning is a hot topic in the field of the classification of hyperspectral image (HSI), and it has aroused wide attention. However, in fine-grained classification tasks, such as tree species classification, the uncertain spectrum remains the major factor restraining the classification performance. In order to solve the dilemma of forest tree species classification, a dual-concentrated network with morphological features (DNMF) is proposed. First, mathematical morphology is used to extract the morphological features of HSI. Then, coarse-grained information is extracted from the original hyperspectral data, and fine-grained information is extracted from morphological features. After that, both morphological representations and spectral inputs are fed into DNMF, and the overall evaluation index and visual image are obtained. The advantage of DNMF is that it decouples the spatial and spectral information, and a multisource information fusion process is then simulated. Accordingly, DNMF obtains high tree species classification accuracy. In order to verify the superiority of DNMF, we choose Gaofeng State-owned Forest Farm in Guangxi Province and the Belgium dataset, which was collected near the western part of Belgium as the research area. Related experiments demonstrate that the DNMF model achieves clearly better classification performance over other competitive baselines.",
        "references": [
            "10fb16414324a5db44f5d830adcb4810af59eed0",
            "e555093a7817eb9c8f2ba3c24da1f710e0d2f11f",
            "662cbc150e06a99fe078d4e4c33f2a295cbb7707",
            "d3b234a3df280817ac110406c8f66e94c49905ad",
            "4397dfccb9649f0dfbfce7090f5b801fce24a72e",
            "bff8253cadb82dacc8fb7a6185cca122a55e06e9",
            "b4891152b7291a204d30a4786f25ea6846635c4b",
            "4cf28fc05744d9cfd3206b6b6e8a81c823e740f6",
            "310b4401dd987a8bb4188d613df6920c926b148f",
            "b55f3abd8ad1e570021a8b609a99a42507305a71"
        ],
        "related_topics": [
            "Discriminant Non-negative Matrix Factorization",
            "Classification",
            "Tree Species Classification",
            "Hyperspectral Imagery",
            "Hyperspectral Data",
            "Fine-grained Classification",
            "Deep Learning",
            "Mathematical Morphology"
        ],
        "reference_count": "42",
        "citation_count": "7"
    },
    {
        "Id": "78a991a04776599de11d30bc2dd7a35ff1712e90",
        "title": "Wide and Deep Fourier Neural Network for Hyperspectral Remote Sensing Image Classification",
        "authors": [
            "Jiangbo Xi",
            "Okan K. Ersoy",
            "Ming Cong",
            "Chaoying Zhao",
            "Wei Qu",
            "Tianjun Wu"
        ],
        "date": "19 June 2022",
        "abstract": "A wide and deep Fourier network to learn features efficiently by using pruned features extracted in the frequency domain by composed of multiple wide Fourier layers to extract hierarchical features layer-by-layer efficiently. Hyperspectral remote sensing image (HSI) classification is very useful in different applications, and recently, deep learning has been applied for HSI classification successfully. However, the number of training samples is usually limited, causing difficulty in use of very deep learning models. We propose a wide and deep Fourier network to learn features efficiently by using pruned features extracted in the frequency domain. It is composed of multiple wide Fourier layers to extract hierarchical features layer-by-layer efficiently. Each wide Fourier layer includes a large number of Fourier transforms to extract features in the frequency domain from a local spatial area using sliding windows with given strides.These extracted features are pruned to retain important features and reduce computations. The weights in the final fully connected layers are computed using least squares. The transform amplitudes are used for nonlinear processing with pruned features. The proposed method was evaluated with HSI datasets including Pavia University, KSC, and Salinas datasets. The overall accuracies (OAs) of the proposed method can reach 99.77%, 99.97%, and 99.95%, respectively. The average accuracies (AAs) can achieve 99.55%, 99.95%, and 99.95%, respectively. The Kappa coefficients are as high as 99.69%, 99.96%, and 99.94%, respectively. The experimental results show that the proposed method achieved excellent performance among other compared methods. The proposed method can be used for applications including classification, and image segmentation tasks, and has the ability to be implemented with lightweight embedded computing platforms. The future work is to improve the method to make it available for use in applications including object detection, time serial data prediction, and fast implementation.",
        "references": [
            "77836f76b7cd75ff8c4f5f1e0fb1e1a5f4008861",
            "371983a066dd92f2e4b8315f8263a3adcce57c94",
            "50fe48616ceff28319061f49b4aae8c76db1cd49",
            "33f2761d08da1c5b1b6a8f65ee6930075cf9927e",
            "86fdd7fe5700f00e4bcc70983a97c1b9669c953b",
            "411771fabca49e687b5bb8410a58ddaafb4c71a9",
            "d7de9124087e3687abf05055b8c3d2045c6e94ce",
            "16a7a491bb9194d38bfe3b2f6ce7a68b404fcf7d",
            "399bba9c5fbd458d5c1e237c19b45b379d5d2808",
            "28f3446718da6fed450bded33576322bd8d60448"
        ],
        "related_topics": [
            "Classification",
            "Hyperspectral Imagery",
            "Deep Learning",
            "Fully Connected Layers",
            "Fourier Network",
            "Hierarchical Features",
            "Hyperspectral Remote Sensing",
            "Fourier-Neural-Network",
            "Image Segmentation",
            "Sliding-window"
        ],
        "reference_count": "30",
        "citation_count": "7"
    },
    {
        "Id": "544e1071d2c951eb730d4790fb44ed82a3d0dfeb",
        "title": "Improved Quasi-Recurrent Neural Network for Hyperspectral Image Denoising",
        "authors": [
            "Zeqiang Lai",
            "Ying Fu"
        ],
        "date": "27 November 2022",
        "abstract": "This paper introduces an adaptive fusion module to replace its vanilla additive skip connection to better fuse the features of the encoder and decoder and identifies several important techniques to further enhance the performance, which includes removing batch normalization, use of extra frequency loss, and learning rate warm-up. Hyperspectral image is unique and useful for its abundant spectral bands, but it subsequently requires extra elaborated treatments of the spatial-spectral correlation as well as the global correlation along the spectrum for building a robust and powerful HSI restoration algorithm. By considering such HSI characteristics, 3D Quasi-Recurrent Neural Network (QRNN3D) is one of the HSI denoising networks that has been shown to achieve excellent performance and flexibility. In this paper, we show that with a few simple modifications, the performance of QRNN3D could be substantially improved further. Our modifications are based on the finding that through QRNN3D is powerful for modeling spectral correlation, it neglects the proper treatment between features from different sources and its training strategy is suboptimal. We, therefore, introduce an adaptive fusion module to replace its vanilla additive skip connection to better fuse the features of the encoder and decoder. We additionally identify several important techniques to further enhance the performance, which includes removing batch normalization, use of extra frequency loss, and learning rate warm-up. Experimental results on various noise settings demonstrate the effectiveness and superior performance of our method.",
        "references": [
            "a792fbcff5d3e230f1c59c089195409d51421263",
            "2d99d56ae3dc38a3949dcc9f8578579d09be0fae",
            "e7e4d2dd46e0efbfb69131fb924012084337e034",
            "de74305d2ce63d616aa28c93c7644e4c40a9602b",
            "841eeeb0c3e1ee0a486e8b1f0502de844b340fc4",
            "a4608bfe6a44eeb37a5ca9d65b992d302040a3d1",
            "f675035662882dc44b2a557104dcda24e783a281",
            "b1983976d43dfec7bcc918d67ed826e9b8f3c46c",
            "28f3446718da6fed450bded33576322bd8d60448",
            "2c2acfdbd61336f0b4d9974a7ff6ce963f6a73e5"
        ],
        "related_topics": [
            "QRNN3D",
            "Spatial-spectral Correlations",
            "Batch Normalization",
            "Hyperspectral Image Denoising"
        ],
        "reference_count": "0",
        "citation_count": "32"
    },
    {
        "Id": "371983a066dd92f2e4b8315f8263a3adcce57c94",
        "title": "Wide Sliding Window and Subsampling Network for Hyperspectral Image Classification",
        "authors": [
            "Jiangbo Xi",
            "Okan K. Ersoy",
            "Jianwu Fang",
            "Ming Cong",
            "Tianjun Wu",
            "Chaoying Zhao",
            "Zhenhong Li"
        ],
        "date": "2021",
        "abstract": "A wide sliding window and subsampling network (WSWS Net) for HSI classification based on layers of transform kernels with sliding windows and subsAMpling (W SWS) that can learn higher level spatial and spectral features efficiently and be trained easily by only computing linear weights with least squares. Recently, deep learning methods, for example, convolutional neural networks (CNNs), have achieved high performance in hyperspectral image (HSI) classification. The limited training samples of HSI images make it hard to use deep learning methods with many layers and a large number of convolutional kernels as in large scale imagery tasks, and CNN-based methods usually need long training time. In this paper, we present a wide sliding window and subsampling network (WSWS Net) for HSI classification. It is based on layers of transform kernels with sliding windows and subsampling (WSWS). It can be extended in the wide direction to learn both spatial and spectral features more efficiently. The learned features are subsampled to reduce computational loads and to reduce memorization. Thus, layers of WSWS can learn higher level spatial and spectral features efficiently, and the proposed network can be trained easily by only computing linear weights with least squares. The experimental results show that the WSWS Net achieves excellent performance with different hyperspectral remotes sensing datasets compared with other shallow and deep learning methods. The effects of ratio of training samples, the sizes of image patches, and the visualization of features in WSWS layers are presented.",
        "references": [
            "135fe6fd213b468a35345d7fb8a442beec460f1f",
            "914e2f0bb6d5d4fb25e2940dbf4ebb3660710f31",
            "50fe48616ceff28319061f49b4aae8c76db1cd49",
            "ec9aa46ebc50a03ea9d7d20d80a232e6bd4293de",
            "25abe220befdbeffce61e6dcdd9fa0fffb7cbea9",
            "d1cac56b10e8af20d1d0e5e6aeae9ca33200878b",
            "0f990cb8bbd3767350842b0975b4b32a600f41e1",
            "4a9bc2ef17b211ede1dc73ac9b24a31612f88735",
            "86fdd7fe5700f00e4bcc70983a97c1b9669c953b",
            "33f2761d08da1c5b1b6a8f65ee6930075cf9927e"
        ],
        "related_topics": [
            "Deep Learning",
            "Hyperspectral Imagery",
            "Image Patches",
            "Convolutional Neural Network",
            "Memorization",
            "Sliding-window",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "43",
        "citation_count": "5"
    },
    {
        "Id": "99adda00d7427163996270bf68107a80fd9bca11",
        "title": "Mixed Attention Network for Hyperspectral Image Denoising",
        "authors": [
            "Zeqiang Lai",
            "Ying Fu"
        ],
        "date": "27 January 2023",
        "abstract": "An attentive skip-connection that adaptively controls the propor-tion of the low- and high-level spatial-spectral features from the encoder and decoder to better enhance the aggregated features is proposed. Hyperspectral image denoising is unique for the highly similar and correlated spectral information that should be properly considered. However, existing methods show lim-itations in exploring the spectral correlations across different bands and feature interactions within each band. Besides, the low- and high-level features usually exhibit different importance for different spatial-spectral regions, which is not fully explored for current algorithms as well. In this paper, we present a Mixed Attention Network (MAN) that simultaneously considers the inter- and intra-spectral correlations as well as the interactions between low- and high-level spatial-spectral meaningful features. Speci\ufb01cally, we introduce a multi-head recurrent spectral attention that ef-\ufb01ciently integrates the inter-spectral features across all the spectral bands. These features are further enhanced with a progressive spectral channel attention by exploring the intra-spectral relationships. Moreover, we propose an attentive skip-connection that adaptively controls the propor-tion of the low- and high-level spatial-spectral features from the encoder and decoder to better enhance the aggregated features. Extensive experiments show that our MAN outperforms existing state-of-the-art methods on simulated and real noise settings while maintaining a low cost of parameters and running time. Code is available at https: //github.com/Zeqiang-Lai/MAN .",
        "references": [
            "b1983976d43dfec7bcc918d67ed826e9b8f3c46c",
            "a792fbcff5d3e230f1c59c089195409d51421263",
            "2a67272efd2b205acda3dddb16272eba91284d4c",
            "f675035662882dc44b2a557104dcda24e783a281",
            "28f3446718da6fed450bded33576322bd8d60448",
            "b0d7f39543b3e0372d8d15377dbc19246b0412cb",
            "841eeeb0c3e1ee0a486e8b1f0502de844b340fc4",
            "e7e4d2dd46e0efbfb69131fb924012084337e034",
            "de74305d2ce63d616aa28c93c7644e4c40a9602b",
            "2d99d56ae3dc38a3949dcc9f8578579d09be0fae"
        ],
        "related_topics": [
            "Hyperspectral Image Denoising",
            "Parameters",
            "Feature Interactions"
        ],
        "reference_count": "46",
        "citation_count": "7"
    },
    {
        "Id": "4fcafdca973e9c7d59bcc6a5595d10c3b4abc7d4",
        "title": "Dual Convolutional Neural Networks for Hyperspectral Satellite Images Classification (DCNN-HSI)",
        "authors": [
            "Maissa Hamouda",
            "Med Salim Bouhlel"
        ],
        "date": "18 November 2020",
        "abstract": "A new approach to the reduction and classification of HSI is proposed consisting of a dual Convolutional Neural Networks (DCNN), which aims to improve precision and computing time. Hyperspectral Satellite Images (HSI) presents a very interesting technology for mapping, environmental protection, and security. HSI is very rich in spectral and spatial characteristics, which are non-linear and highly correlated which makes classification difficult. In this paper, we propose a new approach to the reduction and classification of HSI. This deep approach consisting of a dual Convolutional Neural Networks (DCNN), which aims to improve precision and computing time. This approach involves two main steps; the first is to extract the spectral data and reduce it by CNN until a single value representing the active pixel is displayed. The second consists in classifying the only remaining spatial band on CNN until the class of each pixel is obtained. The tests were applied to three different hyperspectral data sets and showed the effectiveness of the proposed method.",
        "references": [
            "7cae6175cc9762dd9da56d90acdde31a2dd3d8b7",
            "59e20b18c9c98c321f7e65162e8d8ac42426065f",
            "989ac349530becfa49ca4ec9d274fba352a0ce4b",
            "662cbc150e06a99fe078d4e4c33f2a295cbb7707",
            "fca90d8db505be2767385dbb4f9be57409b25865",
            "f44d4fdc3eaf3546ff3c99ce306681b82dea1f95",
            "12621cc314ac1fd10b7ce719ff0326a70b03ce64",
            "135fe6fd213b468a35345d7fb8a442beec460f1f",
            "28f3446718da6fed450bded33576322bd8d60448",
            "1dc459f8fcd3d57307b38480bbf9fad162460dde"
        ],
        "related_topics": [
            "Classification",
            "Hyperspectral Imagery",
            "Convolutional Neural Network",
            "Hyperspectral Data Sets",
            "Deep Convolutional Neural Networks"
        ],
        "reference_count": "17",
        "citation_count": "3"
    },
    {
        "Id": "da4e0402c30f9aaf8de6e074d4fe86b842d57ca5",
        "title": "Tensor Dictionary Self-Taught Learning Classification Method for Hyperspectral Image",
        "authors": [
            "Fengshuang Liu",
            "J. Fu",
            "Qiang Wang",
            "Rongqiang Zhao"
        ],
        "date": "2 September 2022",
        "abstract": "A tensor-based dictionary self-taught learning (TDSL) classification method to provide some insight into these challenges of precise object classification based on Hyperspectral imagery with limited training data is proposed. Precise object classification based on Hyperspectral imagery with limited training data presents a challenging task. We propose a tensor-based dictionary self-taught learning (TDSL) classification method to provide some insight into these challenges. The idea of TDSL is to utilize a small amount of unlabeled data to improve the supervised classification. The TDSL trains tensor feature extractors from unlabeled data, extracts joint spectral-spatial tensor features and performs classification on the labeled data set. These two data sets can be gathered over different scenes even by different sensors. Therefore, TDSL can complete cross-scene and cross-sensor classification tasks. For training tensor feature extractors on unlabeled data, we propose a sparse tensor-based dictionary learning algorithm for three-dimensional samples. In the algorithm, we initialize dictionaries using Tucker decomposition and update these dictionaries based on the K higher-order singular value decomposition. These dictionaries are feature extractors, which are used to extract sparse joint spectral-spatial tensor features on the labeled data set. To provide classification results, the support vector machine as the classifier is applied to the tensor features. The TDSL with the majority vote (TDSLMV) can reduce the misclassified pixels in homogenous regions and at the edges of different homogenous regions, which further refines the classification. The proposed methods are evaluated on Indian Pines, Pavia University, and Houston2013 datasets. The classification results show that TDSLMV achieves as high as 99.13%, 99.28%, and 99.76% accuracies, respectively. Compared with several state-of-the-art methods, the classification accuracies of the proposed methods are improved by at least 2.5%.",
        "references": [
            "6007a8fdc7ccfc5975f7760db1a4f8831c36193a",
            "3de023fa8aef889abe06f17d426b5e313c5ba2ae",
            "3ff19fd08103de4bead049290aed3557d4394cab",
            "c317404601e9663c42887d7e1a6d4983365e1c69",
            "526773c63b419534c82afa8cb09dd50c9ecab77e",
            "d987470cc86d5a9f51872f0b8de4d9971cbd2590",
            "28f3446718da6fed450bded33576322bd8d60448",
            "097615d18c38ec8ed986a7af586d38d804eee482",
            "7d4d512445903e8ad75f0dcfa8baec27b1fe8620",
            "f8987ce55d716c293db94514071cdb6b7f451bd7"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Tensor Dictionary",
            "Classification Accuracy",
            "Tucker Decomposition",
            "Houston2013"
        ],
        "reference_count": "26",
        "citation_count": "4"
    },
    {
        "Id": "77836f76b7cd75ff8c4f5f1e0fb1e1a5f4008861",
        "title": "Dynamic Wide and Deep Neural Network for Hyperspectral Image Classification",
        "authors": [
            "Jiangbo Xi",
            "Ming Cong",
            "Okan K. Ersoy",
            "Weibao Zou",
            "Chaoying Zhao",
            "Zhenhong Li",
            "Junkai Gu",
            "Tianjun Wu"
        ],
        "date": "2021",
        "abstract": "The experimental results showed that the proposed DWDNN had the highest test accuracies compared to both the typical machine learning methods such as support vector machine (SVM), multilayer perceptron (MLP), radial basis function (RBF), and the recently proposed deep learning methods including the 2D convolutional neural network (CNN) and the 3D CNN designed for HSI classification. Recently, deep learning has been successfully and widely used in hyperspectral image (HSI) classification. Considering the difficulty of acquiring HSIs, there are usually a small number of pixels used as the training instances. Therefore, it is hard to fully use the advantages of deep learning networks; for example, the very deep layers with a large number of parameters lead to overfitting. This paper proposed a dynamic wide and deep neural network (DWDNN) for HSI classification, which includes multiple efficient wide sliding window and subsampling (EWSWS) networks and can grow dynamically according to the complexity of the problems. The EWSWS network in the DWDNN was designed both in the wide and deep direction with transform kernels as hidden units. These multiple layers of kernels can extract features from the low to high level, and because they are extended in the wide direction, they can learn features more steadily and smoothly. The sliding windows with the stride and subsampling were designed to reduce the dimension of the features for each layer; therefore, the computational load was reduced. Finally, all the weights were only from the fully connected layer, and the iterative least squares method was used to compute them easily. The proposed DWDNN was tested with several HSI data including the Botswana, Pavia University, and Salinas remote sensing datasets with different numbers of instances (from small to big). The experimental results showed that the proposed method had the highest test accuracies compared to both the typical machine learning methods such as support vector machine (SVM), multilayer perceptron (MLP), radial basis function (RBF), and the recently proposed deep learning methods including the 2D convolutional neural network (CNN) and the 3D CNN designed for HSI classification.",
        "references": [
            "371983a066dd92f2e4b8315f8263a3adcce57c94",
            "411771fabca49e687b5bb8410a58ddaafb4c71a9",
            "50fe48616ceff28319061f49b4aae8c76db1cd49",
            "399bba9c5fbd458d5c1e237c19b45b379d5d2808",
            "86fdd7fe5700f00e4bcc70983a97c1b9669c953b",
            "60d9822b07e1aa8a1fbf7a43e1ba1bf1a36cc930",
            "b19ec45c2445437199c8017e97f789aab4f4e606",
            "33f2761d08da1c5b1b6a8f65ee6930075cf9927e",
            "28f3446718da6fed450bded33576322bd8d60448",
            "0f1af456f7ab0348b87e752a42fad1ba97430d37"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Deep Learning",
            "Support Vector Machines",
            "Overfitting",
            "Radial Basis Function",
            "Pixel",
            "Fully Connected Layers",
            "Deep Neural Networks",
            "Salinas",
            "3D CNNs"
        ],
        "reference_count": "19",
        "citation_count": "7"
    },
    {
        "Id": "5a478d117545ca55a547bc7d79aed12934b27c79",
        "title": "Diagonalized Low-Rank Learning for Hyperspectral Image Classification",
        "authors": [
            "Changda Xing",
            "Meiling Wang",
            "Zhisheng Wang",
            "Chaowei Duan",
            "Yiliu Liu"
        ],
        "date": "2022",
        "abstract": "A diagonalized low-rank learning (DLRL) model is proposed for HSI classification that combines sparsity and collaboration to extract more discriminative features for guaranteeing high information utilization and rich information in the HSI can be fully used for good feature extraction. Hyperspectral image (HSI) classification is a current research hotspot. Most existing methods usually export discriminative features with low-quality distribution and low information utilization, which may induce classification performance degeneration. To remedy such deficiencies, we propose a diagonalized low-rank learning (DLRL) model for HSI classification in this study. Specifically, a classwise regularization is used to capture the classwise block-diagonal structure of low-rank representation, which can further cluster the represented HSI pixels from one class into the same subspace and extract features with well-ordered distribution. Such a regularization assists to easily and correctly classify HSIs. In addition, we combine sparsity and collaboration to extract more discriminative features for guaranteeing high information utilization, i.e., a tradeoff of sparsity and collaboration is sought to acquire both correlations among HSI pixels and characteristics of each pixel. By this way, rich information in the HSI can be fully used for good feature extraction. Further, the estimated feature representation is used as an input to the support vector machine (SVM) classifier for HSI classification. Extensive experiments have been done to validate that the proposed DLRL method achieves much classification performance in contrast to several state-of-the-art algorithms.",
        "references": [
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "8f512f556a992851a7191e730c5be34dc420fe4f",
            "1ed74cc57d99a085072828325b0511ec623b4f5a",
            "727db0ea4f5893ca3dfca4cb5d49d94530ab0190",
            "ef8ae1effca9cd45677086034d8c7b06a69c03e5",
            "bdd57e49191329bac20caa48f3405ac111bf0842",
            "2d0be5ddd3f000f4a0d26af9bf31c5e2362652c1",
            "b4891152b7291a204d30a4786f25ea6846635c4b",
            "83ad3a253c05f7010a39f0c52c23302546ff8ebc"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Classification",
            "Pixel",
            "HSIs",
            "Support Vector Machines",
            "Classifier",
            "Hyperspectral Image Classification",
            "Low-Rank Representation"
        ],
        "reference_count": "47",
        "citation_count": "9"
    },
    {
        "Id": "e7259f0a9afcc9a8314a9a2ce6c5017fda01edc5",
        "title": "Hyperspectral Image Classification with Spatial Filtering and \u21132,1 Norm",
        "authors": [
            "Hao Li",
            "Chang Li",
            "Cong Zhang",
            "Zhe Liu",
            "Chengyin Liu"
        ],
        "date": "1 February 2017",
        "abstract": "A hyperspectral classification method with spatial filtering and \u21132,1 norm (SFL) that can deal with all the test pixels simultaneously and can obtain better classification performance than some other popular classifiers is proposed. Recently, the sparse representation based classification methods have received particular attention in the classification of hyperspectral imagery. However, current sparse representation based classification models have not considered all the test pixels simultaneously. In this paper, we propose a hyperspectral classification method with spatial filtering and \u21132,1 norm (SFL) that can deal with all the test pixels simultaneously. The \u21132,1 norm regularization is used to extract relevant training samples among the whole training data set with joint sparsity. In addition, the \u21132,1 norm loss function is adopted to make it robust for samples that deviate significantly from the rest of the samples. Moreover, to take the spatial information into consideration, a spatial filtering step is implemented where all the training and testing samples are spatially averaged with its nearest neighbors. Furthermore, the non-negative constraint is added to the sparse representation matrix motivated by hyperspectral unmixing. Finally, the alternating direction method of multipliers is used to solve SFL. Experiments on real hyperspectral images demonstrate that the proposed SFL method can obtain better classification performance than some other popular classifiers.",
        "references": [
            "4ab0d77862353cfc1c5d39d4a85fc12c5764843b",
            "4a5ff537ed30b7810d463483eba83c55d9fe51d9",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "9f2f1a5d4f6e582d4afd857915802805a7f4185e",
            "87402a58586ed750d3c43e4c7062a3a6a867bf42",
            "4f9c359b60e2e3efeed37836f4f5839edaa78b54",
            "135aa328a788c02cecfed79291f11f2bbb20603e",
            "28370ac959ea8a46fdf05d1092ee476ace3afe3d",
            "a7578a4673ba8e8abf084bc05cb335d255b862ea",
            "10fb16414324a5db44f5d830adcb4810af59eed0"
        ],
        "related_topics": [
            "Test Pixel",
            "L2,1-norm Regularization",
            "Hyperspectral Unmixing",
            "Hyperspectral Imagery",
            "Classifier",
            "Sparse Representation Based Classification",
            "Sparse Representation",
            "Hyperspectral Image Classification"
        ],
        "reference_count": "69",
        "citation_count": "16"
    },
    {
        "Id": "6007a8fdc7ccfc5975f7760db1a4f8831c36193a",
        "title": "Low-rank tensor learning for classification of hyperspectral image with limited labeled samples",
        "authors": [
            "Zhi He",
            "Jie Hu",
            "Yiwen Wang"
        ],
        "date": "1 April 2018",
        "abstract": "Semantic Scholar extracted view of \"Low-rank tensor learning for classification of hyperspectral image with limited labeled samples\" by Zhi He et al.",
        "references": [
            "a0cbb07c4dd3bb08151ca50dae1c10d70e1973ea",
            "3b719e05301c7f76417e68d68cdb028a1897297a",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "9f2f1a5d4f6e582d4afd857915802805a7f4185e",
            "6299e7a7c7be96d7353e25aa0e7c1a23270b088e",
            "87402a58586ed750d3c43e4c7062a3a6a867bf42",
            "91ae137df087e3f83facf7def0081ea41e1f3fc4",
            "6caa2718e85f8cda7d75342ab36821bf0f681b87",
            "9b365a0198fcede7b8e6c74ec01155558fb1431b",
            "8f512f556a992851a7191e730c5be34dc420fe4f"
        ],
        "related_topics": [
            "Hyperspectral Imagery",
            "Classification",
            "Low Rank Tensor Learning",
            "Superpixel Segmentation",
            "Multilinear Algebra",
            "Class Labels",
            "Minimal Residual",
            "Third-order Tensor",
            "Spectral-spatial Classification Framework"
        ],
        "reference_count": "83",
        "citation_count": "23"
    },
    {
        "Id": "9375fbfdcd1c250c7e340f88e268886ce63bfe18",
        "title": "Semi-Supervised Subspace Clustering via Non-Negative Low-Rank Representation for Hyperspectral Images",
        "authors": [
            "Jipan Yang",
            "Dexiang Zhang",
            "Teng Li",
            "Yan Wang",
            "Qing Yan"
        ],
        "date": "1 August 2018",
        "abstract": "This paper utilized a semi-supervised subspace clustering method based on non-negative low-rank representation (NNLRR) algorithm for HSI clustering, and results show that, the algorithm is effective for hyperspectral image clustering. Hyperspectral images (HSIs) own inherent complexity, so, clustering for HSIs is a very challenging task. In this paper, we utilized a semi-supervised subspace clustering method based on non-negative low-rank representation (NNLRR) algorithm for HSI clustering. Firstly, NNLRR used Gaussian fields and harmonic functions into the low-rank representation (LRR) model. Secondly, NNLRR guided the affinity matrix construction by the supervision information. Next, finding a non-negative low-rank matrix, the matrix represents each sample by some other linear combination points, and the affinity matrix is obtained by the matrix. Then, accomplishing the affinity matrix construction and subspace clustering simultaneously. Thanks for the unification of the two steps, we can guarantee the overall optimum. Experimental results on classical data set show that, the algorithm is effective for hyperspectral image clustering.",
        "references": [
            "83fbb34960fe7424340976e39ae595ed33136448",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "7195c0473400110af96ef50d3f4a02e317439c69",
            "fbbdfa934b32f7db3d922f972a6d5ff7d97688d9",
            "bd569acc57705863f8de3a26853471e7b93e66f0",
            "e9a9ec050dca1f00283b56e046e8a28e11986d58",
            "3d22552235f5c51d33b657fb816050820c6e055e",
            "2ca8d98ac323f02aaf398f199b69f1b203a7f7db",
            "b19d27e1bda4d039f9eaf2b2eb9d47f75abe9d75",
            "37e702af5fc27934ecb43c616489939c36e6a5f2"
        ],
        "related_topics": [
            "HSIs",
            "Semi-supervised Subspace Clustering",
            "Low-Rank Representation",
            "Harmonic Functions",
            "Gaussian Fields"
        ],
        "reference_count": "14",
        "citation_count": "2"
    },
    {
        "Id": "523b537b528386ebd9164c9ff561ad66498400dc",
        "title": "Self-supervised sparse coding scheme for image classification based on low rank representation",
        "authors": [
            "Ao Li",
            "Deyun Chen",
            "Zhiqiang Wu",
            "Guanglu Sun",
            "Kezheng Lin"
        ],
        "date": "20 June 2018",
        "abstract": "A novel approach based on self-supervised sparse representation is proposed for image classification that aims to preserve the local structure of codings for similar samples and demonstrates the effectiveness and efficiency of this approach compared with existing state-of-the-art methods. Recently, sparse representation, which relies on the underlying assumption that samples can be sparsely represented by their labeled neighbors, has been applied with great success to image classification problems. Through sparse representation-based classification (SRC), the label can be assigned with minimum residual between the sample and its synthetic version with class-specific coding, which means that the coding scheme is the most significant factor for classification accuracy. However, conventional SRC-based coding schemes ignore dependency among the samples, which leads to an undesired result that similar samples may be coded into different categories due to quantization sensitivity. To address this problem, in this paper, a novel approach based on self-supervised sparse representation is proposed for image classification. In the proposed approach, the manifold structure of samples is firstly exploited with low rank representation. Next, the low-rank representation matrix is used to characterize the similarity of samples in order to establish a self-supervised sparse coding model, which aims to preserve the local structure of codings for similar samples. Finally, a numerical algorithm utilizing the alternating direction method of multipliers (ADMM) is developed to obtain the approximate solution. Experiments on several publicly available datasets validate the effectiveness and efficiency of our proposed approach compared with existing state-of-the-art methods.",
        "references": [
            "e8096384cf75e95cf6c85d3fb9863d2c455a644c",
            "a73be6ea4e354c669230509754277710d1f2c169",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "1a1a60fd4dc88a14c016b95789385801c6b80574",
            "7477cf04c6b086108f459f693a60272523c134db",
            "f8c5f621831803920afead5650413d5113cdfe93",
            "2f7713dcc35e7c05becf3be5522f36c9546b0364",
            "96e626c8d03ff83b10adb45901e2e7fe247f2cd4",
            "72aa01cc6dbadc631407b4d2d0addec172dc5037",
            "519e0a48e9846e148b78b69301db5f78d4d4f27f"
        ],
        "related_topics": [
            "Samples",
            "Sparse Representation Based Classification",
            "Low-Rank Representation",
            "Sparse Representation",
            "Local Structures",
            "Alternating Direction Method Of Multipliers",
            "Manifold Structure",
            "Classification Accuracy"
        ],
        "reference_count": "26",
        "citation_count": "28"
    },
    {
        "Id": "47a24ca6dbf7e65629a4a06a59207b1f86ba2244",
        "title": "Class Probability Propagation of Supervised Information Based on Sparse Subspace Clustering for Hyperspectral Images",
        "authors": [
            "Qing Yan",
            "Yun Ding",
            "Yi Xia",
            "Yanwen Chong",
            "Chunhou Zheng"
        ],
        "date": "30 September 2017",
        "abstract": "This paper proposes a novel class probability propagation of supervised information based on sparse subspace clustering (CPPSSC) algorithm for HSI clustering that is effective on a variety of challenging data sets. Hyperspectral image (HSI) clustering has drawn increasing attention due to its challenging work with respect to the curse of dimensionality. In this paper, we propose a novel class probability propagation of supervised information based on sparse subspace clustering (CPPSSC) algorithm for HSI clustering. Firstly, we estimate the class probability of unlabeled samples by way of partial known supervised information, which can be addressed by sparse representation-based classification (SRC). Then, we incorporate the class probability into the traditional sparse subspace clustering (SSC) model to obtain a more accurate sparse representation coefficient matrix accompanied by obvious block diagonalization, which will be used to build the similarity matrix. Finally, the cluster results can be obtained by applying the spectral clustering on similarity matrix. Extensive experiments on a variety of challenging data sets illustrate that our proposed method is effective.",
        "references": [
            "e911d655661a1640f2c361641efdaf11237c71a8",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "f9c3f6e2fd3152abc96c27465635caa0f3f79c82",
            "7195c0473400110af96ef50d3f4a02e317439c69",
            "653434bb57d37ade9d0dbf5b66ae803157973bdd",
            "3682ae05ff14bf550ca00f16ea1cacf842e5931b",
            "8feca9c049dc40d61e78fef4ea516f990b414e88",
            "303c92f9a530deeba398a527627964d85904dc72",
            "b1ce1ebcd2116d6fae5e24d8b0e6ab693579cbe9",
            "04f31ca422f2464919a4ebd30b372a7e19221f1f"
        ],
        "related_topics": [
            "Sparse Subspace Clustering",
            "Similarity Matrix",
            "Sparse Representation Based Classification",
            "Supervised Information",
            "Hyperspectral Imagery",
            "Block-diagonalization",
            "Spectral Clustering",
            "Unlabeled Samples"
        ],
        "reference_count": "50",
        "citation_count": "14"
    },
    {
        "Id": "303c92f9a530deeba398a527627964d85904dc72",
        "title": "Probabilistic class structure regularized sparse representation graph for semi-supervised hyperspectral image classification",
        "authors": [
            "Yuanjie Shao",
            "Nong Sang",
            "Changxin Gao",
            "Li Ma"
        ],
        "date": "1 March 2017",
        "abstract": "Semantic Scholar extracted view of \"Probabilistic class structure regularized sparse representation graph for semi-supervised hyperspectral image classification\" by Yuanjie Shao et al.",
        "references": [
            "3bbafaa25837bc4c8a69136fab551dbf86bc5941",
            "7c997a648976fb9df320c6ca332c9dc155820454",
            "ff9ec0619a005c5ffb22ccf6faf6b97d81f60e2b",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "e61eddf6c9e65c5a78ba8a59f042d1150eaef87f",
            "b7360bc3f9c1a674b6c6d541538c3a5ce2665ba0",
            "2dd91115091f1691ea37c4b14788ca4199354012",
            "e02bc29aa007d0f4dcfe98e89776c66a991c458d",
            "677dc448f1dcb487afbf6133c1f2b98a49941102",
            "373785462b77c813192ba4e443d2f2f34cdec27b"
        ],
        "related_topics": [
            "PCSSR",
            "Semi-Supervised Learning",
            "Hyperion",
            "Alternating Direction Method",
            "Sparse Representation",
            "Hyperspectral Image Classification",
            "Adaptive Penalty"
        ],
        "reference_count": "58",
        "citation_count": "66"
    },
    {
        "Id": "04e85b45426a0d087f1b03422f863c77d924b787",
        "title": "Accurate Multiobjective Low-Rank and Sparse Model for Hyperspectral Image Denoising Method",
        "authors": [
            "Yuting Wan",
            "Ailong Ma",
            "Wei He",
            "Yanfei Zhong"
        ],
        "date": "10 May 2021",
        "abstract": "An accurate multiobjective low-rank and sparse denoising framework is proposed for HSIs to achieve accurate modeling and a subfitness strategy is constructed to achieve effective optimization by comparing the objective function values corresponding to each band for each solution. Due to the unavoidable influence of sparse and Gaussian noise during the process of data acquisition, the quality of hyperspectral images (HSIs) is degraded and their applications are greatly limited. It is therefore necessary to restore clean HSIs. In the traditional methods, low-rank and sparse matrix decomposition methods are usually applied to restore the pure data matrix from the observed data matrix. However, due to the fact that the optimization of the ${l}_{0}$ -norm for the sparse modeling is a nonconvex and NP-hard problem, convex relaxation and regularization parameters are usually introduced. However, convex relaxation often leads to inaccurate sparse modeling results, and the sensitive regularization parameters can lead to unstable results. Thus, in this article, to address these issues, an accurate multiobjective low-rank and sparse denoising framework is proposed for HSIs to achieve accurate modeling. The ${l}_{0}$ -norm is directly modeled as the sparse noise and is optimized by an evolutionary algorithm, and the denoising problem is converted into a multiobjective optimization problem through simultaneously optimizing the low-rank term, the sparse term, and the data fidelity term, without sensitive regularization parameters. However, since the low-rank clean image and sparse noise of the HSI are encoded into a solution, the length of the solution is too long to be optimized. In this article, a subfitness strategy is constructed to achieve effective optimization by comparing the objective function values corresponding to each band for each solution. The experiments undertaken with simulated images in 11 noise cases and four real noisy images confirm the effectiveness of the proposed method.",
        "references": [
            "124db146d4bf80f1b1963307d4e949588c25019c",
            "bb11dbdea13afa19eeb7a665648f51ca503e5adc",
            "d7d966d3b76a2531d88074a30a677b3e8ea230ae",
            "d5d70d4002ba36ff088205ffac8cdd41675bf99d",
            "1b5cb3aa61aa919dfd8e7c34c421f1983e2ac190",
            "ca34d295ba86f9175b17804f71d1d254624da683",
            "4ce970ce37a7d5ad0596757206598b82df937913",
            "ed7edfadc29dfa793e49cd4bfcc174034c850835",
            "12a16464940843661b954202fb20e6fa2b6195a4",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9"
        ],
        "related_topics": [
            "Low-rank",
            "HSIs",
            "Multiobjective Optimization",
            "Evolutionary Algorithms",
            "Real Noisy Images",
            "Optimization",
            "Gaussian Noise"
        ],
        "reference_count": "70",
        "citation_count": "12"
    },
    {
        "Id": "54592200fcff8e0e469a76db66d9c5d737d3f2f4",
        "title": "A hierarchical weighted low-rank representation for image clustering and classification",
        "authors": [
            "Zhiqiang Fu",
            "Yao Zhao",
            "Dongxia Chang",
            "Yiming Wang"
        ],
        "date": "4 November 2020",
        "abstract": "Semantic Scholar extracted view of \"A hierarchical weighted low-rank representation for image clustering and classification\" by Zhiqiang Fu et al.",
        "references": [
            "77d387615455cc3690ad5756053498625cd5109e",
            "8f88bcf3b2e0fb9cb09240541d4b65bcdcd89826",
            "83fbb34960fe7424340976e39ae595ed33136448",
            "35df217f7401e134ec91dd49b5126ca23332896d",
            "274bd95173e9175b745822a4c026140674d16aa5",
            "b4ea9ef2d03cd1b96b93df868611a5f0160d7abd",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "047175fb23f6f152d86e81100ba7140dd2847636",
            "bab02d6e30e771f5241887f3cce509f9dd8b0c40",
            "e02bc29aa007d0f4dcfe98e89776c66a991c458d"
        ],
        "related_topics": [
            "Low-Rank Representation",
            "Semi-Supervised Classification",
            "Affinity Propagation",
            "Unsupervised Learning",
            "Subspace Structures",
            "Local Structures",
            "Image Clustering",
            "Classification"
        ],
        "reference_count": "48",
        "citation_count": "18"
    },
    {
        "Id": "cc5a9c59c1108077bba351ac0b753a687f93dda8",
        "title": "Joint learning of deep multi-scale features and diversified metrics for hyperspectral image classification",
        "authors": [
            "Zhiqiang Gong",
            "Ping Zhong",
            "Yang Yu",
            "Jiaxin Shan",
            "Weidong Hu"
        ],
        "date": "1 September 2017",
        "abstract": "A D- DSML-MSCNN method, which jointly learns deep multi-scale features and diversified metrics for hyperspectral image classification, is proposed to take both advantages of D-DSML and MSCNN. Due to the high spectral resolution and the similarity of some spectrums between different classes, hyperspectral image classification turns out to be an important but challenging task. Researches show the powerful ability of deep learning for hyperspectral image classification. However, the lack of training samples makes it difficult to extract discriminative features and achieve performance as expected. To solve the problem, a multi-scale CNN which can extract multi-scale features is designed for hyperspectral image classification. Furthermore, D-DSML, a diversified metric, is proposed to further improve the representational ability of deep methods. In this paper, a D-DSML-MSCNN method, which jointly learns deep multi-scale features and diversified metrics for hyperspectral image classification, is proposed to take both advantages of D-DSML and MSCNN. Experiments are conducted on Pavia University data to show the effectiveness of our method for hyperspectral image classification. The results show the advantage of our method when compared with other recent results.",
        "references": [
            "10fb16414324a5db44f5d830adcb4810af59eed0",
            "fd794917872688d60df8c74b42cc88b774079104",
            "ec9aa46ebc50a03ea9d7d20d80a232e6bd4293de",
            "0e7e22fe094b0e4b0aa67d4915072c598512da35",
            "2904d2a41cfd3e3c0e6f3a4b53f460e6d80ba7a9",
            "2369db9921078c4bb76072ef7d6426e9f1dbfdb5",
            "45dea041cba8e96bd4448e8a76a6e81b7ea5c337",
            "24650c6f597ca397fa96ead7ff3891eb2f4800fc",
            "f1e11fe6b40310cd5262f8484b1fa08de797c6d1",
            "cdb903803efdd2dbd93cd3cc29eab632a2ca66dd"
        ],
        "related_topics": [
            "Hyperspectral Image Classification",
            "Multi-scale Features",
            "D-DSML",
            "Representational Ability",
            "Deep Learning"
        ],
        "reference_count": "0",
        "citation_count": "23"
    },
    {
        "Id": "41747cbdbed84762dfbfc305254c97021279dc6e",
        "title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "6 November 2019",
        "abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2910bec6d4de87e22be5119cef3c488d2ae50e2a",
            "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced"
        ],
        "related_topics": [
            "Uninformed Students",
            "Anomaly-free Images",
            "Per-region-overlap",
            "MVTec Anomaly Detection Dataset",
            "Unsupervised Anomaly Segmentation",
            "Anomaly-free Training Data",
            "Anomalous Regions",
            "MVTec AD",
            "Spatial Anomaly Map",
            "OCGAN"
        ],
        "reference_count": "37",
        "citation_count": "376"
    },
    {
        "Id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "date": "8 April 2021",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ],
        "related_topics": [
            "CutPaste",
            "Anomaly Score Map",
            "CutPaste Augmentation",
            "Pseudo Anomalies",
            "Uninformed Students",
            "Cut-Paste",
            "Semantic Anomaly Detection",
            "Image-level Anomaly Detection",
            "Gaussian Density Estimator",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "67",
        "citation_count": "389"
    },
    {
        "Id": "3b3aefbbdb64e5812f133f220b3f129a36a30065",
        "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
        "authors": [
            "Hanqiu Deng",
            "Xingyu Li"
        ],
        "date": "26 January 2022",
        "abstract": "A novel T-S model consisting of a teacher encoder and a student decoder is proposed and a simple yet effective \u201creverse distillation\u201d paradigm is introduced, demonstrating the proposed approach's effectiveness and generalizability. Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "599fd051c9438011ec5b581983c89e8922b4a5e6",
            "30895c61bb836f2cae7ef5ba6516886f746a7153",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "93040f8a5d10e8fde279e18d353aa3dca2873900",
            "9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ],
        "related_topics": [
            "Reverse Distillation",
            "Student Decoder",
            "One-Class Embedding",
            "CutPaste",
            "Multiresolution Knowledge Distillation",
            "Large Defects",
            "Anomaly-free Samples",
            "Pseudo Anomalies",
            "WideResnet-50",
            "Localize Anomaly"
        ],
        "reference_count": "52",
        "citation_count": "161"
    },
    {
        "Id": "5fdd9cfb9b22b9e575d36e98e5d6f52a83729e42",
        "title": "Reconstructed Student-Teacher and Discriminative Networks for Anomaly Detection",
        "authors": [
            "Shinji Yamada",
            "Satoshi Kamiya",
            "Kazuhiro Hotta"
        ],
        "date": "14 October 2022",
        "abstract": "A powerful anomaly detection method is proposed based on student-teacher feature pyramid matching (STPM), which consists of a student and teacher network and a discriminative network, which displayed high accuracy on the MVTec anomaly detection dataset. Anomaly detection is an important problem in computer vision; however, the scarcity of anomalous samples makes this task difficult. Thus, recent anomaly detection methods have used only \u201cnormal images\u201d with no abnormal areas for training. In this work, a powerful anomaly detection method is proposed based on student-teacher feature pyramid matching (STPM), which consists of a student and teacher network. Generative models are another approach to anomaly detection. They reconstruct normal images from an input and compute the difference between the predicted normal and the input. Unfortunately, STPM does not have the ability to generate normal images. To improve the accuracy of STPM, this work uses a student network, as in generative models, to reconstruct normal features. This improves the accuracy; however, the anomaly maps for normal images are not clean because STPM does not use anomaly images for training, which decreases the accuracy of the image-level anomaly detection. To further improve accuracy, a discriminative network trained with pseudo-anomalies from anomaly maps is used in our method, which consists of two pairs of student-teacher networks and a discriminative network. The method displayed high accuracy on the MVTec anomaly detection dataset.",
        "references": [
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "5f61089d3d548a515f01b473f0119137d1f340d4",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "9277dc70c74bcadf80dab11c28ead83fd085deec"
        ],
        "related_topics": [
            "Anomaly Detection",
            "Normal Images",
            "STPM",
            "Anomaly Map",
            "Generative Models",
            "Student Network",
            "MVTec Anomaly Detection Dataset",
            "Pseudo Anomalies",
            "Image-level Anomaly Detection",
            "Teacher Network"
        ],
        "reference_count": "35",
        "citation_count": "16"
    },
    {
        "Id": "02805f18989b7e77f30ee13defd6fecfcd0f499f",
        "title": "Student-Teacher Feature Pyramid Matching for Anomaly Detection",
        "authors": [
            "Guodong Wang",
            "Shumin Han",
            "Errui Ding",
            "Di Huang"
        ],
        "date": "7 March 2021",
        "abstract": "This paper proposes a simple yet powerful approach to anomaly detection, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and efficiency. Anomaly detection is a challenging task and usually formulated as an one-class learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and efficiency. Given a strong model pre-trained on image classification as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature matching enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on the MVTec anomaly detection dataset, superior to the state of the art ones.",
        "references": [
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "2528a82dd2266600d4ee2b54165556a984de94d4",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "6af440915b8a0718c93be1cf61905e41e620484a"
        ],
        "related_topics": [
            "Student-Teacher Feature Pyramid Matching",
            "Anomaly Localization",
            "Per-region-overlap",
            "PaDiM",
            "MVTec AD",
            "Feature Pyramids",
            "Student Network",
            "Anomaly Detection",
            "Scoring Function",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "47",
        "citation_count": "83"
    },
    {
        "Id": "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
        "title": "MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "1 June 2019",
        "abstract": "This work introduces the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories, and conducts a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolved neural networks. The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the \ufb01eld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the \ufb01rst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",
        "references": [
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "732c21998e251d64cd58b6a86886ee5907efeaa5",
            "9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "5d90f06bb70a0a3dced62413346235c02b1aa086"
        ],
        "related_topics": [
            "MVTec AD",
            "MVTec Anomaly Detection",
            "UnSupervised Anomaly Detection",
            "Texture Categories",
            "Metal Nut",
            "Anomalous Images",
            "MVTec AD Dataset",
            "Anomalous Regions",
            "Spatial Anomaly Map",
            "Anomaly-free Images"
        ],
        "reference_count": "29",
        "citation_count": "748"
    },
    {
        "Id": "95a26eafabf06b1fc5dec6c460a927cf5964e97e",
        "title": "DR\u00c6M \u2013 A discriminatively trained reconstruction embedding for surface anomaly detection",
        "authors": [
            "Vitjan Zavrtanik",
            "Matej Kristan",
            "Danijel Sko{\\vc}aj"
        ],
        "date": "17 August 2021",
        "abstract": "The proposed DR\u00c6M method enables direct anomaly localization without the need for additional complicated post-processing of the network output and can be trained using simple and general anomaly simulations. Visual surface anomaly detection aims to detect local image regions that significantly deviate from normal appearance. Recent surface anomaly detection methods rely on generative models to accurately reconstruct the normal areas and to fail on anomalies. These methods are trained only on anomaly-free images, and often require hand-crafted post-processing steps to localize the anomalies, which prohibits optimizing the feature extraction for maximal detection capability. In addition to reconstructive approach, we cast surface anomaly detection primarily as a discriminative problem and propose a discriminatively trained reconstruction anomaly embedding model (DR\u00c6M). The proposed method learns a joint representation of an anomalous image and its anomaly-free reconstruction, while simultaneously learning a decision boundary between normal and anomalous examples. The method enables direct anomaly localization without the need for additional complicated post-processing of the network output and can be trained using simple and general anomaly simulations. On the challenging MVTec anomaly detection dataset, DR\u00c6M outperforms the current state-of-the-art unsupervised methods by a large margin and even de-livers detection performance close to the fully-supervised methods on the widely used DAGM surface-defect detection dataset, while substantially outperforming them in localization accuracy. Code at github.com/VitjanZ/DRAEM.",
        "references": [
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "f93bdba4177051d3cb285e65dc911dc77d332d11",
            "62b77e5cb85fc61b84edd532f6d65714be152596",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "17d3f90cb63fbac50a5e49b8a46e633ec1f526fd",
            "2e8d62277e40d465343e8dfb32ecc246f320540e",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "41747cbdbed84762dfbfc305254c97021279dc6e"
        ],
        "related_topics": [
            "DRAEM",
            "Surface Anomaly Detection",
            "Anomaly Localization",
            "Anomaly-free Images",
            "Synthetic Anomalies",
            "Discriminative Sub-network",
            "Anomaly Score Map",
            "Simulated Anomalies",
            "Anomalous Images",
            "Image-level AUROC"
        ],
        "reference_count": "34",
        "citation_count": "226"
    },
    {
        "Id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
        "title": "Deep Residual Learning for Image Recognition",
        "authors": [
            "Kaiming He",
            "X. Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "date": "10 December 2015",
        "abstract": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
        "references": [
            "eb42cf88027de515750f230b23b1a057dc782108",
            "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd",
            "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "d6f2f611da110b5b5061731be3fc4c7f45d8ee23",
            "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14",
            "8ad35df17ae4064dd174690efb04d347428f1117"
        ],
        "related_topics": [
            "Deep Residual Learning",
            "Residual Functions",
            "ImageNet Localization",
            "COCO Segmentation",
            "Stacked Layers",
            "Residual Learning",
            "VGG Nets",
            "ImageNet",
            "Layers",
            "Image Recognition"
        ],
        "reference_count": "54",
        "citation_count": "152,373"
    },
    {
        "Id": "9277dc70c74bcadf80dab11c28ead83fd085deec",
        "title": "Sub-Image Anomaly Detection with Deep Pyramid Correspondences",
        "authors": [
            "Niv Cohen",
            "Yedid Hoshen"
        ],
        "date": "5 May 2020",
        "abstract": "This work presents a novel anomaly segmentation approach based on alignment between an anomalous image and a constant number of the similar normal images, which is shown to achieve state-of-the-art performance on unsupervised anomaly detection and localization while requiring virtually no training time. Nearest neighbor (kNN) methods utilizing deep pre-trained features exhibit very strong anomaly detection performance when applied to entire images. A limitation of kNN methods is the lack of segmentation map describing where the anomaly lies inside the image. In this work we present a novel anomaly segmentation approach based on alignment between an anomalous image and a constant number of the similar normal images. Our method, Semantic Pyramid Anomaly Detection (SPADE) uses correspondences based on a multi-resolution feature pyramid. SPADE is shown to achieve state-of-the-art performance on unsupervised anomaly detection and localization while requiring virtually no training time.",
        "references": [
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "f008d9b244fcb393ceb57b42ea165e58a31286bd",
            "1f528877c4d8d5df3b3abbfa64379677d451956b",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "e021d59638966a6fbb36854cc2cf1045de7a62d2",
            "fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "04513c7c0b3a63fde81a996dae064a28d453c17a",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900"
        ],
        "related_topics": [
            "Anomalous Images",
            "Per-region-overlap",
            "Normal Images",
            "Spatially-adaptive Denormalization",
            "Anomaly Segmentation",
            "Visual Anomaly Detection",
            "MVTec Dataset",
            "Pixel-level Anomaly Detection",
            "ShanghaiTech Campus",
            "Image-level Anomaly Detection"
        ],
        "reference_count": "41",
        "citation_count": "264"
    },
    {
        "Id": "3b3aefbbdb64e5812f133f220b3f129a36a30065",
        "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
        "authors": [
            "Hanqiu Deng",
            "Xingyu Li"
        ],
        "date": "26 January 2022",
        "abstract": "A novel T-S model consisting of a teacher encoder and a student decoder is proposed and a simple yet effective \u201creverse distillation\u201d paradigm is introduced, demonstrating the proposed approach's effectiveness and generalizability. Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "599fd051c9438011ec5b581983c89e8922b4a5e6",
            "30895c61bb836f2cae7ef5ba6516886f746a7153",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "93040f8a5d10e8fde279e18d353aa3dca2873900",
            "9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ],
        "related_topics": [
            "Reverse Distillation",
            "Student Decoder",
            "One-Class Embedding",
            "CutPaste",
            "Multiresolution Knowledge Distillation",
            "Large Defects",
            "Anomaly-free Samples",
            "Pseudo Anomalies",
            "WideResnet-50",
            "Localize Anomaly"
        ],
        "reference_count": "52",
        "citation_count": "161"
    },
    {
        "Id": "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
        "title": "Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection",
        "authors": [
            "Guodong Wang",
            "Shumin Han",
            "Errui Ding",
            "Di Huang"
        ],
        "date": "2021",
        "abstract": "This paper proposes a simple yet powerful approach to anomaly detection, implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Anomaly detection is a challenging task and usually for-mulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Given a strong model pre-trained on image classi\ufb01cation as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, signi\ufb01cantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256 \u00d7 256), at least dozens of times faster than the latest counterparts.",
        "references": [
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "388645c44061f6e88fff0ecdad2f622936207d67",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2528a82dd2266600d4ee2b54165556a984de94d4"
        ],
        "related_topics": [
            "Student-Teacher Feature Pyramid Matching",
            "Pixel-level Anomaly Detection",
            "Anomaly-free Images",
            "Image-level Anomaly Detection",
            "MVTec AD Dataset",
            "Per-region-overlap",
            "Student Network",
            "Feature Pyramids",
            "Unsupervised Learning",
            "Scoring Function"
        ],
        "reference_count": "45",
        "citation_count": "63"
    },
    {
        "Id": "41747cbdbed84762dfbfc305254c97021279dc6e",
        "title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "6 November 2019",
        "abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2910bec6d4de87e22be5119cef3c488d2ae50e2a",
            "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced"
        ],
        "related_topics": [
            "Uninformed Students",
            "Anomaly-free Images",
            "Per-region-overlap",
            "MVTec Anomaly Detection Dataset",
            "Unsupervised Anomaly Segmentation",
            "Anomaly-free Training Data",
            "Anomalous Regions",
            "MVTec AD",
            "Spatial Anomaly Map",
            "OCGAN"
        ],
        "reference_count": "37",
        "citation_count": "376"
    },
    {
        "Id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "date": "8 April 2021",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ],
        "related_topics": [
            "CutPaste",
            "Anomaly Score Map",
            "CutPaste Augmentation",
            "Pseudo Anomalies",
            "Uninformed Students",
            "Cut-Paste",
            "Semantic Anomaly Detection",
            "Image-level Anomaly Detection",
            "Gaussian Density Estimator",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "67",
        "citation_count": "389"
    },
    {
        "Id": "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
        "title": "Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection",
        "authors": [
            "Dong Gong",
            "Lingqiao Liu",
            "Vuong Le",
            "Budhaditya Saha",
            "Moussa Reda Mansour",
            "Svetha Venkatesh",
            "Anton van den Hengel"
        ],
        "date": "4 April 2019",
        "abstract": "The proposed memory-augmented autoencoder called MemAE is free of assumptions on the data type and thus general to be applied to different tasks and proves the excellent generalization and high effectiveness of the proposed MemAE. Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder \"generalizes\" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.",
        "references": [
            "2b75ba7f75170b73d913c515cc0deefef6c88f5f",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "10a498003e9204f5fc1328e706510a37e514d8c7",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "8381157eae4fbf8908d0312a9642f8e69e944449",
            "99dff291f260b3cc3ff190106b0c2e3e685223a4",
            "afac99b10a5c7e531f73e4a4866d6ee3c9e86cd4",
            "bbd0e204f48a45735e1065c8b90b298077b73192"
        ],
        "related_topics": [
            "MemAE",
            "Memory-augmented Autoencoder",
            "Prototypical Normal Patterns",
            "Normal Data",
            "Memory Module",
            "Temporally-coherent Sparse Coding",
            "UnSupervised Anomaly Detection",
            "UCSD Ped2",
            "Video Anomaly Detection",
            "Prototypical Elements"
        ],
        "reference_count": "54",
        "citation_count": "854"
    },
    {
        "Id": "4dd78b8d466b4cfe55a1bbdc694291197ce62541",
        "title": "DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation",
        "authors": [
            "Jie Yang",
            "Yong Shi",
            "Zhiquan Qi"
        ],
        "date": "26 November 2020",
        "abstract": "Semantic Scholar extracted view of \"DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation\" by Jie Yang et al.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6",
            "75a838cbc1541858b9c484001cade327640dc280",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "1bbf746cca4bcafd274d197ac9fae82b245bf97b",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "d9d7ab13ce305ccee309c989a2341d72b1252070",
            "fe09f7a379944444201552e952b910188c0aeaca",
            "9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "8da55e685a7bef9c897788ab519a8710c695c419"
        ],
        "related_topics": [
            "Deep Feature Reconstruction",
            "Anomalous Regions",
            "Unsupervised Anomaly Segmentation",
            "Benchmark Dataset",
            "Digital Forensic Readiness",
            "Anomaly Detection"
        ],
        "reference_count": "42",
        "citation_count": "60"
    },
    {
        "Id": "1c0165247ce1d56a9de7be50ca6c4a49f0db4a82",
        "title": "Self-Supervised Masking for Unsupervised Anomaly Detection and Localization",
        "authors": [
            "Chaoqin Huang",
            "Qinwei Xu",
            "Yanfeng Wang",
            "Yu Wang",
            "Ya Zhang"
        ],
        "date": "13 May 2022",
        "abstract": "A self-supervised learning approach through random masking and then restoring, named SSM for unsupervised anomaly detection and localization, that enhances the training of the inpainting network but also leads to great improvement in the efficiency of mask prediction at inference. Recently, anomaly detection and localization in multimedia data have received significant attention among the machine learning community. In real-world applications such as medical diagnosis and industrial defect detection, anomalies only present in a fraction of the images. To extend the reconstruction-based anomaly detection architecture to the localized anomalies, we propose a self-supervised learning approach through random masking and then restoring, named Self-Supervised Masking (SSM) for unsupervised anomaly detection and localization. SSM not only enhances the training of the inpainting network but also leads to great improvement in the efficiency of mask prediction at inference. Through random masking, each image is augmented into a diverse set of training triplets, thus enabling the autoencoder to learn to reconstruct with masks of various sizes and shapes during training. To improve the efficiency and effectiveness of anomaly detection and localization at inference, we propose a novel progressive mask refinement approach that progressively uncovers the normal regions and finally locates the anomalous regions. The proposed SSM method outperforms several state-of-the-arts for both anomaly detection and anomaly localization, achieving 98.3% AUC on Retinal-OCT and 93.9% AUC on MVTec AD, respectively.",
        "references": [
            "e13d3f39cb9d03c57fef1344a825c163160dd8e7",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "8ee35ed698527d9695c872e3b76715fec4ef69ad",
            "badbd3a3df684fc8f7032c4577fb92fb1a743243",
            "d743c1b674ae539ef387252b8400a8b06c3ecf20",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "6259b02912cebc224f3a2b1324e811a152a0177d",
            "9a679663be4981d99b79f28dc946ac24344935d6"
        ],
        "related_topics": [
            "Anomaly Detection",
            "Area Under The ROC Curve",
            "UnSupervised Anomaly Detection",
            "Random Masking",
            "Inference",
            "Inpainting Network",
            "Retinal OCT",
            "Anomalous Regions",
            "Self-Supervised Learning",
            "MVTec AD"
        ],
        "reference_count": "85",
        "citation_count": "33"
    },
    {
        "Id": "6517f92d519fc126cc18924231bafd8945a554d1",
        "title": "Reconstruction Student with Attention for Student-Teacher Pyramid Matching",
        "authors": [
            "Shinji Yamada",
            "Kazuhiro Hotta"
        ],
        "date": "30 November 2021",
        "abstract": "A powerful method which compensates for the shortcomings of Student-Teacher Feature Pyramid Matching (STPM), which can be trained from only normal images with small number of epochs is proposed. Anomaly detection and localization are important problems in computer vision. Recently, Convolutional Neural Network (CNN) has been used for visual inspection. In particular, the scarcity of anomalous samples increases the difficulty of this task, and unsupervised leaning based methods are attracting attention. We focus on Student-Teacher Feature Pyramid Matching (STPM) which can be trained from only normal images with small number of epochs. Here we proposed a powerful method which compensates for the shortcomings of STPM. Proposed method consists of two students and two teachers that a pair of student-teacher network is the same as STPM. The other student-teacher network has a role to reconstruct the features of normal products. By reconstructing the features of normal products from an abnormal image, it is possible to detect abnormalities with higher accuracy by taking the difference between them. The new student-teacher network uses attention modules and different teacher network from the original STPM. Attention mechanism acts to successfully reconstruct the normal regions in an input image. Different teacher network prevents looking at the same regions as the original STPM. Six anomaly maps obtained from the two student-teacher networks are used to calculate the final anomaly map. Student-teacher network for reconstructing features improved AUC scores for pixel level and image level in comparison with the original STPM.",
        "references": [
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "82527ee075d2f7bf731da80edd8d4a92b01c2b8b",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "e8874d7d585ae1c355e186efdcc9f704b3d43b49",
            "ad655c25e052fa4eeed53421344aca6f239c4c9d",
            "a8f3dc53e321fbb2565f5925def4365b9f68d1af",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "31f9eb39d840821979e5df9f34a6e92dd9c879f2"
        ],
        "related_topics": [
            "STPM",
            "Convolutional Neural Network",
            "Image Level",
            "Pixel Level",
            "Attention Modules",
            "Anomaly Map",
            "Computer Vision",
            "Normal Images",
            "AUC Scores",
            "Anomaly Detection"
        ],
        "reference_count": "33",
        "citation_count": "17"
    },
    {
        "Id": "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
        "title": "Anomaly Detection using One-Class Neural Networks",
        "authors": [
            "Raghavendra Chalapathy",
            "Aditya Krishna Menon",
            "Sanjay Chawla"
        ],
        "date": "18 February 2018",
        "abstract": "A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and PFAM), OC-NN significantly outperforms existing state-of-the-art anomaly detection methods. We propose a one-class neural network (OC-NN) model to detect anomalies in complex data sets. OC-NN combines the ability of deep networks to extract a progressively rich representation of data with the one-class objective of creating a tight envelope around normal data. The OC-NN approach breaks new ground for the following crucial reason: data representation in the hidden layer is driven by the OC-NN objective and is thus customized for anomaly detection. This is a departure from other approaches which use a hybrid approach of learning deep features using an autoencoder and then feeding the features into a separate anomaly detection method like one-class SVM (OC-SVM). The hybrid OC-SVM approach is sub-optimal because it is unable to influence representational learning in the hidden layers. A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and GTSRB), OC-NN performs on par with state-of-the-art methods and outperformed conventional shallow methods in some scenarios.",
        "references": [
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "1d4ec24a6da3be62dc5d7efbae2a101c63f187e8",
            "2b75ba7f75170b73d913c515cc0deefef6c88f5f",
            "88f761749f5ac789f84b19ed0cff75c131dd8a29",
            "c53352a4239568cc915ad968aff51c49924a3072",
            "00a1077d298f2917d764eb729ab1bc86af3bd241",
            "081651b38ff7533550a3adfc1c00da333a8fe86c",
            "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf"
        ],
        "related_topics": [
            "One-Class Neural Networks",
            "OC-SVM",
            "Anomaly Detection",
            "Hidden Layer",
            "Deep Network",
            "CIFAR",
            "Autoencoders",
            "One-Class SVMs",
            "German Traffic Sign Recognition Benchmark"
        ],
        "reference_count": "46",
        "citation_count": "353"
    },
    {
        "Id": "82998db067c4c7fe9c7586202bf5e4249cd8f00b",
        "title": "Mixed Attention Auto Encoder for Multi-class Industrial Anomaly Detection",
        "authors": [
            "Jiangqi Liu",
            "Feng Wang"
        ],
        "date": "22 September 2023",
        "abstract": "A unified mixed-attention auto encoder (MAAE) to implement multi-class anomaly detection with a single model and deliver remarkable performances on the benchmark dataset compared with the state-of-the-art methods. Most existing methods for unsupervised industrial anomaly detection train a separate model for each object category. This kind of approach can easily capture the category-specific feature distributions, but results in high storage cost and low training efficiency. In this paper, we propose a unified mixed-attention auto encoder (MAAE) to implement multi-class anomaly detection with a single model. To alleviate the performance degradation due to the diverse distribution patterns of different categories, we employ spatial attentions and channel attentions to effectively capture the global category information and model the feature distributions of multiple classes. Furthermore, to simulate the realistic noises on features and preserve the surface semantics of objects from different categories which are essential for detecting the subtle anomalies, we propose an adaptive noise generator and a multi-scale fusion module for the pre-trained features. MAAE delivers remarkable performances on the benchmark dataset compared with the state-of-the-art methods.",
        "references": [
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "3d2b77469dc6c12bad63ce675def923b1f2a2628",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "c47fb40c71a70242c1320804139e1640e940e6c0",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "2e8d62277e40d465343e8dfb32ecc246f320540e",
            "ac62ed8a9b77d613189b63004f4a5d4c5cc082fe",
            "2d8c97db4bae00ff243d122b957091a236a697a7"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "20"
    },
    {
        "Id": "e59cd738bce1f415acd62c9ced1d120e573de69f",
        "title": "LafitE: Latent Diffusion Model with Feature Editing for Unsupervised Multi-class Anomaly Detection",
        "authors": [
            "Haonan Yin",
            "Guanlong Jiao",
            "Qianhui Wu",
            "B{\\&quot;o}rje F. Karlsson",
            "Biqing Huang",
            "Chin-Yew Lin"
        ],
        "date": "16 July 2023",
        "abstract": "A unified model to detect anomalies from objects belonging to multiple classes when only normal data is accessible is developed, and the proposed LafitE, \\ie, Latent Diffusion Model with Feature Editing, outperforms state-of-art methods by a significant margin in terms of average AUROC. In the context of flexible manufacturing systems that are required to produce different types and quantities of products with minimal reconfiguration, this paper addresses the problem of unsupervised multi-class anomaly detection: develop a unified model to detect anomalies from objects belonging to multiple classes when only normal data is accessible. We first explore the generative-based approach and investigate latent diffusion models for reconstruction to mitigate the notorious ``identity shortcut'' issue in auto-encoder based methods. We then introduce a feature editing strategy that modifies the input feature space of the diffusion model to further alleviate ``identity shortcuts'' and meanwhile improve the reconstruction quality of normal regions, leading to fewer false positive predictions. Moreover, we are the first who pose the problem of hyperparameter selection in unsupervised anomaly detection, and propose a solution of synthesizing anomaly data for a pseudo validation set to address this problem. Extensive experiments on benchmark datasets MVTec-AD and MPDD show that the proposed LafitE, \\ie, Latent Diffusion Model with Feature Editing, outperforms state-of-art methods by a significant margin in terms of average AUROC. The hyperparamters selected via our pseudo validation set are well-matched to the real test set.",
        "references": [
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "d78f2e0d5e3040ad62d5bcd0abca8a8507bff209",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "20f6fce7726e7b3ab4ca45ef40d92b79f093f825",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ],
        "related_topics": [],
        "reference_count": "65",
        "citation_count": "One"
    },
    {
        "Id": "ecfccca99ebb4edfb4d505d7faeedb3eb88decd0",
        "title": "DiAD: A Diffusion-based Framework for Multi-class Anomaly Detection",
        "authors": [
            "Haoyang He",
            "Jiangning Zhang",
            "Hongxu Chen",
            "Xuhai Chen",
            "Zhishan Li",
            "Xu Chen",
            "Yabiao Wang",
            "Chengjie Wang",
            "Lei Xie"
        ],
        "date": "11 December 2023",
        "abstract": "A Difusion-based Anomaly Detection (DiAD) framework for multi-class anomaly detection, which consists of a pixel-space autoencoder, a latent-space Semantic-Guided (SG) network with a connection to the stable diffusion's denoising network, and a feature-space pre-trained feature extractor. Reconstruction-based approaches have achieved remarkable outcomes in anomaly detection. The exceptional image reconstruction capabilities of recently popular diffusion models have sparked research efforts to utilize them for enhanced reconstruction of anomalous images. Nonetheless, these methods might face challenges related to the preservation of image categories and pixel-wise structural integrity in the more practical multi-class setting. To solve the above problems, we propose a Difusion-based Anomaly Detection (DiAD) framework for multi-class anomaly detection, which consists of a pixel-space autoencoder, a latent-space Semantic-Guided (SG) network with a connection to the stable diffusion's denoising network, and a feature-space pre-trained feature extractor. Firstly, The SG network is proposed for reconstructing anomalous regions while preserving the original image's semantic information. Secondly, we introduce Spatial-aware Feature Fusion (SFF) block to maximize reconstruction accuracy when dealing with extensively reconstructed areas. Thirdly, the input and reconstructed images are processed by a pre-trained feature extractor to generate anomaly maps based on features extracted at different scales. Experiments on MVTec-AD and VisA datasets demonstrate the effectiveness of our approach which surpasses the state-of-the-art methods, e.g., achieving 96.8/52.6 and 97.2/99.0 (AUROC/AP) for localization and detection respectively on multi-class MVTec-AD dataset. Code will be available at https://lewandofskee.github.io/projects/diad.",
        "references": [
            "28367cd3b68489ebd819ddfc3fb042b301abd3c7",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "55d49aa6bd3e6605c6510a147c1fb5bdd7af0b12",
            "62b77e5cb85fc61b84edd532f6d65714be152596",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "20f6fce7726e7b3ab4ca45ef40d92b79f093f825",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "015e11f1862ccb808e701123dbe1a84f0bead671",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f"
        ],
        "related_topics": [],
        "reference_count": "59",
        "citation_count": "2"
    },
    {
        "Id": "c911d99205cbeaea42e0690916a119b84ae0aaf5",
        "title": "MLAD: A Unified Model for Multi-system Log Anomaly Detection",
        "authors": [
            "Runqiang Zang",
            "Hongcheng Guo",
            "Jian Yang",
            "Jiaheng Liu",
            "Zhoujun Li",
            "Tieqiao Zheng",
            "Xu Shi",
            "Liangfan Zheng",
            "Bo Zhang"
        ],
        "date": "15 January 2024",
        "abstract": "This work proposes MLAD, a novel anomaly detection model that incorporates semantic relational reasoning across multiple systems, and employs Sentence-bert to capture the similarities between log sequences and convert them into highly-dimensional learnable semantic vectors. In spite of the rapid advancements in unsupervised log anomaly detection techniques, the current mainstream models still necessitate specific training for individual system datasets, resulting in costly procedures and limited scalability due to dataset size, thereby leading to performance bottlenecks. Furthermore, numerous models lack cognitive reasoning capabilities, posing challenges in direct transferability to similar systems for effective anomaly detection. Additionally, akin to reconstruction networks, these models often encounter the\"identical shortcut\"predicament, wherein the majority of system logs are classified as normal, erroneously predicting normal classes when confronted with rare anomaly logs due to reconstruction errors. To address the aforementioned issues, we propose MLAD, a novel anomaly detection model that incorporates semantic relational reasoning across multiple systems. Specifically, we employ Sentence-bert to capture the similarities between log sequences and convert them into highly-dimensional learnable semantic vectors. Subsequently, we revamp the formulas of the Attention layer to discern the significance of each keyword in the sequence and model the overall distribution of the multi-system dataset through appropriate vector space diffusion. Lastly, we employ a Gaussian mixture model to highlight the uncertainty of rare words pertaining to the\"identical shortcut\"problem, optimizing the vector space of the samples using the maximum expectation model. Experiments on three real-world datasets demonstrate the superiority of MLAD.",
        "references": [
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "687d0ebe2c89670f190f9202449005beadcda377",
            "c08a65e47b13c52744b6564e39c0e7c8f32a2074",
            "3fb7f11028819d6a6913174b69aca3b2229e54f0",
            "d20ac00f8d7139a087ee67d705ee5ff0ca5d5b19",
            "fefeded74334e5eafa47c5df6de2837fe3b7502d",
            "5fbea83bafab0a51c173c9230e272905702c8978",
            "a7c60fda14de91095d2a205d7efc3ef4c46a0f6a",
            "ae23ed6d405e7ab31c15e4fdf3a9fafadfee41c2",
            "6a0cc3de8c81a7cff55fb637478509dd9cfb72ef"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "50"
    },
    {
        "Id": "78873db8417583041c4fe5de25ad7a699c126a66",
        "title": "OmniAL: A Unified CNN Framework for Unsupervised Anomaly Localization",
        "authors": [
            "Ying Zhao"
        ],
        "date": "1 June 2023",
        "abstract": "A unified CNN framework for unsupervised anomaly localization, named OmniAL, is proposed that surpasses the state-of-the-art of unified models and makes the first attempt to conduct a comprehensive study on the robustness of unsuper supervised anomaly localization and detection methods against different level adversarial attacks. Unsupervised anomaly localization and detection is crucial for industrial manufacturing processes due to the lack of anomalous samples. Recent unsupervised advances on industrial anomaly detection achieve high performance by training separate models for many different categories. The model storage and training time cost of this paradigm is high. Moreover, the setting of one-model-N-classes leads to fearful degradation of existing methods. In this paper, we propose a unified CNN framework for unsupervised anomaly localization, named OmniAL. This method conquers aforementioned problems by improving anomaly synthesis, reconstruction and localization. To prevent the model learning identical reconstruction, it trains the model with proposed panel-guided synthetic anomaly data rather than directly using normal data. It increases anomaly reconstruction error for multi-class distribution by using a network that is equipped with proposed Dilated Channel and Spatial Attention (DCSA) blocks. To better localize the anomaly regions, it employs proposed DiffNeck between reconstruction and localization sub-networks to explore multi-level differences. Experiments on 15-class MVTecAD and 12-class VisA datasets verify the advantage of proposed OmniAL that surpasses the state-of-the-art of unified models. On 15-class-MVTecAD/12-class-VisA, its single unified model achieves 97.2/87.8 image-AUROC, 98.3/96.6 pixel-AUROC and 73.4/41.7 pixel-AP for anomaly detection and localization respectively. Besides that, we make the first attempt to conduct a comprehensive study on the robustness of unsupervised anomaly localization and detection methods against different level adversarial attacks. Experiential results show OmniAL has good application prospects for its superior performance.",
        "references": [
            "a6a237a7625f2c3175e44070ee9bad6e917798b0",
            "51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "2e8d62277e40d465343e8dfb32ecc246f320540e",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "57e0b6a1a47afe3d0cee58d387a7cfcd3bdd5e73",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "95a26eafabf06b1fc5dec6c460a927cf5964e97e"
        ],
        "related_topics": [
            "Unsupervised Anomaly Localization",
            "Spatial Attention",
            "VisA Dataset",
            "Adversarial Attacks",
            "Anomalous Samples",
            "Anomaly Detection",
            "Convolutional Neural Network",
            "Pixel AUROC"
        ],
        "reference_count": "45",
        "citation_count": "9"
    },
    {
        "Id": "d2ad908b75063cbfde78e99c3b1f44c60a1ae311",
        "title": "Hierarchical Vector Quantized Transformer for Multi-class Unsupervised Anomaly Detection",
        "authors": [
            "Ruiying Lu",
            "YuJie Wu",
            "Long Tian",
            "Dongsheng Wang",
            "Bo Chen",
            "Xiyang Liu",
            "Ruimin Hu"
        ],
        "date": "22 October 2023",
        "abstract": "This paper proposes a hierarchical vector quantized prototype-oriented Transformer under a probabilistic framework, and investigates an exquisite hierarchical framework to relieve the codebook collapse issue and replenish frail normal patterns. Unsupervised image Anomaly Detection (UAD) aims to learn robust and discriminative representations of normal samples. While separate solutions per class endow expensive computation and limited generalizability, this paper focuses on building a unified framework for multiple classes. Under such a challenging setting, popular reconstruction-based networks with continuous latent representation assumption always suffer from the\"identical shortcut\"issue, where both normal and abnormal samples can be well recovered and difficult to distinguish. To address this pivotal issue, we propose a hierarchical vector quantized prototype-oriented Transformer under a probabilistic framework. First, instead of learning the continuous representations, we preserve the typical normal patterns as discrete iconic prototypes, and confirm the importance of Vector Quantization in preventing the model from falling into the shortcut. The vector quantized iconic prototype is integrated into the Transformer for reconstruction, such that the abnormal data point is flipped to a normal data point.Second, we investigate an exquisite hierarchical framework to relieve the codebook collapse issue and replenish frail normal patterns. Third, a prototype-oriented optimal transport method is proposed to better regulate the prototypes and hierarchically evaluate the abnormal score. By evaluating on MVTec-AD and VisA datasets, our model surpasses the state-of-the-art alternatives and possesses good interpretability. The code is available at https://github.com/RuiyingLu/HVQ-Trans.",
        "references": [
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "78873db8417583041c4fe5de25ad7a699c126a66",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "cfc21dbbdcb4c50c553d1e1fb0dbc69f61ce1d30",
            "57e0b6a1a47afe3d0cee58d387a7cfcd3bdd5e73",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "51"
    },
    {
        "Id": "336f4126e59eb7f9d167f9b76fe379280029d651",
        "title": "A Novel MAE-Based Self-Supervised Anomaly Detection and Localization Method",
        "authors": [
            "Yibo Chen",
            "Haolong Peng",
            "Le Huang",
            "Jianming Zhang",
            "Wei Jiang"
        ],
        "date": "2023",
        "abstract": "A novel end-to-end approach for multi-class anomaly detection: self-supervised Mask-pretrained Anomaly Localization Autoencoder (MALA) that demonstrates its applicability across diverse styles of industrial products. Despite significant advancements in self-supervised anomaly detection, multi-class anomaly detection tasks still pose substantial challenges. Most existing methods require individual network training for each category of objects. This paper presents a novel end-to-end approach for multi-class anomaly detection: self-supervised Mask-pretrained Anomaly Localization Autoencoder (MALA). Firstly, the masked autoencoder (MAE) and Pseudo Label Prediction Module (PLPM) are utilized to recover and perceive normal image patterns. Subsequently, the encoder weights are frozen for further end-to-end network training to predict anomalous maps directly. Token Balance Module(TBM) facilitates anomalous perception and improves anomaly segmentation. By utilizing the Visual Transformer and employing image inpainting as a proxy task, remarkable generalization results are achieved. The proposed method demonstrates its applicability across diverse styles of industrial products. Experiments are conducted on MVTech AD, VisA, KolektorSDD2, and MT datasets, achieving state-of-the-art results in multi-task anomaly detection and segmentation tasks. Specifically, we obtain image AUROC of 98.% and pixel AUROC of 97.1% on the MVTech AD dataset, pixel AUROC of 97.1% on the VisA dataset, and pixel AUROC of 98.7% on the KolektorSDD2 dataset.",
        "references": [
            "21484ffc19b1c5e41cbd49aff061db4dfb5286c2",
            "2c1837be2e4e6c4f47d51c42773e398897c372a6",
            "a4b4b63968260f142b0b5a10d8868f18d6930f4c",
            "1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af",
            "78873db8417583041c4fe5de25ad7a699c126a66",
            "e29734b4945611c4eeb49bd176086881e71ba25a",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "57e0b6a1a47afe3d0cee58d387a7cfcd3bdd5e73",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "18abe29e2c50fa0b5c113a2e9458b89fb1197a8d"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "74"
    },
    {
        "Id": "60264ea13394896aeb7bb514f761a287cab1a54d",
        "title": "UniFormaly: Towards Task-Agnostic Unified Framework for Visual Anomaly Detection",
        "authors": [
            "Yujin Lee",
            "Harin Lim",
            "Seoyoon Jang",
            "Hyunsoo Yoon"
        ],
        "date": "24 July 2023",
        "abstract": "Back Patch Masking (BPM) and top k-ratio feature matching are introduced and UniFormaly is presented, a universal and powerful anomaly detection framework that achieves outstanding results on various tasks and datasets. Visual anomaly detection aims to learn normality from normal images, but existing approaches are fragmented across various tasks: defect detection, semantic anomaly detection, multi-class anomaly detection, and anomaly clustering. This one-task-one-model approach is resource-intensive and incurs high maintenance costs as the number of tasks increases. We present UniFormaly, a universal and powerful anomaly detection framework. We emphasize the necessity of our off-the-shelf approach by pointing out a suboptimal issue in online encoder-based methods. We introduce Back Patch Masking (BPM) and top k-ratio feature matching to achieve unified anomaly detection. BPM eliminates irrelevant background regions using a self-attention map from self-supervised ViTs. This operates in a task-agnostic manner and alleviates memory storage consumption, scaling to tasks with large-scale datasets. Top k-ratio feature matching unifies anomaly levels and tasks by casting anomaly scoring into multiple instance learning. Finally, UniFormaly achieves outstanding results on various tasks and datasets. Codes are available at https://github.com/YoojLee/Uniformaly.",
        "references": [
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "23ad8fc48530ce366f8192dfb48d0f7df1dba277",
            "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "41747cbdbed84762dfbfc305254c97021279dc6e"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "44"
    },
    {
        "Id": "83aa8ce07aeda545ce3092acfaf071b6626f1903",
        "title": "Exploring Plain ViT Reconstruction for Multi-class Unsupervised Anomaly Detection",
        "authors": [
            "Jiangning Zhang",
            "Xuhai Chen",
            "Yabiao Wang",
            "Chengjie Wang",
            "Yong Liu",
            "Xiangtai Li",
            "Ming-Hsuan Yang",
            "Dacheng Tao"
        ],
        "date": "12 December 2023",
        "abstract": "Plain ViT architecture for MUAD is explored, which achieves state-of-the-art results and efficiency on the MVTec AD and VisA datasets without bells and whistles, obtaining 85.4 mAD that surpasses SoTA UniAD by +3.0, and a comprehensive and fair evaluation benchmark on eight metrics for the MUAD task is proposed. This work studies the recently proposed challenging and practical Multi-class Unsupervised Anomaly Detection (MUAD) task, which only requires normal images for training while simultaneously testing both normal/anomaly images for multiple classes. Existing reconstruction-based methods typically adopt pyramid networks as encoders/decoders to obtain multi-resolution features, accompanied by elaborate sub-modules with heavier handcraft engineering designs for more precise localization. In contrast, a plain Vision Transformer (ViT) with simple architecture has been shown effective in multiple domains, which is simpler, more effective, and elegant. Following this spirit, this paper explores plain ViT architecture for MUAD. Specifically, we abstract a Meta-AD concept by inducing current reconstruction-based methods. Then, we instantiate a novel and elegant plain ViT-based symmetric ViTAD structure, effectively designed step by step from three macro and four micro perspectives. In addition, this paper reveals several interesting findings for further exploration. Finally, we propose a comprehensive and fair evaluation benchmark on eight metrics for the MUAD task. Based on a naive training recipe, ViTAD achieves state-of-the-art (SoTA) results and efficiency on the MVTec AD and VisA datasets without bells and whistles, obtaining 85.4 mAD that surpasses SoTA UniAD by +3.0, and only requiring 1.1 hours and 2.3G GPU memory to complete model training by a single V100 GPU. Source code, models, and more results are available at https://zhangzjn.github.io/projects/ViTAD.",
        "references": [
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "ecfccca99ebb4edfb4d505d7faeedb3eb88decd0",
            "78873db8417583041c4fe5de25ad7a699c126a66",
            "7f12319e9b0cdbef09f720bd34dacb8422504df6",
            "a09cbcaac305884f043810afc4fa4053099b5970",
            "5533bf9f2385ebece563fea35b19e998db64e597",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "886fa942f73fa0c047c5a5ab87d9770dda3c8119",
            "c9319fe84d32f00fe8e10dcf2310181236c2629a",
            "7db5da4321d526539ac567fb56cd8900def4b1e5"
        ],
        "related_topics": [],
        "reference_count": "113",
        "citation_count": "One"
    },
    {
        "Id": "553b25f1e371ae6bd7126af54206444043ee7da3",
        "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection",
        "authors": [
            "Qihang Zhou",
            "Guansong Pang",
            "Yu Tian",
            "Shibo He",
            "Jiming Chen"
        ],
        "date": "29 October 2023",
        "abstract": "A novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across different domains, to learn object-agnostic text prompts that capture generic normality and abnormality in an image regardless of its foreground objects. Zero-shot anomaly detection (ZSAD) requires detection models trained using auxiliary data to detect anomalies without any training sample in a target dataset. It is a crucial task when training data is not accessible due to various concerns, \\eg, data privacy, yet it is challenging since the models need to generalize to anomalies across different domains where the appearance of foreground objects, abnormal regions, and background features, such as defects/tumors on different products/organs, can vary significantly. Recently large pre-trained vision-language models (VLMs), such as CLIP, have demonstrated strong zero-shot recognition ability in various vision tasks, including anomaly detection. However, their ZSAD performance is weak since the VLMs focus more on modeling the class semantics of the foreground objects rather than the abnormality/normality in the images. In this paper we introduce a novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across different domains. The key insight of AnomalyCLIP is to learn object-agnostic text prompts that capture generic normality and abnormality in an image regardless of its foreground objects. This allows our model to focus on the abnormal image regions rather than the object semantics, enabling generalized normality and abnormality recognition on diverse types of objects. Large-scale experiments on 17 real-world anomaly detection datasets show that AnomalyCLIP achieves superior zero-shot performance of detecting and segmenting anomalies in datasets of highly diverse class semantics from various defect inspection and medical imaging domains. Code will be made available at https://github.com/zqhang/AnomalyCLIP.",
        "references": [
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "4b182347b943548fe6479393bb24adac21740675",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "aa207668318fec38d60b79f407fb64982e46fce9",
            "7d90243c5a46430a36c5ba88627b5d254450a1e1",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "2c1837be2e4e6c4f47d51c42773e398897c372a6",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "8e37b3b30a1fce1a3f41374ceaf168d2e79bf53f"
        ],
        "related_topics": [],
        "reference_count": "59",
        "citation_count": "6"
    },
    {
        "Id": "3b3aefbbdb64e5812f133f220b3f129a36a30065",
        "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
        "authors": [
            "Hanqiu Deng",
            "Xingyu Li"
        ],
        "date": "26 January 2022",
        "abstract": "A novel T-S model consisting of a teacher encoder and a student decoder is proposed and a simple yet effective \u201creverse distillation\u201d paradigm is introduced, demonstrating the proposed approach's effectiveness and generalizability. Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \u201creverse distillation\u201d paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "599fd051c9438011ec5b581983c89e8922b4a5e6",
            "30895c61bb836f2cae7ef5ba6516886f746a7153",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "93040f8a5d10e8fde279e18d353aa3dca2873900",
            "9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9"
        ],
        "related_topics": [
            "Reverse Distillation",
            "Student Decoder",
            "One-Class Embedding",
            "CutPaste",
            "Multiresolution Knowledge Distillation",
            "Large Defects",
            "Anomaly-free Samples",
            "Pseudo Anomalies",
            "WideResnet-50",
            "Localize Anomaly"
        ],
        "reference_count": "52",
        "citation_count": "161"
    },
    {
        "Id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "date": "8 April 2021",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ],
        "related_topics": [
            "CutPaste",
            "Anomaly Score Map",
            "CutPaste Augmentation",
            "Pseudo Anomalies",
            "Uninformed Students",
            "Cut-Paste",
            "Semantic Anomaly Detection",
            "Image-level Anomaly Detection",
            "Gaussian Density Estimator",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "67",
        "citation_count": "389"
    },
    {
        "Id": "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
        "title": "MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "1 June 2019",
        "abstract": "This work introduces the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories, and conducts a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolved neural networks. The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the \ufb01eld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the \ufb01rst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",
        "references": [
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "732c21998e251d64cd58b6a86886ee5907efeaa5",
            "9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "5d90f06bb70a0a3dced62413346235c02b1aa086"
        ],
        "related_topics": [
            "MVTec AD",
            "MVTec Anomaly Detection",
            "UnSupervised Anomaly Detection",
            "Texture Categories",
            "Metal Nut",
            "Anomalous Images",
            "MVTec AD Dataset",
            "Anomalous Regions",
            "Spatial Anomaly Map",
            "Anomaly-free Images"
        ],
        "reference_count": "29",
        "citation_count": "748"
    },
    {
        "Id": "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
        "title": "Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection",
        "authors": [
            "Guodong Wang",
            "Shumin Han",
            "Errui Ding",
            "Di Huang"
        ],
        "date": "2021",
        "abstract": "This paper proposes a simple yet powerful approach to anomaly detection, implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Anomaly detection is a challenging task and usually for-mulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Given a strong model pre-trained on image classi\ufb01cation as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, signi\ufb01cantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256 \u00d7 256), at least dozens of times faster than the latest counterparts.",
        "references": [
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "388645c44061f6e88fff0ecdad2f622936207d67",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2528a82dd2266600d4ee2b54165556a984de94d4"
        ],
        "related_topics": [
            "Student-Teacher Feature Pyramid Matching",
            "Pixel-level Anomaly Detection",
            "Anomaly-free Images",
            "Image-level Anomaly Detection",
            "MVTec AD Dataset",
            "Per-region-overlap",
            "Student Network",
            "Feature Pyramids",
            "Unsupervised Learning",
            "Scoring Function"
        ],
        "reference_count": "45",
        "citation_count": "63"
    },
    {
        "Id": "8ee35ed698527d9695c872e3b76715fec4ef69ad",
        "title": "Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection",
        "authors": [
            "Xudong Yan",
            "Huaidong Zhang",
            "Xuemiao Xu",
            "Xiaowei Hu",
            "Pheng-Ann Heng"
        ],
        "date": "18 May 2021",
        "abstract": "This work presents a Semantic Context based Anomaly Detection Network, SCADN, for unsupervised anomaly detection by learning the semantic context from the normal samples by generating multi-scale striped masks to remove a part of regions from thenormal samples and training a generative adversarial network to reconstruct the unseen regions. Unsupervised anomaly detection aims to identify data samples that have low probability density from a set of input samples, and only the normal samples are provided for model training. The inference of abnormal regions on the input image requires an understanding of the surrounding semantic context. This work presents a Semantic Context based Anomaly Detection Network, SCADN, for unsupervised anomaly detection by learning the semantic context from the normal samples. To achieve this, we first generate multi-scale striped masks to remove a part of regions from the normal samples, and then train a generative adversarial network to reconstruct the unseen regions. Note that the masks are designed in multiple scales and stripe directions, and various training examples are generated to obtain the rich semantic context . In testing, we obtain an error map by computing the difference between the reconstructed image and the input image for all samples, and infer the abnormal samples based on the error maps. Finally, we perform various experiments on three public benchmark datasets and a new dataset LaceAD collected by us, and show that our method clearly outperforms the current state-of-the-art methods.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "18e9e01f6cff97b9ac35c4300761cfc61a04ad8a",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "8381157eae4fbf8908d0312a9642f8e69e944449",
            "70f9968a356d840040a1c9207906f60376dc6bd4",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803"
        ],
        "related_topics": [
            "Normal Samples",
            "UnSupervised Anomaly Detection",
            "Abnormal Samples",
            "Generative Adversarial Networks"
        ],
        "reference_count": "46",
        "citation_count": "74"
    },
    {
        "Id": "18f207d8dab7357f4f674211ec4f150de1c93a0e",
        "title": "Learning Memory-Guided Normality for Anomaly Detection",
        "authors": [
            "Hyunjong Park",
            "Jongyoun Noh",
            "Bumsub Ham"
        ],
        "date": "30 March 2020",
        "abstract": "This work proposes to use a memory module with a new update scheme where items in the memory record prototypical patterns of normal data, boosting the discriminative power of both memory items and deeply learned features from normal data and lessening the representation capacity of CNNs. We address the problem of anomaly detection, that is, detecting anomalous events in a video sequence. Anomaly detection methods based on convolutional neural networks (CNNs) typically leverage proxy tasks, such as reconstructing input video frames, to learn models describing normality without seeing anomalous samples at training time, and quantify the extent of abnormalities using the reconstruction error at test time. The main drawbacks of these approaches are that they do not consider the diversity of normal patterns explicitly, and the powerful representation capacity of CNNs allows to reconstruct abnormal video frames. To address this problem, we present an unsupervised learning approach to anomaly detection that considers the diversity of normal patterns explicitly, while lessening the representation capacity of CNNs. To this end, we propose to use a memory module with a new update scheme where items in the memory record prototypical patterns of normal data. We also present novel feature compactness and separateness losses to train the memory, boosting the discriminative power of both memory items and deeply learned features from normal data. Experimental results on standard benchmarks demonstrate the effectiveness and efficiency of our approach, which outperforms the state of the art.",
        "references": [
            "7a89447be0a176368926f1ef108512f4df5e27be",
            "fef6f1e04fa64f2f26ac9f01cd143dd19e549790",
            "792250ae660b7c25f85eeea7dcae623e4301d97c",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "e5366a704ffa3b41aacd385f3c087ec3fd566934",
            "094ac7510d1723cb9c2da01db47291322aa29025",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "8a6acba7fb2aad1299fcf35701417e063d410ed4",
            "10a498003e9204f5fc1328e706510a37e514d8c7",
            "527cc8cd2af06a9ac2e5cded806bab5c3faad9cf"
        ],
        "related_topics": [
            "Separateness Losses",
            "Normal Patterns",
            "CUHK Avenue",
            "Memory Module",
            "UCSD Ped2",
            "Prototypical Patterns",
            "MemAE",
            "Memory Items",
            "Abnormal Frames",
            "Memory-augmented Autoencoder"
        ],
        "reference_count": "52",
        "citation_count": "414"
    },
    {
        "Id": "7b7087b7452adc2fe8a874678049f591c1342c0f",
        "title": "Deep Morphological Anomaly Detection Based on Angular Margin Loss",
        "authors": [
            "Taehyeon Kim",
            "Eun Gi Hong",
            "Yoonsik Choe"
        ],
        "date": "16 July 2021",
        "abstract": "The main idea behind the proposed algorithm is to train a multiclass model to classify hundreds of morphological transformation cases applied to all the given data, which outperforms several recent anomaly detection methodologies in various datasets. Deep anomaly detection aims to identify \u201cabnormal\u201d data by utilizing a deep neural network trained on a normal training dataset. In general, industrial visual anomaly detection systems distinguish between normal and \u201cabnormal\u201d data through small morphological differences such as cracks and stains. Nevertheless, most existing algorithms emphasize capturing the semantic features of normal data rather than the morphological features. Therefore, they yield poor performance on real-world visual inspection, although they show their superiority in simulations with representative image classification datasets. To address this limitation, we propose a novel deep anomaly detection algorithm based on the salient morphological features of normal data. The main idea behind the proposed algorithm is to train a multiclass model to classify hundreds of morphological transformation cases applied to all the given data. To this end, the proposed algorithm utilizes a self-supervised learning strategy, making unsupervised learning straightforward. Additionally, to enhance the performance of the proposed algorithm, we replaced the cross-entropy-based loss function with the angular margin loss function. It is experimentally demonstrated that the proposed algorithm outperforms several recent anomaly detection methodologies in various datasets.",
        "references": [
            "0dccbb7902ddda1d32599b65f8b34d90c44dc718",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "f7174c5c29c3904cc2d23f26be2b896a5bc715b4",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803"
        ],
        "related_topics": [],
        "reference_count": "38",
        "citation_count": "2"
    },
    {
        "Id": "38ca689c2f916c648ea3ecb1043facbc4bea0d4f",
        "title": "Puzzle-AE: Novelty Detection in Images through Solving Puzzles",
        "authors": [
            "Mohammadreza Salehi",
            "Ainaz Eftekhar",
            "Niousha Sadjadi",
            "Mohammad Hossein Rohban",
            "Hamid R. Rabiee"
        ],
        "date": "29 August 2020",
        "abstract": "This work proposes adversarial robust training as an effective automatic shortcut removal and achieves competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Autoencoder, as an essential part of many anomaly detection methods, is lacking flexibility on normal data in complex datasets. U-Net is proved to be effective for this purpose but overfits on the training data if trained by just using reconstruction error similar to other AE-based frameworks. Puzzle-solving, as a pretext task of self-supervised learning (SSL) methods, has earlier proved its ability in learning semantically meaningful features. We show that training U-Nets based on this task is an effective remedy that prevents overfitting and facilitates learning beyond pixel-level features. Shortcut solutions, however, are a big challenge in SSL tasks, including jigsaw puzzles. We propose adversarial robust training as an effective automatic shortcut removal. We achieve competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Unlike many competitors, the proposed framework is stable, fast, data-efficient, and does not require unprincipled early stopping.",
        "references": [
            "10b219619e88931fabb674037bbb633682775136",
            "c2b733a79db700b971327a58ef42699fe8a416aa",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "6d4a87759917132913319960389f17fa1fe8b630",
            "8381157eae4fbf8908d0312a9642f8e69e944449",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "70f9968a356d840040a1c9207906f60376dc6bd4",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "599fd051c9438011ec5b581983c89e8922b4a5e6"
        ],
        "related_topics": [
            "Puzzle-AE",
            "Latent Space Autoregression",
            "U-Net",
            "Anomaly Detection",
            "Semi-Supervised Learning",
            "Data Efficient",
            "Early Stopping",
            "Self-Supervised Learning",
            "Overfitting",
            "Novelty Detection"
        ],
        "reference_count": "66",
        "citation_count": "34"
    },
    {
        "Id": "205a1c89058ea55fe536c6484a62213d1d0f0160",
        "title": "An Improved Reverse Distillation Model for Unsupervised Anomaly Detection",
        "authors": [
            "Van-Duc Nguyen",
            "Hoang Huu Bach",
            "Le Hong Trang"
        ],
        "date": "3 January 2023",
        "abstract": "Testing results obtained on benchmarks for AD and one-class novelty detection showed that the proposed model outperforms the SOTA ones, proving the utility and applicability of the suggested strategy. Using knowledge distillation for unsupervised anomaly detection problems is more efficient. Recently, a reverse distillation (RD) model has been presented a novel teacher-student (T-S) model for the problem [7]. In the model, the student network uses the one-class embedding from the teacher model as input with the goal of restoring the teacher's rep-resentations. The knowledge distillation starts with high-level abstract presentations and moves down to low-level aspects using a model called one-class bottleneck embedding (OCBE). Although its performance is expressive, it still leverages the power of transforming input images before applying this architecture. Instead of only using raw images, in this paper, we transform them using augmentation techniques. The teacher will encode raw and transformed inputs to get raw representation (encoded from raw inputs) and transformed representation (encoded from transformed inputs). The student must restore the transformed representation from the bottleneck to the raw representation. Testing results obtained on benchmarks for AD and one-class novelty detection showed that our proposed model outperforms the SOTA ones, proving the utility and applicability of the suggested strategy.",
        "references": [
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "93040f8a5d10e8fde279e18d353aa3dca2873900",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e"
        ],
        "related_topics": [
            "Knowledge Distillation",
            "Reverse Distillation",
            "UnSupervised Anomaly Detection",
            "Student Network",
            "One-Class Embedding",
            "One-class Novelty Detection",
            "Self-organizing Tree Algorithm"
        ],
        "reference_count": "0",
        "citation_count": "24"
    },
    {
        "Id": "cec282840ed7992af45400472fa545c94a6e3f7d",
        "title": "ADPS: Asymmetric Distillation Post-Segmentation for Image Anomaly Detection",
        "authors": [
            "Peng Xing",
            "Hao Tang",
            "Jinhui Tang",
            "Zechao Li"
        ],
        "date": "19 October 2022",
        "abstract": "This work proposes an innovative approach called Asymmetric Distillation Post-Segmentation (ADPS), which employs an asymmetric distillation paradigm that takes distinct forms of the same image as the input of the teacher-student networks, driving the student network to learn discriminating representations for anomalous regions. Knowledge Distillation-based Anomaly Detection (KDAD) methods rely on the teacher-student paradigm to detect and segment anomalous regions by contrasting the unique features extracted by both networks. However, existing KDAD methods suffer from two main limitations: 1) the student network can effortlessly replicate the teacher network's representations, and 2) the features of the teacher network serve solely as a ``reference standard\"and are not fully leveraged. Toward this end, we depart from the established paradigm and instead propose an innovative approach called Asymmetric Distillation Post-Segmentation (ADPS). Our ADPS employs an asymmetric distillation paradigm that takes distinct forms of the same image as the input of the teacher-student networks, driving the student network to learn discriminating representations for anomalous regions. Meanwhile, a customized Weight Mask Block (WMB) is proposed to generate a coarse anomaly localization mask that transfers the distilled knowledge acquired from the asymmetric paradigm to the teacher network. Equipped with WMB, the proposed Post-Segmentation Module (PSM) is able to effectively detect and segment abnormal regions with fine structures and clear boundaries. Experimental results demonstrate that the proposed ADPS outperforms the state-of-the-art methods in detecting and segmenting anomalies. Surprisingly, ADPS significantly improves Average Precision (AP) metric by 9% and 20% on the MVTec AD and KolektorSDD2 datasets, respectively.",
        "references": [
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "d08775cf2bebcffa05c6fa506f687ef56953f128",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "93040f8a5d10e8fde279e18d353aa3dca2873900"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "66"
    },
    {
        "Id": "61840de4d9610558d510cfcf32986e93511a4cef",
        "title": "Asymmetric Distillation Post-Segmentation Method for Image Anomaly Detection",
        "authors": [
            "Peng-Fei Xing",
            "Zechao Li"
        ],
        "date": "2022",
        "abstract": "A novel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network is proposed and achieves state-of-the-art anomaly segmentation results. Knowledge distillation-based anomaly detection methods generate same outputs for unknown classes due to the symmetric form of the input and ignore the powerful semantic information of the output of the teacher network since it is only used as a \u201creference standard\u201d. Towards this end, this work proposes a novel Asymmetric Distillation Post-Segmentation (ADPS) method to effectively explore the asymmetric structure of the input and the discriminative features of the teacher network. Speci\ufb01cally, a simple yet effective asymmetric input approach is proposed to make different data \ufb02ows through the teacher and student networks. The student network enables to have different inductive and expressive abilities, which can generate different outputs in anomalous regions. Besides, to further explore the semantic information of the teacher network and obtain effective discriminative boundaries, the Weight Mask Block (WMB) and the post-segmentation module are proposede. WMB leverages a weighted strategy by exploring teacher-student feature maps to highlight anomalous features. The post-segmentation module further learns the anomalous features and obtains valid discriminative boundaries. Experimental results on three benchmark datasets demonstrate that the proposed ADPS achieves state-of-the-art anomaly segmentation results.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "2b32b46f346d9b13268f0e74e5242a10a712a352",
            "8e180ffb0c4bfe4db41a245637042a28fc98d891",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "d08775cf2bebcffa05c6fa506f687ef56953f128",
            "6517f92d519fc126cc18924231bafd8945a554d1",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f"
        ],
        "related_topics": [
            "Teacher Network",
            "Student Network",
            "Semantic Information",
            "Weighted Mini-bucket",
            "Unknown Classes",
            "Image Anomaly Detection",
            "Anomalous Regions",
            "Knowledge Distillation",
            "Anomaly Detection",
            "Benchmark Dataset"
        ],
        "reference_count": "0",
        "citation_count": "52"
    },
    {
        "Id": "5c04ce7f8510af40f2931535feeaf220832ab548",
        "title": "SLSG: Industrial Image Anomaly Detection by Learning Better Feature Embeddings and One-Class Classification",
        "authors": [
            "Minghui Yang",
            "Jing Liu",
            "Zhiwei Yang",
            "Zhaoyang Wu"
        ],
        "date": "30 April 2023",
        "abstract": "A network based on self-supervised learning and self-attentive graph convolution (SLSG) for anomaly detection, which comprehensively models the dense and sparse relationships among elements in the image, which further strengthens the detection of logical anomalies. Industrial image anomaly detection under the setting of one-class classification has significant practical value. However, most existing models struggle to extract separable feature representations when performing feature embedding and struggle to build compact descriptions of normal features when performing one-class classification. One direct consequence of this is that most models perform poorly in detecting logical anomalies which violate contextual relationships. Focusing on more effective and comprehensive anomaly detection, we propose a network based on self-supervised learning and self-attentive graph convolution (SLSG) for anomaly detection. SLSG uses a generative pre-training network to assist the encoder in learning the embedding of normal patterns and the reasoning of position relationships. Subsequently, SLSG introduces the pseudo-prior knowledge of anomaly through simulated abnormal samples. By comparing the simulated anomalies, SLSG can better summarize the normal features and narrow down the hypersphere used for one-class classification. In addition, with the construction of a more general graph structure, SLSG comprehensively models the dense and sparse relationships among elements in the image, which further strengthens the detection of logical anomalies. Extensive experiments on benchmark datasets show that SLSG achieves superior anomaly detection performance, demonstrating the effectiveness of our method.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "355b4e74774798c177c82943eef925d66a2bb2ce",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "e5349e937545d3f3d18d254bd21d695e7350ea8e",
            "d08775cf2bebcffa05c6fa506f687ef56953f128",
            "7f12319e9b0cdbef09f720bd34dacb8422504df6"
        ],
        "related_topics": [
            "One-class Classification",
            "Anomaly Detection",
            "Logical Anomalies",
            "Feature Embeddings",
            "Normal Patterns",
            "Simulated Anomalies",
            "Hypersphere",
            "Embeddings",
            "Self-Supervised Learning",
            "Benchmark Dataset"
        ],
        "reference_count": "0",
        "citation_count": "57"
    },
    {
        "Id": "2013f18832e0fb11c7aaf1f4f8da453aebda488c",
        "title": "Pull & Push: Leveraging Differential Knowledge Distillation for Efficient Unsupervised Anomaly Detection and Localization",
        "authors": [
            "Qihang Zhou",
            "Shibo He",
            "Haoyu Liu",
            "Tao Chen",
            "Jiming Chen"
        ],
        "date": "1 May 2023",
        "abstract": "This work designs an efficient teacher-student model for anomaly detection and localization, which maximizes pixel-wise discrepancies for anomalous regions approximated by data augmentation and simultaneously minimizes discrepancies for pixel- wise normal regions between these two networks. Recently, much attention has been paid to segmenting subtle unknown defect regions by knowledge distillation in an unsupervised setting. Most previous studies concentrated on guiding the student network to learn the same representations on the normality, neglecting the different behaviors of the abnormality. This leads to a high probability of false detection of subtle defects. To address such an issue, we propose to push representations on abnormal areas of the teacher and student network as far as possible while pulling representations on normal areas as close as possible. Based on this idea, we design an efficient teacher-student model for anomaly detection and localization, which maximizes pixel-wise discrepancies for anomalous regions approximated by data augmentation and simultaneously minimizes discrepancies for pixel-wise normal regions between these two networks. The explicit differential knowledge distillation enlarges the margin between normal representations and abnormal ones in favour of discriminating them. Then, the appropriate small student network is not only efficient, but more importantly, helps inhibit the generalization ability of anomalous patterns when learning normal patterns, facilitating the precise decision boundary. The experimental results on the MVTec AD, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our proposed method achieves better performance than current state-of-the-art (SOTA) approaches. Especially, For the MVTec AD dataset with high resolution images, we achieve 98.1 AUROC% and 93.6 AUPRO% in anomaly localization, outperforming knowledge distillation based SOTA methods by 1.1 AUROC% and 1.5 AUPRO% with a lightweight model.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "4dd78b8d466b4cfe55a1bbdc694291197ce62541",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "7d90243c5a46430a36c5ba88627b5d254450a1e1",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "23ad8fc48530ce366f8192dfb48d0f7df1dba277"
        ],
        "related_topics": [
            "Student Network",
            "Knowledge Distillation",
            "MVTec AD",
            "Self-organizing Tree Algorithm",
            "Area Under The Receiver Operating Characteristic Curve",
            "Margin",
            "Student Model",
            "CIFAR-10",
            "UnSupervised Anomaly Detection",
            "Anomaly Detection"
        ],
        "reference_count": "64",
        "citation_count": "8"
    },
    {
        "Id": "fa5aaa7c45e4cd727226a75f5b1b8e5d33460a87",
        "title": "Contextual Affinity Distillation for Image Anomaly Detection",
        "authors": [
            "J. Zhang",
            "Masanori Suganuma",
            "Takayuki Okatani"
        ],
        "date": "6 July 2023",
        "abstract": "The global context condensing block (GCCB) is designed and a contextual affinity loss for the student training and anomaly scoring is proposed and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset. Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "23ad8fc48530ce366f8192dfb48d0f7df1dba277",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "e26851c89afcfb1a0fe00292590c9f6e830c4ec0"
        ],
        "related_topics": [
            "Logical Anomalies",
            "Long-range Dependencies",
            "Image Anomaly Detection",
            "Knowledge Distillation",
            "Anomaly Scoring"
        ],
        "reference_count": "40",
        "citation_count": "One"
    },
    {
        "Id": "98e3b4be394a4bc137ac3707c3c90b8df505b1d0",
        "title": "Remembering Normality: Memory-guided Knowledge Distillation for Unsupervised Anomaly Detection",
        "authors": [
            "Zhihao Gu",
            "Liang Liu",
            "Xu Chen",
            "Ran Yi",
            "Jiangning Zhang",
            "Yabiao Wang",
            "Chengjie Wang",
            "Annan Shu",
            "Guannan Jiang",
            "Lizhuang Ma"
        ],
        "date": "1 October 2023",
        "abstract": "A novel Memory-guided Knowledge-Distillation framework that adaptively modulates the normality of student features in detecting anomalies is introduced and a normality recall memory is proposed to strengthen the normality of student-generated features by recalling the stored normal information. Knowledge distillation (KD) has been widely explored in unsupervised anomaly detection (AD). The student is assumed to constantly produce representations of typical patterns within trained data, named \"normality\", and the representation discrepancy between the teacher and student model is identified as anomalies. However, it suffers from the \"normality forgetting\" issue. Trained on anomaly-free data, the student still well reconstructs anomalous representations for anomalies and is sensitive to fine patterns in normal data, which also appear in training. To mitigate this issue, we introduce a novel Memory-guided Knowledge-Distillation (MemKD) framework that adaptively modulates the normality of student features in detecting anomalies. Specifically, we first propose a normality recall memory (NR Memory) to strengthen the normality of student-generated features by recalling the stored normal information. In this sense, representations will not present anomalies and fine patterns will be well described. Subsequently, we employ a normality embedding learning strategy to promote information learning for the NR Memory. It constructs a normal exemplar set so that the NR Memory can memorize prior knowledge in anomaly-free data and later recall them from the query feature. Consequently, comprehensive experiments demonstrate that the proposed MemKD achieves promising results on five benchmarks.",
        "references": [
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "655158947fd2a3b1e77703d9f4e951e7c583f894",
            "93040f8a5d10e8fde279e18d353aa3dca2873900",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "9775d372bfaf889a395dc714e283b6a179e62537"
        ],
        "related_topics": [],
        "reference_count": "32",
        "citation_count": "One"
    },
    {
        "Id": "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
        "title": "Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection",
        "authors": [
            "Guodong Wang",
            "Shumin Han",
            "Errui Ding",
            "Di Huang"
        ],
        "date": "2021",
        "abstract": "This paper proposes a simple yet powerful approach to anomaly detection, implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Anomaly detection is a challenging task and usually for-mulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Given a strong model pre-trained on image classi\ufb01cation as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, signi\ufb01cantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256 \u00d7 256), at least dozens of times faster than the latest counterparts.",
        "references": [
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "388645c44061f6e88fff0ecdad2f622936207d67",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2528a82dd2266600d4ee2b54165556a984de94d4"
        ],
        "related_topics": [
            "Student-Teacher Feature Pyramid Matching",
            "Pixel-level Anomaly Detection",
            "Anomaly-free Images",
            "Image-level Anomaly Detection",
            "MVTec AD Dataset",
            "Per-region-overlap",
            "Student Network",
            "Feature Pyramids",
            "Unsupervised Learning",
            "Scoring Function"
        ],
        "reference_count": "45",
        "citation_count": "63"
    },
    {
        "Id": "41747cbdbed84762dfbfc305254c97021279dc6e",
        "title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "6 November 2019",
        "abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2910bec6d4de87e22be5119cef3c488d2ae50e2a",
            "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced"
        ],
        "related_topics": [
            "Uninformed Students",
            "Anomaly-free Images",
            "Per-region-overlap",
            "MVTec Anomaly Detection Dataset",
            "Unsupervised Anomaly Segmentation",
            "Anomaly-free Training Data",
            "Anomalous Regions",
            "MVTec AD",
            "Spatial Anomaly Map",
            "OCGAN"
        ],
        "reference_count": "37",
        "citation_count": "376"
    },
    {
        "Id": "8e180ffb0c4bfe4db41a245637042a28fc98d891",
        "title": "Learning Unsupervised Metaformer for Anomaly Detection",
        "authors": [
            "Jhih-Ciang Wu",
            "Ding-Jie Chen",
            "Chiou-Shann Fuh",
            "Tyng-Luh Liu"
        ],
        "date": "1 October 2021",
        "abstract": "This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap, and uses an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions. Anomaly detection (AD) aims to address the task of classification or localization of image anomalies. This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap. The former generalizes an AD model to tackling a broad range of object categories, while the latter provides useful clues for localizing abnormal regions. At the core of our method is an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions, i.e., to explore the reconstruction gap at those regions of interest. We justify the effectiveness of our method with SOTA results on the MVTec AD dataset of industrial images and highlight the adaptation flexibility of the universal Metaformer with multi-class and few-shot scenarios.",
        "references": [
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "10a498003e9204f5fc1328e706510a37e514d8c7",
            "bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "6af440915b8a0718c93be1cf61905e41e620484a"
        ],
        "related_topics": [
            "Reconstruction Gap",
            "Instance-aware Attention",
            "MetaFormer",
            "Anomaly Detection",
            "Industrial Images",
            "Object Categories",
            "Classification",
            "MVTec AD Dataset",
            "Few-shot Scenario"
        ],
        "reference_count": "39",
        "citation_count": "42"
    },
    {
        "Id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "date": "8 April 2021",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ],
        "related_topics": [
            "CutPaste",
            "Anomaly Score Map",
            "CutPaste Augmentation",
            "Pseudo Anomalies",
            "Uninformed Students",
            "Cut-Paste",
            "Semantic Anomaly Detection",
            "Image-level Anomaly Detection",
            "Gaussian Density Estimator",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "67",
        "citation_count": "389"
    },
    {
        "Id": "d08775cf2bebcffa05c6fa506f687ef56953f128",
        "title": "AnoSeg: Anomaly Segmentation Network Using Self-Supervised Learning",
        "authors": [
            "Jou Won Song",
            "Kyeongbo Kong",
            "Ye In Park",
            "Seonggyun Kim",
            "Suk-Ju Kang"
        ],
        "date": "7 October 2021",
        "abstract": "The experiments show that the proposed AnoSeg outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset and compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks. Anomaly segmentation, which localizes defective areas, is an important component in large-scale industrial manufacturing. However, most recent researches have focused on anomaly detection. This paper proposes a novel anomaly segmentation network (AnoSeg) that can directly generate an accurate anomaly map using self-supervised learning. For highly accurate anomaly segmentation, the proposed AnoSeg considers three novel techniques: Anomaly data generation based on hard augmentation, self-supervised learning with pixel-wise and adversarial losses, and coordinate channel concatenation. First, to generate synthetic anomaly images and reference masks for normal data, the proposed method uses hard augmentation to change the normal sample distribution. Then, the proposed AnoSeg is trained in a self-supervised learning manner from the synthetic anomaly data and normal data. Finally, the coordinate channel, which represents the pixel location information, is concatenated to an input of AnoSeg to consider the positional relationship of each pixel in the image. The estimated anomaly map can also be utilized to improve the performance of anomaly detection. Our experiments show that the proposed method outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset. In addition, we compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks and demonstrated the superiority of our method for anomaly segmentation.",
        "references": [
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "62b77e5cb85fc61b84edd532f6d65714be152596",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "1a00dc525da31292e3734cbae2de681f114e30b1",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "e13d3f39cb9d03c57fef1344a825c163160dd8e7"
        ],
        "related_topics": [
            "AnoSeg",
            "Synthetic Anomaly Data",
            "Anomaly Segmentation",
            "Self-Supervised Learning",
            "Normal Data",
            "Anomaly Detection",
            "Intersection Over Union",
            "Adversarial Loss",
            "MVTec AD Dataset",
            "Segmentation Task"
        ],
        "reference_count": "27",
        "citation_count": "30"
    },
    {
        "Id": "363c81a08858df8dd7d1bde79c6e002e3b19f900",
        "title": "Attribute Restoration Framework for Anomaly Detection",
        "authors": [
            "Fei Ye",
            "Chaoqin Huang",
            "Jinkun Cao",
            "Maosen Li",
            "Ya Zhang",
            "Cewu Lu"
        ],
        "date": "25 November 2019",
        "abstract": "This work proposes to break information equivalence among input and supervision for reconstruction tasks by erasing selected attributes from the original data and reformulate it as a restoration task, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. With the recent advances in deep neural networks, anomaly detection in multimedia has received much attention in the computer vision community. While reconstruction-based methods have recently shown great promise for anomaly detection, the information equivalence among input and supervision for reconstruction tasks can not effectively force the network to learn semantic feature embeddings. We here propose to break this equivalence by erasing selected attributes from the original data and reformulate it as a restoration task, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. Through forcing the network to restore the original image, the semantic feature embeddings related to the erased attributes are learned by the network. During testing phases, because anomalous data are restored with the attribute learned from the normal data, the restoration error is expected to be large. Extensive experiments have demonstrated that the proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUROC of the top-performing baseline by 10.1%. We also evaluate our method on a real-world anomaly detection dataset MVTec AD.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "7c4528f0ff263b6e7a6cee0e959f0e3615b3c65e",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7"
        ],
        "related_topics": [
            "MVTec AD",
            "Anomaly Detection",
            "Anomalous Data",
            "Supervision",
            "ImageNet",
            "Restoration Tasks",
            "Reconstruction-based Methods",
            "Area Under The Receiver Operating Characteristic Curve",
            "Normal Data",
            "Benchmark Dataset"
        ],
        "reference_count": "46",
        "citation_count": "127"
    },
    {
        "Id": "93040f8a5d10e8fde279e18d353aa3dca2873900",
        "title": "Divide-and-Assemble: Learning Block-wise Memory for Unsupervised Anomaly Detection",
        "authors": [
            "Jinlei Hou",
            "Yingying Zhang",
            "Qiaoyong Zhong",
            "Di Xie",
            "Shiliang Pu",
            "Hong Zhou"
        ],
        "date": "28 July 2021",
        "abstract": "By varying the granularity of division on feature maps, this work is able to modulate the reconstruction capability of the model for both normal and abnormal samples, and achieves state-of-the-art performance on the challenging MVTec AD dataset. Reconstruction-based methods play an important role in unsupervised anomaly detection in images. Ideally, we expect a perfect reconstruction for normal samples and poor reconstruction for abnormal samples. Since the generalizability of deep neural networks is difficult to control, existing models such as autoencoder do not work well. In this work, we interpret the reconstruction of an image as a divide-and-assemble procedure. Surprisingly, by varying the granularity of division on feature maps, we are able to modulate the reconstruction capability of the model for both normal and abnormal samples. That is, finer granularity leads to better reconstruction, while coarser granularity leads to poorer reconstruction. With proper granularity, the gap between the reconstruction error of normal and abnormal samples can be maximized. The divide-and-assemble framework is implemented by embedding a novel multi-scale block-wise memory module into an autoencoder network. Besides, we introduce adversarial learning and explore the semantic latent representation of the discriminator, which improves the detection of subtle anomaly. We achieve state-of-the-art performance on the challenging MVTec AD dataset. Remarkably, we improve the vanilla autoencoder model by 10.1% in terms of the AUROC score.",
        "references": [
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2f7af18b35d155064243c21d0818b1570a3a696e",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "7c4528f0ff263b6e7a6cee0e959f0e3615b3c65e",
            "18f207d8dab7357f4f674211ec4f150de1c93a0e",
            "6af440915b8a0718c93be1cf61905e41e620484a"
        ],
        "related_topics": [
            "DAAD",
            "MVTec AD",
            "Abnormal Samples",
            "Autoencoders",
            "UnSupervised Anomaly Detection",
            "Normal Samples",
            "Feature Maps",
            "Reconstruction-based Methods",
            "Discriminator",
            "MVTec AD Dataset"
        ],
        "reference_count": "57",
        "citation_count": "77"
    },
    {
        "Id": "a9eed8bdee35598dba7e4133d0b08691982106dc",
        "title": "Adaptive Context-Aware Distillation for Industrial Image Anomaly Detection",
        "authors": [
            "Yuan-yuan He",
            "Hua Yang",
            "Zhouping Yin"
        ],
        "date": "2024",
        "abstract": "Extensive experiments with mainstream anomaly detection datasets show that ACAD outperforms the state-of-the-art competitors in accuracy and efficiency and the experimental results with a real-world inkjet printing organic electroluminescence display (OLED) panel dataset further demonstrate the effectiveness of the method. Image anomaly detection is extremely challenging in industrial manufacturing processes due to unforeseen and diversified anomalies. Recently, unsupervised anomaly detection methods based on knowledge distillation have been developed and have shown remarkable potential. While most existing methods are devoted to knowledge generalization, they are inadequate for the fine-grained detection task. To address this issue, we propose a novel adaptive context-aware distillation (ACAD) paradigm that gives due consideration to distillation component dependencies and knowledge transfer optimization. Technically, a novel adaptive distillation module (ADM) is proposed for optimal context-aware knowledge transfer, which consists of contrastive decoupling distillation (CDD) and masked perceiving distillation (MPD). The proposed CDD helps to constrain the distribution of different semantic patterns and strengthen the discriminative capability. Vanilla methods treat every pixel as an equal contribution and fail to focus on critical information. To this end, the MPD is proposed to weigh different contextual knowledge adaptively. Extensive experiments with mainstream anomaly detection datasets show that ACAD outperforms the state-of-the-art competitors in accuracy and efficiency. In addition, the experimental results with a real-world inkjet printing organic electroluminescence display (OLED) panel dataset further demonstrate the effectiveness of our method.",
        "references": [
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "2013f18832e0fb11c7aaf1f4f8da453aebda488c",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "2b32b46f346d9b13268f0e74e5242a10a712a352",
            "d17df33c9b6453d61d01353e94592f1757caee8a",
            "51ba3b33f445199d9f3cddb5b00c7e2927199b0c",
            "23ad8fc48530ce366f8192dfb48d0f7df1dba277",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "63"
    },
    {
        "Id": "35dfd96486c38d9a21b1d29e2381d72cd7928b2f",
        "title": "Teacher-Student Network for 3D Point Cloud Anomaly Detection with Few Normal Samples",
        "authors": [
            "Jianjian Qin",
            "Chunzhi Gu",
            "Junzhou Yu",
            "Chaoxi Zhang"
        ],
        "date": "31 October 2022",
        "abstract": "A teacher-student structured model for 3D anomaly detection that uses feature space alignment, dimension zoom, and max pooling to extract the features of the point cloud and then minimize a multi-scale loss between the feature vectors produced by the teacher and the student networks. Anomaly detection, which is a critical and popular topic in computer vision, aims to detect anomalous samples that are different from the normal (i.e., non-anomalous) ones. The current mainstream methods focus on anomaly detection for images, whereas little attention has been paid to 3D point cloud. In this paper, drawing inspiration from the knowledge transfer ability of teacher-student architecture and the impressive feature extraction capability of recent neural networks, we design a teacher-student structured model for 3D anomaly detection. Specifically, we use feature space alignment, dimension zoom, and max pooling to extract the features of the point cloud and then minimize a multi-scale loss between the feature vectors produced by the teacher and the student networks. Moreover, our method only requires very few normal samples to train the student network due to the teacher-student distillation mechanism. Once trained, the teacher-student network pair can be leveraged jointly to fulfill 3D point cloud anomaly detection based on the calculated anomaly score. For evaluation, we compare our method against the reconstruction-based method on the ShapeNet-Part dataset. The experimental results and ablation studies quantitatively and qualitatively confirm that our model can achieve higher performance compared with the state of the arts in 3D anomaly detection with very few training samples.",
        "references": [
            "7d5c0ae2985e0c665cb3713aaa169ee5c7c9794f",
            "ca6294ce6f38f3f6ff694ba67d02eaad7fc92f4e",
            "02805f18989b7e77f30ee13defd6fecfcd0f499f",
            "d997beefc0922d97202789d2ac307c55c2c52fba",
            "cd382609f0029aae042e91a5a46b3dc2ba58a321",
            "3b3aefbbdb64e5812f133f220b3f129a36a30065",
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "2013f18832e0fb11c7aaf1f4f8da453aebda488c",
            "655158947fd2a3b1e77703d9f4e951e7c583f894",
            "5fdd9cfb9b22b9e575d36e98e5d6f52a83729e42"
        ],
        "related_topics": [
            "Anomaly Detection",
            "3D Point Clouds",
            "Normal Samples",
            "Anomaly Score",
            "Max-pooling",
            "Reconstruction-based Methods",
            "ShapeNet Part Dataset",
            "Teacher-student Architecture",
            "Neural Network",
            "Computer Vision"
        ],
        "reference_count": "55",
        "citation_count": "2"
    },
    {
        "Id": "1d0274b642f852897205fc9854e0de4068f89513",
        "title": "Cascade RDN: Towards Accurate Localization in Industrial Visual Anomaly Detection With Structural Anomaly Generation",
        "authors": [
            "Jian Zhang",
            "Ge Yang",
            "Runwei Ding",
            "Yidi Li"
        ],
        "date": "1 September 2023",
        "abstract": "A novel cascade reconstruction-discriminant network (Cascade RDN), which adopts a cascade structure to obtain representative discriminative reconstruction embedding and achieves state-of-the-art anomaly classification scores on BTAD. Unsupervised visual anomaly detection uses only anomaly-free images to detect anomalous patterns, whose recent methods mainly focus on the anomaly classification sub-task but neglect to localize anomalies accurately. Existing reconstruction-based and representation-based methods yield anomaly score maps that often predict erroneous responses. The method jointly trained with the discriminative network is not suitable for anomalies other than texture types. This letter propose a novel cascade reconstruction-discriminant network (Cascade RDN), which adopts a cascade structure to obtain representative discriminative reconstruction embedding. The bi-direction channel attention module is designed to enable the two discriminative sub-networks to boost each other. Moreover, a general structural anomaly generation is presented to complement the existing textured anomaly generation to cover all types of surface anomalies. The proposed method outperforms previous anomaly localization methods by 7%-10% in AP on two challenging benchmarks MVTec AD and BTAD. Meanwhile, it achieves state-of-the-art anomaly classification scores on BTAD.",
        "references": [
            "95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "62b77e5cb85fc61b84edd532f6d65714be152596",
            "9277dc70c74bcadf80dab11c28ead83fd085deec",
            "45535b86c60661dd4c4e4f375abae80937563499",
            "2c1837be2e4e6c4f47d51c42773e398897c372a6",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "41747cbdbed84762dfbfc305254c97021279dc6e"
        ],
        "related_topics": [
            "Surface Anomaly",
            "Anomaly Score Map",
            "MVTec AD",
            "Anomaly-free Images"
        ],
        "reference_count": "27",
        "citation_count": "One"
    },
    {
        "Id": "a76b4ff38181905e30c78e5da2c847a8ba1bcef9",
        "title": "Improving Vision Anomaly Detection with the Guidance of Language Modality",
        "authors": [
            "Dong Chen",
            "Kaihang Pan",
            "Guoming Wang",
            "Yueting Zhuang",
            "Siliang Tang"
        ],
        "date": "4 October 2023",
        "abstract": "This paper proposes Cross-modal Guidance (CMG), which consists of Cross-Modal Entropy Reduction (CMER) and Cross- modal Linear Embedding (CMLE), to tackle the redundant information issue and sparse space issue, respectively. Recent years have seen a surge of interest in anomaly detection for tackling industrial defect detection, event detection, etc. However, existing unsupervised anomaly detectors, particularly those for the vision modality, face significant challenges due to redundant information and sparse latent space. Conversely, the language modality performs well due to its relatively single data. This paper tackles the aforementioned challenges for vision modality from a multimodal point of view. Specifically, we propose Cross-modal Guidance (CMG), which consists of Cross-modal Entropy Reduction (CMER) and Cross-modal Linear Embedding (CMLE), to tackle the redundant information issue and sparse space issue, respectively. CMER masks parts of the raw image and computes the matching score with the text. Then, CMER discards irrelevant pixels to make the detector focus on critical contents. To learn a more compact latent space for the vision anomaly detector, CMLE learns a correlation structure matrix from the language modality, and then the latent space of vision modality will be learned with the guidance of the matrix. Thereafter, the vision latent space will get semantically similar images closer. Extensive experiments demonstrate the effectiveness of the proposed methods. Particularly, CMG outperforms the baseline that only uses images by 16.81%. Ablation experiments further confirm the synergy among the proposed methods, as each component depends on the other to achieve optimal performance.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "1028c987f9d2dd0a1249714382e79f5c986e1804",
            "945b53ede48dae40af9870030fc4985a119cd1b8",
            "df5459473123b0e0a2fc78d812ec161f6ab0ee7e",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "2013f18832e0fb11c7aaf1f4f8da453aebda488c",
            "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "0fe615dc0a422100e85cfb7e26c9306c481f6c75",
            "7f3bd25aab417d4a2c9ef19e18932ee6775300e8",
            "b95533611d08f00daa03fbf28a4c57456aaf2880"
        ],
        "related_topics": [],
        "reference_count": "43",
        "citation_count": "One"
    },
    {
        "Id": "58d59beb750e8c0e1d52b04dbc6c1c8b5ea3178a",
        "title": "Learning Global-Local Correspondence with Semantic Bottleneck for Logical Anomaly Detection",
        "authors": [
            "Haiming Yao",
            "Wenyong Yu",
            "Wei Luo",
            "Zhenfeng Qiang",
            "Donghao Luo",
            "Xiaotian Zhang"
        ],
        "date": "10 March 2023",
        "abstract": "This paper presents a novel framework, named Global-Local Correspondence Framework (GLCF), for visual anomaly detection with logical constraints, that consists of a local branch for detecting structural anomalies and a global Branch for detecting logical anomalies and introduces a novel semantic bottleneck enabled by the visual Transformer. This paper presents a novel framework, named Global-Local Correspondence Framework (GLCF), for visual anomaly detection with logical constraints. Visual anomaly detection has become an active research area in various real-world applications, such as industrial anomaly detection and medical disease diagnosis. However, most existing methods focus on identifying local structural degeneration anomalies and often fail to detect high-level functional anomalies that involve logical constraints. To address this issue, we propose a two-branch approach that consists of a local branch for detecting structural anomalies and a global branch for detecting logical anomalies. To facilitate local-global feature correspondence, we introduce a novel semantic bottleneck enabled by the visual Transformer. Moreover, we develop feature estimation networks for each branch separately to detect anomalies. Our proposed framework is validated using various benchmarks, including industrial datasets, Mvtec AD, Mvtec Loco AD, and the Retinal-OCT medical dataset. Experimental results show that our method outperforms existing methods, particularly in detecting logical anomalies.",
        "references": [
            "11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "e26851c89afcfb1a0fe00292590c9f6e830c4ec0",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "6841ea2b9aead78b6335d6636f7e4ae7e33cbe4b",
            "7db5da4321d526539ac567fb56cd8900def4b1e5",
            "2c8e5a7c4643c92860497f2ff16bc9fe7fe1f046",
            "fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "1dec7a6629eb87952f3f1367eb2917d29870d4ed",
            "62b77e5cb85fc61b84edd532f6d65714be152596"
        ],
        "related_topics": [
            "Logical Anomalies",
            "Visual Anomaly Detection",
            "Semantic Bottlenecks",
            "Industrial Anomaly Detection",
            "Visual Transformers",
            "MVTec AD",
            "Industrial Datasets",
            "MVTec LOCO AD",
            "Logical Anomaly Detection"
        ],
        "reference_count": "49",
        "citation_count": "2"
    },
    {
        "Id": "e74a8db12f7514d481d3b695b8dbc661dbb26be2",
        "title": "FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly Detection",
        "authors": [
            "Tongkun Liu",
            "Bing Li",
            "Xiao Du",
            "Bingke Jiang",
            "Leqi Geng",
            "Feiyang Wang",
            "Zhuo Zhao"
        ],
        "date": "13 September 2023",
        "abstract": "Frequency-aware Image Restoration (FAIR), a novel self-supervised image restoration task that restores images from their high-frequency components, enables precise reconstruction of normal patterns while mitigating unfavorable generalization to anomalies. Image reconstruction-based anomaly detection models are widely explored in industrial visual inspection. However, existing models usually suffer from the trade-off between normal reconstruction fidelity and abnormal reconstruction distinguishability, which damages the performance. In this paper, we find that the above trade-off can be better mitigated by leveraging the distinct frequency biases between normal and abnormal reconstruction errors. To this end, we propose Frequency-aware Image Restoration (FAIR), a novel self-supervised image restoration task that restores images from their high-frequency components. It enables precise reconstruction of normal patterns while mitigating unfavorable generalization to anomalies. Using only a simple vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency on various defect detection datasets. Code: https://github.com/liutongkun/FAIR.",
        "references": [
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "2c8e5a7c4643c92860497f2ff16bc9fe7fe1f046",
            "230c875f7563abf2e11bc79c0ae8855bfa52123c",
            "e021d59638966a6fbb36854cc2cf1045de7a62d2",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "a70bc416b1124525499b0ac3d5b009637dc6c187",
            "2c1837be2e4e6c4f47d51c42773e398897c372a6",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "43"
    },
    {
        "Id": "2116df9be0019c173ec58a123aafec39a03a5827",
        "title": "Self-Supervised Visual Representation Learning via Residual Momentum",
        "authors": [
            "Trung Xuan Pham",
            "Axi Niu",
            "Zhang Kang",
            "Sultan Rizky Hikmawan Madjid",
            "Jiajing Hong",
            "Daehyeok Kim",
            "Joshua Tian Jin Tee",
            "Chang Dong Yoo"
        ],
        "date": "17 November 2022",
        "abstract": "This work highlights the importance of reducing the teacher-student intra-gap in momentum-based contrastive learning frameworks and provides a practical solution for improving the quality of learned representations. Self-supervised learning (SSL) has emerged as a promising approach for learning representations from unlabeled data. Momentum-based contrastive frameworks such as MoCo-v3 have shown remarkable success among the many SSL methods proposed in recent years. However, a significant gap in encoder representation exists between the online encoder (student) and the momentum encoder (teacher) in these frameworks, limiting the performance on downstream tasks. We identify this gap as a bottleneck often overlooked in existing frameworks and propose \u201cresidual momentum\u201d that explicitly reduces the gap during training to encourage the student to learn representations closer to the teacher\u2019s. We also reveal that a similar technique, knowledge distillation (KD), to reduce the distribution gap with cross-entropy-based loss in supervised learning is useless in the SSL context and demonstrate that the intra-representation gap measured by cosine similarity is crucial for EMA-based SSLs. Extensive experiments on different benchmark datasets and architectures demonstrate the superiority of our method compared to state-of-the-art contrastive learning baselines. Specifically, our method outperforms MoCo-v3 0.7% top-1 in ImageNet, 2.82% on CIFAR-100, 1.8% AP, and 3.0% AP75 on VOC detection pre-trained on the COCO dataset; it also improves DenseCL with 0.5% AP (800ep) and 0.6% AP75 (1600ep). Our work highlights the importance of reducing the teacher-student intra-gap in momentum-based contrastive learning frameworks and provides a practical solution for improving the quality of learned representations.",
        "references": [
            "9c1770c992c772916112507b53f3ffb9f259ba70",
            "2f399c4e23e540342e3ff6002be900833e96c8d6",
            "c3ef14ae4f90fa85b307415434c88df1028984ff",
            "4effd0f6b51b73335c3a2b7b880d168fbbe09298",
            "40b68df4635298c32725891bc46ee0201dac56c1",
            "d2b686b7480ab914c75bacb8357abbcf2a22bf00",
            "6f92dcefc5f6b4346f619ae7546a8bd2d6decade",
            "1e1e10d75c4ebabdbfb7912ca4cc06a27ffa85af",
            "8e90de490be759e15987168225f4add8e16810f8",
            "34733eaf66007516347a40ad5d9bbe1cc9dacb6b"
        ],
        "related_topics": [
            "Semi-Supervised Learning",
            "Momentum Encoders",
            "Self-Supervised Learning",
            "Benchmark Dataset",
            "Self-supervised"
        ],
        "reference_count": "91",
        "citation_count": "3"
    },
    {
        "Id": "3827ec14b1b6a1152f1b54c2339d98953dfcfae9",
        "title": "Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection",
        "authors": [
            "Chen Liu",
            "Shibo He",
            "Qihang Zhou",
            "Shizhong Li",
            "Wenchao Meng"
        ],
        "date": "26 January 2024",
        "abstract": "This work proposes AnomalyLLM, a knowledge distillation-based time series anomaly detection approach where the student network is trained to mimic the features of the large language model (LLM)-based teacher network that is pretrained on large-scale datasets. Self-supervised methods have gained prominence in time series anomaly detection due to the scarcity of available annotations. Nevertheless, they typically demand extensive training data to acquire a generalizable representation map, which conflicts with scenarios of a few available samples, thereby limiting their performance. To overcome the limitation, we propose \\textbf{AnomalyLLM}, a knowledge distillation-based time series anomaly detection approach where the student network is trained to mimic the features of the large language model (LLM)-based teacher network that is pretrained on large-scale datasets. During the testing phase, anomalies are detected when the discrepancy between the features of the teacher and student networks is large. To circumvent the student network from learning the teacher network's feature of anomalous samples, we devise two key strategies. 1) Prototypical signals are incorporated into the student network to consolidate the normal feature extraction. 2) We use synthetic anomalies to enlarge the representation gap between the two networks. AnomalyLLM demonstrates state-of-the-art performance on 15 datasets, improving accuracy by at least 14.5\\% in the UCR dataset.",
        "references": [
            "96086f8b0c05d7cbbd6f6ca7890dbab42f15ad75",
            "b949d5529ba08949ffc79ca82708dc6886ce4fca",
            "16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277",
            "d84cf745c534c010b8e55e5a4a04878906848dc3",
            "1725ad1d8cc0e539ac5d0a85657d5c95b4538c5e",
            "5b7f5488c380cf5085a5dd93e993ad293b225eee",
            "4ba2f8dfc1a4fccec80cf95ce3f0eeff3066f21e",
            "3082698875debe15b8e13ad3f26299243e513436",
            "18c44c6baf1d6cbc1c0f6286bf74aa3c7e5cea24",
            "e9dcd9b4a3ec96185757cc882d687553cbfa03cf"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "45"
    },
    {
        "Id": "4317714f4e427b5b7dc77870e59be00f5a89c43d",
        "title": "A Method for Image Anomaly Detection Based on Distillation and Reconstruction",
        "authors": [
            "Jiaxiang Luo",
            "Jianzhao Zhang"
        ],
        "date": "1 November 2023",
        "abstract": "A method for anomaly evaluation based on patch similarity that calculates the difference between the reconstructed image and the input image according to different regions of the image, thus improving the sensitivity and accuracy of the anomaly score. Image anomaly detection is a trending research topic in computer vision. The objective is to build models using available normal samples to detect various abnormal images without depending on real abnormal samples. It has high research significance and value for applications in the detection of defects in product appearance, medical image analysis, hyperspectral image processing, and other fields. This paper proposes an image anomaly detection algorithm based on feature distillation and an autoencoder structure, which uses the feature distillation structure of a dual-teacher network to train the encoder, thus suppressing the reconstruction of abnormal regions. This system also introduces an attention mechanism to highlight the detection objects, achieving effective detection of different defects in product appearance. In addition, this paper proposes a method for anomaly evaluation based on patch similarity that calculates the difference between the reconstructed image and the input image according to different regions of the image, thus improving the sensitivity and accuracy of the anomaly score. This paper conducts experiments on several datasets, and the results show that the proposed algorithm has superior performance in image anomaly detection. It achieves 98.8% average AUC on the SMDC-DET dataset and 98.9% average AUC on the MVTec-AD dataset.",
        "references": [
            "00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "cc0c5d8104cd1c1887ed192039a78b1e99fe1bb3",
            "a4b849c4537ec9f45d380a7bd1d9aa6e1baa9b53",
            "1086f9b2d3e9c13adddf99245089dbcdc72f83ef",
            "5fdd9cfb9b22b9e575d36e98e5d6f52a83729e42",
            "732750bec3b4d8c0108d6daed642500765d5c0ca",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "40"
    },
    {
        "Id": "41747cbdbed84762dfbfc305254c97021279dc6e",
        "title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "6 November 2019",
        "abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2910bec6d4de87e22be5119cef3c488d2ae50e2a",
            "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced"
        ],
        "related_topics": [
            "Uninformed Students",
            "Anomaly-free Images",
            "Per-region-overlap",
            "MVTec Anomaly Detection Dataset",
            "Unsupervised Anomaly Segmentation",
            "Anomaly-free Training Data",
            "Anomalous Regions",
            "MVTec AD",
            "Spatial Anomaly Map",
            "OCGAN"
        ],
        "reference_count": "37",
        "citation_count": "376"
    },
    {
        "Id": "5435a9ab36a308cef10bc725104e8f778ed3a328",
        "title": "Skip-GANomaly: Skip Connected and Adversarially Trained Encoder-Decoder Anomaly Detection",
        "authors": [
            "Samet Ak\u00e7ay",
            "Amir Atapour-Abarghouei",
            "T. Breckon"
        ],
        "date": "25 January 2019",
        "abstract": "This work introduces an unsupervised anomaly detection model, trained only on the normal (non-anomalous, plentiful) samples in order to learn the normality distribution of the domain, and hence detect abnormality based on deviation from this model. Despite inherent ill-definition, anomaly detection is a research endeavour of great interest within machine learning and visual scene understanding alike. Most commonly, anomaly detection is considered as the detection of outliers within a given data distribution based on some measure of normality. The most significant challenge in real-world anomaly detection problems is that available data is highly imbalanced towards normality (i.e. non-anomalous) and contains at most a sub-set of all possible anomalous samples - hence limiting the use of well-established supervised learning methods. By contrast, we introduce an unsupervised anomaly detection model, trained only on the normal (non-anomalous, plentiful) samples in order to learn the normality distribution of the domain, and hence detect abnormality based on deviation from this model. Our proposed approach employs an encoder-decoder convolutional neural network with skip connections to thoroughly capture the multi-scale distribution of the normal data distribution in image space. Furthermore, utilizing an adversarial training scheme for this chosen architecture provides superior reconstruction both within image space and a lower-dimensional embedding vector space encoding. Minimizing the reconstruction error metric within both the image and hidden vector spaces during training aids the model to learn the distribution of normality as required. Higher reconstruction metrics during subsequent test and deployment are thus indicative of a deviation from this normal distribution, hence indicative of an anomaly. Experimentation over established anomaly detection benchmarks and challenging real-world datasets, within the context of X-ray security screening, shows the unique promise of such a proposed approach.",
        "references": [
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "8381157eae4fbf8908d0312a9642f8e69e944449",
            "b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "559a52d27ff8e3ae0cdf1e7948c137ff566285c8",
            "39b8f34e71553622bb16b547211d0d769563c61d",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "571b0750085ae3d939525e62af510ee2cee9d5ea",
            "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1",
            "eb7ee0bc355652654990bcf9f92f124688fde493",
            "8388f1be26329fa45e5807e968a641ce170ea078"
        ],
        "related_topics": [
            "Skip-GANomaly",
            "X-ray Security Screening",
            "Anomaly Detection",
            "Adversarially Trained",
            "Machine Learning",
            "Skip Connections",
            "Visual Scene Understanding"
        ],
        "reference_count": "37",
        "citation_count": "265"
    },
    {
        "Id": "0535625be630c6a67f4c244ebf3aa61ad088fc70",
        "title": "GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training",
        "authors": [
            "Samet Ak\u00e7ay",
            "Amir Atapour-Abarghouei",
            "T. Breckon"
        ],
        "date": "17 May 2018",
        "abstract": "This work introduces a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space and shows the model efficacy and superiority over previous state-of-the-art approaches. Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when datasets are highly biased towards one class (normal) due to the insufficient sample size of the other class (abnormal). While this can be addressed as a supervised learning problem, a significantly more challenging problem is that of detecting the unknown/unseen anomaly case that takes us instead into the space of a one-class, semi-supervised learning paradigm. We introduce such a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space. Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension vector, which is then used to reconstruct the generated output image. The use of the additional encoder network maps this generated image to its latent representation. Minimizing the distance between these images and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from this learned data distribution at inference time is indicative of an outlier from that distribution - an anomaly. Experimentation over several benchmark datasets, from varying domains, shows the model efficacy and superiority over previous state-of-the-art approaches.",
        "references": [
            "e399a626ba21fafb19b3661603ec9724058e951b",
            "559a52d27ff8e3ae0cdf1e7948c137ff566285c8",
            "39b8f34e71553622bb16b547211d0d769563c61d",
            "c8c04ed972d38e2326a53d322a6f2d7e0f8218c1",
            "571b0750085ae3d939525e62af510ee2cee9d5ea",
            "fcf43325529c8b1cc26aeb52fd5d7e532abb0a40",
            "1db6e3078597386ac4222ba6c3f4f61b61f53539",
            "86ee1835a56722b76564119437070782fc90eb19",
            "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79"
        ],
        "related_topics": [
            "GANomaly",
            "Normal Samples",
            "AnoGAN",
            "Semi-supervised Anomaly Detection",
            "Encoder Loss",
            "Encoder-decoder-encoder Pipeline",
            "Normal Data Distribution",
            "Abnormal Samples",
            "Abnormal Images",
            "Bidirectional Generative Adversarial Networks"
        ],
        "reference_count": "55",
        "citation_count": "1,001"
    },
    {
        "Id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "date": "8 April 2021",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ],
        "related_topics": [
            "CutPaste",
            "Anomaly Score Map",
            "CutPaste Augmentation",
            "Pseudo Anomalies",
            "Uninformed Students",
            "Cut-Paste",
            "Semantic Anomaly Detection",
            "Image-level Anomaly Detection",
            "Gaussian Density Estimator",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "67",
        "citation_count": "389"
    },
    {
        "Id": "4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f",
        "title": "Fence GAN: Towards Better Anomaly Detection",
        "authors": [
            "Cuong Phuc Ngo",
            "Amadeus Aristo Winarto",
            "Connie Khor Li Kou",
            "Sojeong Park",
            "Farhan Akram",
            "Hwee Kuan Lee"
        ],
        "date": "2 April 2019",
        "abstract": "With the modified GAN loss proposed, the anomaly detection method, called Fence GAN (FGAN), directly uses the discriminator score as an anomaly threshold and the experimental results show that FGAN yields the best anomaly classification accuracy compared to state-of-the-art methods. Anomaly detection is a classical problem where the aim is to detect anomalous data that do not belong to the normal data distribution. Current state-of-the-art methods for anomaly detection on complex high-dimensional data are based on the generative adversarial network (GAN). However, the traditional GAN loss is not directly aligned with the anomaly detection objective: it encourages the distribution of the generated samples to overlap with the real data and so the resulting discriminator is ineffective as an anomaly detector. In this paper, we propose modifications to the GAN loss such that the generated samples lie at the boundaries of the real data distribution. With our modified GAN loss, our anomaly detection method, called Fence GAN (FGAN), directly uses the discriminator score as an anomaly threshold. Our experimental results on the MNIST, CIFAR10 and KDD99 datasets show that FGAN yields the best anomaly classification accuracy compared to state-of-the-art methods.",
        "references": [
            "5f61089d3d548a515f01b473f0119137d1f340d4",
            "a47f8794d88c5c27123153c4eb9e08046e2b0c9d",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "e399a626ba21fafb19b3661603ec9724058e951b",
            "732750bec3b4d8c0108d6daed642500765d5c0ca",
            "10a498003e9204f5fc1328e706510a37e514d8c7",
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7"
        ],
        "related_topics": [
            "Fence GAN",
            "Anomaly Detection",
            "GAN Loss",
            "Discriminator",
            "Generative Adversarial Networks",
            "KDD99",
            "CIFAR-10",
            "Real Data Distribution",
            "Normal Data Distribution",
            "Anomaly Threshold"
        ],
        "reference_count": "34",
        "citation_count": "71"
    },
    {
        "Id": "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
        "title": "MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "1 June 2019",
        "abstract": "This work introduces the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories, and conducts a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolved neural networks. The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the \ufb01eld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the \ufb01rst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",
        "references": [
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "732c21998e251d64cd58b6a86886ee5907efeaa5",
            "9c24454b071bc8e96ea46c5064a7bddf07cca464",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "5d90f06bb70a0a3dced62413346235c02b1aa086"
        ],
        "related_topics": [
            "MVTec AD",
            "MVTec Anomaly Detection",
            "UnSupervised Anomaly Detection",
            "Texture Categories",
            "Metal Nut",
            "Anomalous Images",
            "MVTec AD Dataset",
            "Anomalous Regions",
            "Spatial Anomaly Map",
            "Anomaly-free Images"
        ],
        "reference_count": "29",
        "citation_count": "748"
    },
    {
        "Id": "8e180ffb0c4bfe4db41a245637042a28fc98d891",
        "title": "Learning Unsupervised Metaformer for Anomaly Detection",
        "authors": [
            "Jhih-Ciang Wu",
            "Ding-Jie Chen",
            "Chiou-Shann Fuh",
            "Tyng-Luh Liu"
        ],
        "date": "1 October 2021",
        "abstract": "This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap, and uses an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions. Anomaly detection (AD) aims to address the task of classification or localization of image anomalies. This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap. The former generalizes an AD model to tackling a broad range of object categories, while the latter provides useful clues for localizing abnormal regions. At the core of our method is an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions, i.e., to explore the reconstruction gap at those regions of interest. We justify the effectiveness of our method with SOTA results on the MVTec AD dataset of industrial images and highlight the adaptation flexibility of the universal Metaformer with multi-class and few-shot scenarios.",
        "references": [
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "10a498003e9204f5fc1328e706510a37e514d8c7",
            "bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "6af440915b8a0718c93be1cf61905e41e620484a"
        ],
        "related_topics": [
            "Reconstruction Gap",
            "Instance-aware Attention",
            "MetaFormer",
            "Anomaly Detection",
            "Industrial Images",
            "Object Categories",
            "Classification",
            "MVTec AD Dataset",
            "Few-shot Scenario"
        ],
        "reference_count": "39",
        "citation_count": "42"
    },
    {
        "Id": "98fa8f7b28f43830a22612be53bb393cf421bbc1",
        "title": "Anomaly detection with Wasserstein GAN",
        "authors": [
            "Ilyass Haloui",
            "Jayant Sen Gupta",
            "Vincent Feuillard"
        ],
        "date": "6 December 2018",
        "abstract": "W-GAN with encoder seems to produce state of the art anomaly detection scores on MNIST dataset and its usage on multi-variate time series is investigated. Generative adversarial networks are a class of generative algorithms that have been widely used to produce state-of-the-art samples. In this paper, we investigate GAN to perform anomaly detection on time series dataset. In order to achieve this goal, a bibliography is made focusing on theoretical properties of GAN and GAN used for anomaly detection. A Wasserstein GAN has been chosen to learn the representation of normal data distribution and a stacked encoder with the generator performs the anomaly detection. W-GAN with encoder seems to produce state of the art anomaly detection scores on MNIST dataset and we investigate its usage on multi-variate time series.",
        "references": [
            "b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "559a52d27ff8e3ae0cdf1e7948c137ff566285c8",
            "13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "1c5b16f980fedc25d9ad954f999e604df9f94fa7",
            "571b0750085ae3d939525e62af510ee2cee9d5ea",
            "1db6e3078597386ac4222ba6c3f4f61b61f53539",
            "488bb25e0b1777847f04c943e6dbc4f84415b712",
            "061146b1d7938d7a8dae70e3531a00fceb3c78e8",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79"
        ],
        "related_topics": [
            "Anomaly Detection",
            "Generative Adversarial Networks",
            "Wasserstein GANs",
            "MNIST Dataset",
            "Normal Data Distribution"
        ],
        "reference_count": "16",
        "citation_count": "13"
    },
    {
        "Id": "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
        "title": "Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection",
        "authors": [
            "Guodong Wang",
            "Shumin Han",
            "Errui Ding",
            "Di Huang"
        ],
        "date": "2021",
        "abstract": "This paper proposes a simple yet powerful approach to anomaly detection, implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Anomaly detection is a challenging task and usually for-mulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and ef\ufb01ciency. Given a strong model pre-trained on image classi\ufb01cation as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, signi\ufb01cantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256 \u00d7 256), at least dozens of times faster than the latest counterparts.",
        "references": [
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7",
            "388645c44061f6e88fff0ecdad2f622936207d67",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced",
            "f076e4355c0facf111716dcab2837803367dd2d8",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2528a82dd2266600d4ee2b54165556a984de94d4"
        ],
        "related_topics": [
            "Student-Teacher Feature Pyramid Matching",
            "Pixel-level Anomaly Detection",
            "Anomaly-free Images",
            "Image-level Anomaly Detection",
            "MVTec AD Dataset",
            "Per-region-overlap",
            "Student Network",
            "Feature Pyramids",
            "Unsupervised Learning",
            "Scoring Function"
        ],
        "reference_count": "45",
        "citation_count": "63"
    },
    {
        "Id": "363c81a08858df8dd7d1bde79c6e002e3b19f900",
        "title": "Attribute Restoration Framework for Anomaly Detection",
        "authors": [
            "Fei Ye",
            "Chaoqin Huang",
            "Jinkun Cao",
            "Maosen Li",
            "Ya Zhang",
            "Cewu Lu"
        ],
        "date": "25 November 2019",
        "abstract": "This work proposes to break information equivalence among input and supervision for reconstruction tasks by erasing selected attributes from the original data and reformulate it as a restoration task, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. With the recent advances in deep neural networks, anomaly detection in multimedia has received much attention in the computer vision community. While reconstruction-based methods have recently shown great promise for anomaly detection, the information equivalence among input and supervision for reconstruction tasks can not effectively force the network to learn semantic feature embeddings. We here propose to break this equivalence by erasing selected attributes from the original data and reformulate it as a restoration task, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. Through forcing the network to restore the original image, the semantic feature embeddings related to the erased attributes are learned by the network. During testing phases, because anomalous data are restored with the attribute learned from the normal data, the restoration error is expected to be large. Extensive experiments have demonstrated that the proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUROC of the top-performing baseline by 10.1%. We also evaluate our method on a real-world anomaly detection dataset MVTec AD.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "7c4528f0ff263b6e7a6cee0e959f0e3615b3c65e",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "dbc7401e3e75c40d3c720e7db3c906d48bd742d7"
        ],
        "related_topics": [
            "MVTec AD",
            "Anomaly Detection",
            "Anomalous Data",
            "Supervision",
            "ImageNet",
            "Restoration Tasks",
            "Reconstruction-based Methods",
            "Area Under The Receiver Operating Characteristic Curve",
            "Normal Data",
            "Benchmark Dataset"
        ],
        "reference_count": "46",
        "citation_count": "127"
    },
    {
        "Id": "2b32b46f346d9b13268f0e74e5242a10a712a352",
        "title": "Self-Supervised Guided Segmentation Framework for Unsupervised Anomaly Detection",
        "authors": [
            "Peng Xing",
            "Yanpeng Sun",
            "Zechao Li"
        ],
        "date": "26 September 2022",
        "abstract": "A novel Self- Supervised Guided Segmentation Framework is proposed by jointly exploring effective generation method of forged anoma- lous samples and the normal sample features as the guidance information of segmentation for anomaly detection. \u2014Unsupervised anomaly detection is a challenging task in industrial applications since it is impracticable to col-lect suf\ufb01cient anomalous samples. In this paper, a novel Self- Supervised Guided Segmentation Framework (SGSF) is proposed by jointly exploring effective generation method of forged anoma- lous samples and the normal sample features as the guidance information of segmentation for anomaly detection. Speci\ufb01cally, to ensure that the generated forged anomaly samples are conducive to model training, the Saliency Augmentation Module (SAM) is proposed. SAM introduces a saliency map to generate saliency Perlin noise map, and develops an adaptive segmentation strategy to generate irregular masks in the saliency region. Then, the masks are utilized to generate forged anomalous samples as negative samples for training. Unfortunately, the distribution gap between forged and real anomaly samples makes it dif\ufb01cult for models trained based on forged samples to effectively locate real anomalies. Towards this end, the Self-supervised Guidance Network (SGN) is proposed. It leverages the self-supervised module to extract features that are noise-free and contain normal semantic information as the prior knowledge of the segmentation module. The segmentation module with the knowledge of normal patterns segments out the abnormal regions that are different from the guidance features. To evaluate the effectiveness of SGSF for anomaly detection, extensive experiments are conducted on three anomaly detection datasets. The experimental results show that SGSF achieves state-of-the-art anomaly detection results.",
        "references": [
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "e13d3f39cb9d03c57fef1344a825c163160dd8e7",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "363c81a08858df8dd7d1bde79c6e002e3b19f900",
            "95a26eafabf06b1fc5dec6c460a927cf5964e97e",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "c707517507873bc2cdc489b6fd9af74770468c48"
        ],
        "related_topics": [
            "Anomalous Samples",
            "Anomaly Detection",
            "Normal Patterns",
            "Negative Samples",
            "Samples",
            "Saliency Maps",
            "Anomaly Detection Datasets",
            "Irregular Masks",
            "UnSupervised Anomaly Detection",
            "Self-supervised"
        ],
        "reference_count": "51",
        "citation_count": "8"
    },
    {
        "Id": "8e180ffb0c4bfe4db41a245637042a28fc98d891",
        "title": "Learning Unsupervised Metaformer for Anomaly Detection",
        "authors": [
            "Jhih-Ciang Wu",
            "Ding-Jie Chen",
            "Chiou-Shann Fuh",
            "Tyng-Luh Liu"
        ],
        "date": "1 October 2021",
        "abstract": "This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap, and uses an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions. Anomaly detection (AD) aims to address the task of classification or localization of image anomalies. This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap. The former generalizes an AD model to tackling a broad range of object categories, while the latter provides useful clues for localizing abnormal regions. At the core of our method is an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions, i.e., to explore the reconstruction gap at those regions of interest. We justify the effectiveness of our method with SOTA results on the MVTec AD dataset of industrial images and highlight the adaptation flexibility of the universal Metaformer with multi-class and few-shot scenarios.",
        "references": [
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "10a498003e9204f5fc1328e706510a37e514d8c7",
            "bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "6af440915b8a0718c93be1cf61905e41e620484a"
        ],
        "related_topics": [
            "Reconstruction Gap",
            "Instance-aware Attention",
            "MetaFormer",
            "Anomaly Detection",
            "Industrial Images",
            "Object Categories",
            "Classification",
            "MVTec AD Dataset",
            "Few-shot Scenario"
        ],
        "reference_count": "39",
        "citation_count": "42"
    },
    {
        "Id": "41747cbdbed84762dfbfc305254c97021279dc6e",
        "title": "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings",
        "authors": [
            "Paul Bergmann",
            "Michael Fauser",
            "David Sattlegger",
            "Carsten Steger"
        ],
        "date": "6 November 2019",
        "abstract": "A powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images by trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "2910bec6d4de87e22be5119cef3c488d2ae50e2a",
            "68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d",
            "e163a2e89c136cb4442e34c72f7173a0ff46dc79",
            "f88cfc38dec02dcf050eb1f56d2d59d90b24e04c",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "67b9c2b376a01d8757dc6d704be450d1c46c4ced"
        ],
        "related_topics": [
            "Uninformed Students",
            "Anomaly-free Images",
            "Per-region-overlap",
            "MVTec Anomaly Detection Dataset",
            "Unsupervised Anomaly Segmentation",
            "Anomaly-free Training Data",
            "Anomalous Regions",
            "MVTec AD",
            "Spatial Anomaly Map",
            "OCGAN"
        ],
        "reference_count": "37",
        "citation_count": "376"
    },
    {
        "Id": "d08775cf2bebcffa05c6fa506f687ef56953f128",
        "title": "AnoSeg: Anomaly Segmentation Network Using Self-Supervised Learning",
        "authors": [
            "Jou Won Song",
            "Kyeongbo Kong",
            "Ye In Park",
            "Seonggyun Kim",
            "Suk-Ju Kang"
        ],
        "date": "7 October 2021",
        "abstract": "The experiments show that the proposed AnoSeg outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset and compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks. Anomaly segmentation, which localizes defective areas, is an important component in large-scale industrial manufacturing. However, most recent researches have focused on anomaly detection. This paper proposes a novel anomaly segmentation network (AnoSeg) that can directly generate an accurate anomaly map using self-supervised learning. For highly accurate anomaly segmentation, the proposed AnoSeg considers three novel techniques: Anomaly data generation based on hard augmentation, self-supervised learning with pixel-wise and adversarial losses, and coordinate channel concatenation. First, to generate synthetic anomaly images and reference masks for normal data, the proposed method uses hard augmentation to change the normal sample distribution. Then, the proposed AnoSeg is trained in a self-supervised learning manner from the synthetic anomaly data and normal data. Finally, the coordinate channel, which represents the pixel location information, is concatenated to an input of AnoSeg to consider the positional relationship of each pixel in the image. The estimated anomaly map can also be utilized to improve the performance of anomaly detection. Our experiments show that the proposed method outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset. In addition, we compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks and demonstrated the superiority of our method for anomaly segmentation.",
        "references": [
            "211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "62b77e5cb85fc61b84edd532f6d65714be152596",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "1a00dc525da31292e3734cbae2de681f114e30b1",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "eb60fe884c53b420edbce57059b242cfcbae0f7c",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "3447d8b47a8cf7ce9f04ede314f0ded8172fa470",
            "e13d3f39cb9d03c57fef1344a825c163160dd8e7"
        ],
        "related_topics": [
            "AnoSeg",
            "Synthetic Anomaly Data",
            "Anomaly Segmentation",
            "Self-Supervised Learning",
            "Normal Data",
            "Anomaly Detection",
            "Intersection Over Union",
            "Adversarial Loss",
            "MVTec AD Dataset",
            "Segmentation Task"
        ],
        "reference_count": "27",
        "citation_count": "30"
    },
    {
        "Id": "6517f92d519fc126cc18924231bafd8945a554d1",
        "title": "Reconstruction Student with Attention for Student-Teacher Pyramid Matching",
        "authors": [
            "Shinji Yamada",
            "Kazuhiro Hotta"
        ],
        "date": "30 November 2021",
        "abstract": "A powerful method which compensates for the shortcomings of Student-Teacher Feature Pyramid Matching (STPM), which can be trained from only normal images with small number of epochs is proposed. Anomaly detection and localization are important problems in computer vision. Recently, Convolutional Neural Network (CNN) has been used for visual inspection. In particular, the scarcity of anomalous samples increases the difficulty of this task, and unsupervised leaning based methods are attracting attention. We focus on Student-Teacher Feature Pyramid Matching (STPM) which can be trained from only normal images with small number of epochs. Here we proposed a powerful method which compensates for the shortcomings of STPM. Proposed method consists of two students and two teachers that a pair of student-teacher network is the same as STPM. The other student-teacher network has a role to reconstruct the features of normal products. By reconstructing the features of normal products from an abnormal image, it is possible to detect abnormalities with higher accuracy by taking the difference between them. The new student-teacher network uses attention modules and different teacher network from the original STPM. Attention mechanism acts to successfully reconstruct the normal regions in an input image. Different teacher network prevents looking at the same regions as the original STPM. Six anomaly maps obtained from the two student-teacher networks are used to calculate the final anomaly map. Student-teacher network for reconstructing features improved AUC scores for pixel level and image level in comparison with the original STPM.",
        "references": [
            "931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "82527ee075d2f7bf731da80edd8d4a92b01c2b8b",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "317c172f314f8cb634f7569ed5bf3ae7dd25c313",
            "e8874d7d585ae1c355e186efdcc9f704b3d43b49",
            "ad655c25e052fa4eeed53421344aca6f239c4c9d",
            "a8f3dc53e321fbb2565f5925def4365b9f68d1af",
            "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "31f9eb39d840821979e5df9f34a6e92dd9c879f2"
        ],
        "related_topics": [
            "STPM",
            "Convolutional Neural Network",
            "Image Level",
            "Pixel Level",
            "Attention Modules",
            "Anomaly Map",
            "Computer Vision",
            "Normal Images",
            "AUC Scores",
            "Anomaly Detection"
        ],
        "reference_count": "33",
        "citation_count": "17"
    },
    {
        "Id": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
        "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
        "authors": [
            "Chun-Liang Li",
            "Kihyuk Sohn",
            "Jinsung Yoon",
            "Tomas Pfister"
        ],
        "date": "8 April 2021",
        "abstract": "This work proposes a two-stage framework for building anomaly detectors using normal training data only, which first learns self-supervised deep representations and then builds a generative one-class classifier on learned representations. We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "references": [
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "5db790198b9acf4e5efe350acdd814238fcacaa7",
            "37595f7a51982d776e57c7280b9445474d90f0be",
            "41747cbdbed84762dfbfc305254c97021279dc6e",
            "16a67491ed4bdb6293d1c2be35b0e8bae962cdeb",
            "0535625be630c6a67f4c244ebf3aa61ad088fc70",
            "206c2e79b5f1b4541b85f47517666961ed49500e",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "30b99ae0682d42a2010be401dd1d8f7baca9bb5f"
        ],
        "related_topics": [
            "CutPaste",
            "Anomaly Score Map",
            "CutPaste Augmentation",
            "Pseudo Anomalies",
            "Uninformed Students",
            "Cut-Paste",
            "Semantic Anomaly Detection",
            "Image-level Anomaly Detection",
            "Gaussian Density Estimator",
            "MVTec Anomaly Detection Dataset"
        ],
        "reference_count": "67",
        "citation_count": "389"
    },
    {
        "Id": "b7d57cb75058728ba141b0fe4056d78d272c0d24",
        "title": "Few-shot Anomaly Detection in Text with Deviation Learning",
        "authors": [
            "Anindya Sundar Das",
            "Aravind Ajay",
            "Sriparna Saha",
            "Monowar H. Bhuyan"
        ],
        "date": "22 August 2023",
        "abstract": "FATE is introduced, a deep few-shot learning-based framework that leverages limited anomaly examples and learns anomaly scores explicitly in an end-to-end method using deviation learning and is optimized to learn the distinct behavior of anomalies. Most current methods for detecting anomalies in text concentrate on constructing models solely relying on unlabeled data. These models operate on the presumption that no labeled anomalous examples are available, which prevents them from utilizing prior knowledge of anomalies that are typically present in small numbers in many real-world applications. Furthermore, these models prioritize learning feature embeddings rather than optimizing anomaly scores directly, which could lead to suboptimal anomaly scoring and inefficient use of data during the learning process. In this paper, we introduce FATE, a deep few-shot learning-based framework that leverages limited anomaly examples and learns anomaly scores explicitly in an end-to-end method using deviation learning. In this approach, the anomaly scores of normal examples are adjusted to closely resemble reference scores obtained from a prior distribution. Conversely, anomaly samples are forced to have anomalous scores that considerably deviate from the reference score in the upper tail of the prior. Additionally, our model is optimized to learn the distinct behavior of anomalies by utilizing a multi-head self-attention layer and multiple instance learning approaches. Comprehensive experiments on several benchmark datasets demonstrate that our proposed approach attains a new level of state-of-the-art performance.",
        "references": [
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "1f5cfe35ada7bba999508ebc216deab4df77840b",
            "763e280d27e3ea65bc80eaeb7e5054e23ddd5ff2",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "f5a951b9596be0df5ad7ede180b405c9e97a65c9",
            "6ec00ff233c19b47ef44dd57cdb22a7385586c0c",
            "96ed8ce9ef9fc475db9e02c79f984dc110409b62",
            "92584dac09356c3c2e915932956bdc06f91d453f"
        ],
        "related_topics": [
            "Anomaly Score",
            "Detecting Anomalies",
            "Multi-head Self Attention Layers",
            "Normal Examples",
            "Few Shot Anomaly Detection",
            "Feature Embeddings",
            "Prior Distribution",
            "Benchmark Dataset",
            "Federated AI Technology Enabler"
        ],
        "reference_count": "0",
        "citation_count": "38"
    },
    {
        "Id": "30aa23a6a32312666f2609339582744203024993",
        "title": "Deep Weakly-supervised Anomaly Detection",
        "authors": [
            "Guansong Pang",
            "Chunhua Shen",
            "Huidong Jin",
            "Anton van den Hengel"
        ],
        "date": "30 October 2019",
        "abstract": "Empirical results on 12 real-world datasets show that PReNet significantly outperforms nine competing methods in detecting seen and unseen anomalies, and theoretically and empirically justify the robustness of the model w.r.t. anomaly contamination in the unlabeled data. Recent semi-supervised anomaly detection methods that are trained using small labeled anomaly examples and large unlabeled data (mostly normal data) have shown largely improved performance over unsupervised methods. However, these methods often focus on fitting abnormalities illustrated by the given anomaly examples only (i.e., seen anomalies), and consequently they fail to generalize to those that are not, i.e., new types/classes of anomaly unseen during training. To detect both seen and unseen anomalies, we introduce a novel deep weakly-supervised approach, namely Pairwise Relation prediction Network (PReNet), that learns pairwise relation features and anomaly scores by predicting the relation of any two randomly sampled training instances, in which the pairwise relation can be anomaly-anomaly, anomaly-unlabeled, or unlabeled-unlabeled. Since unlabeled instances are mostly normal, the relation prediction enforces a joint learning of anomaly-anomaly, anomaly-normal, and normal-normal pairwise discriminative patterns, respectively. PReNet can then detect any seen/unseen abnormalities that fit the learned pairwise abnormal patterns, or deviate from the normal patterns. Further, this pairwise approach also seamlessly and significantly augments the training anomaly data. Empirical results on 12 real-world datasets show that PReNet significantly outperforms nine competing methods in detecting seen and unseen anomalies. We also theoretically and empirically justify the robustness of our model w.r.t. anomaly contamination in the unlabeled data. The code is available at https://github.com/mala-lab/PReNet.",
        "references": [
            "8ed98bd58c799718d6fd389e2218bb89b1ecb9d7",
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "f5a951b9596be0df5ad7ede180b405c9e97a65c9",
            "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "d9e8925a5ccbb1db50c69dd6ccc18fe567f7fe12",
            "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "de638f32e6e5762328357b855a9af3de8c20ea29",
            "cf2e99c821af11966bf415e8c277ae3eb9f8677c",
            "add459d9d37743dc2baad703fe17f794cb6b5d3f"
        ],
        "related_topics": [
            "Anomaly Score Learning",
            "DevNet",
            "Deviation Loss",
            "PReNet",
            "Anomaly Score",
            "Unlabeled-unlabeled",
            "Anomaly Contamination",
            "Generalize",
            "Unseen Anomalies",
            "Semi-supervised Anomaly Detection"
        ],
        "reference_count": "73",
        "citation_count": "47"
    },
    {
        "Id": "9f667d6cec1d607d729ac3a4b6ff9b673d634887",
        "title": "Few-shot Anomaly Detection and Classification Through Reinforced Data Selection",
        "authors": [
            "Xiao Han",
            "Depeng Xu",
            "Shuhan Yuan",
            "Xintao Wu"
        ],
        "date": "1 November 2022",
        "abstract": "This work proposes a few-shot anomaly detection and classification model through reinforced data selection (FADS), a novel framework that iteratively improves the performance of anomaly detectionand classification by exploring the unlabeled dataset to augment the training set. Due to the scarcity of anomalies, deep anomaly detection models are predominately trained in an unsupervised or semi-supervised manner depending on the availability of a small number of labeled samples. Currently, most unsupervised approaches detect anomalies by identifying the deviate patterns, and some semi-supervised studies also use labeled anomalies to improve performance. However, few studies have focused on how to take advantage of potential anomalies in an easily obtained and large-scale unlabeled dataset. Meanwhile, in a semi-supervised setting, although we assume having a small number of labeled anomalies, the task of anomaly classification is under-exploited. In this work, considering the problem of anomaly detection and classification by giving limited labeled samples as well as a large number of unlabeled samples, we propose a few-shot anomaly detection and classification model through reinforced data selection (FADS), a novel framework that iteratively improves the performance of anomaly detection and classification by exploring the unlabeled dataset to augment the training set. Experimental results show that FADS is able to improve the performance of anomaly detection and classification with only a few labeled samples initially.",
        "references": [
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "5365948c073e51a0568b20931c56dc8d6a6f94cb",
            "a2e667e4382aaa8e02a17d0522c1a910790ab65b",
            "6af440915b8a0718c93be1cf61905e41e620484a",
            "f4b74295a2aeaff7fab34a414e1feb5e52d52cb8",
            "c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3",
            "71d1ac92ad36b62a04f32ed75a10ad3259a7218d",
            "00a1077d298f2917d764eb729ab1bc86af3bd241",
            "08d2a01979a273766178c734e1478c68910a8e2b"
        ],
        "related_topics": [
            "Few Shot Anomaly Detection",
            "Unlabeled Dataset",
            "Factor Analysis Of Dynamic Structure",
            "Deep Anomaly Detection",
            "Samples",
            "Training Set",
            "Anomaly Detection",
            "Classification"
        ],
        "reference_count": "0",
        "citation_count": "24"
    },
    {
        "Id": "1922cfc82f3d3817b7dcca95adb609c607525979",
        "title": "RoSAS: Deep Semi-Supervised Anomaly Detection with Contamination-Resilient Continuous Supervision",
        "authors": [
            "Hongzuo Xu",
            "Yijie Wang",
            "Guansong Pang",
            "Songlei Jian",
            "Ninghui Liu",
            "Yongjun Wang"
        ],
        "date": "25 July 2023",
        "abstract": "Semantic Scholar extracted view of \"RoSAS: Deep Semi-Supervised Anomaly Detection with Contamination-Resilient Continuous Supervision\" by Hongzuo Xu et al.",
        "references": [
            "a4dc61de356af114bb18cc247f8b108558d157f7",
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "16550cce229c84682cab742af75b28cde0cca731",
            "cf2e99c821af11966bf415e8c277ae3eb9f8677c",
            "23751b74d9fa42a8a041149018ddfe9efc0d4b7b",
            "30aa23a6a32312666f2609339582744203024993",
            "0b4bffc1f173147a732d2f2766cb1ccdf242e146",
            "7ac3e09d74ca15fdafa5f730617cd65059a144f3",
            "6a4f7514cf25a36b746b09eab4a2576a12961cb0"
        ],
        "related_topics": [
            "Anomaly Contamination",
            "Labeled Anomalies",
            "Semi-supervised Anomaly Detection",
            "Deep Semi-supervised Anomaly Detection",
            "Unsupervised Models",
            "Inliers",
            "Unlabeled Anomalies",
            "Anomaly Score",
            "AUC-PR"
        ],
        "reference_count": "51",
        "citation_count": "2"
    },
    {
        "Id": "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
        "title": "Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection*",
        "authors": [
            "Choubo Ding",
            "Guansong Pang",
            "Chunhua Shen"
        ],
        "date": "28 March 2022",
        "abstract": "This paper proposes a novel approach that learns disentangled representations of abnormalities illustrated by seen anomalies, pseudo anomalies, and latent residual anomalies (i.e., samples that have unusual residuals compared to the normal data in a latent space), with the last two abnormalities designed to detect unseen anomalies. Despite most existing anomaly detection studies assume the availability of normal training samples only, a few labeled anomaly examples are often available in many real-world applications, such as defect samples identified during random quality inspection, lesion images confirmed by radiologists in daily medical screening, etc. These anomaly examples provide valuable knowledge about the application-specific abnormality, enabling significantly improved detection of similar anomalies in some recent models. However, those anomalies seen during training often do not illustrate every possible class of anomaly, rendering these models ineffective in generalizing to unseen anomaly classes. This paper tackles open-set supervised anomaly detection, in which we learn detection models using the anomaly examples with the objective to detect both seen anomalies (\u2018gray swans\u2019) and unseen anomalies (\u2018black swans\u2019). We propose a novel approach that learns disentangled representations of abnormalities illustrated by seen anomalies, pseudo anomalies, and latent residual anomalies (i.e., samples that have unusual residuals compared to the normal data in a latent space), with the last two abnormalities designed to detect unseen anomalies. Extensive experiments on nine real-world anomaly detection datasets show superior performance of our model in detecting seen and unseen anomalies under diverse settings. Code and data are available at: https://github.com/choubo/DRA",
        "references": [
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "8ed98bd58c799718d6fd389e2218bb89b1ecb9d7",
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "c48def9076e58095c4aea49a8daa931af1990701",
            "2d8c97db4bae00ff243d122b957091a236a697a7",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "0c5ed0c30375703306f36d341d31772f3bd5af47",
            "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "f5a951b9596be0df5ad7ede180b405c9e97a65c9"
        ],
        "related_topics": [
            "Seen Anomalies",
            "Unseen Anomalies",
            "DevNet",
            "Fractional Lower Order Statistics",
            "Latent Space",
            "Pseudo Anomalies",
            "Disentangled Representations",
            "Supervised Anomaly Detection",
            "Radiologist",
            "Anomaly Class"
        ],
        "reference_count": "76",
        "citation_count": "42"
    },
    {
        "Id": "21484ffc19b1c5e41cbd49aff061db4dfb5286c2",
        "title": "Self-Supervised Normalizing Flows for Image Anomaly Detection and Localization",
        "authors": [
            "Li-Ling Chiu",
            "Shang-Hong Lai"
        ],
        "date": "1 June 2023",
        "abstract": "This work presents a novel self-supervised normalizing flow-based density estimation model, which is trained by maximizing the likelihood of normal images and minimizing thelihood of synthetic anomalous images, and improves the transformation subnet of the affine coupling layers in the flow- based model by dynamic stacking convolution and self-attention blocks. Image anomaly detection aims to detect out-of-distribution instances. Most existing methods treat anomaly detection as an unsupervised task because anomalous training data and labels are usually scarce or unavailable. Recently, image synthesis has been used to generate anomalous samples which deviate from normal sample distribution for model training. By using the synthesized anomalous training samples, we present a novel self-supervised normalizing flow-based density estimation model, which is trained by maximizing the likelihood of normal images and minimizing the likelihood of synthetic anomalous images. By adding constraints to abnormal samples in our loss function, our model training is focused on normal samples rather than synthetic samples. Moreover, we improve the transformation subnet of the affine coupling layers in our flow-based model by dynamic stacking convolution and self-attention blocks. We evaluate our method on MVTec-AD, BTAD, and DAGM datasets and achieve state-of-the-art performance compared to flow-based and self-supervised methods on both anomaly detection and localization tasks.",
        "references": [
            "11709bfadfd6bbb371f4077bccb7c26d93c39cdd",
            "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "2c89b183df320c3ef698989bdc5d1d4731c4d65d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
            "d08775cf2bebcffa05c6fa506f687ef56953f128",
            "5435a9ab36a308cef10bc725104e8f778ed3a328",
            "62b77e5cb85fc61b84edd532f6d65714be152596",
            "da003ed2925e3c8347b33de4e388cb9e6cd06893"
        ],
        "related_topics": [
            "Image Anomaly Detection",
            "Anomaly Detection",
            "MVTec AD",
            "Loss Function",
            "DAGM Dataset",
            "Localization Task",
            "Normal Images",
            "Affine Coupling Layer",
            "Image Synthesis"
        ],
        "reference_count": "49",
        "citation_count": "2"
    },
    {
        "Id": "941501b63b767a87a9727ad21f0f854ccd35ea73",
        "title": "A weakly supervised anomaly detection method based on deep anomaly scoring network",
        "authors": [
            "Xin Xie",
            "Zixi Li",
            "Yuhui Huang",
            "Dengquan Wu"
        ],
        "date": "19 May 2023",
        "abstract": "Comprehensive experiments on the challenging MVTec AD, KolektorSDD and ELPV datasets show that the proposed weakly supervised anomaly detection model achieves better results in anomaly detection and location, and has better robustness. Recently most anomaly detection methods mainly use normal samples or unlabeled data for training. Due to the lack of prior anomaly knowledge, normal samples with noisy data are easy to be misjudged as anomalies. Therefore, this paper proposes a weakly supervised anomaly detection model based on a deep anomaly scoring network. In this model, ResNet is used as a feature extraction network, and the Res2Net module is added to ResNet, which extracts multi-scale features at a fine-grained level to improve the multi-scale representation ability of the network. At the same time, efficient channel attention is introduced to enhance feature extraction performance by allocating the attention to feature channels. In addition, the anomaly score network calculates the anomaly score directly according to the extracted feature representation and optimizes the anomaly score in an end-to-end way. Comprehensive experiments on the challenging MVTec AD, KolektorSDD and ELPV datasets show that compared with the current advanced anomaly detection methods, our model achieves better results in anomaly detection and location, and has better robustness.",
        "references": [
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "78661cecf81340be9bd5720ac5ae97dc0e037bb9",
            "18abe29e2c50fa0b5c113a2e9458b89fb1197a8d",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "57b2198f9a8df773425aa6cc88c9870cb07779e2",
            "182d11020bf2842f135f1ec1dcac20237e0dc8b7",
            "d65eb30e5f0d2013fd5e4f45d1413bc2969ee803",
            "6af440915b8a0718c93be1cf61905e41e620484a"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "34"
    },
    {
        "Id": "553b25f1e371ae6bd7126af54206444043ee7da3",
        "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection",
        "authors": [
            "Qihang Zhou",
            "Guansong Pang",
            "Yu Tian",
            "Shibo He",
            "Jiming Chen"
        ],
        "date": "29 October 2023",
        "abstract": "A novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across different domains, to learn object-agnostic text prompts that capture generic normality and abnormality in an image regardless of its foreground objects. Zero-shot anomaly detection (ZSAD) requires detection models trained using auxiliary data to detect anomalies without any training sample in a target dataset. It is a crucial task when training data is not accessible due to various concerns, \\eg, data privacy, yet it is challenging since the models need to generalize to anomalies across different domains where the appearance of foreground objects, abnormal regions, and background features, such as defects/tumors on different products/organs, can vary significantly. Recently large pre-trained vision-language models (VLMs), such as CLIP, have demonstrated strong zero-shot recognition ability in various vision tasks, including anomaly detection. However, their ZSAD performance is weak since the VLMs focus more on modeling the class semantics of the foreground objects rather than the abnormality/normality in the images. In this paper we introduce a novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across different domains. The key insight of AnomalyCLIP is to learn object-agnostic text prompts that capture generic normality and abnormality in an image regardless of its foreground objects. This allows our model to focus on the abnormal image regions rather than the object semantics, enabling generalized normality and abnormality recognition on diverse types of objects. Large-scale experiments on 17 real-world anomaly detection datasets show that AnomalyCLIP achieves superior zero-shot performance of detecting and segmenting anomalies in datasets of highly diverse class semantics from various defect inspection and medical imaging domains. Code will be made available at https://github.com/zqhang/AnomalyCLIP.",
        "references": [
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "4b182347b943548fe6479393bb24adac21740675",
            "3aa681914a7da79f7d7293f51a058eefe61c8bb7",
            "aa207668318fec38d60b79f407fb64982e46fce9",
            "7d90243c5a46430a36c5ba88627b5d254450a1e1",
            "6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d",
            "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "2c1837be2e4e6c4f47d51c42773e398897c372a6",
            "0e8446c00ed21c19f62d71ab208a7b3601671766",
            "8e37b3b30a1fce1a3f41374ceaf168d2e79bf53f"
        ],
        "related_topics": [],
        "reference_count": "59",
        "citation_count": "6"
    },
    {
        "Id": "70672c29c0e48201e9d3e740255242e1a2fb4bf1",
        "title": "Anomaly Heterogeneity Learning for Open-set Supervised Anomaly Detection",
        "authors": [
            "Jiawen Zhu",
            "Choubo Ding",
            "Yu Tian",
            "Guansong Pang"
        ],
        "date": "19 October 2023",
        "abstract": "A novel approach, namely Anomaly Heterogeneity Learning (AHL), that simulates a diverse set of heterogeneous anomaly distributions and then utilizes them to learn a unified heterogeneous abnormality model and is a generic framework that existing OSAD models can plug and play for enhancing their abnormality modeling. Open-set supervised anomaly detection (OSAD) - a recently emerging anomaly detection area - aims at utilizing a few samples of anomaly classes seen during training to detect unseen anomalies (i.e., samples from open-set anomaly classes), while effectively identifying the seen anomalies. Benefiting from the prior knowledge illustrated by the seen anomalies, current OSAD methods can often largely reduce false positive errors. However, these methods treat the anomaly examples as from a homogeneous distribution, rendering them less effective in generalizing to unseen anomalies that can be drawn from any distribution. In this paper, we propose to learn heterogeneous anomaly distributions using the limited anomaly examples to address this issue. To this end, we introduce a novel approach, namely Anomaly Heterogeneity Learning (AHL), that simulates a diverse set of heterogeneous (seen and unseen) anomaly distributions and then utilizes them to learn a unified heterogeneous abnormality model. Further, AHL is a generic framework that existing OSAD models can plug and play for enhancing their abnormality modeling. Extensive experiments on nine real-world anomaly detection datasets show that AHL can 1) substantially enhance different state-of-the-art (SOTA) OSAD models in detecting both seen and unseen anomalies, achieving new SOTA performance on a large set of datasets, and 2) effectively generalize to unseen anomalies in new target domains.",
        "references": [
            "6a4f7514cf25a36b746b09eab4a2576a12961cb0",
            "8ed98bd58c799718d6fd389e2218bb89b1ecb9d7",
            "df4b7476c206621f14264ca421686b4adafd8506",
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "30aa23a6a32312666f2609339582744203024993",
            "62d49fa60b54fed1e2a2cde3cb49d3639db76768",
            "3e90e30b2e8c11c4c459b32fbbe0cd0dbe95d2c3",
            "c48def9076e58095c4aea49a8daa931af1990701",
            "568a93409f91e959b075ffee9435204b4f15569c"
        ],
        "related_topics": [],
        "reference_count": "70",
        "citation_count": "One"
    },
    {
        "Id": "a78430349519ce3d3a4cf5e7dce7846740b4940a",
        "title": "Anomaly Detection with Score Distribution Discrimination",
        "authors": [
            "Minqi Jiang",
            "Songqiao Han",
            "Hailiang Huang"
        ],
        "date": "26 June 2023",
        "abstract": "This paper proposes to optimize the anomaly scoring function from the view of score distribution, thus better retaining the diversity and more fine-grained information of input data, especially when the unlabeled data contains anomaly noises in more practical AD scenarios. Recent studies give more attention to the anomaly detection (AD) methods that can leverage a handful of labeled anomalies along with abundant unlabeled data. These existing anomaly-informed AD methods rely on manually predefined score target(s), e.g., prior constant or margin hyperparameter(s), to realize discrimination in anomaly scores between normal and abnormal data. However, such methods would be vulnerable to the existence of anomaly contamination in the unlabeled data, and also lack adaptation to different data scenarios. In this paper, we propose to optimize the anomaly scoring function from the view of score distribution, thus better retaining the diversity and more fine-grained information of input data, especially when the unlabeled data contains anomaly noises in more practical AD scenarios. We design a novel loss function called Overlap loss that minimizes the overlap area between the score distributions of normal and abnormal samples, which no longer depends on prior anomaly score targets and thus acquires adaptability to various datasets. Overlap loss consists of Score Distribution Estimator and Overlap Area Calculation, which are introduced to overcome challenges when estimating arbitrary score distributions, and to ensure the boundness of training loss. As a general loss component, Overlap loss can be effectively integrated into multiple network architectures for constructing AD models. Extensive experimental results indicate that Overlap loss based AD models significantly outperform their state-of-the-art counterparts, and achieve better performance on different types of anomalies.",
        "references": [
            "180300ff8282220c76c7c41ded4d9d8c1be4d3fc",
            "1b44498c7bde6bc34d6489834eb5dcfbd3df1eb1",
            "f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed",
            "4c1abd8969fc1c360f50373f6552bcfb3cc408b7",
            "cf2e99c821af11966bf415e8c277ae3eb9f8677c",
            "f1305bbd54db0345533906726e3425f742312c55",
            "30aa23a6a32312666f2609339582744203024993",
            "0bff4af924788d9779041513b6894385eac51ffd",
            "f5a951b9596be0df5ad7ede180b405c9e97a65c9",
            "8d53096bdf5c0b387fbad537a755151e015518ec"
        ],
        "related_topics": [
            "Anomaly Detection",
            "Scoring Function",
            "Anomaly Score",
            "Loss Function",
            "Anomaly Contamination",
            "Labeled Anomalies",
            "Overlap Area",
            "Training Loss"
        ],
        "reference_count": "77",
        "citation_count": "One"
    },
    {
        "Id": "e3fab195d4d79f76672d381097e659241037a1ba",
        "title": "PFed-LDP: A Personalized Federated Local Differential Privacy Framework for IoT Sensing Data",
        "authors": [
            "Jiechao Gao",
            "Mingyue Tang",
            "Tianhao Wang",
            "Brad Campbell"
        ],
        "date": "6 November 2022",
        "abstract": "This paper designs a federated learning framework in a personalized fashion to reduce the accuracy loss caused by privacy-preserving techniques, and presents PFed-LDP, a private and accurate federated local differential privacy (LDP) framework for IoT sensing data. Recent advancements in deep learning techniques have shown great potential for smart Internet of Things (IoT) applications. However, the edge devices of IoT applications often collect and store only limited data, which is insufficient for training modern deep learning models. Collaborative training methods such as cloud computing and federated learning set steps to build robust models for IoT applications, yet these methods bring the concern of data privacy (e.g., untrusted central server, model inversion). On the other hand, directly applying privacy-preserving techniques such as differential privacy can dramatically degrade the performance of IoT applications. Inspired by the development of model personalization, we aim to design a federated learning framework in a personalized fashion to reduce the accuracy loss caused by privacy-preserving techniques. In this paper, we present PFed-LDP, a private and accurate federated local differential privacy (LDP) framework for IoT sensing data. We first design a dynamic layer sharing mechanism to separate the local model into global layers and personalized layers. Second, we apply LDP noise to the global layers and transmit them to the federated learning framework for aggregation. Third, each local client updates their model with local personalized layers and aggregated global layers to perform IoT tasks. Our experiments on real-world datasets show that we only sacrifice 1.6% of accuracy to achieve privacy-preserving IoT applications. We also observe that our method has the smallest accuracy range, which means we can achieve the best performance for the worst performed client.",
        "references": [
            "61724a421569317ba470d48ebdd7316ab8e91b50",
            "b408358a5d2300e1fc6cc1a58a18d45a2b75420d",
            "755ce68419718d9b798071dfc8249cc000ac9a24",
            "150a3349ed577264bd496f55d26cf99d8f935ef0",
            "d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70",
            "a3bd27592ed9879bf46216242e1111eb62d15a94",
            "3f70dc09f979b102c010d4bb500ceb09f18e3b17"
        ],
        "related_topics": [
            "Introduction Internet",
            "Federated Learning",
            "Personalized Layer",
            "Deep Learning",
            "Federated",
            "Privacy-preserving Techniques",
            "Differential Privacy",
            "Data Privacy",
            "Local Differential Privacy",
            "Accuracy Loss"
        ],
        "reference_count": "10",
        "citation_count": "2"
    },
    {
        "Id": "7d1918878a87bebf76a25454272daf5d79fdadcb",
        "title": "A Distributed Privacy-Preserving Framework for Deep Learning with Edge-Cloud Computing",
        "authors": [
            "Fei Dai",
            "Guozhi Liu",
            "Bi Huang",
            "Xiaolong Xu",
            "Chaochao Chen",
            "Zhangbing Zhou",
            "Xiaokang Zhou"
        ],
        "date": "1 August 2022",
        "abstract": "A distributed privacy-preserving framework for DL with edge-cloud computing, where direct privacy leakage and indirect privacy leakage of training data are both considered and achieves high accuracy under low privacy budgets. Industrial Internet of Things (IIoT) systems can leverage deep learning (DL) models to provide intelligent applications. However, the training process of such DL models tends to leak privacy when the training data contain sensitive operational and management information. Most studies about privacy-preserving DL require a trusted data collector and thus are not suitable in an untrusted environment. In this paper, we propose a distributed privacy-preserving framework for DL with edge-cloud computing, where direct privacy leakage and indirect privacy leakage of training data are both considered. First, a pre-trained convolutional neural network (CNN) is partitioned into two parts for limiting direct privacy leakage of raw data, namely the feature module and the classification module. The feature module consisting of the lower layers of the CNN is deployed on an edge server, which is used to attract the feature of raw data. The feature data is fed to the classification module consisting of the higher layers of the CNN, which is deployed on the cloud server to compute image classification tasks. Second, a perturbation module between the feature module and the classification module is designed for limiting indirect privacy leakage during feature data transmission. The perturbation module uses local differential privacy (LDP) to produce noise in the feature data. Third, to further improve the accuracy, we retrain the classification module with the randomized feature data from edge servers. Experimental results show that the proposed framework achieves high accuracy under low privacy budgets.",
        "references": [
            "61724a421569317ba470d48ebdd7316ab8e91b50",
            "0c90e82452d2a70c30b297f968b0f28d6430e7b4",
            "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "024ba5b9d5769c4bedb379ce1486f455fc760897",
            "4f2d4e821dd03ac5df7d5448948bc738aefdd6db",
            "56a6c21446d9640f3f0759bdb42a092d21dd8d05",
            "f9f3ea6d762e45d10f51baccca87346312c9ce54",
            "29ae7d9e9caf52b738244ba2c2d9a0ebe67b5945",
            "7ca27c63216aa90603bbacf01ae85f268d635e4f",
            "e9a986c8ff6c2f381d026fe014f6aaa865f34da7"
        ],
        "related_topics": [
            "Convolutional Neural Network",
            "Feature Modules",
            "Industrial Internet Of Things",
            "Deep Learning",
            "Local Differential Privacy",
            "Edge Servers",
            "Privacy Budget",
            "Image Classification Task"
        ],
        "reference_count": "0",
        "citation_count": "26"
    },
    {
        "Id": "3a5149834ae2cd6baab4126a585a1547e086bd4b",
        "title": "A Review of Privacy-Preserving Federated Learning, Deep Learning, and Machine Learning IIoT and IoTs Solutions",
        "authors": [
            "Victor Obarafor",
            "Man Qi",
            "Leishi Zhang"
        ],
        "date": "8 July 2023",
        "abstract": "A review of AI approaches leveraged by researchers in protecting the device and data security aspects of privacy specifically for de-centralised architecture based industrial IoT systems (IIOTs) as they are generating large amount of data and are safety critical. Internet of Things (IoT) is a growing computing trend that encompasses every connected thing. Over the recent years, IoT has recorded an exponential growth, leading to billions of smart devices, and still increasing. In contrast to other computing devices, some IoTs generate large amount of data, however, this has become a source of concern as data could contain users\u2019 privacy which should be protected at all costs against any potential security breach incident. Securing IoT is very significant with its continuous adoption and use, hence, researchers have proposed several security mechanisms and techniques to safeguard and protect IoT systems and devices. Notwithstanding, there are some research gaps that are yet to be addressed irrespective of the relevant contributions made in protection of users\u2019 privacy and confidentiality using IoTs. In this paper, the researcher solely focused on a review of AI approaches leveraged by researchers in protecting the device and data security aspects of privacy specifically for de-centralised architecture based industrial IoT systems (IIOTs) as they are generating large amount of data and are safety critical. The results achieved, unresolved issues and recommendations for future research are contained in this review.",
        "references": [
            "61724a421569317ba470d48ebdd7316ab8e91b50",
            "0280a9a8de2a073daa73217bf8b0fe3ceb8b34ae",
            "6031238ed718f5f7f09ca15da1a5b4a820e99f54",
            "29f480190a861091565e6cf2956c2c2b0331f5ad",
            "cca397249752ec9a7af599fa78f6f5484c293612",
            "8e00277d353b59e90190344c5c64a7e4b1ad8d2d",
            "7ec7b68af3be7218bfe4ebc5e277c1baa7eb083f",
            "67498fdf77fd036a09a4593c37b012d6cf34f3f6",
            "f2f8e1593e519af46804790e736c19158716aeb1",
            "f64ffe92f29c64d7be8c4516637579e13461cc87"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "35"
    },
    {
        "Id": "924f4997faa42388d94ca8f9cc518b1f54c55992",
        "title": "Privacy-Preserving Offloading in Edge Intelligence Systems With Inductive Learning and Local Differential Privacy",
        "authors": [
            "Jude Tchaye-Kondi",
            "Yanlong Zhai",
            "Jun Shen",
            "Liehuang Zhu"
        ],
        "date": "1 December 2023",
        "abstract": "DeepGuess is presented, a privacy-preserving and latency-aware deep-learning framework that introduces a new learning mechanism enabled by the AutoEncoder architecture: inductive learning. We address privacy and latency issues in edge-cloud computing environments where the neural network training is centralized. This paper considers the scenario where the edge devices are the only data sources for the deep learning model to be trained on the central server. Improper access to the massive amounts of data generated by edge devices could lead to privacy concerns. As a result, existing solutions for preserving privacy and reducing network latency in the edge environment rely on auxiliary datasets with no privacy risks or pre-trained models to build the client side feature extractor. However, finding auxiliary datasets or pre-trained models is not always guaranteed and may be challenging. To bridge this gap and eliminate the reliance on auxiliary datasets or pre-trained models of existing solutions, this paper presents DeepGuess, a privacy-preserving and latency-aware deep-learning framework. DeepGuess introduces a new learning mechanism enabled by the AutoEncoder architecture: inductive learning. With inductive learning, sensitive data stays on devices and is not explicitly sent to the central server to engage in back-propagations. To further enhance privacy, we propose a new local differential privacy algorithm that allows edge devices to apply random noise to features extracted from their sensitive data before being transferred to the non-trusted central server. The experimental evaluation of DeepGuess with various datasets and in a real-world scenario shows that our solution achieves comparable or even higher accuracy than existing solutions while reducing data transfer over the network by more than 50%.",
        "references": [
            "51b4bde0f3e381ae75dee5e41a43a32c71c61f71",
            "61724a421569317ba470d48ebdd7316ab8e91b50",
            "6f0685d61328f0f90972fe822258d574b74e9c7a",
            "60951974d24dd83e288117b0cd217af6a5d34178",
            "d1dbf643447405984eeef098b1b320dee0b3b8a7",
            "7fcb90f68529cbfab49f471b54719ded7528d0ef",
            "88857e68305c4845c5744aafb5be60c1117e17ea",
            "0694b4eed6496d883c724a7731bbdaa2ea45b815",
            "07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b",
            "49bdeb07b045dd77f0bfe2b44436608770235a23"
        ],
        "related_topics": [],
        "reference_count": "46",
        "citation_count": "One"
    }
]