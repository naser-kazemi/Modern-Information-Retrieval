[
    {
        "Id": "6d8052588c62e5bf2a073ae414867a78784ff663",
        "title": "Transformer-based deep neural network language models for Alzheimer\u2019s disease risk assessment from targeted speech",
        "authors": [
            "Ali Roshanzamir",
            "Hamid K. Aghajan",
            "Mahdieh Soleymani Baghshah"
        ],
        "date": "21 January 2021",
        "abstract": "Using pre-trained language models can improve AD prediction not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features. Background We developed transformer-based deep learning models based on natural language processing for early risk assessment of Alzheimer\u2019s disease from the picture description test. Methods The lack of large datasets poses the most important limitation for using complex models that do not require feature engineering. Transformer-based pre-trained deep language models have recently made a large leap in NLP research and application. These models are pre-trained on available large datasets to understand natural language texts appropriately, and are shown to subsequently perform well on classification tasks with small training sets. The overall classification model is a simple classifier on top of the pre-trained deep language model. Results The models are evaluated on picture description test transcripts of the Pitt corpus, which contains data of 170 AD patients with 257 interviews and 99 healthy controls with 243 interviews. The large bidirectional encoder representations from transformers (BERT Large ) embedding with logistic regression classifier achieves classification accuracy of 88.08%, which improves the state-of-the-art by 2.48%. Conclusions Using pre-trained language models can improve AD prediction. This not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features.",
        "references": [
            "a7425f74a9e7bdd3ae6763c515c9534fb18a3560",
            "73ee478f44296ee9a9e810fa106462ca52ece708",
            "9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "4d4117e4e5214dcc887317e302db724df545729e",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "8cd1d603498e65ae19baa59bdb31617f441d4296",
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "bbeae238e2d1373b75ce20ce96b4a5b87383a622",
            "6ca330477a1509b0a5b3d1848564b954bb5e29a4"
        ],
        "related_topics": [
            "Natural Language Processing",
            "Classification Task",
            "Deep Neural Networks",
            "Training Set",
            "Transformer",
            "Pitt Corpus",
            "Classifier",
            "Language Models",
            "Expert-defined Features",
            "Classification Accuracy"
        ],
        "reference_count": "55",
        "citation_count": "50"
    },
    {
        "Id": "b9464b492f6638035d25b42f32ff3d51cb6d1e30",
        "title": "MG-BERT: Multi-Graph Augmented BERT for Masked Language Modeling",
        "authors": [
            "Parishad BehnamGhader",
            "Hossein Zakerinia",
            "Mahdieh Soleymani Baghshah"
        ],
        "date": "1 June 2021",
        "abstract": "Multi-Graph augmented BERT (MG-BERT) model that is based on BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs is proposed. Pre-trained models like Bidirectional Encoder Representations from Transformers (BERT), have recently made a big leap forward in Natural Language Processing (NLP) tasks. However, there are still some shortcomings in the Masked Language Modeling (MLM) task performed by these models. In this paper, we first introduce a multi-graph including different types of relations between words. Then, we propose Multi-Graph augmented BERT (MG-BERT) model that is based on BERT. MG-BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs. The proposed model also employs a dynamic sentence graph to capture local context effectively. Experimental results demonstrate that our model can considerably enhance the performance in the MLM task.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "b36b2914f16c78b1bf88ee720342d893d8a9fc46",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "cd8a9914d50b0ac63315872530274d158d6aff09",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "2cab7f5d64a427cb59fb21112fe8dc28fb753b56",
            "c80fecc35eb0f26bd1e8af02e53234ac830b63ff"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Masked Language Modeling",
            "Natural Language Processing",
            "Tokens",
            "Knowledge Graph",
            "Global Word Co-occurrence",
            "Text Corpus"
        ],
        "reference_count": "29",
        "citation_count": "2"
    },
    {
        "Id": "b9e98f630e8eaf77ddcd0f80d1360b611ae61e70",
        "title": "Deep Learning-Based Proarrhythmia Analysis Using Field Potentials Recorded From Human Pluripotent Stem Cells Derived Cardiomyocytes",
        "authors": [
            "Zeinab Golgooni",
            "Sara Mirsadeghi",
            "Mahdieh Soleymani Baghshah",
            "Pedram Ataee",
            "Hossein Baharvand",
            "Sara Pahlavan",
            "Hamid R. Rabiee"
        ],
        "date": "28 March 2019",
        "abstract": "A novel method for automated analysis of \u201cirregularity\u201d in an in vitro model of cardiotoxicity experiments is introduced, which may overcome the drawbacks of using predesigned features that restricts the classification performance to the comprehensiveness and the quality of the designed features. An early characterization of drug-induced cardiotoxicity may be possible by combining comprehensive in vitro proarrhythmia assay and deep learning techniques. We aimed to develop a method to automatically detect irregular beating rhythm of field potentials recorded from human pluripotent stem cells (hPSC) derived cardiomyocytes (hPSC-CM) by multi-electrode array (MEA) system. We included field potentials from 380 experiments, which were labeled as normal or arrhythmic by electrophysiology experts. Convolutional and recurrent neural networks (CNN and RNN) were employed for automatic classification of field potential recordings. A preparation phase was initially applied to split 60-s long recordings into a series of 5-s windows. Subsequently, the classification phase comprising of two main steps was designed and applied. The first step included the classification of 5-s windows by using a designated CNN. While, the results of 5-s window assessments were used as the input sequence to an RNN that aggregates these results in the second step. The output was then compared to electrophysiologist-level arrhythmia detection, resulting in 0.83 accuracy, 0.93 sensitivity, 0.70 specificity, and 0.80 precision. In summary, this paper introduces a novel method for automated analysis of \u201cirregularity\u201d in an in vitro model of cardiotoxicity experiments. Thus, our method may overcome the drawbacks of using predesigned features that restricts the classification performance to the comprehensiveness and the quality of the designed features. Furthermore, automated analysis may facilitate the quality control experiments through the procedure of drug development with respect to cardiotoxicity and avoid late drug attrition from market.",
        "references": [
            "50afa4fa74b0475ca0264461c79f7bd42fcc494c",
            "307ff8f512098497e2c69b79c00fbb7b3cc9650e",
            "7a373d7dbd44ad99e5287f78b0e168e33498b44d",
            "04232aeef8343cfdf85fe9b5d0164ea186029ed1",
            "e6f337f871168ec891b3f0fc1b060005e8e4de01",
            "4ef11d0b2d5bd02eab3f8113601370fc7183cc30",
            "b2e9ab6f182579d75fa0a61d266252b258e61746",
            "04aecf353a9d854d4ce2b602a6d5920af7f07b2b",
            "89a125d1a89bcd0c18df6810786f92d27ee4e17f",
            "c3abc2d4b3cb86d6e3606f225c671fff3b334c9b"
        ],
        "related_topics": [
            "Recurrent Neural Networks",
            "Convolutional Neural Network",
            "Deep Learning",
            "More Electric Aircraft",
            "Classification",
            "Arrhythmia Detection"
        ],
        "reference_count": "46",
        "citation_count": "7"
    },
    {
        "Id": "1eae26fe1ca566f17468080c3aecab1c3f9efb66",
        "title": "A Deep Learning Framework for Viable Tumor Burden Estimation",
        "authors": [
            "Seyed Alireza Fatemi Jahromi",
            "Ali Asghar Khani",
            "Hatef Otroshi Shahreza",
            "Mahdieh Soleymani Baghshah",
            "Hamid Behroozi"
        ],
        "date": "23 December 2020",
        "abstract": "This paper proposes a deep learning framework for the segmentation of whole and viable tumor areas of liver cancer from whole-slide images (WSIs) using Fast Segmentation Convolutional Neural Network (Fast-SCNN) as the network. Liver masses have become a common clinical challenge since they require to be defined and accurately categorized as neoplastic or nonneoplastic lesions. Hepatocellular carcinoma (HCC), the most common histologic type of primary liver malignancy, is a global health concern being the fifth most common cancer and the second cause of cancer mortality worldwide. Accurate diagnosis, which in some circumstances requires histopathology results, is necessary for appropriate management. Also, some tumor characteristics help in predicting tumor behavior and patient response to therapy. In this paper, we propose a deep learning framework for the segmentation of whole and viable tumor areas of liver cancer from whole-slide images (WSIs). To this end, we use Fast Segmentation Convolutional Neural Network (Fast-SCNN) as our network. We use the dataset from PAIP 2019 challenge. After data-augmentation on the training subset, we train the network with a multi-term loss function and SWA technique. Our model achieves 0.80 for the median of the Jaccard Index for the task of Viable Tumor Segmentation and 0.77 for the median of Weighted Absolute Accuracy for the task of Viable Tumor Burden Estimation on the whole-slide images of the test subset.",
        "references": [
            "d779b87172306c37c2c711512e84bc8112adf21e",
            "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7",
            "769149c0dc0ed308eca8bc916f4326b2e2f57a1f",
            "21ba757bf394720e0b66b86e7638ae28742d6570",
            "f9638ee3738d30c23a5f8f84988aed7120a08fac",
            "6048de9749a1f31ac70e5c30030ceb1dc5d3f2b0",
            "ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
            "188f8f6f70947215a9dfeebb0b577155e0d3d339",
            "ae1c89817a3a239e5344293138bdd80293983460",
            "57a892b9576baeba70277179712d5b09e19224b9"
        ],
        "related_topics": [],
        "reference_count": "62",
        "citation_count": "3"
    },
    {
        "Id": "5a5f7d39433d68059e513b947a9fde62b5d4d3fe",
        "title": "An attribute learning method for zero-shot recognition",
        "authors": [
            "Ramtin Yazdanian",
            "Seyed Mohsen Shojaee",
            "Mahdieh Soleymani Baghshah"
        ],
        "date": "1 May 2017",
        "abstract": "Experimental results show that the learned attributes by the proposed attribute learning method can improve the accuracy of the state-of-the-art zero-shot learning methods. Recently, the problem of integrating side information about classes has emerged in the learning settings like zero-shot learning. Although using multiple sources of information about the input space has been investigated in the last decade and many multi-view and multi-modal learning methods have already been introduced, the attribute learning for classes (output space) is a new problem that has been attended in the last few years. In this paper, we propose an attribute learning method that can use different sources of descriptions for classes to find new attributes that are more proper to be used as class signatures. Experimental results show that the learned attributes by the proposed method can improve the accuracy of the state-of-the-art zero-shot learning methods.",
        "references": [
            "5fd80e47d53c64512a0b85a4c7a0beb24bc35766",
            "a6b8cd5f34b438f487679b1166ea03e56eb14c9e",
            "b29227f8dde62a5cd21678b4bc429206615485a2",
            "846946cd21413211a4701f309c3927d67363cd30",
            "ac98259064e86f643f2cd11e5417b43bf28daa91",
            "caa632d101a41a7860562e4399a5eaa9a4088b55",
            "755e9f43ce398ae8737366720c5f82685b0c253e",
            "244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa",
            "018e730f8947173e1140210d4d1760d05c9d3854",
            "cb461276fad5710d8a7e2868867a9b01df040119"
        ],
        "related_topics": [
            "Attributes Learning",
            "Zero-Shot Learning",
            "Side Information",
            "Zero-shot Learning Methods",
            "Input Space",
            "Zero-shot Recognition"
        ],
        "reference_count": "0",
        "citation_count": "29"
    },
    {
        "Id": "623c9b5574306cb58c9ec20332726c0242bb8667",
        "title": "A Transfer Learning Method for Detecting Alzheimer's Disease Based on Speech and Natural Language Processing",
        "authors": [
            "Ning-hong Liu",
            "Kexue Luo",
            "Zhenming Yuan",
            "Yan Chen"
        ],
        "date": "13 April 2022",
        "abstract": "The transfer learning method in this study improves AD prediction, which does not only reduces the need for feature engineering but also addresses the lack of sufficiently large datasets. Alzheimer's disease (AD) is a neurodegenerative disease that is difficult to be detected using convenient and reliable methods. The language change in patients with AD is an important signal of their cognitive status, which potentially helps in early diagnosis. In this study, we developed a transfer learning model based on speech and natural language processing (NLP) technology for the early diagnosis of AD. The lack of large datasets limits the use of complex neural network models without feature engineering, while transfer learning can effectively solve this problem. The transfer learning model is firstly pre-trained on large text datasets to get the pre-trained language model, and then, based on such a model, an AD classification model is performed on small training sets. Concretely, a distilled bidirectional encoder representation (distilBert) embedding, combined with a logistic regression classifier, is used to distinguish AD from normal controls. The model experiment was evaluated on Alzheimer's dementia recognition through spontaneous speech datasets in 2020, including the balanced 78 healthy controls (HC) and 78 patients with AD. The accuracy of the proposed model is 0.88, which is almost equivalent to the champion score in the challenge and a considerable improvement over the baseline of 75% established by organizers of the challenge. As a result, the transfer learning method in this study improves AD prediction, which does not only reduces the need for feature engineering but also addresses the lack of sufficiently large datasets.",
        "references": [
            "b3537407b00c76103ac21bb7cd0ce7047dfdf025",
            "76add6b0dcbe4d85e86855d9d99bc91e2d9c9e26",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
            "a67e59ba96d86a0b609b84363dc212f3dfef97dd",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "a7425f74a9e7bdd3ae6763c515c9534fb18a3560",
            "2042cec0e9d1883f6c1c55c021b20da45effed11",
            "37b87993a3681f83810e8a412a20e4c233f1f228",
            "134d608f4e78da82c9c3c119f57cbde32e220f5e"
        ],
        "related_topics": [],
        "reference_count": "50",
        "citation_count": "11"
    },
    {
        "Id": "eec962309a9b3bbae2740045820a8df0f8cad13c",
        "title": "Improving Alzheimer's Disease Detection for Speech Based on Feature Purification Network",
        "authors": [
            "Ning-hong Liu",
            "Zhenming Yuan",
            "Qingfeng Tang"
        ],
        "date": "3 March 2022",
        "abstract": "This study proposes a novel feature purification network that can improve the representation learning of transformer model further and applies it to improve transformer's performance on three public dementia datasets and gets improved classification results markedly. Alzheimer's disease (AD) is a neurodegenerative disease involving the decline of cognitive ability with illness progresses. At present, the diagnosis of AD mainly depends on the interviews between patients and doctors, which is slow, expensive, and subjective, so it is not a better solution to recognize AD using the currently available neuropsychological examinations and clinical diagnostic criteria. A recent study has indicated the potential of language analysis for AD diagnosis. In this study, we proposed a novel feature purification network that can improve the representation learning of transformer model further. Though transformer has made great progress in generating discriminative features because of its long-distance reasoning ability, there is still room for improvement. There exist many common features that are not indicative of any specific class, and we rule out the influence of common features from traditional features extracted by transformer encoder and can get more discriminative features for classification. We apply this method to improve transformer's performance on three public dementia datasets and get improved classification results markedly. Specifically, the method on Pitt datasets gets state-of-the-art (SOTA) result.",
        "references": [
            "a67e59ba96d86a0b609b84363dc212f3dfef97dd",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "494d1214ad408719bd5e267cf6a4dad163af4121",
            "6350a7fb5b32f6d7e32047a3ad7ff30a746789eb",
            "3f6989f605e650e14bae236568768172f4037382",
            "a7425f74a9e7bdd3ae6763c515c9534fb18a3560",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8",
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "d24d3b28c48d1049395a7dc4e05cd00db87f32ea"
        ],
        "related_topics": [],
        "reference_count": "55",
        "citation_count": "5"
    },
    {
        "Id": "b5fdd83f8235655c41c784769197e2b25598fcca",
        "title": "GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models",
        "authors": [
            "Changye Li",
            "David S. Knopman",
            "Weizhe Xu",
            "Trevor A. Cohen",
            "Serguei V. S. Pakhomov"
        ],
        "date": "25 March 2022",
        "abstract": "A novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (G PT-D), to compute the ratio between these two models\u2019 perplexities on language from cognitively healthy and impaired individuals is proposed. Deep learning (DL) techniques involving fine-tuning large numbers of model parameters have delivered impressive performance on the task of discriminating between language produced by cognitively healthy individuals, and those with Alzheimer\u2019s disease (AD). However, questions remain about their ability to generalize beyond the small reference sets that are publicly available for research. As an alternative to fitting model parameters directly, we propose a novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (GPT-D), to compute the ratio between these two models\u2019 perplexities on language from cognitively healthy and impaired individuals. This technique approaches state-of-the-art performance on text data from a widely used \u201cCookie Theft\u201d picture description task, and unlike established alternatives also generalizes well to spontaneous conversations. Furthermore, GPT-D generates text with characteristics known to be associated with AD, demonstrating the induction of dementia-related linguistic anomalies. Our study is a step toward better understanding of the relationships between the inner workings of generative neural language models, the language that they produce, and the deleterious effects of dementia on human speech and language characteristics.",
        "references": [
            "00c5abdffe51ab33e745e6804d4821ca59db52d8",
            "493c66214eb6ff66040538192bdad398e6cf1a50",
            "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "068a3d62f1d3eaaaba03df23912db89b5adeb41c",
            "d1511472de8df3ac57290aa501dbd72ec087e3ae",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "508884a136a461869be128027950d2aa1778518c",
            "5671c7890b7bfa329b161144661126aa0bcc6480",
            "5b6d03ed66473599ee31872b3cd5ad2ce282371f"
        ],
        "related_topics": [
            "Generalize",
            "Linguistic Anomalies",
            "Perplexity",
            "Deep Learning",
            "Cookie Theft",
            "Fine-tuning",
            "GPT-2"
        ],
        "reference_count": "49",
        "citation_count": "10"
    },
    {
        "Id": "915a55642ba2930061f625b86fee7daa362769cf",
        "title": "Data Augmentation for Dementia Detection in Spoken Language",
        "authors": [
            "Anna Hl&#x27;edikov&#x27;a",
            "Dominika Woszczyk",
            "Alican Acman",
            "Soteris Demetriou",
            "Bj{\\&quot;o}rn Schuller"
        ],
        "date": "26 June 2022",
        "abstract": "It is shown that data augmentation improves performance for both the text- and audio-based models and that such results are comparable to state-of-the-art results on the popular ADReSS set, with carefully crafted architectures and features. Dementia is a growing problem as our society ages, and detection methods are often invasive and expensive. Recent deep-learning techniques can offer a faster diagnosis and have shown promising results. However, they require large amounts of labelled data which is not easily available for the task of dementia detection. One effective solution to sparse data problems is data augmentation, though the exact methods need to be selected carefully. To date, there has been no empirical study of data augmentation on Alzheimer's disease (AD) datasets for NLP and speech processing. In this work, we investigate data augmentation techniques for the task of AD detection and perform an empirical evaluation of the different approaches on two kinds of models for both the text and audio domains. We use a transformer-based model for both domains, and SVM and Random Forest models for the text and audio domains, respectively. We generate additional samples using traditional as well as deep learning based methods and show that data augmentation improves performance for both the text- and audio-based models and that such results are comparable to state-of-the-art results on the popular ADReSS set, with carefully crafted architectures and features.",
        "references": [
            "2042cec0e9d1883f6c1c55c021b20da45effed11",
            "0932bef7467fdd06f6e22ad2562f1cf377be0e5e",
            "e59be08b66dddf32092aa0c71400443c46d47c59",
            "0d678b625e12a4f09e859aa100e66a39531f7c80",
            "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
            "d1511472de8df3ac57290aa501dbd72ec087e3ae",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "ddb3481ebfb2ceb60fbc8341771568ee343692c0",
            "00c5abdffe51ab33e745e6804d4821ca59db52d8",
            "93bdefc9d8feccdef5ff1396fd3c117968899794"
        ],
        "related_topics": [
            "Audio Domain",
            "Natural Language Processing",
            "Deep Learning",
            "Support Vector Machines",
            "State-of-the-art Results",
            "Random Forests",
            "Labelled Data",
            "Dementia Detection",
            "Architecture"
        ],
        "reference_count": "34",
        "citation_count": "4"
    },
    {
        "Id": "72b3390486d9b9e4f520e158eae290219d68fc16",
        "title": "Deep learning-based speech analysis for Alzheimer\u2019s disease detection: a literature review",
        "authors": [
            "Qin Yang",
            "Xin Li",
            "Xinyun Ding",
            "Feiyang Xu",
            "Zhenhua Ling"
        ],
        "date": "14 December 2022",
        "abstract": "The mainstreams and limitations in the current studies of deep learning-based speech analysis and language processing techniques for Alzheimer's disease detection are pointed out and a direction for future research is provided. Background Alzheimer\u2019s disease has become one of the most common neurodegenerative diseases worldwide, which seriously affects the health of the elderly. Early detection and intervention are the most effective prevention methods currently. Compared with traditional detection methods such as traditional scale tests, electroencephalograms, and magnetic resonance imaging, speech analysis is more convenient for automatic large-scale Alzheimer\u2019s disease detection and has attracted extensive attention from researchers. In particular, deep learning-based speech analysis and language processing techniques for Alzheimer\u2019s disease detection have been studied and achieved impressive results. Methods To integrate the latest research progresses, hundreds of relevant papers from ACM, DBLP, IEEE, PubMed, Scopus, Web of Science electronic databases, and other sources were retrieved. We used these keywords for paper search: (Alzheimer OR dementia OR cognitive impairment) AND (speech OR voice OR audio) AND (deep learning OR neural network). Conclusions Fifty-two papers were finally retained after screening. We reviewed and presented the speech databases, deep learning methods, and model performances of these studies. In the end, we pointed out the mainstreams and limitations in the current studies and provided a direction for future research.",
        "references": [
            "0509758ffb8448aa367db8f81e961e9dbd932918",
            "cc2e10b0a706f22bc0117709f99949459fca19d1",
            "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
            "45244b8cc907a7b0656db6c3e4c938c3a6904e17",
            "0932bef7467fdd06f6e22ad2562f1cf377be0e5e",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
            "5442efa8c8f98e69da5e9894eb2281c449c294b1",
            "5b63aef5d7e53b83ebb82a5166a2b4ce34e72ddb",
            "2042cec0e9d1883f6c1c55c021b20da45effed11"
        ],
        "related_topics": [],
        "reference_count": "93",
        "citation_count": "9"
    },
    {
        "Id": "0590ec99d2b36b8922139078ac1a91fd62eeda61",
        "title": "Exploring Multimodal Approaches for Alzheimer's Disease Detection Using Patient Speech Transcript and Audio Data",
        "authors": [
            "Hongmin Cai",
            "Xiaoke Huang",
            "Zheng Liu",
            "Wenxiong Liao",
            "Haixing Dai",
            "Zihao Wu",
            "Dajiang Zhu",
            "Hui Ren",
            "Quanzheng Li",
            "Tianming Liu",
            "Xiang Li"
        ],
        "date": "5 July 2023",
        "abstract": "This study investigates various methods for detecting AD using patients' speech and transcripts data from the DementiaBank Pitt database using pre-trained language models and Graph Neural Network (GNN) that constructs a graph from the speech transcript, and extracts features using GNN for AD detection. Alzheimer's disease (AD) is a common form of dementia that severely impacts patient health. As AD impairs the patient's language understanding and expression ability, the speech of AD patients can serve as an indicator of this disease. This study investigates various methods for detecting AD using patients' speech and transcripts data from the DementiaBank Pitt database. The proposed approach involves pre-trained language models and Graph Neural Network (GNN) that constructs a graph from the speech transcript, and extracts features using GNN for AD detection. Data augmentation techniques, including synonym replacement, GPT-based augmenter, and so on, were used to address the small dataset size. Audio data was also introduced, and WavLM model was used to extract audio features. These features were then fused with text features using various methods. Finally, a contrastive learning approach was attempted by converting speech transcripts back to audio and using it for contrastive learning with the original audio. We conducted intensive experiments and analysis on the above methods. Our findings shed light on the challenges and potential solutions in AD detection using speech and audio data.",
        "references": [
            "623c9b5574306cb58c9ec20332726c0242bb8667",
            "37b87993a3681f83810e8a412a20e4c233f1f228",
            "664b507618929d9da1d7f4c30e4f849e765102eb",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "8bf3d85e625b591e517b96177ed7ac5983267a88",
            "28ec4da8fa83ceb95c3d557712a585ce286874fc",
            "ddb3481ebfb2ceb60fbc8341771568ee343692c0",
            "1067c44e473b6998f89e13f0d4c0de730def43f0",
            "1cbd65718ab7adf47ec372ed2e02a3409791218c",
            "416dab850fda842b13a4f28164514d98f836fff7"
        ],
        "related_topics": [
            "Graph Neural Network",
            "Contrastive Learning",
            "Language Understanding",
            "WavLM Models",
            "Synonym Replacement"
        ],
        "reference_count": "38",
        "citation_count": "6"
    },
    {
        "Id": "9358d9e9afbc1eaf6b2f2042a8adc573556f566e",
        "title": "Comparative study of Deep Classifiers for Early Dementia Detection using Speech Transcripts",
        "authors": [
            "Anjana S. Nambiar",
            "Kanigolla Likhita",
            "K. V. S. Sri Pujya",
            "Deepa Gupta",
            "Susmitha Vekkot",
            "S. Lalitha"
        ],
        "date": "24 November 2022",
        "abstract": "This paper aims to detect early signs of dementia in patients using English speech transcript files using considerable deep learning and natural language processing techniques like GloVe, Word 2Vec, Doc2Vec word embeddings and LSTM, BiLSTM and GRU, BERT, RoBERTa and ALBERT. The applications of artificial intelligence are increasing day by day. The world is transformed by AI technologies like automated systematic processes and virtual assistance. Dementia is a disorder that causes disintegration in the mental capacity of an individual. This is not a disease but a group of symptoms caused by various other conditions and is common in older people. Detecting dementia in the early stages will reduce complications and provide access to medical attention and medications. Dementia is detected in patients by examining their ability to think, communicate and their physical movements. This is done by performing numerous physical and mental status exams. This paper aims to detect early signs of dementia in patients using English speech transcript files. The proposed models employ considerable deep learning and natural language processing techniques like GloVe, Word2Vec, Doc2Vec word embeddings and LSTM, BiLSTM, GRU, BERT, RoBERTa and ALBERT. The models were trained using the Pitt Corpus from the DementiaBank dataset. The best accuracy obtained was 0.812 using the BERT+BilSTM model, and the best F1 score obtained was 0.81 by the ALBERT+BiLSTM model.",
        "references": [
            "5b63aef5d7e53b83ebb82a5166a2b4ce34e72ddb",
            "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
            "f2a93c2ecdfc2d6407feda6d848f1194e18697ae",
            "acacb4176fa29ebd4ba328af8cf0b960375725fe",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "f214e1faf9f4172efd46c9bec3b2a90029c0564c",
            "5671c7890b7bfa329b161144661126aa0bcc6480",
            "2fa837dc96f0af98100497b4106a5b2e6d2091d6"
        ],
        "related_topics": [],
        "reference_count": "23",
        "citation_count": "2"
    },
    {
        "Id": "bb583b71b6a7f09a41e5a2840c16fae0dff325e7",
        "title": "Learning implicit sentiments in Alzheimer's disease recognition with contextual attention features",
        "authors": [
            "Ning-hong Liu",
            "Zhenming Yuan",
            "Yan Chen",
            "Chuang Liu",
            "Lingxing Wang"
        ],
        "date": "17 May 2023",
        "abstract": "The proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts. Background Alzheimer's disease (AD) is difficult to diagnose on the basis of language because of the implicit emotion of transcripts, which is defined as a supervised fuzzy implicit emotion classification at the document level. Recent neural network-based approaches have not paid attention to the implicit sentiments entailed in AD transcripts. Method A two-level attention mechanism is proposed to detect deep semantic information toward words and sentences, which enables it to attend to more words and fewer sentences differentially when constructing document representation. Specifically, a document vector was built by progressively aggregating important words into sentence vectors and important sentences into document vectors. Results Experimental results showed that our method achieved the best accuracy of 91.6% on annotated public Pitt corpora, which validates its effectiveness in learning implicit sentiment representation for our model. Conclusion The proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts.",
        "references": [
            "ca352ea6ac66c03a0cc22759098713e4202c71c6",
            "d24d3b28c48d1049395a7dc4e05cd00db87f32ea",
            "3d28cb8c175323409ab302780a55382a3cf5c2c9",
            "beccf5bc709167e483e8ea0f58829c34a2bde2e7",
            "4e4136382ddab4b5b357dd8c9c81789d930065fb",
            "bbeae238e2d1373b75ce20ce96b4a5b87383a622",
            "8e3a3ba309fe68f5b1d02266a03395332f7d945c",
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "623c9b5574306cb58c9ec20332726c0242bb8667",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323"
        ],
        "related_topics": [],
        "reference_count": "67",
        "citation_count": "2"
    },
    {
        "Id": "4884e4edb5268c065cbc191a65eadde172d66bbf",
        "title": "OViTAD: Optimized Vision Transformer to Predict Various Stages of Alzheimer\u2019s Disease Using Resting-State fMRI and Structural MRI Data",
        "authors": [
            "Saman Sarraf",
            "Arman Sarraf",
            "Danielle D. DeSouza",
            "John S. Anderson",
            "Milton Kabia"
        ],
        "date": "27 November 2021",
        "abstract": "This study introduced an optimized vision transformer architecture to predict the group membership by separating healthy adults, mild cognitive impairment, and Alzheimer\u2019s\u2019 brains within the same age group using resting-state functional and structural magnetic resonance imaging data. Advances in applied machine learning techniques for neuroimaging have encouraged scientists to implement models to diagnose brain disorders such as Alzheimer\u2019s disease at early stages. Predicting the exact stage of Alzheimer\u2019s disease is challenging; however, complex deep learning techniques can manage this with precision. While successful, these complex architectures are difficult to interrogate and computationally expensive. Therefore, using novel, simpler architectures with more efficient pattern extraction capabilities, such as transformers, is of interest to neuroscientists. This study introduced an optimized vision transformer architecture to predict the group membership by separating healthy adults, mild cognitive impairment, and Alzheimer\u2019s\u2019 brains within the same age group (>75 years) using resting-state functional (rs-fMRI) and structural magnetic resonance imaging (sMRI) data. Our optimized architecture known as OViTAD is currently the sole vision transformer-based end-to-end pipeline and outperformed the existing transformer models and most state-of-the-art solutions. Our model achieved F1-scores of 97%\u00b10.0 and 99.55%\u00b10.39 from the testing sets for the rs-fMRI and sMRI modalities in the triple-class prediction experiments. Furthermore, our model reached these performances using 30% fewer parameters than a vanilla transformer. The model was robust and repeatable, producing similar estimates across three runs (we reported the averaged evaluation metrics). Finally, to challenge the model, we observed how it handled increasing noise levels by inserting varying numbers of healthy brains into the two dementia groups. Our findings suggest that optimized vision transformers are a promising and exciting new approach for neuroimaging applications, especially for Alzheimer\u2019s disease prediction.",
        "references": [
            "bb95ef99ae56f6b1087d6a3aec6ba18b766b237a",
            "76a54893e1d51c9ed2fe3e3d3455065ef8ac6957",
            "5a58e76821a6493e68945a381c36fa676b085cbe",
            "a9e3128aed75ae08137ce7f3568a79bbb0bdee60",
            "49aa918d596bbca54af39b7974fc1de2d2410edc",
            "5473fa1f52bc0e82c5e0cc3c24e65e9930f00977",
            "eaf35385d79ef18dc22291ed3fecd8547dd91165",
            "677a3d0fc891cd0b281b24e89592400d6e630141",
            "b80fc284e0497d0015bbd1cc8bd0bea7fa4ad704",
            "d80a79d254243b6a0ac7518895804354c3125780"
        ],
        "related_topics": [],
        "reference_count": "116",
        "citation_count": "12"
    },
    {
        "Id": "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
        "title": "Deep Learning-Based Diagnosis of Alzheimer\u2019s Disease",
        "authors": [
            "Tausifa Jan Saleem",
            "Syed Rameem Zahra",
            "Fan Wu",
            "Ahmed M. Alwakeel",
            "Mohammed M. Alwakeel",
            "Fathe Jeribi",
            "Mohammad Hijji"
        ],
        "date": "1 May 2022",
        "abstract": "The current state-of-the-art in AD diagnosis using deep learning is reviewed, including the most recent trends and findings using a thorough literature review. Alzheimer\u2019s disease (AD), the most familiar type of dementia, is a severe concern in modern healthcare. Around 5.5 million people aged 65 and above have AD, and it is the sixth leading cause of mortality in the US. AD is an irreversible, degenerative brain disorder characterized by a loss of cognitive function and has no proven cure. Deep learning techniques have gained popularity in recent years, particularly in the domains of natural language processing and computer vision. Since 2014, these techniques have begun to achieve substantial consideration in AD diagnosis research, and the number of papers published in this arena is rising drastically. Deep learning techniques have been reported to be more accurate for AD diagnosis in comparison to conventional machine learning models. Motivated to explore the potential of deep learning in AD diagnosis, this study reviews the current state-of-the-art in AD diagnosis using deep learning. We summarize the most recent trends and findings using a thorough literature review. The study also explores the different biomarkers and datasets for AD diagnosis. Even though deep learning has shown promise in AD diagnosis, there are still several challenges that need to be addressed.",
        "references": [
            "3539f67ba7f9025e2695709814aef4864843473b",
            "dba5eb1ddceae62c4901ca9f804753a2bb93f959",
            "6390feb4793cdbccd96ce7245e25cef955e5f659",
            "7af1d268967d225601f56a7815a2a94da6e34d52",
            "f56f5e516f71822b085591f59020f3cf373f654c",
            "3a3255f0a10596bdf2d38e404ef5f4e0e560690b",
            "59ab74aa3c97cb41576c83da5a94ddda96603b3d",
            "4739e3fe607a8f3ab19e68aaf6eec710515e2ad2",
            "63e13545e992830c08737ad77831376af298dbe4",
            "f90e37dc39cbdf49cd44b41071fb5a4cdd07ad14"
        ],
        "related_topics": [],
        "reference_count": "100",
        "citation_count": "29"
    },
    {
        "Id": "44a422a2514c1cd6828423b5edce53d0dbdabd73",
        "title": "Structure-inducing pre-training",
        "authors": [
            "Matthew B. A. McDermott",
            "Brendan Yap",
            "Peter Szolovits",
            "Marinka Zitnik"
        ],
        "date": "18 March 2021",
        "abstract": "A pre-training framework is introduced that enables a granular and comprehensive understanding of how relational structure can be induced, and empirically demonstrates its advantages by showing that it outperforms existing pre- training state-of-the-art methods. Language model pre-training and the derived general-purpose methods have reshaped machine learning research. However, there remains considerable uncertainty regarding why pre-training improves the performance of downstream tasks. This challenge is pronounced when using language model pre-training in domains outside of natural language. Here we investigate this problem by analysing how pre-training methods impose relational structure in induced per-sample latent spaces\u2014that is, what constraints do pre-training methods impose on the distance or geometry between the pre-trained embeddings of samples. A comprehensive review of pre-training methods reveals that this question remains open, despite theoretical analyses showing the importance of understanding this form of induced structure. Based on this review, we introduce a pre-training framework that enables a granular and comprehensive understanding of how relational structure can be induced. We present a theoretical analysis of the framework from the first principles and establish a connection between the relational inductive bias of pre-training and fine-tuning performance. Empirical studies spanning three data modalities and ten fine-tuning tasks confirm theoretical analyses, inform the design of novel pre-training methods and establish consistent improvements over a compelling suite of methods. Designing methods to induce explicit and deep structural constraints in latent space at the sample level is an open problem in natural language processing-derived methods relying on transfer learning. McDermott and colleagues propose and analyse a pre-training framework imposing such structural constraints, and empirically demonstrate its advantages by showing that it outperforms existing pre-training state-of-the-art methods.",
        "references": [
            "d56c1fc337fb07ec004dc846f80582c327af717c",
            "9ba6ad0de7dbe1a3b10c44106049adb96f87d483",
            "789a7069d1a2d02d784e4821685b216cc63e6ec8",
            "96c22a88ec3b9d3799daa41098555ab665c24ea8",
            "abaadb4c6affc4d874c4f59bfac60686e851cb5e",
            "0fc66c750d06da8dc47e7a3ae9f24af9ff3d6617",
            "319b84be7a843250bc81d7086f79a4126d550277",
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "7eda139d737eea10fc1d95364327a41ec0cee4a4"
        ],
        "related_topics": [
            "Pre-training",
            "Pre-training Methods",
            "Geometry",
            "Machine Learning",
            "Fine-tuning Performance"
        ],
        "reference_count": "159",
        "citation_count": "8"
    },
    {
        "Id": "24520e6560c45bf24f75b8dbaf07b157a8807faf",
        "title": "Structure Inducing Pre-Training",
        "authors": [
            "Matthew B. A. McDermott"
        ],
        "date": "2021",
        "abstract": "A descriptive framework for pre-training that illustrates how relational structure can be induced is introduced and demonstrates the utility of this framework through theoretical and empirical analyses showing that this approach can offer meaningful improvements over existing methods across various domains and tasks. Language model pre-training (LMPT) has been incredibly impactful in natural language processing; however, LMPT methods have not been as successful when generalized to other domains, such as biomedical domains. To understand this disparity, we first ask what properties of natural language make language modeling so successful and whether or not these hold in other domains. Next, we ask to what extent existing pre-training methods are explicitly designed to account for these discrepancies. We find that the question of how existing pre-training methods impose relational structure in their induced, per-sample latent spaces\u2014 i.e. , what constraints do pre-training methods impose on the distance between the pre-trained embeddings of x i and x j \u2014is both significantly understudied and important for LMPT performance in non-NLP domains. To address this, we introduce a descriptive framework for pre-training that illustrates how relational structure can be induced. We demonstrate the utility of this framework through theoretical and empirical analyses showing that this approach can offer meaningful improvements over existing methods across various domains and tasks.",
        "references": [
            "d56c1fc337fb07ec004dc846f80582c327af717c",
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "abaadb4c6affc4d874c4f59bfac60686e851cb5e",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "319b84be7a843250bc81d7086f79a4126d550277",
            "a2412fdebd53bd25476f834ae2b8aa8cb44cb1e1",
            "9ba6ad0de7dbe1a3b10c44106049adb96f87d483",
            "789a7069d1a2d02d784e4821685b216cc63e6ec8",
            "018987cad9845a37cd0e6f1d78596041c911d4f5",
            "a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "190"
    },
    {
        "Id": "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
        "title": "ERNIE: Enhanced Language Representation with Informative Entities",
        "authors": [
            "Zhengyan Zhang",
            "Xu Han",
            "Zhiyuan Liu",
            "Xin Jiang",
            "Maosong Sun",
            "Qun Liu"
        ],
        "date": "17 May 2019",
        "abstract": "This paper utilizes both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE) which can take full advantage of lexical, syntactic, and knowledge information simultaneously, and is comparable with the state-of-the-art model BERT on other common NLP tasks. Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.",
        "references": [
            "3b1d8eb163ffff598c2faa0d9d7cf933857a359f",
            "083b9fd0f36528eb7ca35786ba5fb0149adc7727",
            "031e4e43aaffd7a479738dcea69a2d5be7957aa3",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
            "5aadc803228b70c3cc6b31e332770d47d7fb1e6e",
            "400e746bc8027c4b5f915cae6123cd1775484b4d",
            "345ef9a7d9af0ac0816d76803ddcf9b6d19404d7",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992"
        ],
        "related_topics": [
            "Enhanced Language Representation With Informative Entity",
            "Large-scale Textual Corpora",
            "Knowledge Information",
            "Knowledge-driven Tasks",
            "Informative Entities",
            "Knowledge Masking Strategies",
            "T-Encoder",
            "Entity Sequence",
            "Open Entity",
            "Entity Typing"
        ],
        "reference_count": "59",
        "citation_count": "1,087"
    },
    {
        "Id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "authors": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "date": "2019",
        "abstract": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks. We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
        "references": [
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "ac11062f1f368d97f4c826c317bf50dcc13fdb59",
            "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e",
            "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
            "b9de9599d7241459db9213b5cdd7059696f5ef8d",
            "8c1b00128e74f1cd92aede3959690615695d5101",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d",
            "421fc2556836a6b441de806d7b393a35b6eaea58"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Language Representation Model",
            "Deep Bidirectional Transformers",
            "Pre-training",
            "Unlabeled Text",
            "Token-level Tasks",
            "Deep Bidirectional Representations",
            "Paraphrasing",
            "Sentence-level Tasks",
            "Question Answering"
        ],
        "reference_count": "63",
        "citation_count": "67,630"
    },
    {
        "Id": "31184789ef4c3084af930b1e0dede3215b4a9240",
        "title": "KG-BERT: BERT for Knowledge Graph Completion",
        "authors": [
            "Liang Yao",
            "Chengsheng Mao",
            "Yuan Luo"
        ],
        "date": "7 September 2019",
        "abstract": "This work treats triples in knowledge graphs as textual sequences and proposes a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.",
        "references": [
            "cd8a9914d50b0ac63315872530274d158d6aff09",
            "96acb1c882ad655c6b8459c2cd331803801446ca",
            "cab46caf83a9e0390c6ca4d8603187969c9a53ad",
            "bd345877856dc83c2c10c125dbf0f41e2bde38b1",
            "e379f7c85441df5d8ddc1565cabf4b4290c22f1f",
            "17a1e5d78bffb17979ac55aa792698727fe25a21",
            "3ce14b7a3c1b89c717eba10229d9d80d80bd0e04",
            "aa1b05e8449eb5ee93b114453d9c946ae00459b1",
            "67cab3bafc8fa9e1ae3ff89791ad43c81441d271",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde"
        ],
        "related_topics": [
            "KG-BERT",
            "Knowledge Graph Completion",
            "Triple Classification",
            "Entity Descriptions",
            "KG Completion Tasks",
            "Relation Descriptions",
            "FB15k-237",
            "WN18RR",
            "Head Entity",
            "ConvE"
        ],
        "reference_count": "44",
        "citation_count": "361"
    },
    {
        "Id": "96901acc92d68350443774596fa2b38bc522a0ce",
        "title": "Barack\u2019s Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling",
        "authors": [
            "IV RobertL.Logan",
            "Nelson F. Liu",
            "Matthew E. Peters",
            "Matt Gardner",
            "Sameer Singh"
        ],
        "date": "17 June 2019",
        "abstract": "This work introduces the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context that enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model\u2019s ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.",
        "references": [
            "58c6f890a1ae372958b7decf56132fe258152722",
            "9c81f16df774c772dbefc947fe0e467b72500844",
            "0fa5142f908afc94c923ca2adbe14a5673bc76eb",
            "dab7e605237ad4f4fe56dcba2861b8f0a57112be",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "13395213d47f78672ab4e81573f2b0fa0cfc8c6d",
            "efbd381493bb9636f489b965a2034d529cd56bcd",
            "604764133befe7a0aaa692919545846197e6e065",
            "dec8fe49a9336149e1268a332ce4ab9ecea7841b"
        ],
        "related_topics": [
            "Factual Knowledge",
            "Knowledge Graph",
            "Neural Language Models",
            "Large Language Models"
        ],
        "reference_count": "29",
        "citation_count": "158"
    },
    {
        "Id": "b36b2914f16c78b1bf88ee720342d893d8a9fc46",
        "title": "Learning beyond Datasets: Knowledge Graph Augmented Neural Networks for Natural Language Processing",
        "authors": [
            "K. M. Annervaz",
            "Somnath Basu Roy Chowdhury",
            "Ambedkar Dukkipati"
        ],
        "date": "16 February 2018",
        "abstract": "This work proposes to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks by introducing a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. Machine Learning has been the quintessential solution for many AI problems, but learning models are heavily dependent on specific training data. Some learning models can be incorporated with prior knowledge using a Bayesian setup, but these learning models do not have the ability to access any organized world knowledge on demand. In this work, we propose to enhance learning models with world knowledge in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks. Our aim is to develop a deep learning model that can extract relevant prior support facts from knowledge graphs depending on the task using attention mechanism. We introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task. Using this method we show significant improvement in performance for text classification with 20Newsgroups (News20) & DBPedia datasets, and natural language inference with Stanford Natural Language Inference (SNLI) dataset. We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a knowledge base.",
        "references": [
            "96acb1c882ad655c6b8459c2cd331803801446ca",
            "e3274206b36a603abc4a335af91273ecba5e73cc",
            "6fba4968f1b39d490bf95fe4030e3d385f167074",
            "033f25ad905ef2ed32a8331cf38b83953ff15922",
            "50d53cc562225549457cbc782546bfbe1ac6f0cf",
            "79baf8cf6be6510f69be8c515516136138678cf5",
            "d77de3a4ddfa62f8105c0591fd41e549edcfd95f",
            "18bd7cd489874ed9976b4f87a6a558f9533316e0",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "955fe2ee26d888ae22749b0853981b8b581b133d"
        ],
        "related_topics": [
            "Knowledge Graph",
            "Natural Language Processing",
            "Stanford Natural Language Inference",
            "Relation Clusters",
            "Text Classification",
            "Deep Learning",
            "News20",
            "Augmented Neural Networks",
            "Machine Learning",
            "Natural Language Inference"
        ],
        "reference_count": "40",
        "citation_count": "61"
    },
    {
        "Id": "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
        "title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation",
        "authors": [
            "Xiaozhi Wang",
            "Tianyu Gao",
            "Zhaocheng Zhu",
            "Zhiyuan Liu",
            "Juan-Zi Li",
            "Jian Tang"
        ],
        "date": "13 November 2019",
        "abstract": "A unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs is proposed. Abstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "06a73ad09664435f8b3cd90293f4e05a047cf375",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "96acb1c882ad655c6b8459c2cd331803801446ca",
            "f0efb4f8e1e5957bb252d9d530202b1cef9b0494",
            "70af3ee98c53441d9090119f7b76efb1b6d03edd",
            "6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "994afdf0db0cb0456f4f76468380822c2f532726",
            "f7b0d94fd4a32c4c9be472b4e8d6c5bc308f0dfa"
        ],
        "related_topics": [
            "Wikidata5m",
            "Knowledge Embedding",
            "Kepler",
            "Knowledge-enhanced PLM",
            "Factual Knowledge",
            "Entity Typing",
            "Entity Descriptions",
            "OpenEntity",
            "Entity Linker",
            "Enhanced Language Representation With Informative Entity"
        ],
        "reference_count": "75",
        "citation_count": "420"
    },
    {
        "Id": "cd8a9914d50b0ac63315872530274d158d6aff09",
        "title": "Modeling Relational Data with Graph Convolutional Networks",
        "authors": [
            "M. Schlichtkrull",
            "Thomas Kipf",
            "Peter Bloem",
            "Rianne van den Berg",
            "Ivan Titov",
            "Max Welling"
        ],
        "date": "17 March 2017",
        "abstract": "It is shown that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline. Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to handle the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline.",
        "references": [
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "822f1ed9a76a57cc19d8fda7745365b97130b97a",
            "af2e6165b68e75c911dfdb8f81f9ab6627722ab7",
            "50d53cc562225549457cbc782546bfbe1ac6f0cf",
            "86412306b777ee35aba71d4795b02915cb8a04c3",
            "1ef01e7bfab2041bc0c0a56a57906964df9fc985",
            "e745b0506f4133263633eb05e5006a8cff4129f0",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "6b7d6e6416343b2a122f8416e69059ce919026ef",
            "97f7ef7a5332218e0e9ce75ad5cf77048466ca83"
        ],
        "related_topics": [
            "R-GCNs",
            "Relational Graph Convolutional Networks",
            "R-GCN Model",
            "AIFB",
            "Basis Decomposition",
            "Graph Convolutional Networks",
            "Entity Classification",
            "Link Prediction",
            "FB15k-237",
            "Multi-relational Data"
        ],
        "reference_count": "54",
        "citation_count": "3,569"
    },
    {
        "Id": "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
        "title": "Translating Embeddings for Modeling Multi-relational Data",
        "authors": [
            "Antoine Bordes",
            "Nicolas Usunier",
            "Alberto Garc{\\&#x27;i}a-Dur{\\&#x27;a}n",
            "Jason Weston",
            "Oksana Yakhnenko"
        ],
        "date": "5 December 2013",
        "abstract": "TransE is proposed, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities, which proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.",
        "references": [
            "04cc04457e09e17897f9256c86b45b92d70a401f",
            "f6764d853a14b0c34df1d2283e76277aead40fde",
            "eb6208f3e2c0942e38ceffc443dcf64d2cb4ec82",
            "834cb8e1e738b8d2c6d24e652ac966d6e7089a46",
            "8007fc25a1f5c03f7c8ac95ccf5cf8aa3d989092",
            "498ca0a1f8c980586408addf7ab2919ecdb7dd3d",
            "1f4a4769e4d2fb846e59c2f185e0377190739f18",
            "fec691d09b564986ad27162ce15344604c840ff9",
            "81bbe42e3ec09c28b8864956148e58f4cb5aa860",
            "4e07791ee0872401215f12aefde342bd843240cc"
        ],
        "related_topics": [
            "Multi-relational Data",
            "TransE",
            "Entities",
            "Corrupted Triplet",
            "Freebase",
            "Hits@10",
            "Structured Embeddings",
            "Correct Entity",
            "Link Prediction",
            "FB15k"
        ],
        "reference_count": "18",
        "citation_count": "6,040"
    },
    {
        "Id": "447afc6231eb05eb43040d1eedcc4ce8fb83dbdb",
        "title": "A deep learning platform to assess drug proarrhythmia risk.",
        "authors": [
            "Ricardo Serrano",
            "D. A. M. Feyen",
            "Arne A.N. Bruyneel",
            "Anna Pavlovna Hnatiuk",
            "Michelle M Vu",
            "Prashila L. Amatya",
            "Isaac Perea-Gil",
            "Maricela Prado",
            "Timon Seeger",
            "Joseph C. Wu",
            "Ioannis Karakikes",
            "Mark Mercola"
        ],
        "date": "1 December 2022",
        "abstract": "Semantic Scholar extracted view of \"A deep learning platform to assess drug proarrhythmia risk.\" by Ricardo Serrano et al.",
        "references": [
            "5dfe5441982721cdc1e208248a07ff9c2a8e5077",
            "d658b2a1829a0ead47a7e7a65729812f3a01b37b",
            "57405d26a2faf70f8cdb81a7a43e0df3a65527ed",
            "b9e98f630e8eaf77ddcd0f80d1360b611ae61e70",
            "e811e9973adf089ab9aaf5fcff7b92b3cb1b201f",
            "fc8a1a3d7538bb264d5d58ad6dfe9ef71a2ce16e",
            "a610242d1e177bb04a3d6e35b5d34afd8648bfb0",
            "d334dc46a9f89085f3652d2a89f17ee7cca00533",
            "d1c166e8edf5e672ccc08dc65b1979aaeaafa775",
            "ec95ce0f861eae0dbd4e5f28fcaaa9ae1c132217"
        ],
        "related_topics": [],
        "reference_count": "59",
        "citation_count": "3"
    },
    {
        "Id": "258a795ac1ab24c6aefb6cb13b8ebb11bc191f53",
        "title": "Machine Learning Techniques to Classify Healthy and Diseased Cardiomyocytes by Contractility Profile.",
        "authors": [
            "Diogo Teles",
            "Youngbin Kim",
            "Kacey Ronaldson-Bouchard",
            "Gordana Vunjak\u2010Novakovic"
        ],
        "date": "21 June 2021",
        "abstract": "The proposed computational machine learning evaluation of human iPS cell-derived cardiomyocytes' contractility profiles has the potential to identify other genetic proarrhythmic events, screen therapeutic agents for inducing or suppressing long QT events, and predict drug-target interactions. Cardiomyocytes derived from human induced pluripotent stem (iPS) cells enable the study of cardiac physiology and the developmental testing of new therapeutic drugs in a human setting. In parallel, machine learning methods are being applied to biomedical science in unprecedented ways. Machine learning has been used to distinguish healthy from diseased cardiomyocytes using calcium (Ca2+) transient signals. Most Ca2+ transient signals are obtained via terminal assays that do not permit longitudinal studies, although some recently developed options can circumvent these concerns. Here, we describe the use of machine learning to identify healthy and diseased cardiomyocytes according to their contractility profiles, which are derived from brightfield videos. This noncontact, label-free approach allows for the continued cultivation of cells after they have been evaluated for use in other assays and can be readily extended to organs-on-chip. To demonstrate utility, we assessed contractility profiles of cardiomyocytes obtained from patients with Timothy Syndrome (TS), a long QT disease which can lead to fatal arrhythmias, and from healthy individuals. The videos were processed and classified using machine learning methods and their performance was evaluated according to several parameters. The trained algorithms were able to distinguish the TS cardiomyocytes from healthy controls and classify two different healthy controls. The proposed computational machine learning evaluation of human iPS cell-derived cardiomyocytes' contractility profiles has the potential to identify other genetic proarrhythmic events, screen therapeutic agents for inducing or suppressing long QT events, and predict drug-target interactions. The same approach could be readily extended to the evaluation of engineered cardiac tissues within single-tissue and multi-tissue organs-on-chip.",
        "references": [
            "7f794e1de178811d59906073919f33a3fc285a50",
            "a4f1d2c80eeb3f1f0d82c9c001da2245409af496",
            "d942a55fc7e0f4e5173f0bf220c913009f948a45",
            "19469b840011bc30fa3a3514a6fa79e6316306bc",
            "fa3c6644935a17d1c4f90c88606a13682c71e373",
            "ab842c83f9193ec022d6181c26d2baede82aec6f",
            "ecb847cedfb20d1535d8874453442e64e4de32e0",
            "5d586dd663580dea97fa99d0561d694f4f7165cc",
            "a8f367044f48f5c4f56fec21c73510091c1160e5",
            "55f89ae65f0f60db8f7062ed13c3b47e8f4c774f"
        ],
        "related_topics": [],
        "reference_count": "41",
        "citation_count": "10"
    },
    {
        "Id": "45016f9aae59e7dbafcc7dd3c4dc09e81eab2f77",
        "title": "Assessment of Drug Proarrhythmicity Using Artificial Neural Networks With in silico Deterministic Model Outputs",
        "authors": [
            "Yedam Yoo",
            "Aroli Marcellinus",
            "Da Un Jeong",
            "Ki-Suk Kim",
            "Ki Moo Lim"
        ],
        "date": "10 December 2021",
        "abstract": "An artificial neural networks (ANN) model that uses nine multiple input features, considering the action potential morphology, calcium transient morphology, and charge features to further improve the performance of drug toxicity evaluation is proposed. As part of the Comprehensive in vitro Proarrhythmia Assay initiative, methodologies for predicting the occurrence of drug-induced torsade de pointes via computer simulations have been developed and verified recently. However, their predictive performance still requires improvement. Herein, we propose an artificial neural networks (ANN) model that uses nine multiple input features, considering the action potential morphology, calcium transient morphology, and charge features to further improve the performance of drug toxicity evaluation. The voltage clamp experimental data for 28 drugs were augmented to 2,000 data entries using an uncertainty quantification technique. By applying these data to the modified O\u2019Hara Rudy in silico model, nine features (dVm/dtmax, APresting, APD90, APD50, Caresting, CaD90, CaD50, qNet, and qInward) were calculated. These nine features were used as inputs to an ANN model to classify drug toxicity into high-risk, intermediate-risk, and low-risk groups. The model was trained with data from 12 drugs and tested using the data of the remaining 16 drugs. The proposed ANN model demonstrated an AUC of 0.92 in the high-risk group, 0.83 in the intermediate-risk group, and 0.98 in the low-risk group. This was higher than the classification performance of the method proposed in previous studies.",
        "references": [
            "df6103a88acf71bf60e98b77421c58cbf243c5e2",
            "121780241577fe00c666ed8585dd70b66e3701db",
            "d85ed2dc274e6ff2f8ad78993b6ede2cabdae32e",
            "df20cabf16c54a10c9129c663af8b3fdae5c030f",
            "57bd2c9f64088b56de5739dc97d55fc1005c52f4",
            "8644b79769bfe4ddf5b674826afe40fbf4ab1882",
            "0e91304d5768a653049056e1dec472acd777a4ef",
            "3d63e2dce60eade6f7e57d77cd4f71a69f1bc2cd",
            "f561e7f7829a4536f96c1e682f94c03f2ace5220",
            "b9e98f630e8eaf77ddcd0f80d1360b611ae61e70"
        ],
        "related_topics": [],
        "reference_count": "22",
        "citation_count": "7"
    },
    {
        "Id": "2f50b9125e74a2d9b02dff9787fc9b73320a2a4a",
        "title": "Characterizing arrhythmia using machine learning analysis of Ca2+ cycling in human cardiomyocytes",
        "authors": [
            "Jeremy Kah Sheng Pang",
            "Sabrina Chia",
            "Jinqiu Zhang",
            "Piotr Szyniarowski",
            "Colin Stewart",
            "Henry He Yang",
            "Woon Khiong Chan",
            "Shi-Yan Ng",
            "Boon Seng Soh"
        ],
        "date": "25 June 2022",
        "abstract": "Semantic Scholar extracted view of \"Characterizing arrhythmia using machine learning analysis of Ca2+ cycling in human cardiomyocytes\" by Jeremy Kah Sheng Pang et al.",
        "references": [
            "a4e7d8475d1b5ee317557788147234d5b426929a",
            "b9e98f630e8eaf77ddcd0f80d1360b611ae61e70",
            "fa3c6644935a17d1c4f90c88606a13682c71e373",
            "87f5a4a69b1e06d07d7170cfb3f4e1a8da93fbab",
            "12d8d758cd927b0f5d6243ac09c1c221759b0cb8",
            "34d04d46e4d27f31b8df447b4e9993772d92ebd3",
            "021734b9edfd52261680f3613996a6901f1ecdeb",
            "b704c18b49757a3f43ebc7f29c6bbe27702dcfaa",
            "88499b49a830a39dd16381e224d8880e47d868ce",
            "c6eab69692f4408e83f583215ef1be57127c833a"
        ],
        "related_topics": [],
        "reference_count": "41",
        "citation_count": "5"
    },
    {
        "Id": "1959a6d5627be11afcabd21797627e0894a0d05c",
        "title": "From biomimicry to bioelectronics: Smart materials for cardiac tissue engineering",
        "authors": [
            "Olurotimi A. Bolonduro",
            "Breanna M. Duffy",
            "Akshita A. Rao",
            "Lauren D. Black",
            "Brian P. Timko"
        ],
        "date": "26 February 2020",
        "abstract": "This review discusses recent efforts in materials science and nanotechnology to achieve functional three-dimensional scaffolds that modulate and monitor cardiac tissue function and describes how solid-state nanomaterials may be integrated within these systems to provide unique electrical and nanotopographic cues that improve electromechanical synchrony. Effective strategies in cardiac tissue engineering require matrices that recapitulate the mechanical, topographic and electrical cues present in the native extracellular matrix. In this review, we discuss recent efforts in materials science and nanotechnology to achieve functional three-dimensional (3D) scaffolds that modulate and monitor cardiac tissue function. We consider key design considerations, including choice of biopolymer matrix, cell sources, and delivery methods for eventual therapies. We then discuss how solid-state nanomaterials may be integrated within these systems to provide unique electrical and nanotopographic cues that improve electromechanical synchrony. We describe how these approaches may be extended to complex, spatially heterogeneous constructs using 3D bioprinting techniques. Finally, we describe how scaffold materials may be augmented with bioelectronic components to achieve hybrid myocardium that monitors or controls electrophysiological activity. Collectively, these approaches provide a framework for achieving cardiac tissues with tunable, rationally-designed functionalities. We discuss future prospects and remaining challenges for clinical translation.",
        "references": [
            "5d3c7f7ce596b96071096e1b5f5fe1cbe5dc9342",
            "40ebec46e518cec48982a5b13c9ee4c31d91d705",
            "f390a0c248536f3e35ce688a754ee094b822ca76",
            "744aa7eb4c9cc8acd3d233f4066e5beda8deb46b",
            "6572a9721347bd014d4fcbb3a0f954123cf18253",
            "af4d379bffec6e87433404cf037259536d3fdd84",
            "1406d72ab144329ff69600e3c92fa8b12b7e81f4",
            "2fc5b0239cffbc224fe1d902be89f0ff5752464b",
            "129029e7fa5a2464981ae866a5cfad5905b6f883",
            "6b045d4d8214b3d10457fcac133b3e92af3a4498"
        ],
        "related_topics": [],
        "reference_count": "151",
        "citation_count": "20"
    },
    {
        "Id": "8a73d44ab7a59d76f97b629a43b5eb4c18960967",
        "title": "Ensemble Deep Learning Models for Heart Disease Classification: A Case Study from Mexico",
        "authors": [
            "Asma Baccouche",
            "Begonya Garcia-Zapirain",
            "Cristian Castillo Olea",
            "Adel Said Elmaghraby"
        ],
        "date": "14 April 2020",
        "abstract": "It is shown that ensemble-learning framework based on deep models could overcome the problem of classifying an unbalanced heart disease dataset and can lead to highly accurate models that are adapted for clinical real data and diagnosis use. Heart diseases are highly ranked among the leading causes of mortality in the world. They have various types including vascular, ischemic, and hypertensive heart disease. A large number of medical features are reported for patients in the Electronic Health Records (EHR) that allow physicians to diagnose and monitor heart disease. We collected a dataset from Medica Norte Hospital in Mexico that includes 800 records and 141 indicators such as age, weight, glucose, blood pressure rate, and clinical symptoms. Distribution of the collected records is very unbalanced on the different types of heart disease, where 17% of records have hypertensive heart disease, 16% of records have ischemic heart disease, 7% of records have mixed heart disease, and 8% of records have valvular heart disease. Herein, we propose an ensemble-learning framework of different neural network models, and a method of aggregating random under-sampling. To improve the performance of the classification algorithms, we implement a data preprocessing step with features selection. Experiments were conducted with unidirectional and bidirectional neural network models and results showed that an ensemble classifier with a BiLSTM or BiGRU model with a CNN model had the best classification performance with accuracy and F1-score between 91% and 96% for the different types of heart disease. These results are competitive and promising for heart disease dataset. We showed that ensemble-learning framework based on deep models could overcome the problem of classifying an unbalanced heart disease dataset. Our proposed framework can lead to highly accurate models that are adapted for clinical real data and diagnosis use.",
        "references": [
            "7f2bdb8d2794a7cc2131bf49d82668910221c3f9",
            "5481e477edaccab044eb7320b28ee6801662d9a4",
            "d7e518c8cda621083edc9fc534fe55c2f148e8f2",
            "d3773ac1e551aec4fd10f5dae8bd36090d0d3928",
            "53c5972eec92b21f213f2c1d6c2b6e8f23882700",
            "3eb8c0f997a5770a68ac35a8f46bd3156c640691",
            "83ef0b469a994b998d412d523e58256e7a151601",
            "2bc3644ce4de7fce5812c1455e056649a47c1bbf",
            "4a0b6172743540fb5269c8e38240f88b33223e1a",
            "b3045322d47df8c99941b76eef7422b09bb2f073"
        ],
        "related_topics": [
            "Deep Model",
            "Random Under-sampling",
            "Monitor",
            "Deep Learning",
            "Feature Selection",
            "Ensemble",
            "Bidirectional Long Short Term Memory"
        ],
        "reference_count": "79",
        "citation_count": "67"
    },
    {
        "Id": "20484b42bd462ef016de99ffa71f67c6c295ed8a",
        "title": "Analysis of the Drawbacks of English-Chinese Intelligent Machine Translation Based on Deep Learning",
        "authors": [
            "Hongmei Li",
            "Wei Xiong"
        ],
        "date": "28 October 2021",
        "abstract": "Semantic Scholar extracted view of \"Analysis of the Drawbacks of English-Chinese Intelligent Machine Translation Based on Deep Learning\" by Hongmei Li et al.",
        "references": [
            "28293e2b07acccc222f5b0deca15105430759a92",
            "94065708365639c43863ceed237555a3469d40f0",
            "b9e98f630e8eaf77ddcd0f80d1360b611ae61e70",
            "7ddc973a3243d6d6559c9aa5da976670552e2784",
            "2e535b8cd02c2f767670ba47a43ad449fa1faad7",
            "bbf052271c70dd926cd230bb5640cdcdfeccf1cc",
            "05381e08a8835646d5f4ed299cfd306e907ee77c"
        ],
        "related_topics": [],
        "reference_count": "7",
        "citation_count": "One"
    },
    {
        "Id": "50afa4fa74b0475ca0264461c79f7bd42fcc494c",
        "title": "In vitro electrophysiological drug testing using human embryonic stem cell derived cardiomyocytes.",
        "authors": [
            "Oren Caspi",
            "Ilanit Itzhaki",
            "Izhak Kehat",
            "Amira Gepstein",
            "Gil Arbel",
            "Irit Huber",
            "Jonathan Satin",
            "Lior Gepstein"
        ],
        "date": "11 February 2009",
        "abstract": "It is hypothesized that human embryonic stem cell-derived cardiomyocytes assessed with a combination of single cell electrophysiology and microelectrode array (MEA) mapping can serve as a novel model for Electrophysiological drug screening. Pro-arrhythmia (development of cardiac arrhythmias as a pharmacological side effect) has become the single most common cause of the withdrawal or restrictions of previously marketed drugs. The development of new medications, free from these side effects, is hampered by the lack of an in vitro assay for human cardiac tissue. We hypothesized that human embryonic stem cell-derived cardiomyocytes (hESC-CMs) assessed with a combination of single cell electrophysiology and microelectrode array (MEA) mapping can serve as a novel model for electrophysiological drug screening. Current-clamp studies revealed that E-4031 and Sotalol (IKr blockers) significantly increased hESC-CM's action potential duration and also induced after-depolarizations (the in vitro correlates of increased arrhythmogenic potential). Multicellular aggregates of hESC-CMs were then analyzed with the MEA technique. Application of class I (Quinidine, Procaineamide) and class III (Sotalol) antiarrhythmic agents, E-4031, and Cisapride (a noncardiogenic agent known to lengthen QT) resulted in dose-dependent prolongation of the corrected field potential duration (cFPD). We next utilized the MEA technique to also assess pharmacological effects on conduction. Activation maps demonstrated significant conduction slowing following administration of Na channel blockers (Quinidine and Propafenone) and of the gap junction blocker (1-heptanol). While most attention has been focused on the prospects of using hESC-derived cardiomyocytes for regenerative medicine, this study highlights the possible utilization of these unique cells also for cardiac electrophysiological studies, drug screening, and target validation.",
        "references": [
            "2269e63b969cb7b62d51c86f2c58ec645dad2303",
            "0e01651f92b8aa685df569856997f2ddff12c1e5",
            "65b5a7936849b6f1278cdf6b5b9eaf9e126799c4",
            "cf06c03542b1407e3da9d8fdb8ce7ace9a8ba07c",
            "00edea7e3c0f45492baea5ffa637b311857a6383",
            "997aeac7640fdf10adc7486a02173d144a767aee",
            "bc0e497fd8d8ed4ecf91075373af29cf0b049d4f",
            "84d07718fa5452e3899d6070d17b4bbdcb87bd61",
            "ad421e55153d9e844c2be6db43d2a450076c3b73",
            "5b11057670ddd12789ab9d0bf10b7e7bb76ce9f0"
        ],
        "related_topics": [],
        "reference_count": "53",
        "citation_count": "237"
    },
    {
        "Id": "307ff8f512098497e2c69b79c00fbb7b3cc9650e",
        "title": "Estimating the risk of drug-induced proarrhythmia using human induced pluripotent stem cell-derived cardiomyocytes.",
        "authors": [
            "Liang Guo",
            "Rory M. C. Abrams",
            "Joshua Babiarz",
            "Jennifer D. Cohen",
            "Seiji Kameoka",
            "Martin J. Sanders",
            "Eric T Chiao",
            "Kyle L Kolaja"
        ],
        "date": "1 September 2011",
        "abstract": "The first published report of a high-throughput functional assay employing a monolayer of beating human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) is described, detailing a model that accurately detects drug-induced cardiac abnormalities. Improved in vitro systems for predicting drug-induced toxicity are needed in the pharmaceutical and biotechnology industries to decrease late-stage drug attrition. One unmet need is an early screen for cardiotoxicity, which accounts for about one third of safety-based withdrawn pharmaceuticals. Herein, the first published report of a high-throughput functional assay employing a monolayer of beating human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) is described, detailing a model that accurately detects drug-induced cardiac abnormalities. Using 96-well plates with interdigitated electrode arrays that assess impedance, the rhythmic, synchronous contractions of the iPSC-CMs were detected. Treatment of the iPSC-CMs with 28 different compounds with known cardiac effects resulted in compound-specific changes in the beat rate and/or the amplitude of the impedance measurement. Changes in impedance for the compounds tested were comparable with the results from a related technology, electric field potential assessment obtained from microelectrode arrays. Using the results from the set of compounds, an index of drug-induced arrhythmias was calculated, enabling the determination of a drug's proarrhythmic potential. This system of interrogating human cardiac function in vitro opens new opportunities for predicting cardiac toxicity and studying cardiac biology.",
        "references": [
            "0e01651f92b8aa685df569856997f2ddff12c1e5",
            "65b5a7936849b6f1278cdf6b5b9eaf9e126799c4",
            "c1cb043d6cc44f9c661a45c1daba623d41b36bf1",
            "2b552d462e7cc16f40d1e8ef2765c9e81f8c54db",
            "22a81a3583b6993c46a6e006a684529668239b89",
            "9ec3175129b38d7c239f9a640b8252e643728f57",
            "cf313169a9639e7b837404546589aeb24224e863",
            "cca805487ff41c849517930de4e53c00f2116213",
            "0d6cbdbb65410e3853272e74e8f7707897d8a8b2",
            "43ca6679e5e24a6d70634be4f23de81d09415c14"
        ],
        "related_topics": [],
        "reference_count": "42",
        "citation_count": "263"
    },
    {
        "Id": "7a373d7dbd44ad99e5287f78b0e168e33498b44d",
        "title": "Interpretation of field potentials measured on a multi electrode array in pharmacological toxicity screening on primary and human pluripotent stem cell-derived cardiomyocytes",
        "authors": [
            "Leon G. J. Tertoolen",
            "Stefan R. Braam",
            "B. J. van Meer",
            "Robert Passier",
            "Christine L. Mummery",
            "Christine L. Mummery"
        ],
        "date": "30 January 2017",
        "abstract": "Semantic Scholar extracted view of \"Interpretation of field potentials measured on a multi electrode array in pharmacological toxicity screening on primary and human pluripotent stem cell-derived cardiomyocytes\" by L. Tertoolen et al.",
        "references": [
            "0e01651f92b8aa685df569856997f2ddff12c1e5",
            "88499b49a830a39dd16381e224d8880e47d868ce",
            "bf613c2aa1d514e099cff15eeb751653321cbcb6",
            "04b17d30b1cee5eba210e40150e80a51b196dc7a",
            "98fb5773e149e1ef59e9612098209d2ac44cdd8a",
            "f8317fe10a44714ed9c1d6df54c50bd075896f01",
            "74062c98a4c16981407a0c181abadc85dd03eb97",
            "0ed904b68234575f6109403eb7a228da2f1b0faa",
            "9e4ba0fc9b6103fdd5509e8cdf370971648a6e2f",
            "de63e783210fe097f6164e66aa125ed014d44dff"
        ],
        "related_topics": [],
        "reference_count": "11",
        "citation_count": "53"
    },
    {
        "Id": "9dbdcc1701aec174a6d0cf748b9bf5704ee4640a",
        "title": "Structure-aware scale-adaptive networks for cancer segmentation in whole-slide images",
        "authors": [
            "Yibao Sun",
            "Edgar Giussepi Lopez Molina",
            "Yaqi Wang",
            "Xingru Huang",
            "Huiyu Zhou",
            "Qianni Zhang"
        ],
        "date": "26 September 2021",
        "abstract": "A structure-aware scale-adaptive feature selection method for efficient and accurate cancer segmentation based on a segmentation network with a popular encoder-decoder architecture and a structural similarity metric is proposed for better tissue structure awareness to deal with small region segmentation. Cancer segmentation in whole-slide images is a fundamental step for viable tumour burden estimation, which is of great value for cancer assessment. However, factors like vague boundaries or small regions dissociated from viable tumour areas make it a challenging task. Considering the usefulness of multi-scale features in various vision-related tasks, we present a structure-aware scale-adaptive feature selection method for efficient and accurate cancer segmentation. Based on a segmentation network with a popular encoder-decoder architecture, a scale-adaptive module is proposed for selecting more robust features to represent the vague, non-rigid boundaries. Furthermore, a structural similarity metric is proposed for better tissue structure awareness to deal with small region segmentation. In addition, advanced designs including several attention mechanisms and the selective-kernel convolutions are applied to the baseline network for comparative study purposes. Extensive experimental results show that the proposed structure-aware scale-adaptive networks achieve outstanding performance on liver cancer segmentation when compared to top ten submitted results in the challenge of PAIP 2019. Further evaluation on colorectal cancer segmentation shows that the scale-adaptive module improves the baseline network or outperforms the other excellent designs of attention mechanisms when considering the tradeoff between efficiency and accuracy.",
        "references": [
            "f9638ee3738d30c23a5f8f84988aed7120a08fac",
            "42e968fff5a5426ed8bd92b49e2bb33ac4da0572",
            "f8c41cfaa1bea1e3a64228babf1ff8fc3b94fc4e",
            "474c6fa8fb311f442802fff455102b4d2dd39014",
            "67943d61b1e30f7cee0b82feff2794f05d4494ee",
            "466a533ad3abb6bdaa3e8201944af10e877c0c46",
            "2a2bdf5cf0d73bc333423a8fd246593f4bf65322",
            "a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "b33d9e5f49c4ddb8baf7c19e6d61843c2bc1774a",
            "1eae26fe1ca566f17468080c3aecab1c3f9efb66"
        ],
        "related_topics": [
            "Baseline Network",
            "Whole Slide Images",
            "Multi-scale Features",
            "PAIP 2019",
            "Encoder-decoder Architectures",
            "Robust Features",
            "Scale-Adaptive Networks",
            "Segmentation Network",
            "Liver Cancer Segmentation"
        ],
        "reference_count": "58",
        "citation_count": "One"
    },
    {
        "Id": "d43f2a1cefcd8a508c7f7dafd1fffdf01dd69394",
        "title": "A CNN-Based Wearable Assistive System for Visually Impaired People Walking Outdoors",
        "authors": [
            "I-Hsuan Hsieh",
            "Hsiao-Chu Cheng",
            "Hao-Hsiang Ke",
            "Hsiang-Chieh Chen",
            "Wen-June Wang"
        ],
        "date": "26 October 2021",
        "abstract": "This assistive system contains an embedded system\u2014Jetson AGX Xavier and a binocular depth camera\u2014ZED 2 and a voice prompt is played to guide the user toward the most appropriate direction such that the visually impaired user can navigate a safe path on the sidewalk, avoid any obstacles, or walk on the crosswalk safely. In this study, we propose an assistive system for helping visually impaired people walk outdoors. This assistive system contains an embedded system\u2014Jetson AGX Xavier (manufacture by Nvidia in Santa Clara, CA, USA) and a binocular depth camera\u2014ZED 2 (manufacture by Stereolabs in San Francisco, CA, USA). Based on the CNN neural network FAST-SCNN and the depth map obtained by the ZED 2, the image of the environment in front of the visually impaired user is split into seven equal divisions. A walkability confidence value for each division is computed, and a voice prompt is played to guide the user toward the most appropriate direction such that the visually impaired user can navigate a safe path on the sidewalk, avoid any obstacles, or walk on the crosswalk safely. Furthermore, the obstacle in front of the user is identified by the network YOLOv5s proposed by Jocher, G. et al. Finally, we provided the proposed assistive system to a visually impaired person and experimented around an MRT station in Taiwan. The visually impaired person indicated that the proposed system indeed helped him feel safer when walking outdoors. The experiment also verified that the system could effectively guide the visually impaired person walking safely on the sidewalk and crosswalks.",
        "references": [
            "1d354e050441faad62f48b2c1c79e410233a38af",
            "16da16c836399398aef6251695aea2980cbeff48",
            "0ff65672bf1730da5a55f68198b96cc1f7250e94",
            "61b36914ad274c6474b613622e6f4a54612a1ec8",
            "4b81e04b7d121645acfb47bde89d07d7292f91a7",
            "3864eda1012169d8083e898319d7a1e674d02536",
            "021255dbadf7a993a5d9d9b62f27a760971dd24d",
            "c17e9cb6e3b426ce1899ba9c9208e7bc3c00eec8",
            "6ffca71e1579b8cbc990757d438d6f73fb85482c",
            "abf694a72a010f16c10d3a5def299bef097afe2b"
        ],
        "related_topics": [],
        "reference_count": "28",
        "citation_count": "10"
    },
    {
        "Id": "54ac5dca66e0070cd4b91f0cc3f7cca6df1f9eba",
        "title": "A joint Multi-decoder Dual-attention U-Net framework for tumor segmentation in Whole Slide Images",
        "authors": [
            "Heba Abdel-Nabi",
            "Mostafa Z. Ali",
            "Arafat A. Awajan"
        ],
        "date": "1 November 2023",
        "abstract": "Semantic Scholar extracted view of \"A joint Multi-decoder Dual-attention U-Net framework for tumor segmentation in Whole Slide Images\" by Heba Abdel-Nabi et al.",
        "references": [
            "8ad29f74df1474c678fad951df4dfa26418c320d",
            "45a4af72e02de5251655de0eec06403916ffe0b2",
            "545d08577056ba64c9ca6434182fa203bfaaf96a",
            "86400178c1772007d711aec4208a75488d2586b3",
            "9e59276b4c7acc78ce5b7feed7857eae75e7733b",
            "f6600a1bff84d9be43c9a37986d7676a380ef51f",
            "311fda3ecfa04756e8d9dfa4b25e8d05c3d21a9a",
            "c1b4ab9429308bbab64643d463a6b3ca242e1969",
            "2fce96ef8830b42de640aedb49d431f6589f618c",
            "7d873a9c49d3864709aa762f8740edcdbd7369c5"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "41"
    },
    {
        "Id": "d779b87172306c37c2c711512e84bc8112adf21e",
        "title": "Towards Automatic Prostate Gleason Grading Via Deep Convolutional Neural Networks",
        "authors": [
            "Ali Asghar Khani",
            "Seyed Alireza Fatemi Jahromi",
            "Hatef Otroshi Shahreza",
            "Hamid Behroozi",
            "Mahdieh Soleymani Baghshah"
        ],
        "date": "1 December 2019",
        "abstract": "This paper uses the DeepLabV3+ model with MobileNetV2 backbone and train it with the newly released dataset from Gleason 2019 challenge and achieves the mean Cohen's quadratic kappa score of 0.56 with the pathologists' annotations on the test subset which is higher than the inter-pathologists' score. Prostate Cancer has become one of the deadliest cancers among males in many nations. Pathologists use various approaches for the detection and the staging of prostate cancer. Microscopic inspection of biopsy tissues is the most accurate approach among them. The Gleason grading system is used to evaluate the stage of Prostate Cancer using prostate biopsy samples. The task of assigning a grade to each region in a tissue is a time-consuming task. Furthermore, this task often has several challenges since it has considerable inter-observer variability even among expert pathologists. In this paper, we propose an automatic method for this task using a deep learningbased approach. For this purpose, we use the DeepLabV3+ model with MobileNetV2 backbone and train it with the newly released dataset from Gleason 2019 challenge. Our model achieves the mean Cohen's quadratic kappa score of 0.56 with the pathologists' annotations on the test subset which is higher than the inter-pathologists' score (0.55).",
        "references": [
            "2c2f461af47644c0c05a62da0739c4bb48b99cdf",
            "8ce6b544554a79e077e5fc52f55ba8234ce606d4",
            "47262a72c9c7bf5070b97e70b55c6190d1079260",
            "d5b91f292c611dea61f6e95b007ae53c2766a5f9",
            "d20dff7103c3da6753ef108dc825d9fe44bd00d2",
            "50004c086ffd6a201a4b782281aaa930fbfe6ecf",
            "a6876ea89e677a7cc42dd43f27165ff6fd414de5",
            "6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "8f7bb9b751da9ede977395630b4482df634c38be",
            "84c1717345dd451e7a61fe89807b4c017754fc4e"
        ],
        "related_topics": [],
        "reference_count": "36",
        "citation_count": "7"
    },
    {
        "Id": "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7",
        "title": "Detecting Cancer Metastases on Gigapixel Pathology Images",
        "authors": [
            "Yun Liu",
            "Krishna Gadepalli",
            "Mohammad Norouzi",
            "George E. Dahl",
            "Timo Kohlberger",
            "Aleksey Boyko",
            "Subhashini Venugopalan",
            "Aleksei Timofeev",
            "Phil Q. Nelson",
            "Greg S Corrado",
            "Jason D. Hipp",
            "Lily H. Peng",
            "Martin C. Stumpe"
        ],
        "date": "3 March 2017",
        "abstract": "This work presents a framework to automatically detect and localize tumors as small as 100 x 100 pixels in gigapixel microscopy images sized 100,000 x100,000 pixels and achieves image-level AUC scores above 97% on both the Camelyon16 test set and an independent set of 110 slides. Each year, the treatment decisions for more than 230,000 breast cancer patients in the U.S. hinge on whether the cancer has metastasized away from the breast. Metastasis detection is currently performed by pathologists reviewing large expanses of biological tissues. This process is labor intensive and error-prone. We present a framework to automatically detect and localize tumors as small as 100 x 100 pixels in gigapixel microscopy images sized 100,000 x 100,000 pixels. Our method leverages a convolutional neural network (CNN) architecture and obtains state-of-the-art results on the Camelyon16 dataset in the challenging lesion-level tumor detection task. At 8 false positives per image, we detect 92.4% of the tumors, relative to 82.7% by the previous best automated approach. For comparison, a human pathologist attempting exhaustive search achieved 73.2% sensitivity. We achieve image-level AUC scores above 97% on both the Camelyon16 test set and an independent set of 110 slides. In addition, we discover that two slides in the Camelyon16 training set were erroneously labeled normal. Our approach could considerably reduce false negative rates in metastasis detection.",
        "references": [
            "21ba757bf394720e0b66b86e7638ae28742d6570",
            "2f11f86fd805807076b22317738c819484a8e21b",
            "47262a72c9c7bf5070b97e70b55c6190d1079260",
            "80b0a281c520581e474d178e4020721c61ab5667",
            "94087ad5ed11555c260a42f2f9ca9da183c6f87e",
            "d847ee63fe234f9cc2a8be851ed511b7d1a8da36",
            "6196fa503ecd1b0798e5fd3a48ea519fc3ff5765",
            "4661b82606512f03a2f3fcc1d2587152b89f8e73",
            "2729d2918978d5ed602aa843fbdd027d83e0036f",
            "2f4df08d9072fc2ac181b7fced6a245315ce05c8"
        ],
        "related_topics": [
            "Metastasis Detection",
            "Camelyon16 Dataset",
            "CAMELYON-16",
            "Tumor Probability Heatmaps",
            "Pathologist",
            "Convolutional Neural Network",
            "Gigapixel",
            "State-of-the-art Results",
            "AUC Scores",
            "Independent Set"
        ],
        "reference_count": "25",
        "citation_count": "587"
    },
    {
        "Id": "769149c0dc0ed308eca8bc916f4326b2e2f57a1f",
        "title": "Classification and mutation prediction from non\u2013small cell lung cancer histopathology images using deep learning",
        "authors": [
            "Nicolas Coudray",
            "Paolo Santiago Ocampo",
            "Theodore Sakellaropoulos",
            "Navneet Narula",
            "Matija Snuderl",
            "David Feny{\\&quot;o}",
            "Andre L. Moreira",
            "Narges Razavian",
            "Aristotelis Tsirigos"
        ],
        "date": "17 September 2018",
        "abstract": "A deep convolutional neural network model is trained on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue and predicts the ten most commonly mutated genes in LUAD. Visual inspection of histopathology slides is one of the main methods used by pathologists to assess the stage, type and subtype of lung tumors. Adenocarcinoma (LUAD) and squamous cell carcinoma (LUSC) are the most prevalent subtypes of lung cancer, and their distinction requires visual inspection by an experienced pathologist. In this study, we trained a deep convolutional neural network (inception v3) on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue. The performance of our method is comparable to that of pathologists, with an average area under the curve (AUC) of 0.97. Our model was validated on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues and biopsies. Furthermore, we trained the network to predict the ten most commonly mutated genes in LUAD. We found that six of them\u2014STK11, EGFR, FAT1, SETBP1, KRAS and TP53\u2014can be predicted from pathology images, with AUCs from 0.733 to 0.856 as measured on a held-out population. These findings suggest that deep-learning models can assist pathologists in the detection of cancer subtype or gene mutations. Our approach can be applied to any cancer type, and the code is available at https://github.com/ncoudray/DeepPATH.A convolutional neural network model using feature extraction and machine-learning techniques provides a tool for classification of lung cancer histopathology images and predicting mutational status of driver oncogenes",
        "references": [
            "94087ad5ed11555c260a42f2f9ca9da183c6f87e",
            "bd6f783022ebd6704ff34f6bf824ef1cb1ad0cee",
            "add18010e1af63998bae7573f4cd5d2843eeb5bb",
            "abb569b5b79365f57e7d20150b31bf65da89f275",
            "d5b91f292c611dea61f6e95b007ae53c2766a5f9",
            "7256088eece603df2e5675025e8bed90c0f21171",
            "bcc9db4c560ea48d1b205acfc8ec77568d913503",
            "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08",
            "e1e27b29318ff47de91619940019b10fd584c231",
            "30027db82f4eb242a2ee05973cabb06c8f02bd73"
        ],
        "related_topics": [],
        "reference_count": "69",
        "citation_count": "1,675"
    },
    {
        "Id": "21ba757bf394720e0b66b86e7638ae28742d6570",
        "title": "Deep Learning for Identifying Metastatic Breast Cancer",
        "authors": [
            "Dayong Wang",
            "Aditya Khosla",
            "Rishab Gargeya",
            "Humayun Irshad",
            "Andrew H. Beck"
        ],
        "date": "18 June 2016",
        "abstract": "The power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses is demonstrated, by combining the deep learning system's predictions with the human pathologist's diagnoses. The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.",
        "references": [
            "077592c2b76318a15562cf9f962f515988c011fb",
            "13de33ee941f1ebf3ed185c20fb4453a07302c30",
            "bd898f483476e3dcacf83cd85efc64e6319da0e1",
            "64aec645896bb6b444f6d81620fd5c9a1e3d6d6c",
            "44381cda660845d029a111bed20c0e8a8ed2d29b",
            "6196fa503ecd1b0798e5fd3a48ea519fc3ff5765",
            "ab9dce8b2af5e11985736be6bd73ec0968b2bb27",
            "a601a1ea75bde37f4dffd4f4c6025e91d2ae9a29",
            "ef6a1baa9441a4ebc4a5fb90f8c64ff67a61b288",
            "7651dc7f8e73be39aec686542bdc418de69a8b31"
        ],
        "related_topics": [
            "Metastatic Breast Cancer",
            "Camelyon Grand Challenge",
            "Whole Slide Images",
            "Tumor Localization Task",
            "Sentinel Lymph Nodes",
            "WSIs",
            "Tumor Probability Heatmaps",
            "Cancer Metastasis Detection",
            "Human Pathologist",
            "Normal Slides"
        ],
        "reference_count": "26",
        "citation_count": "837"
    },
    {
        "Id": "f9638ee3738d30c23a5f8f84988aed7120a08fac",
        "title": "Multi-scale fully convolutional neural networks for histopathology image segmentation: from nuclear aberrations to the global tissue architecture",
        "authors": [
            "R{\\&quot;u}diger Schmitz",
            "Frederic Madesta",
            "Maximilian Nielsen",
            "Ren{\\&#x27;e} Werner",
            "Thomas R{\\&quot;o}sch"
        ],
        "date": "24 September 2019",
        "abstract": "Semantic Scholar extracted view of \"Multi-scale fully convolutional neural networks for histopathology image segmentation: from nuclear aberrations to the global tissue architecture\" by R\u00fcdiger Schmitz et al.",
        "references": [
            "784906ab63c3743a5d26dca846a49c2edbf4dc6a",
            "455e92c1f629cd8065bc0c8287d3da52b451b98c",
            "9987d9b7fc3a5b3c9d35f47be5cc5d9eede9bf4b",
            "cd7ac742125095aa68a7873e75421f8ef9bc26aa",
            "7e3f1e7e25c7ee9977f7dd78cd6c1d2cab6049bb",
            "6364fdaa0a0eccd823a779fcdd489173f938e91a",
            "95db99286b274352e7e1906ebf63e10ae9fce30c",
            "80bfef962e21e78d3958cf60bd99b143820af1db",
            "a86d7289c76d832e83c99539859b7b186e4ea6c8",
            "7c2bcf6f32b05a04cd3444c030db743e5666af88"
        ],
        "related_topics": [],
        "reference_count": "54",
        "citation_count": "53"
    },
    {
        "Id": "6048de9749a1f31ac70e5c30030ceb1dc5d3f2b0",
        "title": "PFA-ScanNet: Pyramidal Feature Aggregation with Synergistic Learning for Breast Cancer Metastasis Analysis",
        "authors": [
            "Zixu Zhao",
            "Huangjing Lin",
            "Hao Chen",
            "Pheng-Ann Heng"
        ],
        "date": "3 May 2019",
        "abstract": "A novel Pyramidal Feature Aggregation ScanNet (PFA-ScanNet) for robust and fast analysis of breast cancer metastasis, which mainly benefits from the aggregation of extracted local-to-global features with diverse receptive fields and a high-efficiency inference mechanism designed with dense pooling layers. Automatic detection of cancer metastasis from whole slide images (WSIs) is a crucial step for following patient staging and prognosis. Recent convolutional neural network based approaches are struggling with the trade-off between accuracy and computational efficiency due to the difficulty in processing large-scale gigapixel WSIs. To meet this challenge, we propose a novel Pyramidal Feature Aggregation ScanNet (PFA-ScanNet) for robust and fast analysis of breast cancer metastasis. Our method mainly benefits from the aggregation of extracted local-to-global features with diverse receptive fields, as well as the proposed synergistic learning for training the main detector and extra decoder with semantic guidance. Furthermore, a high-efficiency inference mechanism is designed with dense pooling layers, which allows dense and fast scanning for gigapixel WSI analysis. As a result, the proposed PFA-ScanNet achieved the state-of-the-art FROC of 90.2% on the Camelyon16 dataset, as well as competitive kappa score of 0.905 on the Camelyon17 leaderboard. In addition, our method shows leading speed advantage over other methods, about 7.2 min per WSI with a single GPU, making automatic analysis of breast cancer metastasis more applicable in the clinical usage.",
        "references": [
            "e0a711d111eb0373a06d46bbe26b710f7c924ccb",
            "c1555c566a2628f0485b16b2ae4371aff617d7f7",
            "7642c455f69a2fe21d8f03679d3f6df7fcf0e9a5",
            "915adc7d9aacc46b6b8575f4a8be4b7cb4a1caf7",
            "4bfddce2f6356166be52eb7044864812df9c646b",
            "21ba757bf394720e0b66b86e7638ae28742d6570",
            "cfa3d45a6fcf704fe7ab6953424481d1698055a4",
            "5fd490e5ceed129a83d16dbda29ab61fe4aa1acb",
            "2a94c84383ee3de5e6211d43d16e7de387f68878",
            "3617ccfec4bed2d8ac15d0ad1a35b589d9b270cb"
        ],
        "related_topics": [
            "Convolutional Neural Network",
            "Camelyon16 Dataset",
            "Multi-scale Features",
            "Semantic Information",
            "Breast Cancer Metastases",
            "Receptive Field",
            "Synergistic Learning",
            "FROC-score",
            "Deep Neural Networks",
            "WSIs"
        ],
        "reference_count": "14",
        "citation_count": "22"
    },
    {
        "Id": "ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
        "title": "Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer",
        "authors": [
            "Babak Ehteshami Bejnordi",
            "Mitko Veta",
            "Paul Johannes van Diest",
            "Bram van Ginneken",
            "Nico Karssemeijer",
            "Geert J. S. Litjens",
            "Jeroen A. van der Laak",
            "Meyke Hermsen",
            "Quirine F. Manson",
            "Maschenka C. A. Balkenhol",
            "Oscar G. F. Geessink",
            "Nikolaos Stathonikos",
            "Marcory Crf van Dijk",
            "Peter Bult",
            "Francisco Beca",
            "Andrew H. Beck",
            "Dayong Wang",
            "Aditya Khosla",
            "Rishab Gargeya",
            "Humayun Irshad",
            "Aoxiao Zhong",
            "Qi Dou",
            "Quanzheng Li",
            "Hao Chen",
            "Huangjing Lin",
            "Pheng-Ann Heng",
            "Christian Hass",
            "Elia Bruni",
            "Quincy Kwan-Sut Wong",
            "Ugur Halici",
            "Mustafa {\\&quot;U}mit {\\&quot;O}ner",
            "Rengul Cetin-Atalay",
            "Matt Berseth",
            "Vitali Khvatkov",
            "A. Vylegzhanin",
            "Oren Z. Kraus",
            "Muhammad Shaban",
            "Nasir M. Rajpoot",
            "Ruqayya Awan",
            "Korsuk Sirinukunwattana",
            "Talha Qaiser",
            "Yee-Wah Tsang",
            "David Tellez",
            "Jonas Annuscheit",
            "Peter Hufnagl",
            "Mira Valkonen",
            "Kimmo Kartasalo",
            "Leena Latonen",
            "Pekka Ruusuvuori",
            "Kaisa Liimatainen",
            "Shadi Albarqouni",
            "Bharti Mungal",
            "Amitha Anna George",
            "Stefanie Demirci",
            "Nassir Navab",
            "Seiryo Watanabe",
            "Shigeto Seno",
            "Yoichi Takenaka",
            "Hideo Matsuda",
            "Hady Ahmady Phoulady",
            "Vassili A. Kovalev",
            "Alexander Kalinovsky",
            "Vitali Liauchuk",
            "Gloria Bueno",
            "Maria del Milagro Fern{\\&#x27;a}ndez-Carrobles",
            "Ismael Serrano",
            "Oscar Deniz",
            "Daniel Racoceanu",
            "Rui Ven{\\^a}ncio"
        ],
        "date": "12 December 2017",
        "abstract": "In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Importance Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency. Objective Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin\u2013stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists\u2019 diagnoses in a diagnostic setting. Design, Setting, and Participants Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n\u2009=\u2009110) and without (n\u2009=\u2009160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). Exposures Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. Main Outcomes and Measures The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. Results The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P\u2009<\u2009.001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95% CI, 0.927-0.998] for the pathologist WOTC). Conclusions and Relevance In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.",
        "references": [
            "47262a72c9c7bf5070b97e70b55c6190d1079260",
            "a8916917d2e8bf88a63e27c2ecbe6e3294882667",
            "64439e2ec6150424534378a689fa7484849756c5",
            "b23a7d485ee8f60f33119c27acf43607caee3cd3",
            "e1ec11a1cb3d9745fb18d3bf74247f95a6663d08",
            "2729d2918978d5ed602aa843fbdd027d83e0036f",
            "c767fbf94ae063f91fbf14b511bbb21664a394bf",
            "c912e250ba2703d06e4399c7103e84457ecc39d8",
            "f15a6caf0d6062fc6e100c3ed64e2634e5f9949f",
            "ea93a4bed1b4223799795d1a47d8b47de1b61fff"
        ],
        "related_topics": [],
        "reference_count": "71",
        "citation_count": "2,145"
    },
    {
        "Id": "5fd80e47d53c64512a0b85a4c7a0beb24bc35766",
        "title": "Semi-supervised Zero-Shot Learning by a Clustering-based Approach",
        "authors": [
            "Seyed Mohsen Shojaee",
            "Mahdieh Soleymani Baghshah"
        ],
        "date": "29 May 2016",
        "abstract": "A novel semi-supervised zero-shot learning method that works on an embedding space corresponding to abstract deep visual features, such that the mapped signatures of the seen classes are close to labeled samples of the corresponding classes and unlabeled data are also close to the mapped signature of one of the unseen classes. In some of object recognition problems, labeled data may not be available for all categories. Zero-shot learning utilizes auxiliary information (also called signatures) describing each category in order to find a classifier that can recognize samples from categories with no labeled instance. In this paper, we propose a novel semi-supervised zero-shot learning method that works on an embedding space corresponding to abstract deep visual features. We seek a linear transformation on signatures to map them onto the visual features, such that the mapped signatures of the seen classes are close to labeled samples of the corresponding classes and unlabeled data are also close to the mapped signatures of one of the unseen classes. \nWe use the idea that the rich deep visual features provide a representation space in which samples of each class are usually condensed in a cluster. The effectiveness of the proposed method is demonstrated through extensive experiments on four public benchmarks improving the state-of-the-art prediction accuracy on three of them.",
        "references": [
            "a6b8cd5f34b438f487679b1166ea03e56eb14c9e",
            "846946cd21413211a4701f309c3927d67363cd30",
            "b29227f8dde62a5cd21678b4bc429206615485a2",
            "4cc2273cf8640ddd497e86d949dfd79057e5caea",
            "ac98259064e86f643f2cd11e5417b43bf28daa91",
            "244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa",
            "ccbc09d498cad330c37f94e15b77bf220b10ccb4",
            "b2a5c3744eea40c76d0359e517026e8ed6c922ff",
            "cb461276fad5710d8a7e2868867a9b01df040119",
            "caa632d101a41a7860562e4399a5eaa9a4088b55"
        ],
        "related_topics": [
            "Samples",
            "Categories",
            "Zero-Shot Learning",
            "Object Recognition",
            "Embedding Space",
            "Classifier",
            "Unseen Classes",
            "Seen Classes",
            "Linear Transformations",
            "Representation Space"
        ],
        "reference_count": "44",
        "citation_count": "35"
    },
    {
        "Id": "a6b8cd5f34b438f487679b1166ea03e56eb14c9e",
        "title": "Semi-Supervised Zero-Shot Classification with Label Representation Learning",
        "authors": [
            "X. Li",
            "Yuhong Guo",
            "Dale Schuurmans"
        ],
        "date": "7 December 2015",
        "abstract": "A novel zero-shot classification approach that automatically learns label embeddings from the input data in a semi-supervised large-margin learning framework that tackles the target prediction problem directly without introducing intermediate prediction problems. Given the challenge of gathering labeled training data, zero-shot classification, which transfers information from observed classes to recognize unseen classes, has become increasingly popular in the computer vision community. Most existing zero-shot learning methods require a user to first provide a set of semantic visual attributes for each class as side information before applying a two-step prediction procedure that introduces an intermediate attribute prediction problem. In this paper, we propose a novel zero-shot classification approach that automatically learns label embeddings from the input data in a semi-supervised large-margin learning framework. The proposed framework jointly considers multi-class classification over all classes (observed and unseen) and tackles the target prediction problem directly without introducing intermediate prediction problems. It also has the capacity to incorporate semantic label information from different sources when available. To evaluate the proposed approach, we conduct experiments on standard zero-shot data sets. The empirical results show the proposed approach outperforms existing state-of-the-art zero-shot learning methods.",
        "references": [
            "b29227f8dde62a5cd21678b4bc429206615485a2",
            "ab50e0fba1e7964d2686e90f9bed66a06ed6ff42",
            "ccbc09d498cad330c37f94e15b77bf220b10ccb4",
            "755e9f43ce398ae8737366720c5f82685b0c253e",
            "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef",
            "caa632d101a41a7860562e4399a5eaa9a4088b55",
            "018e730f8947173e1140210d4d1760d05c9d3854",
            "c30b9fb837e912ccf3919fdb64e9543fca57799e",
            "f038e8c3656f5c7a4846a7eca731eb567255adcb",
            "88e090ffc1f75eed720b5afb167523eb2e316f7f"
        ],
        "related_topics": [
            "Animals With Attributes",
            "Zero-shot Classification",
            "Multi-class Classification",
            "Unseen Classes",
            "Label Embedding",
            "Zero-shot Learning Methods",
            "Computer Vision"
        ],
        "reference_count": "34",
        "citation_count": "115"
    },
    {
        "Id": "b29227f8dde62a5cd21678b4bc429206615485a2",
        "title": "Max-Margin Zero-Shot Learning for Multi-class Classification",
        "authors": [
            "X. Li",
            "Yuhong Guo"
        ],
        "date": "21 February 2015",
        "abstract": "A semi-supervised max-margin learning framework that integrates the semisupervised classification problem over observed classes and the unsupervised clustering problem over unseen classes together to tackle zero-shot multi-class classification is proposed. Due to the dramatic expanse of data categories and the lack of labeled instances, zero-shot learning, which transfers knowledge from observed classes to recognize unseen classes, has started drawing a lot of attention from the research community. In this paper, we propose a semi-supervised max-margin learning framework that integrates the semisupervised classification problem over observed classes and the unsupervised clustering problem over unseen classes together to tackle zero-shot multi-class classification. By further integrating label embedding into this framework, we produce a dual formulation that permits convenient incorporation of auxiliary label semantic knowledge to improve zero-shot learning. We conduct extensive experiments on three standard image data sets to evaluate the proposed approach by comparing to two state-of-the-art methods. Our results demonstrate the efficacy of the proposed framework.",
        "references": [
            "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef",
            "ab50e0fba1e7964d2686e90f9bed66a06ed6ff42",
            "caa632d101a41a7860562e4399a5eaa9a4088b55",
            "c30b9fb837e912ccf3919fdb64e9543fca57799e",
            "be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be",
            "516b1eda00a955043fbcf037f128b117c9d9b10c",
            "2750dbc60d5ccc8fbe5e4babae6cfab543940f1a",
            "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "88e090ffc1f75eed720b5afb167523eb2e316f7f",
            "3fd90098551bf88c7509521adf1c0ba9b5dfeb57"
        ],
        "related_topics": [
            "Zero-Shot Learning",
            "Unseen Classes",
            "Label Embedding",
            "Labeled Instances",
            "Max-margin"
        ],
        "reference_count": "28",
        "citation_count": "40"
    },
    {
        "Id": "846946cd21413211a4701f309c3927d67363cd30",
        "title": "Synthesized Classifiers for Zero-Shot Learning",
        "authors": [
            "Soravit Changpinyo",
            "Wei-Lun Chao",
            "Boqing Gong",
            "Fei Sha"
        ],
        "date": "2 March 2016",
        "abstract": "This work introduces a set of \"phantom\" object classes whose coordinates live in both the semantic space and the model space and demonstrates superior accuracy of this approach over the state of the art on four benchmark datasets for zero-shot learning. Given semantic descriptions of object classes, zero-shot learning aims to accurately recognize objects of the unseen classes, from which no examples are available at the training stage, by associating them to the seen classes, from which labeled examples are provided. We propose to tackle this problem from the perspective of manifold learning. Our main idea is to align the semantic space that is derived from external information to the model space that concerns itself with recognizing visual features. To this end, we introduce a set of \"phantom\" object classes whose coordinates live in both the semantic space and the model space. Serving as bases in a dictionary, they can be optimized from labeled data such that the synthesized real object classifiers achieve optimal discriminative performance. We demonstrate superior accuracy of our approach over the state of the art on four benchmark datasets for zero-shot learning, including the full ImageNet Fall 2011 dataset with more than 20,000 unseen classes.",
        "references": [
            "755e9f43ce398ae8737366720c5f82685b0c253e",
            "a6b8cd5f34b438f487679b1166ea03e56eb14c9e",
            "ac98259064e86f643f2cd11e5417b43bf28daa91",
            "b2a5c3744eea40c76d0359e517026e8ed6c922ff",
            "b58e0a726d5923f27b83d5cedd0b33fbe2142e45",
            "7c0773c7578433a2277e919ac824f142d5de351c",
            "ccbc09d498cad330c37f94e15b77bf220b10ccb4",
            "b0d08e25e46c28423b60668836d382fdf245e7d9",
            "018e730f8947173e1140210d4d1760d05c9d3854",
            "1b63449f310542b5f65a9c437ccd9e63fbef2f84"
        ],
        "related_topics": [
            "Synthesized Classifiers",
            "Unseen Classes",
            "Cub200 2011 Bird",
            "Semantic Space",
            "Zero-Shot Learning",
            "Animals With Attributes",
            "SUN Attribute",
            "Phantom Classes",
            "Unseen Class Labels",
            "Seen Classes"
        ],
        "reference_count": "55",
        "citation_count": "710"
    },
    {
        "Id": "ac98259064e86f643f2cd11e5417b43bf28daa91",
        "title": "Zero-Shot Learning via Semantic Similarity Embedding",
        "authors": [
            "Ziming Zhang",
            "Venkatesh Saligrama"
        ],
        "date": "15 September 2015",
        "abstract": "A version of the zero-shot learning problem where seen class source and target domain data are provided and the goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information for unseen classes. In this paper we consider a version of the zero-shot learning problem where seen class source and target domain data are provided. The goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information (e.g. attributes) for unseen classes. Our method is based on viewing each source or target data as a mixture of seen class proportions and we postulate that the mixture patterns have to be similar if the two instances belong to the same unseen class. This perspective leads us to learning source/target embedding functions that map an arbitrary source/target domain data into a same semantic space where similarity can be readily measured. We develop a max-margin framework to learn these similarity functions and jointly optimize parameters by means of cross validation. Our test results are compelling, leading to significant improvement in terms of accuracy on most benchmark datasets for zero-shot recognition.",
        "references": [
            "ccbc09d498cad330c37f94e15b77bf220b10ccb4",
            "755e9f43ce398ae8737366720c5f82685b0c253e",
            "caa632d101a41a7860562e4399a5eaa9a4088b55",
            "be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be",
            "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef",
            "ab50e0fba1e7964d2686e90f9bed66a06ed6ff42",
            "4aa4069693bee00d1b0759ca3df35e59284e9845",
            "018e730f8947173e1140210d4d1760d05c9d3854",
            "c30b9fb837e912ccf3919fdb64e9543fca57799e",
            "caccc069e658ea397c9faf673e74c959c734ff53"
        ],
        "related_topics": [
            "Semantic Similarity Embedding",
            "Unseen Classes",
            "Zero-Shot Learning",
            "SUN Attribute",
            "Zero-shot Recognition",
            "Projection Domain Shift Problem",
            "Seen Class Data",
            "Seen Classes",
            "Animals With Attributes",
            "aYahoo"
        ],
        "reference_count": "49",
        "citation_count": "581"
    },
    {
        "Id": "caa632d101a41a7860562e4399a5eaa9a4088b55",
        "title": "Label-Embedding for Attribute-Based Classification",
        "authors": [
            "Zeynep Akata",
            "Florent Perronnin",
            "Za{\\&quot;i}d Harchaoui",
            "Cordelia Schmid"
        ],
        "date": "23 June 2013",
        "abstract": "This work proposes to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors, and introduces a function which measures the compatibility between an image and a label embedding. Attributes are an intermediate representation, which enables parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function which measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. The label embedding framework offers other advantages such as the ability to leverage alternative sources of information in addition to attributes (e.g. class hierarchies) or to transition smoothly from zero-shot learning to learning with large quantities of data.",
        "references": [
            "54aacc196ffe49b3450059fccdf7cd3bb6f6f3c3",
            "88e090ffc1f75eed720b5afb167523eb2e316f7f",
            "a3ea706f6604a1e6e87c33d7a3b4b97b1bb338ef",
            "16a3c2c3e2bfbac65cc89a031b340a5951526183",
            "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "3a4a53fe47036ac89dad070ab87a9d8795b139b1",
            "9d69a7ab54c717df44f152c617a8cc76218437ff",
            "3089e6745b7dd50e41a3a50c6ff831415fe22739",
            "fc23a386c2189f221b25dbd0bb34fcd26ccf60fa",
            "c30b9fb837e912ccf3919fdb64e9543fca57799e"
        ],
        "related_topics": [
            "Direct Attribute Prediction",
            "Animals With Attributes",
            "Caltech-UCSD-Birds",
            "Zero-Shot Learning",
            "Attribute-Based Classification",
            "Label Embedding Framework",
            "WSABIE",
            "Compatibility Function",
            "Label Embedding Space",
            "Class Embeddings"
        ],
        "reference_count": "46",
        "citation_count": "615"
    },
    {
        "Id": "755e9f43ce398ae8737366720c5f82685b0c253e",
        "title": "Zero-Shot Learning Through Cross-Modal Transfer",
        "authors": [
            "Richard Socher",
            "Milind Ganjoo",
            "Christopher D. Manning",
            "A. Ng"
        ],
        "date": "16 January 2013",
        "abstract": "This work introduces a model that can recognize objects in images even if no training data is available for the object class, and uses novelty detection methods to differentiate unseen classes from seen classes. This work introduces a model that can recognize objects in images even if no training data is available for the object class. The only necessary knowledge about unseen visual categories comes from unsupervised text corpora. Unlike previous zero-shot learning models, which can only differentiate between unseen classes, our model can operate on a mixture of seen and unseen classes, simultaneously obtaining state of the art performance on classes with thousands of training images and reasonable performance on unseen classes. This is achieved by seeing the distributions of words in texts as a semantic space for understanding what objects look like. Our deep learning model does not require any manually defined semantic or visual features for either words or images. Images are mapped to be close to semantic word vectors corresponding to their classes, and the resulting image embeddings can be used to distinguish whether an image is of a seen or unseen class. We then use novelty detection methods to differentiate unseen classes from seen classes. We demonstrate two novelty detection strategies; the first gives high accuracy on unseen classes, while the second is conservative in its prediction of novelty and keeps the seen classes' accuracy high.",
        "references": [
            "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "812355cec91fa30bb50e9e992a3549af39e4f6eb",
            "5726c7b40fcc454b77d989656c085520bf6c15fa",
            "6eb3a15108dfdec25b46522ed94b866aeb156de9",
            "100a038fdf29b4b20801887f0ec40e3f10d9a4f9",
            "a78273144520d57e150744cf75206e881e11cc5b",
            "0f6911bc1e6abee8bbf9dd3f8d54d40466429da7",
            "0d8ec0d3ac8c8e0f6dcda6e0b1845d29e985e58b",
            "67fdc1e0d878675e9ac765830f85b461777e49ec"
        ],
        "related_topics": [
            "Unseen Classes",
            "Unseen Categories",
            "Zero-Shot Learning",
            "Semantic Space",
            "Zero-shot Learning Models",
            "Zero-shot Classes",
            "Semantic Word Spaces",
            "Semantic Word Vector",
            "Seen Classes",
            "Unseen"
        ],
        "reference_count": "36",
        "citation_count": "1,375"
    },
    {
        "Id": "244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa",
        "title": "Multi-cue Zero-Shot Learning with Strong Supervision",
        "authors": [
            "Zeynep Akata",
            "Mateusz Malinowski",
            "Mario Fritz",
            "Bernt Schiele"
        ],
        "date": "29 March 2016",
        "abstract": "This work introduces a joint embedding framework that maps multiple text parts as well as multiple semantic parts into a common space that consistently and significantly improves on the state-of-the-art in zero-short recognition and retrieval. Scaling up visual category recognition to large numbers of classes remains challenging. A promising research direction is zero-shot learning, which does not require any training data to recognize new classes, but rather relies on some form of auxiliary information describing the new classes. Ultimately, this may allow to use textbook knowledge that humans employ to learn about new classes by transferring knowledge from classes they know well. The most successful zero-shot learning approaches currently require a particular type of auxiliary information - namely attribute annotations performed by humans - that is not readily available for most classes. Our goal is to circumvent this bottleneck by substituting such annotations by extracting multiple pieces of information from multiple unstructured text sources readily available on the web. To compensate for the weaker form of auxiliary information, we incorporate stronger supervision in the form of semantic part annotations on the classes from which we transfer knowledge. We achieve our goal by a joint embedding framework that maps multiple text parts as well as multiple semantic parts into a common space. Our results consistently and significantly improve on the state-of-the-art in zero-short recognition and retrieval.",
        "references": [
            "ccbc09d498cad330c37f94e15b77bf220b10ccb4",
            "c30b9fb837e912ccf3919fdb64e9543fca57799e",
            "4aa4069693bee00d1b0759ca3df35e59284e9845",
            "6540cb7971d1a9d72562d465172e010fbb729bc3",
            "be2f5d8a7e6b415f1e22cee7dfd9be56b1afd8be",
            "caccc069e658ea397c9faf673e74c959c734ff53",
            "cb461276fad5710d8a7e2868867a9b01df040119",
            "aea0f946e8dcddb65cc2e907456c42453f246a50",
            "88e090ffc1f75eed720b5afb167523eb2e316f7f",
            "98bb60748eb8ef7a671cdd22faa87e377fd13060"
        ],
        "related_topics": [
            "Caltech UCSD Birds-2011",
            "Structured Joint Embedding",
            "Class-Attribute Associations",
            "Zero-Shot Learning",
            "Visual Category Recognition"
        ],
        "reference_count": "55",
        "citation_count": "138"
    },
    {
        "Id": "018e730f8947173e1140210d4d1760d05c9d3854",
        "title": "Zero-shot recognition with unreliable attributes",
        "authors": [
            "Dinesh Jayaraman",
            "Kristen Grauman"
        ],
        "date": "15 September 2014",
        "abstract": "This work proposes a novel random forest approach to train zero-shot models that explicitly accounts for the unreliability of attribute predictions, and obtains more robust discriminative models for the unseen classes by leveraging statistics about each attribute's error tendencies. In principle, zero-shot learning makes it possible to train a recognition model simply by specifying the category's attributes. For example, with classifiers for generic attributes like striped and four-legged, one can construct a classifier for the zebra category by enumerating which properties it possesses\u2014even without providing zebra training images. In practice, however, the standard zero-shot paradigm suffers because attribute predictions in novel images are hard to get right. We propose a novel random forest approach to train zero-shot models that explicitly accounts for the unreliability of attribute predictions. By leveraging statistics about each attribute's error tendencies, our method obtains more robust discriminative models for the unseen classes. We further devise extensions to handle the few-shot scenario and unreliable attribute descriptions. On three datasets, we demonstrate the benefit for visual category learning with zero or few training examples, a critical domain for rare categories or categories defined on the fly.",
        "references": [
            "88e090ffc1f75eed720b5afb167523eb2e316f7f",
            "23e568fcf0192e4ff5e6bed7507ee5b9e6c43598",
            "d6714ee0a3c3c5ead3d681d4bec8e60f042928ef",
            "2198f4130c4850ffebe52d5eeaefc61e15b60426",
            "5e470f5320ae9920b597422dfae5d5e1eadbf55e",
            "caa632d101a41a7860562e4399a5eaa9a4088b55",
            "3fd90098551bf88c7509521adf1c0ba9b5dfeb57",
            "4aa4069693bee00d1b0759ca3df35e59284e9845",
            "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "54aacc196ffe49b3450059fccdf7cd3bb6f6f3c3"
        ],
        "related_topics": [
            "Zero-shot Recognition",
            "Unseen Classes",
            "Class-Attribute Associations",
            "Direct Attribute Prediction",
            "aPascal",
            "Seen Class Images",
            "Attribute Prediction",
            "Recognition Model",
            "Rare Categories",
            "Classifier"
        ],
        "reference_count": "32",
        "citation_count": "283"
    },
    {
        "Id": "cb461276fad5710d8a7e2868867a9b01df040119",
        "title": "Label-Embedding for Image Classification",
        "authors": [
            "Zeynep Akata",
            "Florent Perronnin",
            "Za{\\&quot;i}d Harchaoui",
            "Cordelia Schmid"
        ],
        "date": "30 March 2015",
        "abstract": "This work proposes to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors, and introduces a function that measures the compatibility between an image and a label embedding. Attributes act as intermediate representations that enable parameter sharing between classes, a must when training data is scarce. We propose to view attribute-based image classification as a label-embedding problem: each class is embedded in the space of attribute vectors. We introduce a function that measures the compatibility between an image and a label embedding. The parameters of this function are learned on a training set of labeled samples to ensure that, given an image, the correct classes rank higher than the incorrect ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets show that the proposed framework outperforms the standard Direct Attribute Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a built-in ability to leverage alternative sources of information instead of or in addition to attributes, such as, e.g., class hierarchies or textual descriptions. Moreover, label embedding encompasses the whole range of learning settings from zero-shot learning to regular learning with a large number of labeled examples.",
        "references": [
            "caa632d101a41a7860562e4399a5eaa9a4088b55",
            "caccc069e658ea397c9faf673e74c959c734ff53",
            "54aacc196ffe49b3450059fccdf7cd3bb6f6f3c3",
            "88e090ffc1f75eed720b5afb167523eb2e316f7f",
            "755e9f43ce398ae8737366720c5f82685b0c253e",
            "4aa4069693bee00d1b0759ca3df35e59284e9845",
            "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "a3ea706f6604a1e6e87c33d7a3b4b97b1bb338ef",
            "3a4a53fe47036ac89dad070ab87a9d8795b139b1",
            "2198f4130c4850ffebe52d5eeaefc61e15b60426"
        ],
        "related_topics": [],
        "reference_count": "77",
        "citation_count": "669"
    },
    {
        "Id": "0590ec99d2b36b8922139078ac1a91fd62eeda61",
        "title": "Exploring Multimodal Approaches for Alzheimer's Disease Detection Using Patient Speech Transcript and Audio Data",
        "authors": [
            "Hongmin Cai",
            "Xiaoke Huang",
            "Zheng Liu",
            "Wenxiong Liao",
            "Haixing Dai",
            "Zihao Wu",
            "Dajiang Zhu",
            "Hui Ren",
            "Quanzheng Li",
            "Tianming Liu",
            "Xiang Li"
        ],
        "date": "5 July 2023",
        "abstract": "This study investigates various methods for detecting AD using patients' speech and transcripts data from the DementiaBank Pitt database using pre-trained language models and Graph Neural Network (GNN) that constructs a graph from the speech transcript, and extracts features using GNN for AD detection. Alzheimer's disease (AD) is a common form of dementia that severely impacts patient health. As AD impairs the patient's language understanding and expression ability, the speech of AD patients can serve as an indicator of this disease. This study investigates various methods for detecting AD using patients' speech and transcripts data from the DementiaBank Pitt database. The proposed approach involves pre-trained language models and Graph Neural Network (GNN) that constructs a graph from the speech transcript, and extracts features using GNN for AD detection. Data augmentation techniques, including synonym replacement, GPT-based augmenter, and so on, were used to address the small dataset size. Audio data was also introduced, and WavLM model was used to extract audio features. These features were then fused with text features using various methods. Finally, a contrastive learning approach was attempted by converting speech transcripts back to audio and using it for contrastive learning with the original audio. We conducted intensive experiments and analysis on the above methods. Our findings shed light on the challenges and potential solutions in AD detection using speech and audio data.",
        "references": [
            "623c9b5574306cb58c9ec20332726c0242bb8667",
            "37b87993a3681f83810e8a412a20e4c233f1f228",
            "664b507618929d9da1d7f4c30e4f849e765102eb",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "8bf3d85e625b591e517b96177ed7ac5983267a88",
            "28ec4da8fa83ceb95c3d557712a585ce286874fc",
            "ddb3481ebfb2ceb60fbc8341771568ee343692c0",
            "1067c44e473b6998f89e13f0d4c0de730def43f0",
            "1cbd65718ab7adf47ec372ed2e02a3409791218c",
            "416dab850fda842b13a4f28164514d98f836fff7"
        ],
        "related_topics": [
            "Graph Neural Network",
            "Contrastive Learning",
            "Language Understanding",
            "WavLM Models",
            "Synonym Replacement"
        ],
        "reference_count": "38",
        "citation_count": "6"
    },
    {
        "Id": "5896a22cbdf2c38ce0ddff2299b2c255e8584473",
        "title": "Alzheimer's Detection Using Demographic Information with a Combined Approach of Neural Network and Grid Search CV",
        "authors": [
            "Sofia Biju Francis",
            "Jai Prakash Verma",
            "Madhuri Bhavsar"
        ],
        "date": "8 November 2023",
        "abstract": "This paper focused on an integrated framework that achieved 92.26% accuracy in differentiating AD from NC using a Neural Net-work (NN), Grid Search Cross-Validation with Random Forest, and a few demographic factors related to Alzheimer's disease. Around the world, many are suffering from Demen-tia. It is mainly due to the neurological disorder and the onset of Alzheimer's Disease. Numerous studies have been conducted on its biomarker, Magnetic Resonance Imaging (MRI). Over the years, many algorithms, such as Neural Networks, Support Vector Machines, and various other Machine Learning algorithms, have been implemented to classify Alzheimer's Disease (AD) or Normal Control (NC) from the input MRI images. This paper focused on an integrated framework that achieved 92.26% accuracy in differentiating AD from NC using a Neural Net-work (NN), Grid Search Cross-Validation with Random Forest, and a few demographic factors related to Alzheimer's disease. The accuracies of the other three models-NN with Principal Component Analysis (85.32%), NN with t-SNE (82.57%), and Convolution Neural Networks (77.06%)-have been compared with it. Finer results than all were displayed by the suggested model. As a future extension to this model, we can install different IoT sensors on home appliances and attach them to AD patients themselves to continuously collect heterogeneous data from their behavioural patterns of daily activities and analyse them in the cloud to trigger other alarm sensors for family members or health workers when the AD patients are alone at home. IoT sensors can help confirm the sickness and protect the patient. Hence, the transformation of current healthcare facilities from hospital-centred to patient-centred is available.",
        "references": [
            "6db46220f3a2f9c50eb107953b8672e9529c6c79",
            "2ce3aa51b53da5d23539fe528a5ab9e2069ca7d4",
            "c882cadba1c22b671a77c907952d2eb0cad3a638",
            "56d3b485ef60c4d2631d2a25f01b9a3207a1e0ef",
            "ae43023e86268e1869e12665219d75dd9f5fad9e",
            "1099d1b8b0e514e5505569e79f56c3a9f285095d",
            "677a3d0fc891cd0b281b24e89592400d6e630141",
            "fd81880d09fa9997be8a0fccd5f1bf3fc4eb3fcb",
            "de1ee05fa26456c3e5d985e023fba04338087964",
            "643a53e1159006bc5af8344a2d85a053b52eba0f"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "33"
    },
    {
        "Id": "bb583b71b6a7f09a41e5a2840c16fae0dff325e7",
        "title": "Learning implicit sentiments in Alzheimer's disease recognition with contextual attention features",
        "authors": [
            "Ning-hong Liu",
            "Zhenming Yuan",
            "Yan Chen",
            "Chuang Liu",
            "Lingxing Wang"
        ],
        "date": "17 May 2023",
        "abstract": "The proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts. Background Alzheimer's disease (AD) is difficult to diagnose on the basis of language because of the implicit emotion of transcripts, which is defined as a supervised fuzzy implicit emotion classification at the document level. Recent neural network-based approaches have not paid attention to the implicit sentiments entailed in AD transcripts. Method A two-level attention mechanism is proposed to detect deep semantic information toward words and sentences, which enables it to attend to more words and fewer sentences differentially when constructing document representation. Specifically, a document vector was built by progressively aggregating important words into sentence vectors and important sentences into document vectors. Results Experimental results showed that our method achieved the best accuracy of 91.6% on annotated public Pitt corpora, which validates its effectiveness in learning implicit sentiment representation for our model. Conclusion The proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts.",
        "references": [
            "ca352ea6ac66c03a0cc22759098713e4202c71c6",
            "d24d3b28c48d1049395a7dc4e05cd00db87f32ea",
            "3d28cb8c175323409ab302780a55382a3cf5c2c9",
            "beccf5bc709167e483e8ea0f58829c34a2bde2e7",
            "4e4136382ddab4b5b357dd8c9c81789d930065fb",
            "bbeae238e2d1373b75ce20ce96b4a5b87383a622",
            "8e3a3ba309fe68f5b1d02266a03395332f7d945c",
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "623c9b5574306cb58c9ec20332726c0242bb8667",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323"
        ],
        "related_topics": [],
        "reference_count": "67",
        "citation_count": "2"
    },
    {
        "Id": "1b05a2c29d46c03585bbe066611b7048bf7ec80f",
        "title": "Speech and language processing with deep learning for dementia diagnosis: A systematic review",
        "authors": [
            "Mengke Shi",
            "Gary Cheung",
            "Seyed Reza Shahamiri"
        ],
        "date": "1 October 2023",
        "abstract": "Semantic Scholar extracted view of \"Speech and language processing with deep learning for dementia diagnosis: A systematic review\" by Mengke Shi et al.",
        "references": [
            "5442efa8c8f98e69da5e9894eb2281c449c294b1",
            "394fbb530d22b1cfb4b51e90acf0da488487b429",
            "7e3deabd44eccb0fe2823d8cecf1e182efeeb0f6",
            "de50ac922d8a6b0ddfa8d2770eeee556e007970d",
            "b5d78391f9a4a6b60cc3ef68eb25be3fcd6730d7",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "15c64acfdad83bb6784ec5a6f3af96728000101f",
            "31f87c120a46a60fe4928c12a55e3827a579906a",
            "b3537407b00c76103ac21bb7cd0ce7047dfdf025",
            "5671c7890b7bfa329b161144661126aa0bcc6480"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "145"
    },
    {
        "Id": "4538bf97bfe275d51e389de88a491622822750e9",
        "title": "Enhanced Classification of Alzheimer\u2019s Disease Stages via Weighted Optimized Deep Neural Networks and MRI Image Analysis",
        "authors": [
            "Mudiyala Aparna",
            "Battula Srinivasa Rao"
        ],
        "date": "30 October 2023",
        "abstract": "The proposed detection system employs two-phase transfer learning, augmented with fine-tuning for multi-class classification of brain MRI scans, which allows for the categorization of images into four distinct classes of Alzheimer's disease. Alzheimer's disease, a debilitating neurological disorder, precipitates irreversible cognitive decline and memory loss, predominantly affecting individuals aged 65 years and above. The need for an automated system capable of accurately diagnosing and stratifying Alzheimer's disease into distinct stages is paramount for early intervention and management. However, existing deep learning methodologies are often hampered by protracted training times. In this study, a time-efficient approach incorporating a two-phase transfer learning technique is proposed to surmount this challenge. This method is particularly efficacious in the analysis of Magnetic Resonance Imaging (MRI) data for the identification of Alzheimer's disease. The proposed detection system employs two-phase transfer learning, augmented with fine-tuning for multi-class classification of brain MRI scans. This allows for the categorization of images into four distinct classes: Mild Dementia (MD), Moderate Dementia (MOD), Non-Dementia (ND), and Very Mild Dementia (VMD). The classification of Alzheimer's disease was conducted using various pre-trained deep learning models, including ResNet50V2, InceptionResNetV2, Xception, DenseNet121, VGG16, and MobileNetV2. Among the models tested, ResNet50V2 demonstrated superior performance, achieving a training classification accuracy of 99.35% and a testing accuracy of 99.25%. The results underscore the potential of the proposed method in delivering more accurate classifications than those obtained from extant models, thereby contributing to the early detection and stratification of Alzheimer's disease.",
        "references": [
            "124689f476d0dcfba73454c2a24f45227cef9ae8",
            "d1df058b07fd63c112e6ba6949522675c418b33f",
            "0899c302317aa776ab7b9b9d7b41f9382f145d65",
            "e6821575cf6b692ce3327422822a9a929f903443",
            "1cda1f76c49e0ee2021bfaf2330e4cb7976eae78",
            "1242114389738c04aa86fb1ebcd3668fd880c946",
            "18d01f13782a210970d78fd8259585b69ead6ff6",
            "ffe0ed985400ff3825b5e2fe95bfa796f7c11c99",
            "7443e299fee19654b57481815a7ad3e4309de777",
            "c05ccf9baa41236d9327061db3eaa9567a88b4cb"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "32"
    },
    {
        "Id": "bcb1f54f3ab508840ed7b0ad49ea9926dcd8bbeb",
        "title": "Training Models on Oversampled Data and a Novel Multi-class Annotation Scheme for Dementia Detection",
        "authors": [
            "Nadine Abdelhalim",
            "Ingy Yasser Hassan Abdou Abdelhalim",
            "Riza Theresa Batista-Navarro"
        ],
        "date": "2023",
        "abstract": "A novel three-class annotation scheme for text-based dementia classification in patients, based on their recorded visit interactions, using BERT, RoBERTa and DistilBERT to improve the representation of dementia samples. This work introduces a novel three-class annotation scheme for text-based dementia classification in patients, based on their recorded visit interactions. Multiple models were developed utilising BERT, RoBERTa and DistilBERT. Two approaches were employed to improve the representation of dementia samples: oversampling the underrepresented data points in the original Pitt dataset and combining the Pitt with the Holland and Kempler datasets. The DistilBERT models trained on either an oversampled Pitt dataset or the combined dataset performed best in classifying the dementia class. Specifically, the model trained on the oversampled Pitt dataset and the one trained on the combined dataset obtained state-of-the-art performance with 98.8% overall accuracy and 98.6% macro-averaged F1-score, respectively. The models\u2019 outputs were manually inspected through saliency highlighting, using Local Interpretable Model-agnostic Explanations (LIME), to provide a better understanding of its predictions.",
        "references": [
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "26d037ce575791b4d455b58ad73c0b572c7b2fc6",
            "9e7b7d98e4bc4bb8a3545b7c9bde7f600ea117ad",
            "6d8052588c62e5bf2a073ae414867a78784ff663",
            "623c9b5574306cb58c9ec20332726c0242bb8667",
            "f1d94b29503b01df44456613463fb3f1ff48af9c",
            "be74c71f46bf42bb948d662fcd1ef137dc6dde45",
            "4d4117e4e5214dcc887317e302db724df545729e",
            "ccb6ff57ff24ee53d92acabf1978fcb4e034f5d4",
            "3ce917438bba77b3c73ee865512e6d66930b7090"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Annotation Scheme",
            "LOCAL INTERPRETABLE MODEL-AGNOSTIC EXPLANATIONS",
            "Oversampling",
            "Dementia Detection",
            "Robustly Optimized Bert Pretraining Approach"
        ],
        "reference_count": "47",
        "citation_count": "One"
    },
    {
        "Id": "b9e4b4ea648064ad382d1a4e73c604c9fbdbb10a",
        "title": "Artificial Intelligence for Cognitive Health Assessment: State-of-the-Art, Open Challenges and Future Directions",
        "authors": [
            "Abdul Rehman Javed",
            "Ayesha Saadia",
            "Huma Mughal",
            "Thippa Reddy Gadekallu",
            "Muhammad Rizwan",
            "Praveen Kumar Reddy Maddikunta",
            "Mufti Mahmud",
            "Madhusanka Liyanage",
            "Amir Hussain"
        ],
        "date": "24 June 2023",
        "abstract": "This first-of-its-kind survey paper will significantly contribute to identifying research gaps in the complex and rapidly evolving interdisciplinary mental health field and presents CHA tools, various data acquisition methods for CHA, and open issues, challenges in the CHA domain. The subjectivity and inaccuracy of in-clinic Cognitive Health Assessments (CHA) have led many researchers to explore ways to automate the process to make it more objective and to facilitate the needs of the healthcare industry. Artificial Intelligence (AI) and machine learning (ML) have emerged as the most promising approaches to automate the CHA process. In this paper, we explore the background of CHA and delve into the extensive research recently undertaken in this domain to provide a comprehensive survey of the state-of-the-art. In particular, a careful selection of significant works published in the literature is reviewed to elaborate a range of enabling technologies and AI/ML techniques used for CHA, including conventional supervised and unsupervised machine learning, deep learning, reinforcement learning, natural language processing, and image processing techniques. Furthermore, we provide an overview of various means of data acquisition and the benchmark datasets. Finally, we discuss open issues and challenges in using AI and ML for CHA along with some possible solutions. In summary, this paper presents CHA tools, lists various data acquisition methods for CHA, provides technological advancements, presents the usage of AI for CHA, and open issues, challenges in the CHA domain. We hope this first-of-its-kind survey paper will significantly contribute to identifying research gaps in the complex and rapidly evolving interdisciplinary mental health field.",
        "references": [
            "4af7e170f78d495b75ea8534ab032998035ecd80",
            "6be908576fd986e067cc5c32e4a40a45dcd02caf",
            "209577db989a342930fa5935a432b53e6d6e850b",
            "8df72c48a7ce4418c683c4dd9bb300558ac71d47",
            "1e66429be5124943280045b1b1071bef8a72b2c3",
            "85ee1f6e762dd7cb3944154c13d847c9c94907ee",
            "3539f67ba7f9025e2695709814aef4864843473b",
            "c041af0e08ccd1afb6b94e17e1da2539f5b34b7a",
            "39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "95928530a2bd9949e842538d5a709aa899fb5a8e"
        ],
        "related_topics": [],
        "reference_count": "311",
        "citation_count": "7"
    },
    {
        "Id": "978e25454938a59c73bcde187f305ae9f9f61975",
        "title": "Characterizing and detecting delirium with clinical and computational measures of speech and language disturbance",
        "authors": [
            "Sunny X. Tang",
            "Yan Cong",
            "Gwenyth Mercep",
            "Mutahira Bhatti",
            "Grace Serpe",
            "Valeria Gromova",
            "Sarah Berretta",
            "Majnu John",
            "Mark Y Liberman",
            "Liron D. Sinvani"
        ],
        "date": "4 July 2023",
        "abstract": "Computational speech and language features are promising as accurate, noninvasive and efficient biomarkers of delirium and may also be used to identify subthreshold cognitive disturbances among patients withDelirium. Background: Delirium is a critically underdiagnosed syndrome of altered mental status affecting more than 50% of older adults admitted to hospital. Few studies have incorporated speech and language disturbance in delirium detection. We sought to describe speech and language disturbances in delirium, and provide a proof of concept for detecting delirium using computational speech and language features. Methods: Participants underwent delirium assessment and completed language tasks. Speech and language disturbances were rated using standardized clinical scales. Recordings and transcripts were processed using an automated pipeline to extract acoustic and textual features. We used binomial, elastic net, machine learning models to predict delirium status. Results: We included 33 older adults admitted to hospital, of whom 10 met criteria for delirium. The group with delirium scored higher on total language disturbances and incoherence, and lower on category fluency. Both groups scored lower on category fluency than the normative population. Cognitive dysfunction as a continuous measure was correlated with higher total language disturbance, incoherence, loss of goal and lower category fluency. Including computational language features in the model predicting delirium status increased accuracy to 78%. Limitations: This was a proof-of-concept study with limited sample size, without a set-aside cross-validation sample. Subsequent studies are needed before establishing a generalizable model for detecting delirium. Conclusion: Language impairments were elevated among patients with delirium and may also be used to identify subthreshold cognitive disturbances. Computational speech and language features are promising as accurate, noninvasive and efficient biomarkers of delirium.",
        "references": [
            "bd383d1c53a5b7c0fb63d7e51e79e278645d8476",
            "a45dc8cb688df48d4f7cf0479e12ee835de9d3a4",
            "7f964a501a14b010d619dbf9ef536dfd72ecba97",
            "9d1ef255c823ca09a4a23aa5cb8e4c39f717dc54",
            "79dd01ac3bb2a0d970597d76cbca4b0e6a62bc7b",
            "55702ac4d44328c65b3091f6ba07dda1db9351f9",
            "7d8ff6dac1dbf5f4b6cf7ca9cccee2ddf948f93b",
            "3e9f4632dd8489774a2d1d70dbdacb8d5726c697",
            "808d68f5b8740309082e09698cf8246a8f925e1a",
            "e142e6646354b0b80c4148a8b2baff6042f4119f"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "54"
    },
    {
        "Id": "7913f57abb8b927e72be76d2197910aa0400c828",
        "title": "ChatGPT Demonstrates Potential for Identifying Psychiatric Disorders: Application to Childbirth-Related Post-Traumatic Stress Disorder",
        "authors": [
            "Alon Bartal",
            "Kathleen M. Jagodnik",
            "Sabrina J Chan",
            "Sharon Dekel"
        ],
        "date": "19 October 2023",
        "abstract": "This study examines ChatGPT\u2019s utility to identify post-traumatic stress disorder following childbirth (CB-PTSD), a maternal postpartum mental illness affecting millions of women annually, with no standard screening protocol, and develops an ML model that utilizesChatGPT's knowledge and outperformed ChatG PT and six previously published large language models trained on mental health or clinical domains data. Abstract Free-text analysis using Machine Learning (ML)-based Natural Language Processing (NLP) shows promise for diagnosing psychiatric conditions. Chat Generative Pre-trained Transformer (ChatGPT) has demonstrated initial feasibility for this purpose; however, this work remains preliminary, and whether it can accurately assess mental illness remains to be determined. This study examines ChatGPT\u2019s utility to identify post-traumatic stress disorder following childbirth (CB-PTSD), a maternal postpartum mental illness affecting millions of women annually, with no standard screening protocol. We explore ChatGPT\u2019s potential to screen for CB-PTSD by analyzing maternal childbirth narratives as the sole data source. By developing an ML model that utilizes ChatGPT\u2019s knowledge, we identify CB-PTSD via narrative classification. Our model outperformed (F1 score: 0.82) ChatGPT and six previously published large language models (LLMs) trained on mental health or clinical domains data, suggesting that ChatGPT can be harnessed to identify CB-PTSD. Our modeling approach can be generalized to assess other mental health disorders.",
        "references": [
            "3f48fa7ec5f89508e00c6e8b10eaae2e4c8094ae",
            "f8024852ad061dd7ea048467650ad9a8afcee894",
            "f4c4e148546089123f8da5db4fb246ab4062bd40",
            "9442019231e11d3e6eb3d4729dcaad7d7871c62c",
            "799f0f7524ad443765ae6b887da41a4c03baccf8",
            "f4f149e18505d0d7bad1cf025ff68d93bec74fea",
            "962a140c7e5eb392f53677cf16a27fa4be8883f0",
            "f6bb29e33d1763664e1c6b50167b27f10c0552c8",
            "1360e812b3d5031d3b78768a248311e3af1f1020",
            "d0689453df903a9f7d94de6f17e98ac9ee709c94"
        ],
        "related_topics": [],
        "reference_count": "64",
        "citation_count": "One"
    },
    {
        "Id": "ad93aa0e2120680bf19720f707768b7f350ce706",
        "title": "Understanding mental health through computers: An introduction to computational psychiatry",
        "authors": [
            "Juan Camilo Castro Mart{\\&#x27;i}nez",
            "Hernando Santamar{\\&#x27;i}a-Garc{\\&#x27;i}a"
        ],
        "date": "7 February 2023",
        "abstract": "A narrative review of the basis of the functioning of computational psychiatry with a critical analysis of its concepts helps psychiatry achieve precision and reproducibility, which can help the mental health field achieve significant advancement. Computational psychiatry recently established itself as a new tool in the study of mental disorders and problems. Integration of different levels of analysis is creating computational phenotypes with clinical and research values, and constructing a way to arrive at precision psychiatry are part of this new branch. It conceptualizes the brain as a computational organ that receives from the environment parameters to respond to challenges through calculations and algorithms in continuous feedback and feedforward loops with a permanent degree of uncertainty. Through this conception, one can seize an understanding of the cerebral and mental processes in the form of theories or hypotheses based on data. Using these approximations, a better understanding of the disorder and its different determinant factors facilitates the diagnostics and treatment by having an individual, ecologic, and holistic approach. It is a tool that can be used to homologate and integrate multiple sources of information given by several theoretical models. In conclusion, it helps psychiatry achieve precision and reproducibility, which can help the mental health field achieve significant advancement. This article is a narrative review of the basis of the functioning of computational psychiatry with a critical analysis of its concepts.",
        "references": [
            "a3ab2bc4c43d1f56c1f8cc47457d9888a888e78a",
            "48287368f40b0ab03ad92fcd12f786f448d339ae",
            "9b7b0adeb178e0fb220d7761a87d38026bad8d49",
            "42abde7800c25b90ec1bb9c88dfbe2ab37e5ae16",
            "42dbfa17fec3450adfe31b82faeab1e3b5c82be2",
            "23c8b47e7662f76cebf506e000fb6860e554517d",
            "3e34f105aec857eadff03f977020e525efa8d9aa",
            "101943270f5e89c662207d89db0a0e1519a460d7",
            "dacbb46d3a06e96c5f13f76e393e498dcbfb5de4",
            "1c9f7ab57ad72e071344266a8066078da263092e"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "165"
    },
    {
        "Id": "1b05a2c29d46c03585bbe066611b7048bf7ec80f",
        "title": "Speech and language processing with deep learning for dementia diagnosis: A systematic review",
        "authors": [
            "Mengke Shi",
            "Gary Cheung",
            "Seyed Reza Shahamiri"
        ],
        "date": "1 October 2023",
        "abstract": "Semantic Scholar extracted view of \"Speech and language processing with deep learning for dementia diagnosis: A systematic review\" by Mengke Shi et al.",
        "references": [
            "5442efa8c8f98e69da5e9894eb2281c449c294b1",
            "394fbb530d22b1cfb4b51e90acf0da488487b429",
            "7e3deabd44eccb0fe2823d8cecf1e182efeeb0f6",
            "de50ac922d8a6b0ddfa8d2770eeee556e007970d",
            "b5d78391f9a4a6b60cc3ef68eb25be3fcd6730d7",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "15c64acfdad83bb6784ec5a6f3af96728000101f",
            "31f87c120a46a60fe4928c12a55e3827a579906a",
            "b3537407b00c76103ac21bb7cd0ce7047dfdf025",
            "5671c7890b7bfa329b161144661126aa0bcc6480"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "145"
    },
    {
        "Id": "41015cf26ed07facde6b979fc6427a84a5386c84",
        "title": "revoAD: Revolutionizing Alzhiemer\u2019s Disease Diagnosis through Multimodal Machine Learning for Universal Screening via Speech and Handwriting Patterns",
        "authors": [
            "Benjamin M. Lu",
            "Abhinav Gurram"
        ],
        "date": "23 November 2023",
        "abstract": "This study employs machine learning (ML) to detect AD through speech and handwriting pattern analysis, promising to improve early detection and healthcare access and addressing healthcare disparities by offering low-cost screening, especially in underserved areas. Alzheimer's Disease (AD) is a global public health concern that leads to cognitive decline and memory loss. Existing AD diagnosis methods are invasive, expensive, and time-consuming. Hence, a cost-effective, highly sensitive screening tool is imperative. This study employs machine learning (ML) to detect AD through speech and handwriting pattern analysis. Over 15,000 samples, including audio, handwriting, and cognitive data from AD patients and controls, were preprocessed with Mel-Frequency cepstral coefficient testing, image normalization, binarization, and feature extraction. Six ML models were trained to detect AD based on both speech and handwriting markers like slurred speech, abrupt sentence endings, pronounced forgetfulness, legibility, stroke information, and zone-based features, achieving a combined F1-Score of 96.2% using an 80/20 split. The \"revoAD\" mobile app, developed with React JavaScript and Python OpenCV, achieved a 97.6% training accuracy, 97.3% data validation accuracy, and 10x faster diagnosis, addressing healthcare disparities by offering low-cost screening, especially in underserved areas. This study leveraged machine learning for AD diagnosis, promising to improve early detection and healthcare access.",
        "references": [
            "eec962309a9b3bbae2740045820a8df0f8cad13c",
            "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
            "647c4649b11a92d4797950d50a8294b1beaba22b",
            "9bbcf941d8b10dc17a99ac91d4e586b70d93591c",
            "47799e62dec053a48ae6da8b4658704c940a9492"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "14"
    },
    {
        "Id": "bb583b71b6a7f09a41e5a2840c16fae0dff325e7",
        "title": "Learning implicit sentiments in Alzheimer's disease recognition with contextual attention features",
        "authors": [
            "Ning-hong Liu",
            "Zhenming Yuan",
            "Yan Chen",
            "Chuang Liu",
            "Lingxing Wang"
        ],
        "date": "17 May 2023",
        "abstract": "The proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts. Background Alzheimer's disease (AD) is difficult to diagnose on the basis of language because of the implicit emotion of transcripts, which is defined as a supervised fuzzy implicit emotion classification at the document level. Recent neural network-based approaches have not paid attention to the implicit sentiments entailed in AD transcripts. Method A two-level attention mechanism is proposed to detect deep semantic information toward words and sentences, which enables it to attend to more words and fewer sentences differentially when constructing document representation. Specifically, a document vector was built by progressively aggregating important words into sentence vectors and important sentences into document vectors. Results Experimental results showed that our method achieved the best accuracy of 91.6% on annotated public Pitt corpora, which validates its effectiveness in learning implicit sentiment representation for our model. Conclusion The proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts.",
        "references": [
            "ca352ea6ac66c03a0cc22759098713e4202c71c6",
            "d24d3b28c48d1049395a7dc4e05cd00db87f32ea",
            "3d28cb8c175323409ab302780a55382a3cf5c2c9",
            "beccf5bc709167e483e8ea0f58829c34a2bde2e7",
            "4e4136382ddab4b5b357dd8c9c81789d930065fb",
            "bbeae238e2d1373b75ce20ce96b4a5b87383a622",
            "8e3a3ba309fe68f5b1d02266a03395332f7d945c",
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "623c9b5574306cb58c9ec20332726c0242bb8667",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323"
        ],
        "related_topics": [],
        "reference_count": "67",
        "citation_count": "2"
    },
    {
        "Id": "4f26063cde49c137bee1828f85733bbf805a31e7",
        "title": "Storyline-Centric Detection of Aphasia and Dysarthria in Stroke Patient Transcripts",
        "authors": [
            "Peiqi Sui",
            "K. Wong",
            "Xiaohui Yu",
            "John Volpi",
            "Stephen T. C. Wong"
        ],
        "date": "2023",
        "abstract": "This paper proposes a storyline-centric approach to detect aphasia and dysarthria in acute stroke patients using transcribed picture descriptions alone and enriches the training set with healthy data to address the lack of acute stroke patient data and utilizes knowledge distillation to improve upon a document classification baseline. Aphasia and dysarthria are both common symptoms of stroke, affecting around 30% and 50% of acute ischemic stroke patients. In this paper, we propose a storyline-centric approach to detect aphasia and dysarthria in acute stroke patients using transcribed picture descriptions alone. Our pipeline enriches the training set with healthy data to address the lack of acute stroke patient data and utilizes knowledge distillation to significantly improve upon a document classification baseline, achieving an AUC of 0.814 (aphasia) and 0.764 (dysarthria) on a patient-only validation set.",
        "references": [
            "03761dbd2ccb014e23c01354ec476111635ed46d",
            "d4959ce646c7558d3359c5fe6401aa7583b678b1",
            "18b0f0e45b9a3f94245d2f58be3242f3b7d4feda",
            "39e30ce21c6b236bc249c49be73be8ecc2ed6468",
            "8fff4c20af69475e2c301975e66ae3f835b7113d",
            "7e746ab1a6514a347ec4f155be50292e7a0d7178",
            "014dc117f999465195aebbbe1f0a1965267209fa",
            "811f2ef39e1f0af500c02c06a714cf375a311b1a",
            "871193857871e0b871175f8f5e6e61216e43594a",
            "70a82f36c0eb9c1b1312710de22da5b32bde6b6e"
        ],
        "related_topics": [
            "Dysarthria",
            "Training Set",
            "Knowledge Distillation",
            "Area Under The ROC Curve"
        ],
        "reference_count": "0",
        "citation_count": "36"
    },
    {
        "Id": "e9cb2518a4e34bcc73248884f3de4bc5b644115d",
        "title": "The Emerging Science of Interacting Minds.",
        "authors": [
            "Thalia Wheatley",
            "Mark A Thornton",
            "Arjen Stolk",
            "Luke J Chang"
        ],
        "date": "14 December 2023",
        "abstract": "For over a century, psychology has focused on uncovering mental processes of a single individual. However, humans rarely navigate the world in isolation. The most important determinants of successful development, mental health, and our individual traits and preferences arise from interacting with other individuals. Social interaction underpins who we are, how we think, and how we behave. Here we discuss the key methodological challenges that have limited progress in establishing a robust science of how minds interact and the new tools that are beginning to overcome these challenges. A deep understanding of the human mind requires studying the context within which it originates and exists: social interaction.",
        "references": [
            "a82f56482b9e63714ea0d1948ac3aa6edb092001",
            "b77eddd7a195c388a225fc10100e50d31ab038c7",
            "7340348cc4833ec1ba28056e265019b10bce41f0",
            "e6cf4f1e26e668a87f5c33f67909ac114e5a8e57",
            "5ea1e07fe80a6849554fc57f7d85408e9ac2faf1",
            "b9a8577b1e0e99d18ad7e14d82237d3ec8fd3efc",
            "499b98c1bccb209763eaf353dcfebb286e2167d4",
            "c9ba0edf41a8492762941f84caa1020e9a45e15c",
            "9665a85adfb860ba60e2f810ed2ee696dda6a6f5",
            "6b568474ff5c77df01fa139fe605a3f06ffb86c4"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "145"
    },
    {
        "Id": "a67e59ba96d86a0b609b84363dc212f3dfef97dd",
        "title": "Enriching Neural Models with Targeted Features for Dementia Detection",
        "authors": [
            "Flavio Di Palo",
            "Natalie Parde"
        ],
        "date": "13 June 2019",
        "abstract": "A neural model based on a CNN-LSTM architecture that is able to take in consideration both long language samples and hand-crafted linguistic features to distinguish between dementia affected and healthy patients is proposed. Alzheimers disease is an irreversible brain disease that slowly destroys memory skills andthinking skills leading to the need for full-time care. Early detection of Alzheimer\u2019s dis-ease is fundamental to slow down the progress of the disease. In this work we are developing Natural Language Processing techniques to detect linguistic characteristics of patients suffering Alzheimer\u2019s Disease and related Dementias. We are proposing a neural model based on a CNN-LSTM architecture that is able to take in consideration both long language samples and hand-crafted linguistic features to distinguish between dementia affected and healthy patients. We are exploring the effects of the introduction of an attention mechanism on both our model and the actual state of the art. Our approach is able to set a new state-of-the art on the DementiaBank dataset achieving an F1 Score of 0.929 in the Dementia patients classification Supplementary material include code to run the experiments.",
        "references": [
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "3f6989f605e650e14bae236568768172f4037382",
            "4d4117e4e5214dcc887317e302db724df545729e",
            "c573bafbede27c16015f6150bee264e4135a38be",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "f402db195032286e8a715e531aca1357ac6f4b3a",
            "10f62af29c3fc5e2572baddca559ffbfd6be8787",
            "137743ee8d930661ede1f297d9dc5b593b0d580c",
            "a716451b6135f39639c2eae5cc272eeba66ed6e8",
            "c46e455c47a3cdbf7cd2acf9ce12956e01849d52"
        ],
        "related_topics": [
            "DementiaBank Dataset",
            "Dementia Detection"
        ],
        "reference_count": "20",
        "citation_count": "25"
    },
    {
        "Id": "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
        "title": "Detecting Linguistic Characteristics of Alzheimer\u2019s Dementia by Interpreting Neural Models",
        "authors": [
            "Sweta Karlekar",
            "Tong Niu",
            "Mohit Bansal"
        ],
        "date": "17 April 2018",
        "abstract": "This work uses NLP techniques to classify and analyze the linguistic characteristics ofAD patients using the DementiaBank dataset, and shows that first derivative saliency can not only rediscover previous language patterns of AD patients, but also shed light on the limitations of neural models. Alzheimer\u2019s disease (AD) is an irreversible and progressive brain disease that can be stopped or slowed down with medical treatment. Language changes serve as a sign that a patient\u2019s cognitive functions have been impacted, potentially leading to early diagnosis. In this work, we use NLP techniques to classify and analyze the linguistic characteristics of AD patients using the DementiaBank dataset. We apply three neural models based on CNNs, LSTM-RNNs, and their combination, to distinguish between language samples from AD and control patients. We achieve a new independent benchmark accuracy for the AD classification task. More importantly, we next interpret what these neural models have learned about the linguistic characteristics of AD patients, via analysis based on activation clustering and first-derivative saliency techniques. We then perform novel automatic pattern discovery inside activation clusters, and consolidate AD patients\u2019 distinctive grammar patterns. Additionally, we show that first derivative saliency can not only rediscover previous language patterns of AD patients, but also shed light on the limitations of neural models. Lastly, we also include analysis of gender-separated AD data.",
        "references": [
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "73ee478f44296ee9a9e810fa106462ca52ece708",
            "e6ee69f334b71dc0edc72eecc3f29d0ef846560b",
            "25176248277bd8ad6aaf7a472be9ad21bcbddd9c",
            "c918ad033313ace6cb412063fc9f730ed348229c",
            "074a31b5599a3deebb869a0ded54ddccf86c5655",
            "1bb94d5f567071985b17cc117e6f59ad857aec55",
            "87812cc86532a63b0640ec909081ce081196f206",
            "347c431613fd835ca25a2de277a71de84f4a46c4",
            "543292e3965e681b322c86204a545e3ac915fef2"
        ],
        "related_topics": [
            "DementiaBank Dataset",
            "DementiaBank",
            "Grammar Patterns",
            "Alzheimer's Dementia",
            "Activation Clustering",
            "Convolutional Neural Network"
        ],
        "reference_count": "47",
        "citation_count": "95"
    },
    {
        "Id": "494d1214ad408719bd5e267cf6a4dad163af4121",
        "title": "Identifying Mild Cognitive Impairment and mild Alzheimer's disease based on spontaneous speech using ASR and linguistic features",
        "authors": [
            "G{\\&#x27;a}bor Gosztolya",
            "Veronika Vincze",
            "L{\\&#x27;a}szl{\\&#x27;o} T{\\&#x27;o}th",
            "Magdolna P{\\&#x27;a}k{\\&#x27;a}ski",
            "J{\\&#x27;a}nos K{\\&#x27;a}lm{\\&#x27;a}n",
            "Ildik{\\&#x27;o} Hoffmann"
        ],
        "date": "1 January 2019",
        "abstract": "Semantic Scholar extracted view of \"Identifying Mild Cognitive Impairment and mild Alzheimer's disease based on spontaneous speech using ASR and linguistic features\" by G. Gosztolya et al.",
        "references": [
            "651fd60a871cd7f06511da049427cd7702965884",
            "9eb018471ead7824f3e093673669a9c088044dce",
            "4dfd60a301f792311c7967f08b22d606091f9d12",
            "dd7a14b0d6d814e7351261e184eb4d273a5d21c7",
            "6687a4a7462fb3820676966dee405bc7e4e2d338",
            "be74c71f46bf42bb948d662fcd1ef137dc6dde45",
            "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c",
            "647c4649b11a92d4797950d50a8294b1beaba22b",
            "4e037757379916f6bfa904a07c7eadfe71b67ce0",
            "a3b6bc65831ca24a88b8ecf7277f170ecae086ee"
        ],
        "related_topics": [
            "Mild Cognitive Impairment",
            "Acoustic Features",
            "Automatic Speech Recognition",
            "Prodromal Stage"
        ],
        "reference_count": "93",
        "citation_count": "127"
    },
    {
        "Id": "6350a7fb5b32f6d7e32047a3ad7ff30a746789eb",
        "title": "Intelligent diagnosis of Alzheimer's disease based on internet of things monitoring system and deep learning classification method",
        "authors": [
            "Yuxin Zhou",
            "Yinan Lu",
            "Zhili Pei"
        ],
        "date": "1 June 2021",
        "abstract": "Semantic Scholar extracted view of \"Intelligent diagnosis of Alzheimer's disease based on internet of things monitoring system and deep learning classification method\" by Yuxin Zhou et al.",
        "references": [
            "ccc500ecb9fd7b41d5a6daaa0f78aeb63948109a",
            "816de9c362a4ce1236854dfec8739bbbbee9518d",
            "575ae1c5e66fa2e44d9790bea82925beb09a5940",
            "25b2e9cbcfbf71e90b726b3977ef0330dde304c8",
            "c793d39a7872f18317add7b1acd97b4adbab48e6",
            "572c3ffbe08f278d9166099ac3d6b0980e5f9e33",
            "a7213517703d260d951d246adedcb648cd19c207",
            "a6b68cce9eec9592cd64405b77b7ddb5e4e13a5c",
            "7758ce4126864d9669796edfd0ebb709399627b8",
            "f6a96626a5b68c2c97cd6ab8536912f659520531"
        ],
        "related_topics": [
            "Classification",
            "Virtual World",
            "Deep Learning",
            "Machine Learning"
        ],
        "reference_count": "18",
        "citation_count": "14"
    },
    {
        "Id": "3f6989f605e650e14bae236568768172f4037382",
        "title": "Deep language space neural network for classifying mild cognitive impairment and Alzheimer-type dementia",
        "authors": [
            "Sylvester Olubolu Orimaye",
            "Jojo Sze-Meng Wong",
            "Chee Piau Wong"
        ],
        "date": "7 November 2018",
        "abstract": "Results on the DementiaBank language transcript clinical dataset show that D2NNLM sufficiently learned several linguistic biomarkers in the form of higher order n-grams to distinguish the affected group from the healthy group with reasonable accuracy on very sparse clinical datasets. It has been quite a challenge to diagnose Mild Cognitive Impairment due to Alzheimer\u2019s disease (MCI) and Alzheimer-type dementia (AD-type dementia) using the currently available clinical diagnostic criteria and neuropsychological examinations. As such we propose an automated diagnostic technique using a variant of deep neural networks language models (DNNLM) on the verbal utterances of affected individuals. Motivated by the success of DNNLM on natural language tasks, we propose a combination of deep neural network and deep language models (D2NNLM) for classifying the disease. Results on the DementiaBank language transcript clinical dataset show that D2NNLM sufficiently learned several linguistic biomarkers in the form of higher order n-grams to distinguish the affected group from the healthy group with reasonable accuracy on very sparse clinical datasets.",
        "references": [
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "bca9453da6fbfd06ff9db5bbcb25fabaf9370e22",
            "323615e2591dd62ba51893b680226d9bf72c7d4d",
            "7f26f5e00cacea08c5f8a1149d35764b4b11bf8c",
            "0e19ff870d42fe9fb11a273da3ba8598a3b39b4d",
            "9f79b994b6bbb2da8002582200f6f0b8ba6daf91",
            "03a669f9be0925ad2a1bd07f86e8479955f6a86b",
            "3e5c06e477cf11a0b5823338b4ad31c103dbee5b",
            "4dc3d29f66e887c780343226c8a4278df758a17e",
            "137743ee8d930661ede1f297d9dc5b593b0d580c"
        ],
        "related_topics": [],
        "reference_count": "35",
        "citation_count": "40"
    },
    {
        "Id": "efce1c12cc5782df6384831352e3d43f43bf71ed",
        "title": "A curious case of retrogenesis in language: Automated analysis of language patterns observed in dementia patients and young children",
        "authors": [
            "Changye Li",
            "Jacob Solinsky",
            "Trevor Cohen",
            "Serguei V. S. Pakhomov"
        ],
        "date": "1 December 2023",
        "abstract": "Semantic Scholar extracted view of \"A curious case of retrogenesis in language: Automated analysis of language patterns observed in dementia patients and young children\" by Changye Li et al.",
        "references": [
            "b4618a41a6d40e19ae49b03be8b8c41779543fd7",
            "b5fdd83f8235655c41c784769197e2b25598fcca",
            "7000ae3610001d5dfa5454b61989ab051e03cd6d",
            "99979db50a6f2cdb43225240e44f1928e778554d",
            "6e087bd8e75513a2d3754e460bba742aa61060d0",
            "f8205b602f6cce0dd7ef541ae47235a7e5290f62",
            "2d980880f0caa633ff54d4de9a327ddd5c9348e0",
            "7b20bf88fbeb59ffcbfbf6d431aad84493fc4a25",
            "0959830b666ec7871b547a486076a706571c3e5a",
            "ebbd2cfd1f98d77d7a16db4509c5aaee5ec6f63c"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "36"
    },
    {
        "Id": "579bc5c379054a03b4ce408fe1f03d58647b6aca",
        "title": "Modeling Visual Impairments with Artificial Neural Networks: a Review",
        "authors": [
            "Lucia Schiatti",
            "Monica Gori",
            "Martin Schrimpf",
            "Giulia Cappagli",
            "Federica Morelli",
            "Sabrina Signorini",
            "Boris Katz",
            "Andrei Barbu"
        ],
        "date": "2 October 2023",
        "abstract": "An approach to bridge the gap between the computational models of human vision and the clinical practice on visual impairments (VI) is presented and guidelines to inform the future research about developing and deploying ANNs for clinical applications targeting individuals affected by VI are provided. We present an approach to bridge the gap between the computational models of human vision and the clinical practice on visual impairments (VI). In a nutshell, we propose to connect advances in neuroscience and machine learning to study the impact of VI on key functional competencies and improve treatment strategies. We review related literature, with the goal of promoting the full exploitation of Artificial Neural Network (ANN) models in meeting the needs of visually impaired individuals and the operators working in the field of visual rehabilitation. We first summarize the existing types of visual issues, the key functional vision-related tasks, and the current methodologies used for the assessment of both. Second, we explore the ANNs best suitable to model visual issues and to predict their impact on functional vision-related tasks, at a behavioral (including performance and attention measures) and neural level. We provide guidelines to inform the future research about developing and deploying ANNs for clinical applications targeting individuals affected by VI.",
        "references": [
            "d581b13baa0a3e6ae86da95c89c4ceb2235f2e77",
            "8a92f3fae816f429e399102e8b3ec21a775c902a",
            "b8142ab69de155e9bfc331dcf61d6e84c65e3fb0",
            "3d2452af501a599e27687b96e438e8570ef42670",
            "4dc16756924bd25600a1616c8be1320a82a1d4dd",
            "f6d069cdd805421e0222929698226d447372643d",
            "86f65dc9c715afcc6c37acf42e183a330e43355b",
            "ebf1d7a04b3e0a2d9380eee612771913327ef7b3",
            "8e6e5ae88ae5ba147e02ccfc963fb8044cf031b5",
            "3ecc7ac21c22af073f37294df341c51e5d2d576d"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "114"
    },
    {
        "Id": "772724892819d7e6f15ce536753fdc32d022c0e0",
        "title": "A Survey on Image-text Multimodal Models",
        "authors": [
            "Ruifeng Guo",
            "Jingxuan Wei",
            "Linzhuang Sun",
            "Bihui Yu",
            "Guiyong Chang",
            "Dawei Liu",
            "Sibo Zhang",
            "Zhengbing Yao",
            "Mingjun Xu",
            "Liping Bu"
        ],
        "date": "23 September 2023",
        "abstract": "An exhaustive overview of the present research landscape of image-text multimodal models is offered, introducing a novel classification that segments their evolution into three distinct phases, based on their time of introduction and subsequent impact on the discipline. Amidst the evolving landscape of artificial intelligence, the convergence of visual and textual information has surfaced as a crucial frontier, leading to the advent of image-text multimodal models. This paper provides a comprehensive review of the evolution and current state of image-text multimodal models, exploring their application value, challenges, and potential research trajectories. Initially, we revisit the basic concepts and developmental milestones of these models, introducing a novel classification that segments their evolution into three distinct phases, based on their time of introduction and subsequent impact on the discipline. Furthermore, based on the tasks' significance and prevalence in the academic landscape, we propose a categorization of the tasks associated with image-text multimodal models into five major types, elucidating the recent progress and key technologies within each category. Despite the remarkable accomplishments of these models, numerous challenges and issues persist. This paper delves into the inherent challenges and limitations of image-text multimodal models, fostering the exploration of prospective research directions. Our objective is to offer an exhaustive overview of the present research landscape of image-text multimodal models and to serve as a valuable reference for future scholarly endeavors. We extend an invitation to the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \\href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.",
        "references": [
            "fa6d5345d860892ee3c911ee387fa136942cfc67",
            "35ccd924de9e8483bdcf144cbf2edf09be157b7e",
            "1c83f3f9789df43bf937ae2618721e2da83dcc06",
            "639ed85b464554ebebddc6b9bddd2b364f1cb8ef",
            "be83cbda0b830a9c56dc0e25e53a09fbf955fcab",
            "45dd2a3cd7c27f2e9509b023d702408f5ac11c9d",
            "f1d449cfb19658a8a6b053803ed2f073d2becf36",
            "51615bee01c966ba055920e10778d5331d35bccd",
            "fe66fc9e3d9a52497119bab89ac54fc8b5f8859a",
            "f583bdb250eb1d25aea7d074299ee962cab1d008"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "229"
    },
    {
        "Id": "73e9d798df491cc8015c81064129af3ac984e406",
        "title": "Noninvasive automatic detection of Alzheimer's disease from spontaneous speech: a review",
        "authors": [
            "Xiaoke Qi",
            "Qing Zhou",
            "Jian Dong",
            "Wei Bao"
        ],
        "date": "24 August 2023",
        "abstract": "This paper systematically reviews the technologies to detect the onset of AD from spontaneous speech, including data collection, feature extraction and classification, and addresses challenges related to data size, model explainability, reliability and multimodality fusion. Alzheimer's disease (AD) is considered as one of the leading causes of death among people over the age of 70 that is characterized by memory degradation and language impairment. Due to language dysfunction observed in individuals with AD patients, the speech-based methods offer non-invasive, convenient, and cost-effective solutions for the automatic detection of AD. This paper systematically reviews the technologies to detect the onset of AD from spontaneous speech, including data collection, feature extraction and classification. First the paper formulates the task of automatic detection of AD and describes the process of data collection. Then, feature extractors from speech data and transcripts are reviewed, which mainly contains acoustic features from speech and linguistic features from text. Especially, general handcrafted features and deep embedding features are organized from different modalities. Additionally, this paper summarizes optimization strategies for AD detection systems. Finally, the paper addresses challenges related to data size, model explainability, reliability and multimodality fusion, and discusses potential research directions based on these challenges.",
        "references": [
            "b3537407b00c76103ac21bb7cd0ce7047dfdf025",
            "37b87993a3681f83810e8a412a20e4c233f1f228",
            "92e0608730573341ac43955f2946513f2a5814c4",
            "f91cc0dccd52e1de92d54472d983803febafdf23",
            "da19f6acf469453b1e02cd0be1b7b0e5731b5ec6",
            "06961f070ae235beb6e4424e2e2c740a4444a5ae",
            "d8dd064712d8c7d6bdc4dc5ea02ac2b43539ebcf",
            "329f607e918d0fbb2e4ed2868859e94bfa2691e3",
            "ceb4b96216d4538589fd7dcd3c043e1cd365cdee",
            "80960b590d1a369983e1cb913170288a8fa4be72"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "150"
    },
    {
        "Id": "811238aa81bc93a6ce39aaf342bea4584aad8ce1",
        "title": "Repurposing Artificial Intelligence Tools for Disease Modeling: Case Study of Face Recognition Deficits in Neurodegenerative Diseases",
        "authors": [
            "Gargi Singh",
            "Murali Ramanathan"
        ],
        "date": "2 July 2023",
        "abstract": "As predicted from modeling, brain network failure quotient was related to key clinical outcome measures for cognition and functioning and perturbation of AI networks is a promising method for modeling disease progression effects on complex cognitive outcomes. Face recognition deficits occur in diseases such as prosopagnosia, autism, Alzheimer's disease, and dementias. The objective of this study was to evaluate whether degrading the architecture of artificial intelligence (AI) face recognition algorithms can model deficits in diseases. Two established face recognition models, convolutional\u2010classification neural network (C\u2010CNN) and Siamese network (SN), were trained on the FEI faces data set (~\u200914 images/person for 200 persons). The trained networks were perturbed by reducing weights (weakening) and node count (lesioning) to emulate brain tissue dysfunction and lesions, respectively. Accuracy assessments were used as surrogates for face recognition deficits. The findings were compared with clinical outcomes from the Alzheimer's Disease Neuroimaging Initiative (ADNI) data set. Face recognition accuracy decreased gradually for weakening factors less than 0.55 for C\u2010CNN, and 0.85 for SN. Rapid accuracy loss occurred at higher values. C\u2010CNN accuracy was similarly affected by weakening any convolutional layer whereas SN accuracy was more sensitive to weakening of the first convolutional layer. SN accuracy declined gradually with a rapid drop when nearly all nodes were lesioned. C\u2010CNN accuracy declined rapidly when as few as 10% of nodes were lesioned. CNN and SN were more sensitive to lesioning of the first convolutional layer. Overall, SN was more robust than C\u2010CNN, and the findings from SN experiments were concordant with ADNI results. As predicted from modeling, brain network failure quotient was related to key clinical outcome measures for cognition and functioning. Perturbation of AI networks is a promising method for modeling disease progression effects on complex cognitive outcomes.",
        "references": [
            "d5eb870dd0a6266e9a151bf1812708c4a4db929d",
            "7b361ec46e601a188f34a5415539915db7830c9f",
            "b5fdd83f8235655c41c784769197e2b25598fcca",
            "02d5f66e7a9111cfa2b866e0a9b01a7f3cac53dd",
            "d18c27657893355ee7b282976be800b7ce68dfd7",
            "fc2862d5f799a640d952774970284005dd0b9292",
            "0f2aa6ed82c4784911adf6516a4d87946280ac3b",
            "11da0c62b5131f75cbe782466498649bb9972d3f",
            "0b215fee753609f55722df000ff6eb33866cbb56",
            "eb61110addb425398f0cf74232a20c21ac828cc2"
        ],
        "related_topics": [],
        "reference_count": "40",
        "citation_count": "One"
    },
    {
        "Id": "b69f700ab0f8297230d02108ea399cc7f55803f4",
        "title": "Language Models for German Text Simplification: Overcoming Parallel Data Scarcity through Style-specific Pre-training",
        "authors": [
            "Miriam Ansch{\\&quot;u}tz",
            "Joshua Oehms",
            "Thomas Wimmer",
            "Bartlomiej Jezierski",
            "George Louis Groh"
        ],
        "date": "22 May 2023",
        "abstract": "This work fine-tuned language models on a corpus of German Easy Language, a specific style of German, and used them as decoders in a sequence-to-sequence simplification task, indicating that pre-training on unaligned data can reduce the required parallel data while improving the performance on downstream tasks. Automatic text simplification systems help to reduce textual information barriers on the internet. However, for languages other than English, only few parallel data to train these systems exists. We propose a two-step approach to overcome this data scarcity issue. First, we fine-tuned language models on a corpus of German Easy Language, a specific style of German. Then, we used these models as decoders in a sequence-to-sequence simplification task. We show that the language models adapt to the style characteristics of Easy Language and output more accessible texts. Moreover, with the style-specific pre-training, we reduced the number of trainable parameters in text simplification models. Hence, less parallel data is sufficient for training. Our results indicate that pre-training on unaligned data can reduce the required parallel data while improving the performance on downstream tasks.",
        "references": [
            "7ae2ee48e106a8f9d84f89f8da3f6076a5497d33",
            "04a751a83cb1d5ddb99203762017b985b19a7793",
            "5bdaf318e4cbf3df4c8e965c090290409e11cdab",
            "9a89adc19bc33b02afc7ce5e9cab0c690e09fd4b",
            "edd9f10eaa90d0f0d8921555c254dbf0955aa27c",
            "254bb5439b44eee6397cc014eae01dc494aa5078",
            "eb0024439858af7cc951ce2efa5a6533c3781799",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "98050eeda3b79a18f555480881e1f3bc7d447882",
            "492a655a67e6ec7423a968cedb70eec0cdbc8e98"
        ],
        "related_topics": [
            "Language Models",
            "Parallel Data",
            "Pre-training",
            "Trainable Parameters",
            "Easy Language"
        ],
        "reference_count": "41",
        "citation_count": "4"
    },
    {
        "Id": "83353af505b4012d6b661932e5ffcbbdde1b59d2",
        "title": "TRESTLE: Toolkit for Reproducible Execution of Speech, Text and Language Experiments",
        "authors": [
            "Changye Li",
            "Trevor A. Cohen",
            "Martin Michalowski",
            "Serguei V. S. Pakhomov"
        ],
        "date": "14 February 2023",
        "abstract": "TRESTLE provides a precise digital blueprint of the data pre-processing and selection strategies that can be reused via TRESTLE by other researchers seeking comparable results with their peers and current state-of-the-art (SOTA) approaches. The evidence is growing that machine and deep learning methods can learn the subtle differences between the language produced by people with various forms of cognitive impairment such as dementia and cognitively healthy individuals. Valuable public data repositories such as TalkBank have made it possible for researchers in the computational community to join forces and learn from each other to make significant advances in this area. However, due to variability in approaches and data selection strategies used by various researchers, results obtained by different groups have been difficult to compare directly. In this paper, we present TRESTLE (Toolkit for Reproducible Execution of Speech Text and Language Experiments), an open source platform that focuses on two datasets from the TalkBank repository with dementia detection as an illustrative domain. Successfully deployed in the hackallenge (Hackathon/Challenge) of the International Workshop on Health Intelligence at AAAI 2022, TRESTLE provides a precise digital blueprint of the data pre-processing and selection strategies that can be reused via TRESTLE by other researchers seeking comparable results with their peers and current state-of-the-art (SOTA) approaches.",
        "references": [
            "b5fdd83f8235655c41c784769197e2b25598fcca",
            "99979db50a6f2cdb43225240e44f1928e778554d",
            "d1511472de8df3ac57290aa501dbd72ec087e3ae",
            "00c5abdffe51ab33e745e6804d4821ca59db52d8",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "3cf13e7e55c833276f90ba7a1023667698e39784",
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "bb50e8c44e783ec626351ca7471e1ede6ea37600",
            "d4d0917b77242660b1d285e20a636e4e8acc8a64"
        ],
        "related_topics": [
            "TalkBank",
            "Health Intelligence",
            "Deep Learning",
            "Self-organizing Tree Algorithm"
        ],
        "reference_count": "27",
        "citation_count": "One"
    },
    {
        "Id": "696d3990ad70d71da4e45a6e0fb80e38ddec1bd6",
        "title": "Addressing Domain Changes in Task-oriented Conversational Agents through Dialogue Adaptation",
        "authors": [
            "Tiziano Labruna",
            "Bernardo Magnini"
        ],
        "date": "2023",
        "abstract": "It is suggested that automatic adaptation of training dialogues is a valuable option for re-training obsolete models, based on fine-tuning a generative language model on domain changes, and a significant reduction of performance decrease can be obtained. Recent task-oriented dialogue systems are trained on annotated dialogues, which, in turn, reflect certain domain information (e.g., restaurants or hotels in a given region). However, when such domain knowledge changes (e.g., new restaurants open), the initial dialogue model may become obsolete, decreasing the overall performance of the system. Through a number of experiments, we show, for instance, that adding 50{% of new slot-values reduces of about 55{% the dialogue state-tracker performance. In light of such evidence, we suggest that automatic adaptation of training dialogues is a valuable option for re-training obsolete models. We experimented with a dialogue adaptation approach based on fine-tuning a generative language model on domain changes, showing that a significant reduction of performance decrease can be obtained.",
        "references": [
            "d19c259bae0f83ddada49126787d78a984a4038a",
            "f3bb4b4799f895e34a807cf5c263af3679b43a22",
            "f13981668a98173bf6b49310f171a2093167a027",
            "27816b13be7f75d371beaf337a4e824c69f7c4d5",
            "83c2cd0a435a4e85867e81a71d882d2517fed7e6",
            "cc6e9983b81c67245126235927d7d9e10fb9a1f5",
            "3b0615caf74c7c84a33be78813ec7ebd0f53033d",
            "71f4f230ae9dcccf9a5d2dde5f58bf19e2ab68c0",
            "d3029c069391618357de91f9e45844fb97983eaa",
            "60a821cb03f647b5dfb86eae57f79e49bfdf74f5"
        ],
        "related_topics": [
            "Task-oriented Dialogue Systems",
            "Fine-tuning",
            "Training Dialogues",
            "Conversational Agents",
            "Slot-values",
            "Dialogue Models"
        ],
        "reference_count": "0",
        "citation_count": "26"
    },
    {
        "Id": "bbc32621d343194c4e29c72a9af3c36d342c0164",
        "title": "Towards Domain-Agnostic and Domain-Adaptive Dementia Detection from Spoken Language",
        "authors": [
            "Shahla Farzana",
            "Natalie Parde"
        ],
        "date": "2023",
        "abstract": "Domain adaptation techniques on heterogeneous spoken language data to evaluate generalizability across diverse datasets for a common task: dementia detection find that adapted models exhibit better performance across conversational and task-oriented datasets. Health-related speech datasets are often small and varied in focus. This makes it difficult to leverage them to effectively support healthcare goals. Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern. To test this hypothesis, we experiment with domain adaptation (DA) techniques on heterogeneous spoken language data to evaluate generalizability across diverse datasets for a common task: dementia detection. We find that adapted models exhibit better performance across conversational and task-oriented datasets. The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline. This suggests promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task.",
        "references": [
            "3838e92e4a20e230c697c107638d5fea542181f8",
            "2927bca0d547eca38e49c19de792a5494c186738",
            "964930b97056dce8a2bfb38f3f3d66ab3e160cb1",
            "58b58e76a7394bc1028bde01992b943b4dbea255",
            "c48309c3ffe8bc5f168ba1c18e382721f5f10d00",
            "b5fdd83f8235655c41c784769197e2b25598fcca",
            "360a653f4a7cf84145b9f90f42962e2abf2ddb1c",
            "00c5abdffe51ab33e745e6804d4821ca59db52d8",
            "d1511472de8df3ac57290aa501dbd72ec087e3ae",
            "5c9eb6965c362599beceac8fd29f23581991f5fd"
        ],
        "related_topics": [
            "Dementia Detection",
            "Domain Adaptation",
            "Domain Adaptive"
        ],
        "reference_count": "0",
        "citation_count": "51"
    },
    {
        "Id": "58b58e76a7394bc1028bde01992b943b4dbea255",
        "title": "Are Interaction Patterns Helpful for Task-Agnostic Dementia Detection? An Empirical Exploration",
        "authors": [
            "Shahla Farzana",
            "Natalie Parde"
        ],
        "date": "2022",
        "abstract": "This study adapts an existing DA annotation scheme for two different cognitive tasks present in a popular dementia detection dataset and shows that a DA tagging model leveraging neural sentence embeddings and other information from previous utterances and speaker tags achieves strong performance for both tasks. Dementia often manifests in dialog through specific behaviors such as requesting clarification, communicating repetitive ideas, and stalling, prompting conversational partners to probe or otherwise attempt to elicit information. Dialog act (DA) sequences can have predictive power for dementia detection through their potential to capture these meaningful interaction patterns. However, most existing work in this space relies on content-dependent features, raising questions about their generalizability beyond small reference sets or across different cognitive tasks. In this paper, we adapt an existing DA annotation scheme for two different cognitive tasks present in a popular dementia detection dataset. We show that a DA tagging model leveraging neural sentence embeddings and other information from previous utterances and speaker tags achieves strong performance for both tasks. We also propose content-free interaction features and show that they yield high utility in distinguishing dementia and control subjects across different tasks. Our study provides a step toward better understanding how interaction patterns in spontaneous dialog affect cognitive modeling across different tasks, which carries implications for the design of non-invasive and low-cost cognitive health monitoring tools for use at scale.",
        "references": [
            "b5fdd83f8235655c41c784769197e2b25598fcca",
            "322be2c047c4464942a0ef9c7e0bc8bc0290c541",
            "11fe0b9c4891f8d73ea68b5a48acb1063aa48427",
            "c8855b7e84b08c6c86c252853d068c8dc9d7ad4e",
            "cf0c7194c5342f4d167e95c54685f5f564a7d12b",
            "42935dca0480af822180510a2b364826dcd8a870",
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "02b210f6d2d6872018797efa317789c1768d99e9",
            "a67e59ba96d86a0b609b84363dc212f3dfef97dd",
            "360a653f4a7cf84145b9f90f42962e2abf2ddb1c"
        ],
        "related_topics": [
            "Dementia Detection",
            "Task-agnostic",
            "Dialog Acts",
            "Dialog",
            "Stalling"
        ],
        "reference_count": "36",
        "citation_count": "One"
    },
    {
        "Id": "38bc595650d0d3e4cbb94c07a48f612e70210843",
        "title": "Exploring multi-task learning and data augmentation in dementia detection with self-supervised pretrained models",
        "authors": [
            "Minchuan Chen",
            "Chenfeng Miao",
            "Jun Ma",
            "Shaojun Wang",
            "Jing Xiao"
        ],
        "date": "20 August 2023",
        "abstract": "This work shows that fine-tuning the pretrained SSL models, in conjunction with multi-task learning and data augmentation, boosts the effectiveness of general-purpose speech representations in AD detection. Detection of Alzheimer\u2019s Dementia (AD) is crucial for timely intervention to slow down disease progression. Using sponta-neous speech to detect AD is a non-invasive, efficient and inexpensive approach. Recent innovations in self-supervised learning (SSL) have led to remarkable advances in speech processing. In this work, we investigate a set of SSL models using joint fine-tuning strategy and compare their performance with conventional classification model. Our work shows that fine-tuning the pretrained SSL models, in conjunction with multi-task learning and data augmentation, boosts the effectiveness of general-purpose speech representations in AD detection. The results surpass the baseline and are comparable to state-of-the-art performance on the popular ADReSS dataset. We also compare single-and multi-task training for AD classification, and analyze different augmentation methods to show how to achieve improved results.",
        "references": [
            "915a55642ba2930061f625b86fee7daa362769cf",
            "0932bef7467fdd06f6e22ad2562f1cf377be0e5e",
            "0d678b625e12a4f09e859aa100e66a39531f7c80",
            "6ed99d798eb838c1f8b3a3c56c4467975ac7ae60",
            "00c5abdffe51ab33e745e6804d4821ca59db52d8",
            "92e0608730573341ac43955f2946513f2a5814c4",
            "360a653f4a7cf84145b9f90f42962e2abf2ddb1c",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "134d608f4e78da82c9c3c119f57cbde32e220f5e",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "38"
    },
    {
        "Id": "1930a3e7bdf26caa9922d87669539b7ecc571e87",
        "title": "An Exploration of Multimodality and Data Augmentation for Dementia Classification",
        "authors": [
            "Kaiying Lin",
            "Peter Washington"
        ],
        "date": "6 November 2023",
        "abstract": "It is indicated that synonym-based text data augmentation generally enhances model performance, underscoring the importance of data volume for achieving generalizable performance, and models trained on text data frequently excel and can further improve the performance of other modalities when combined. Dementia is a progressive neurological disorder that profoundly affects the daily lives of older adults, impairing abilities such as verbal communication and cognitive function. Early diagnosis is essential for enhancing both lifespan and quality of life for affected individuals. Despite its importance, diagnosing dementia is complex and often necessitates a multimodal approach incorporating diverse clinical data types. In this study, we fine-tune Wav2vec and Word2vec baseline models using two distinct data types: audio recordings and text transcripts. We experiment with four conditions: original datasets versus datasets purged of short sentences, each with and without data augmentation. Our results indicate that synonym-based text data augmentation generally enhances model performance, underscoring the importance of data volume for achieving generalizable performance. Additionally, models trained on text data frequently excel and can further improve the performance of other modalities when combined. Audio and timestamp data sometimes offer marginal improvements. We provide a qualitative error analysis of the sentence archetypes that tend to be misclassified under each condition, providing insights into the effects of altering data modality and augmentation decisions.",
        "references": [
            "915a55642ba2930061f625b86fee7daa362769cf",
            "2026a519b8a5a8a3a652bd760f9ecf19a2dea6e6",
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "f7254ae607056ba5522c10dbcf21b394967b6d42",
            "23304e74752b604a2b27d5772ee8be2520e506f9",
            "4d0f54d1d482377bcdea8855741078058c044946",
            "d1511472de8df3ac57290aa501dbd72ec087e3ae",
            "b3f58c79ed7d01f9a802278158f3134f5e6187c9",
            "134d608f4e78da82c9c3c119f57cbde32e220f5e"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "23"
    },
    {
        "Id": "d898963243ad4b177b799f197a7732395e165cf6",
        "title": "Evaluating Picture Description Speech for Dementia Detection using Image-text Alignment",
        "authors": [
            "Youxiang Zhu",
            "Nan Lin",
            "Xiaohui Liang",
            "John A. Batsis",
            "Robert M. Roth",
            "Brian MacWhinney"
        ],
        "date": "11 August 2023",
        "abstract": "The first dementia detection models that take both the picture and the description texts as inputs and incorporate knowledge from large pre-trained image-text alignment models are proposed and achieve state-of-the-art performance. Using picture description speech for dementia detection has been studied for 30 years. Despite the long history, previous models focus on identifying the differences in speech patterns between healthy subjects and patients with dementia but do not utilize the picture information directly. In this paper, we propose the first dementia detection models that take both the picture and the description texts as inputs and incorporate knowledge from large pre-trained image-text alignment models. We observe the difference between dementia and healthy samples in terms of the text's relevance to the picture and the focused area of the picture. We thus consider such a difference could be used to enhance dementia detection accuracy. Specifically, we use the text's relevance to the picture to rank and filter the sentences of the samples. We also identified focused areas of the picture as topics and categorized the sentences according to the focused areas. We propose three advanced models that pre-processed the samples based on their relevance to the picture, sub-image, and focused areas. The evaluation results show that our advanced models, with knowledge of the picture and large image-text alignment models, achieve state-of-the-art performance with the best detection accuracy at 83.44%, which is higher than the text-only baseline model at 79.91%. Lastly, we visualize the sample and picture results to explain the advantages of our models.",
        "references": [
            "9c88e11f6aee535766bff772b06883dafa161407",
            "1fe4906d57dab8d93d5695533ba6e5eb0facbec8",
            "2042cec0e9d1883f6c1c55c021b20da45effed11",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "d4b5344c959ea05a880bd816cc4b1ed7ef46262b",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "915a55642ba2930061f625b86fee7daa362769cf",
            "fe800cf60db1181cae0e0b6219ca7ed41aee7d7b",
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "9c525238d583f86909689846b6d09264dc78e93f"
        ],
        "related_topics": [
            "Dementia Detection",
            "Sentences",
            "Detection Accuracy",
            "Image-text Alignment"
        ],
        "reference_count": "0",
        "citation_count": "46"
    },
    {
        "Id": "1fd0a1caafd950194ff8a42a76d1c6dcbe704933",
        "title": "Advancing Stuttering Detection via Data Augmentation, Class-Balanced Loss and Multi-Contextual Deep Learning",
        "authors": [
            "Shakeel Ahmad Sheikh",
            "Md. Sahidullah",
            "Fabrice Hirsch",
            "Slim Ouni"
        ],
        "date": "21 February 2023",
        "abstract": "This work addresses the class imbalance problem in the SD domain via a multi-branching (MB) scheme and by weighting the contribution of classes in the overall loss function, resulting in a huge improvement in stuttering classes on the SEP-28 k dataset over the baseline (<italic>StutterNet</italic). Stuttering is a neuro-developmental speech impairment characterized by uncontrolled utterances (interjections) and core behaviors (blocks, repetitions, and prolongations), and is caused by the failure of speech sensorimotors. Due to its complex nature, stuttering detection (SD) is a difficult task. If detected at an early stage, it could facilitate speech therapists to observe and rectify the speech patterns of persons who stutter (PWS). The stuttered speech of PWS is usually available in limited amounts and is highly imbalanced. To this end, we address the class imbalance problem in the SD domain via a multi-branching (MB) scheme and by weighting the contribution of classes in the overall loss function, resulting in a huge improvement in stuttering classes on the SEP-28 k dataset over the baseline (<italic>StutterNet</italic>). To tackle data scarcity, we investigate the effectiveness of data augmentation on top of a multi-branched training scheme. The augmented training outperforms the MB <italic>StutterNet</italic> (clean) by a relative margin of 4.18% in macro F1-score (<inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F}_{1}$</tex-math></inline-formula>). In addition, we propose a multi-contextual (MC) <italic>StutterNet</italic>, which exploits different contexts of the stuttered speech, resulting in an overall improvement of 4.48% in <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F}_{1}$</tex-math></inline-formula> over the single context based MB <italic>StutterNet</italic>. Finally, we have shown that applying data augmentation in the cross-corpora scenario can improve the overall SD performance by a relative margin of 13.23% in <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {F}_{1}$</tex-math></inline-formula> over the clean training.",
        "references": [
            "fc9a100a8bf54b60b240eeee1b5f5c2b762aee93",
            "3b7c45d9d2ea09c15cd1f12642db30a2c18e12a2",
            "4470ecd2070dc2c6e0988134e11b1b988d66fa41",
            "913ab3a206ab9e5eb78f562db8257c67a43bed44",
            "6664b5be04c11acc04f2eba37886a3482d4f546f",
            "15dc43c4c757fd752cb9c8ddad7989fc39e1028b",
            "7676283e99508d8bfdf63f252332806df215e5ae",
            "8c12df7d6f8cf3a82c38a4af7c443949d645e120",
            "39447f5788a40ae39885c405c46323c329740c11",
            "b81ac8f3df9c2d0694067389dffbe0b9ac3086e5"
        ],
        "related_topics": [
            "People Who Stutter",
            "Stuttering Detection",
            "Stuttering",
            "Personalized Web Search",
            "Class Imbalance Problem",
            "Class-Balanced Loss",
            "Loss Function",
            "Clean Training",
            "SEP-28k Dataset"
        ],
        "reference_count": "71",
        "citation_count": "3"
    },
    {
        "Id": "2042cec0e9d1883f6c1c55c021b20da45effed11",
        "title": "Exploring Deep Transfer Learning Techniques for Alzheimer\u2019s Dementia Detection",
        "authors": [
            "Youxiang Zhu",
            "Xiaohui Liang",
            "John A. Batsis",
            "Robert M. Roth"
        ],
        "date": "7 April 2021",
        "abstract": "A large comparative analysis of varying transfer learning models focusing less on model customization but more on pre-trained models and pre-training datasets revealed insightful relations among models, data types, and data labels in this research area. Examination of speech datasets for detecting dementia, collected via various speech tasks, has revealed links between speech and cognitive abilities. However, the speech dataset available for this research is extremely limited because the collection process of speech and baseline data from patients with dementia in clinical settings is expensive. In this paper, we study the spontaneous speech dataset from a recent ADReSS challenge, a Cookie Theft Picture (CTP) dataset with balanced groups of participants in age, gender, and cognitive status. We explore state-of-the-art deep transfer learning techniques from image, audio, speech, and language domains. We envision that one advantage of transfer learning is to eliminate the design of handcrafted features based on the tasks and datasets. Transfer learning further mitigates the limited dementia-relevant speech data problem by inheriting knowledge from similar but much larger datasets. Specifically, we built a variety of transfer learning models using commonly employed MobileNet (image), YAMNet (audio), Mockingjay (speech), and BERT (text) models. Results indicated that the transfer learning models of text data showed significantly better performance than those of audio data. Performance gains of the text models may be due to the high similarity between the pre-training text dataset and the CTP text dataset. Our multi-modal transfer learning introduced a slight improvement in accuracy, demonstrating that audio and text data provide limited complementary information. Multi-task transfer learning resulted in limited improvements in classification and a negative impact in regression. By analyzing the meaning behind the Alzheimer's disease (AD)/non-AD labels and Mini-Mental State Examination (MMSE) scores, we observed that the inconsistency between labels and scores could limit the performance of the multi-task learning, especially when the outputs of the single-task models are highly consistent with the corresponding labels/scores. In sum, we conducted a large comparative analysis of varying transfer learning models focusing less on model customization but more on pre-trained models and pre-training datasets. We revealed insightful relations among models, data types, and data labels in this research area.",
        "references": [
            "228896a28b18ef3ad956dd8000b5ea3b8a0bfd7e",
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "cc2e10b0a706f22bc0117709f99949459fca19d1",
            "11fe0b9c4891f8d73ea68b5a48acb1063aa48427",
            "9e7b0384bc48c3ae6dc1c66d6ee674902380a2c8",
            "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d",
            "1fe4906d57dab8d93d5695533ba6e5eb0facbec8",
            "d8dd064712d8c7d6bdc4dc5ea02ac2b43539ebcf",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b"
        ],
        "related_topics": [
            "Dual BERT",
            "Transfer Learning",
            "Bidirectional Encoder Representations From Transformers",
            "Pre-training Dataset",
            "Alzheimer's Dementia",
            "Speech Tasks",
            "Pre-trained Models",
            "Deep Transfer Learning",
            "MobileNets",
            "ADReSS Challenge"
        ],
        "reference_count": "68",
        "citation_count": "25"
    },
    {
        "Id": "0932bef7467fdd06f6e22ad2562f1cf377be0e5e",
        "title": "Detecting Alzheimer\u2019s Disease from Speech Using Neural Networks with Bottleneck Features and Data Augmentation",
        "authors": [
            "Zhaoci Liu",
            "Zhiqiang Guo",
            "Zhenhua Ling",
            "Yunxia Li"
        ],
        "date": "6 June 2021",
        "abstract": "This method does not rely on the manual transcriptions and annotations of a subject\u2019s speech, but utilizes the bottleneck features extracted from audio using an ASR model to achieve the state-of-the-art performance of detecting AD using only audio data on this dataset. This paper presents a method of detecting Alzheimer\u2019s disease (AD) from the spontaneous speech of subjects in a picture description task using neural networks. This method does not rely on the manual transcriptions and annotations of a subject\u2019s speech, but utilizes the bottleneck features extracted from audio using an ASR model. The neural network contains convolutional neural network (CNN) layers for local context modeling, bidirectional long shortterm memory (BiLSTM) layers for global context modeling and an attention pooling layer for classification. Furthermore, a masking- based data augmentation method is designed to deal with the data scarcity problem. Experiments on the DementiaBank dataset show that the detection accuracy of our proposed method is 82.59%, which is better than the baseline method based on manually-designed acoustic features and support vector machines (SVM), and achieves the state-of-the-art performance of detecting AD using only audio data on this dataset.",
        "references": [
            "9a1fdc7dc4b41f055f28032b5eae96ac9bb6ceb8",
            "a97936567f0f980600d34485c5e9f0e9c3eb1205",
            "a448c11e3c8b81b10749a089e856c9733b371b2a",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "a7425f74a9e7bdd3ae6763c515c9534fb18a3560",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "c940a209c47594443c5f352890b37a8d3fa9525f",
            "213a5e3915711cfb3fe8a51d3ef712e70b347779",
            "4dfd60a301f792311c7967f08b22d606091f9d12",
            "ec053f3131a9704b6ffb733b9b16d4a9cda489e9"
        ],
        "related_topics": [
            "Convolutional Neural Network",
            "Bottleneck Features",
            "Neural Network",
            "Support Vector Machines",
            "DementiaBank Dataset",
            "Acoustic Features",
            "Detection Accuracy",
            "biLSTM",
            "Augmentations",
            "Global Context Modeling"
        ],
        "reference_count": "24",
        "citation_count": "11"
    },
    {
        "Id": "e59be08b66dddf32092aa0c71400443c46d47c59",
        "title": "Multimodal Deep Learning Models for Detecting Dementia From Speech and Transcripts",
        "authors": [
            "Loukas Ilias",
            "Dimitris Th. Askounis"
        ],
        "date": "17 March 2022",
        "abstract": "New methods to detect AD patients and predict the Mini-Mental State Examination (MMSE) scores in an end-to-end trainable manner consisting of a combination of BERT, Vision Transformer, Co-Attention, Multimodal Shifting Gate, and a variant of the self-attention mechanism are presented. Alzheimer's dementia (AD) entails negative psychological, social, and economic consequences not only for the patients but also for their families, relatives, and society in general. Despite the significance of this phenomenon and the importance for an early diagnosis, there are still limitations. Specifically, the main limitation is pertinent to the way the modalities of speech and transcripts are combined in a single neural network. Existing research works add/concatenate the image and text representations, employ majority voting approaches or average the predictions after training many textual and speech models separately. To address these limitations, in this article we present some new methods to detect AD patients and predict the Mini-Mental State Examination (MMSE) scores in an end-to-end trainable manner consisting of a combination of BERT, Vision Transformer, Co-Attention, Multimodal Shifting Gate, and a variant of the self-attention mechanism. Specifically, we convert audio to Log-Mel spectrograms, their delta, and delta-delta (acceleration values). First, we pass each transcript and image through a BERT model and Vision Transformer, respectively, adding a co-attention layer at the top, which generates image and word attention simultaneously. Secondly, we propose an architecture, which integrates multimodal information to a BERT model via a Multimodal Shifting Gate. Finally, we introduce an approach to capture both the inter- and intra-modal interactions by concatenating the textual and visual representations and utilizing a self-attention mechanism, which includes a gate model. Experiments conducted on the ADReSS Challenge dataset indicate that our introduced models demonstrate valuable advantages over existing research initiatives achieving competitive results in both the AD classification and MMSE regression task. Specifically, our best performing model attains an accuracy of 90.00% and a Root Mean Squared Error (RMSE) of 3.61 in the AD classification task and MMSE regression task, respectively, achieving a new state-of-the-art performance in the MMSE regression task.",
        "references": [
            "01bff7587cf04a9adfb91a3e86c435ab02bf9261",
            "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "2042cec0e9d1883f6c1c55c021b20da45effed11",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "92e0608730573341ac43955f2946513f2a5814c4",
            "23304e74752b604a2b27d5772ee8be2520e506f9",
            "bba090183ac3c67da7be4b64b8211a4108b0b5f7",
            "c67f9bd3209f57c2777d19b018ab4c48b206fa97"
        ],
        "related_topics": [],
        "reference_count": "51",
        "citation_count": "14"
    },
    {
        "Id": "0d678b625e12a4f09e859aa100e66a39531f7c80",
        "title": "Automated Recognition of Alzheimer\u2019s Dementia Using Bag-of-Deep-Features and Model Ensembling",
        "authors": [
            "Zafi Sherhan Syed",
            "Muhammad Shehram Shah Syed",
            "Margaret Lech",
            "Elena Pirogova"
        ],
        "date": "2021",
        "abstract": "It is shown that bag-of-deep-neural-embeddings and ensemble learning offer a viable approach to objective assessment of dementia and a multimodal system that can identify linguistic and paralinguistic traits of dementia using an automated screening tool is proposed. Alzheimer\u2019s dementia is a progressive neurodegenerative disease that causes cognitive and physical impairment. It severely deteriorates the quality of life in affected individuals. An early diagnosis can assist immensely in better management of their healthcare needs. In recent years, there has been a renewed impetus in development of automated methods for recognition of various disorders by leveraging advancements in artificial intelligence. Here, we propose a multimodal system that can identify linguistic and paralinguistic traits of dementia using an automated screening tool. We show that bag-of-deep-neural-embeddings and ensemble learning offer a viable approach to objective assessment of dementia. The developed system is tested on the Alzheimer\u2019s Dementia Recognition Challenge dataset, where it achieved a new state-of-the-art (SOTA) performance for the classification task and matched the current SOTA for the regression task. These results highlight the efficacy of our proposed system for facilitating an early diagnosis of dementia.",
        "references": [
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "92e0608730573341ac43955f2946513f2a5814c4",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "228896a28b18ef3ad956dd8000b5ea3b8a0bfd7e",
            "1311de8ce4f11dca925825c2529256a471eba097",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "134d608f4e78da82c9c3c119f57cbde32e220f5e",
            "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d"
        ],
        "related_topics": [],
        "reference_count": "75",
        "citation_count": "21"
    },
    {
        "Id": "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
        "title": "Classifying Alzheimer's Disease Using Audio and Text-Based Representations of Speech",
        "authors": [
            "R&#x27;mani Haulcy",
            "James R. Glass"
        ],
        "date": "15 January 2021",
        "abstract": "The feasibility of using speech to classify AD and predict neuropsychological scores is illustrated and the top-performing classification models were the support vector machine and random forest classifiers trained on BERT embeddings, which both achieved an accuracy of 85.4% on the test set. Alzheimer's Disease (AD) is a form of dementia that affects the memory, cognition, and motor skills of patients. Extensive research has been done to develop accessible, cost-effective, and non-invasive techniques for the automatic detection of AD. Previous research has shown that speech can be used to distinguish between healthy patients and afflicted patients. In this paper, the ADReSS dataset, a dataset balanced by gender and age, was used to automatically classify AD from spontaneous speech. The performance of five classifiers, as well as a convolutional neural network and long short-term memory network, was compared when trained on audio features (i-vectors and x-vectors) and text features (word vectors, BERT embeddings, LIWC features, and CLAN features). The same audio and text features were used to train five regression models to predict the Mini-Mental State Examination score for each patient, a score that has a maximum value of 30. The top-performing classification models were the support vector machine and random forest classifiers trained on BERT embeddings, which both achieved an accuracy of 85.4% on the test set. The best-performing regression model was the gradient boosting regression model trained on BERT embeddings and CLAN features, which had a root mean squared error of 4.56 on the test set. The performance on both tasks illustrates the feasibility of using speech to classify AD and predict neuropsychological scores.",
        "references": [
            "494d1214ad408719bd5e267cf6a4dad163af4121",
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "cc2e10b0a706f22bc0117709f99949459fca19d1",
            "1d21ee08b6af747d4cce3c5cc6432f7312f3bb58",
            "a97936567f0f980600d34485c5e9f0e9c3eb1205",
            "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b"
        ],
        "related_topics": [],
        "reference_count": "63",
        "citation_count": "48"
    },
    {
        "Id": "d1511472de8df3ac57290aa501dbd72ec087e3ae",
        "title": "Crossing the \u201cCookie Theft\u201d Corpus Chasm: Applying What BERT Learns From Outside Data to the ADReSS Challenge Dementia Detection Task",
        "authors": [
            "Yue Guo",
            "Changye Li",
            "Carol L. Roan",
            "Serguei V. S. Pakhomov",
            "Trevor A. Cohen"
        ],
        "date": "16 April 2021",
        "abstract": "It is found that incorporating WLS data during training a BERT model on ADRe SS data improves its performance on the ADReSS dementia detection task, supporting the hypothesis that incorporatingWLS data adds value in this context. Large amounts of labeled data are a prerequisite to training accurate and reliable machine learning models. However, in the medical domain in particular, this is also a stumbling block as accurately labeled data are hard to obtain. DementiaBank, a publicly available corpus of spontaneous speech samples from a picture description task widely used to study Alzheimer's disease (AD) patients' language characteristics and for training classification models to distinguish patients with AD from healthy controls, is relatively small\u2014a limitation that is further exacerbated when restricting to the balanced subset used in the Alzheimer's Dementia Recognition through Spontaneous Speech (ADReSS) challenge. We build on previous work showing that the performance of traditional machine learning models on DementiaBank can be improved by the addition of normative data from other sources, evaluating the utility of such extrinsic data to further improve the performance of state-of-the-art deep learning based methods on the ADReSS challenge dementia detection task. To this end, we developed a new corpus of professionally transcribed recordings from the Wisconsin Longitudinal Study (WLS), resulting in 1366 additional Cookie Theft Task transcripts, increasing the available training data by an order of magnitude. Using these data in conjunction with DementiaBank is challenging because the WLS metadata corresponding to these transcripts do not contain dementia diagnoses. However, cognitive status of WLS participants can be inferred from results of several cognitive tests including semantic verbal fluency available in WLS data. In this work, we evaluate the utility of using the WLS \u2018controls\u2019 (participants without indications of abnormal cognitive status), and these data in conjunction with inferred \u2018cases\u2019 (participants with such indications) for training deep learning models to discriminate between language produced by patients with dementia and healthy controls. We find that incorporating WLS data during training a BERT model on ADReSS data improves its performance on the ADReSS dementia detection task, supporting the hypothesis that incorporating WLS data adds value in this context. We also demonstrate that weighted cost functions and additional prediction targets may be effective ways to address issues arising from class imbalance and confounding effects due to data provenance.",
        "references": [
            "92e0608730573341ac43955f2946513f2a5814c4",
            "00c5abdffe51ab33e745e6804d4821ca59db52d8",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "99979db50a6f2cdb43225240e44f1928e778554d",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "67caebd696086aa057bc9f451fdce47b44832860",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "3f6989f605e650e14bae236568768172f4037382"
        ],
        "related_topics": [
            "Alzheimer ' S Dementia Recognition Through Spontaneous Speech",
            "DementiaBank",
            "Bidirectional Encoder Representations From Transformers",
            "Semantic Verbal Fluency",
            "BERT Model",
            "Alzheimer's Dementia Recognition Through Spontaneous Speech",
            "Data Provenance",
            "Wisconsin Longitudinal Study",
            "Cookie Theft",
            "ADReSS Challenge"
        ],
        "reference_count": "48",
        "citation_count": "22"
    },
    {
        "Id": "df32bef70b9bd41aa818d2039c938337ab82eb25",
        "title": "A Review on Alzheimer\u2019s Disease Through Analysis of MRI Images Using Deep Learning Techniques",
        "authors": [
            "Battula Srinivasa Rao",
            "Mudiyala Aparna"
        ],
        "date": "2023",
        "abstract": "How convolutional neural network concepts can be used to study brain anatomy in order to detect Alzheimer\u2019s disease is discussed, and the possibility of Deep Learning to improve early diagnosis is discussed. The anatomical structure of the brain has been studied with the help of magnetic resonance imaging (MRI), which has been used to analyze numerous neurological diseases and define pathological areas. Early detection of Alzheimer\u2019s Disease (AD) patients is critical in order to implement preventative measures. Alzheimer\u2019s disease (AD) is the most common chronic disease in the elderly, with a high incidence rate. In recent years, deep learning has seen a lot of success in the medical image analysis. Brain diseases can be more accurately categorized using segmented MRI scans due to in-depth analyses of tissue architecture. Many, complex segmentation approaches have been presented for AD diagnosis. Since deep learning algorithms can yield effective results over a large data collection, they have received interest for use in segmenting the brain\u2019s structure and classifying AD. Consequently, the deep learning techniques are currently favored over machine learning techniques. We discuss how convolutional neural network concepts can be used to study brain anatomy in order to detect AD. New techniques, their results on open datasets, and the benefits of brain MRI segmentation for Alzheimer\u2019s disease categorization are discussed. In this article, the literature on Alzheimer\u2019s disease is briefly reviewed, and the possibility of Deep Learning to improve early diagnosis is discussed.",
        "references": [
            "fd81880d09fa9997be8a0fccd5f1bf3fc4eb3fcb",
            "cd0f2dcbdb25116a0b58180aeac35a9dc5ad6fd8",
            "52d2f27da12d2ac4202d2d1db2c7a04d623cadf0",
            "608a9fec623376dfb3085a8272fb21d1874991ca",
            "73ecaafb45fed6381deb12cfbef0779fc8cfd33f",
            "cbb01ec1eeb343712710dbe7cef85da0c08695a6",
            "2f407fe93f63e2c411368b6634b794254c89a548",
            "075ef6870bd3f5ab3405ed5d506b7bd4e80e52e3",
            "3539f67ba7f9025e2695709814aef4864843473b",
            "8643073ae8f202efcf6a6414f8c57073341e2b99"
        ],
        "related_topics": [
            "Deep Learning",
            "Medical Image Analysis",
            "AD Diagnosis",
            "Magnetic Resonance Images"
        ],
        "reference_count": "0",
        "citation_count": "107"
    },
    {
        "Id": "23ca2e37760fe8fdad318b51c28bed784fab6c51",
        "title": "Interpretable Hierarchical Deep Learning Model for Noninvasive Alzheimer\u2019s Disease Diagnosis",
        "authors": [
            "Maryam Zokaeinikoo",
            "Pooyan Kazemian",
            "Prasenjit Mitra"
        ],
        "date": "17 November 2023",
        "abstract": "An interpretable hierarchical deep learning model that can detect Alzheimer\u2019s disease from the transcripts of patient interviews with 96% accuracy when tested on the DementiaBank data set is developed. Alzheimer\u2019s disease is one of the leading causes of death in the world. Alzheimer\u2019s is typically diagnosed through expensive imaging methods, such as positron emission tomography (PET) scan and magnetic resonance imaging (MRI), as well as invasive methods, such as cerebrospinal fluid analysis. In this study, we develop an interpretable hierarchical deep learning model to detect the presence of Alzheimer\u2019s disease from transcripts of interviews of individuals who were asked to describe a picture. Our deep recurrent neural network employs a novel three-level hierarchical attention over self-attention (AoS3) mechanism to model the temporal dependencies of longitudinal data. We demonstrate the interpretability of the model with the importance score of words, sentences, and transcripts extracted from our AoS3 model. Numerical results demonstrate that our deep learning model can detect Alzheimer\u2019s disease from the transcripts of patient interviews with 96% accuracy when tested on the DementiaBank data set. Our interpretable neural network model can help diagnose Alzheimer\u2019s disease in a noninvasive and affordable manner, improve patient outcomes, and result in cost containment. History: Rema Padman served as the senior editor for this article. Data Ethics & Reproducibility Note: The code capsule is available on Code Ocean at https://codeocean.com/capsule/2881658/tree/v1 and in the e-Companion to this article (available at https://doi.org/10.1287/ijds.2020.0005 ). The study involves secondary use of already-collected data. None of the authors were part of the original study team. The authors had no interaction with living individuals and had no access to protected health information (PHI) or private identifiable information about living individuals.",
        "references": [
            "373b26525f64edfa9d36f5096e8964d73b97d7de",
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "3f6989f605e650e14bae236568768172f4037382",
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "72b3390486d9b9e4f520e158eae290219d68fc16",
            "3bbf04b842e08d28a39e0e0dd4b54a6ab36ace75",
            "9f79b994b6bbb2da8002582200f6f0b8ba6daf91",
            "85ee1f6e762dd7cb3944154c13d847c9c94907ee",
            "0f80f167eb9b90c76c13baf90eab2077d89f9b21",
            "ab43362d0b11b22a2990fae7310765ca67f1c4f2"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "20"
    },
    {
        "Id": "9e53cdbac19e1a2e58c0b924a2d8889281668c54",
        "title": "Alzheimer\u2019s Dementia Speech (Audio vs. Text): Multi-Modal Machine Learning at High vs. Low Resolution",
        "authors": [
            "Prachee Priyadarshinee",
            "Christopher Johann Clarke",
            "Jan Melechovsk{\\&#x27;y}",
            "Cindy Ming Ying Lin",
            "Balamurali B. T.",
            "Jer-Ming Chen"
        ],
        "date": "27 March 2023",
        "abstract": "A systematic comparison across different modalities, granularities and machine learning models to guide in choosing the most effective tools for the automatic detection of Alzheimer\u2019s Dementia from recordings of spontaneous speech finds that text-based classification outperformed audio- based classification with the best performance attaining 88.7%, surpassing other reports to-date relying on the same dataset. Automated techniques to detect Alzheimer\u2019s Dementia through the use of audio recordings of spontaneous speech are now available with varying degrees of reliability. Here, we present a systematic comparison across different modalities, granularities and machine learning models to guide in choosing the most effective tools. Specifically, we present a multi-modal approach (audio and text) for the automatic detection of Alzheimer\u2019s Dementia from recordings of spontaneous speech. Sixteen features, including four feature extraction methods (Energy\u2013Time plots, Keg of Text Analytics, Keg of Text Analytics-Extended and Speech to Silence ratio) not previously applied in this context were tested to determine their relative performance. These features encompass two modalities (audio vs. text) at two resolution scales (frame-level vs. file-level). We compared the accuracy resulting from these features and found that text-based classification outperformed audio-based classification with the best performance attaining 88.7%, surpassing other reports to-date relying on the same dataset. For text-based classification in particular, the best file-level feature performed 9.8% better than the frame-level feature. However, when comparing audio-based classification, the best frame-level feature performed 1.4% better than the best file-level feature. This multi-modal multi-model comparison at high- and low-resolution offers insights into which approach is most efficacious, depending on the sampling context. Such a comparison of the accuracy of Alzheimer\u2019s Dementia classification using both frame-level and file-level granularities on audio and text modalities of different machine learning models on the same dataset has not been previously addressed. We also demonstrate that the subject\u2019s speech captured in short time frames and their dynamics may contain enough inherent information to indicate the presence of dementia. Overall, such a systematic analysis facilitates the identification of Alzheimer\u2019s Dementia quickly and non-invasively, potentially leading to more timely interventions and improved patient outcomes.",
        "references": [
            "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
            "bba090183ac3c67da7be4b64b8211a4108b0b5f7",
            "acacb4176fa29ebd4ba328af8cf0b960375725fe",
            "a97936567f0f980600d34485c5e9f0e9c3eb1205",
            "72b3390486d9b9e4f520e158eae290219d68fc16",
            "8e95b7aef9a0b73884717c24e12b0d18bcb86e76",
            "4e037757379916f6bfa904a07c7eadfe71b67ce0",
            "0d678b625e12a4f09e859aa100e66a39531f7c80",
            "3c9436640e4fee2f0deca5854722fbdc123bc333",
            "5671c7890b7bfa329b161144661126aa0bcc6480"
        ],
        "related_topics": [],
        "reference_count": "23",
        "citation_count": "2"
    },
    {
        "Id": "cacecc0b46c3946a5a9e182011915e8c716d8c0b",
        "title": "Deep Learning Algorithms for Early Alzheimer's Diagnosis: From Data to Prognosis",
        "authors": [
            "Buchepalli Praneeth",
            "P Siva",
            "Deekshith Reddy",
            "Minal Moharir",
            "P Bhuvaneshwar",
            "Ashok Kumar"
        ],
        "date": "18 October 2023",
        "abstract": "The proposed approach seeks to improve the precision, sensitivity, and specificity of AD prediction and classification by utilizing the power of deep learning by using an AD dataset that consists of Magnetic resonance imaging images. Alzheimer's disease (AD) is a neurological condition that worsens over time and affects millions of older people worldwide. An early diagnosis and correct classification of AD are essential for improving patient condition, enabling prompt intervention, and allocating healthcare resources. Healthcare professionals can use the system's predictions and classifications to make judgements about treatment regimens, patient counselling, and resource allocation. Additionally, by offering insightful information on the course of disease, potential therapeutic targets, and creation of fresh remedies, the system advances research into AD. To build reliable models for the precise diagnosis and classification of the disease, deep learning techniques were used to offer a cutting-edge AD prediction and classification system. To train and optimize deep neural networks, the system uses an AD dataset that consists of Magnetic resonance imaging(MRI) images. The dataset consists of 4 classes, Mild Demented, Moderate Demented, Non-Demented and Very Mild Demented. The proposed approach seeks to improve the precision, sensitivity, and specificity of AD prediction and classification by utilizing the power of deep learning. To identify complex patterns and correlations in the data, different deep learning architectures such as ResNet, MobileNet, and Xception are considered. ResNet exhibits the highest predictive accuracy among the three models, achieving an impressive 93%, followed closely by MobileNet at 91%, while Xception achieves an accuracy of 88%. The system's predictive models and classification algorithms can distinguish between various disease phases of the disease.",
        "references": [
            "d4f75b92064ce3869e1f72217dad2069511e88a8",
            "32c80cfd627302b5462f465772d08c293fb876f9",
            "669f7ea6c9f186cc05f18ebe73828691de8c26e0",
            "f2d36024d701c6067fed49764cb05a8dac77f84f",
            "643a53e1159006bc5af8344a2d85a053b52eba0f",
            "d9ca3f7672eb1a9f140fd0c7c0e35dc8a32a7cb1",
            "4f28ec72db0792948f85f6cd294ec9594796af37",
            "8d5bba3ff5edda1a804669803400367036e6ca22",
            "b0957205d60473d069554d5887640aa07777ff49",
            "3ca6b63508472f34599b0ffeb6892c4c7298356c"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "22"
    },
    {
        "Id": "e8301d68695d709cdb7f1f373e42ccc1241d9137",
        "title": "GPT-4 and Neurologists in Screening for Mild Cognitive Impairment in the Elderly: A Comparative Analysis Study",
        "authors": [
            "Hao Yang",
            "Ruihan Wang",
            "Changyu Wang",
            "Hui Gao",
            "Hanlin Cai",
            "Fengying Zhang",
            "Jialin Liu",
            "Siru Liu"
        ],
        "date": "4 December 2023",
        "abstract": "The GPT-4 model shows promise as a diagnostic aid for MCI, potentially improving patient outcomes and reducing healthcare burdens, however, its practical applicability in real-world scenarios requires further investigation and clinical validation. This study evaluates the efficacy of GPT-4 in screening for Mild Cognitive Impairment (MCI) in the elderly, comparing it with junior neurologists. MCI is a precursor to dementia, presenting a significant public health concern due to the rising global aging population. With over 55 million people affected by dementia worldwide, early detection is essential for timely intervention. Common screening tools, while effective, are resource-intensive, highlighting the need for more efficient methods. The study used an exploratory design with 174 participants, comparing the performance of GPT-4 against three junior neurologists. The GPT-4 model was trained using a set of language analysis indicators to evaluate the severity of MCI. Participants' test texts and voices were grouped and independently assessed by the neurologists and the GPT-4 model. The neurologists and the GPT-4 model independently assessed the participants' test corpus. The neurologists assessed both the text and voice of the test, while the GPT model assessed the text only. Results showed that the GPT-4 model had higher accuracy (0.81) compared to the neurologists (ranging from 0.41 to 0.49). GPT-4 demonstrated better discrimination of MCI with significant statistical difference (p < 0.001). The study also developed a clinical risk assessment nomogram based on the top ten weighted features from GPT-4's analysis, aiding in MCI patient evaluation. In conclusion, the GPT-4 model shows promise as a diagnostic aid for MCI, potentially improving patient outcomes and reducing healthcare burdens. However, its practical applicability in real-world scenarios requires further investigation and clinical validation",
        "references": [
            "b6a4a4f95beb28ef838b456784727715481495e8",
            "0121cf0a348608b6a50cc88cacba1514f3f38d3c",
            "59b03e51053b6532fde44699169391abe393a28b",
            "df3e4b1339c626e256943666e1fe6cbf8f494ed6",
            "694de132ce8585533915125993f594b9f4c77f0b",
            "3c648a254136a97ccefd6559ca38ce7a305f2d2c",
            "25d26d34eefac72828c1fd02c0d50e1218a1d0be",
            "2c31f8b166d69d88e082d94deb681275f74b8c53",
            "f7254ae607056ba5522c10dbcf21b394967b6d42",
            "137743ee8d930661ede1f297d9dc5b593b0d580c"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "28"
    },
    {
        "Id": "cc49a722fbafa0b3a349640e569a83f58dd26483",
        "title": "Text Dialogue Analysis for Primary Screening of Mild Cognitive Impairment: Development and Validation Study",
        "authors": [
            "Changyu Wang",
            "Siru Liu",
            "Aiqing Li",
            "Jialin Liu"
        ],
        "date": "2 August 2023",
        "abstract": "ChatGPT was effective in the primary screening of participants with possible MCI and improved standardization of prompts by clinicians would also improve the performance of the model. Background Artificial intelligence models tailored to diagnose cognitive impairment have shown excellent results. However, it is unclear whether large linguistic models can rival specialized models by text alone. Objective In this study, we explored the performance of ChatGPT for primary screening of mild cognitive impairment (MCI) and standardized the design steps and components of the prompts. Methods We gathered a total of 174 participants from the DementiaBank screening and classified 70% of them into the training set and 30% of them into the test set. Only text dialogues were kept. Sentences were cleaned using a macro code, followed by a manual check. The prompt consisted of 5 main parts, including character setting, scoring system setting, indicator setting, output setting, and explanatory information setting. Three dimensions of variables from published studies were included: vocabulary (ie, word frequency and word ratio, phrase frequency and phrase ratio, and lexical complexity), syntax and grammar (ie, syntactic complexity and grammatical components), and semantics (ie, semantic density and semantic coherence). We used R 4.3.0. for the analysis of variables and diagnostic indicators. Results Three additional indicators related to the severity of MCI were incorporated into the final prompt for the model. These indicators were effective in discriminating between MCI and cognitively normal participants: tip-of-the-tongue phenomenon (P<.001), difficulty with complex ideas (P<.001), and memory issues (P<.001). The final GPT-4 model achieved a sensitivity of 0.8636, a specificity of 0.9487, and an area under the curve of 0.9062 on the training set; on the test set, the sensitivity, specificity, and area under the curve reached 0.7727, 0.8333, and 0.8030, respectively. Conclusions ChatGPT was effective in the primary screening of participants with possible MCI. Improved standardization of prompts by clinicians would also improve the performance of the model. It is important to note that ChatGPT is not a substitute for a clinician making a diagnosis.",
        "references": [
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "343a5ab97e47368da0aa7b50256736297cbb9ce6",
            "f7254ae607056ba5522c10dbcf21b394967b6d42",
            "d17a21d5c53035f64a85247d6eb25139ffd95a95",
            "0121cf0a348608b6a50cc88cacba1514f3f38d3c",
            "d943e73b7e71d117ef364e0881ebbf360dc0b36b",
            "b3537407b00c76103ac21bb7cd0ce7047dfdf025",
            "a727707b54c59e917f8e71639eda8cec0d8c69c0",
            "fe43903e21fb94455004bd70a2b49b4db4d0de4b",
            "d6e16ee467ea9d3772827273698fda5e0520c9a3"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "25"
    },
    {
        "Id": "48cfa6ffcaac765dda8badefceda3a13171cdcf9",
        "title": "Lightweight Histological Tumor Classification Using a Joint Sparsity-Quantization Aware Training Framework",
        "authors": [
            "Dina Aboutahoun",
            "Rami Zewail",
            "Keiji Kimura",
            "Mostafa I. Soliman"
        ],
        "date": "2023",
        "abstract": "This work proposes a novel lightweight deep learning model for histological tumor classification through a Joint Sparsity-Quantization Aware Training framework and aims at opening doors toward efficient point-of-care diagnostic devices suitable for environments with limited resources. Cancer decision-making is a complex process that can be exacerbated by the limited availability of oncological expertise. This is particularly true in rural areas and settings with fewer resources. Recently, there has been an interest in the potential of artificial intelligence in reliable computer-aided diagnosis tools in such settings. Nevertheless, the majority of deep learning algorithms are resource hungry in terms of data and storage requirements. In this work, we propose a novel lightweight deep learning model for histological tumor classification through a Joint Sparsity-Quantization Aware Training framework. Extensive experiments were conducted to evaluate the proposed framework. Promising performance has been achieved compared to the most relevant state-of-the-art work with a classification accuracy of 94.26% and an average $5\\times $ reduction in the memory footprint. This work aims at opening doors toward efficient point-of-care diagnostic devices suitable for environments with limited resources.",
        "references": [
            "92616cd09774a796ca6287a5b7e3f2f68117a4d4",
            "394c2bac7426f964376a90a3934017ef23c58dd1",
            "dabcd6a9dd0c4f6ef5e36b187d3c606096e5e7cd",
            "1912293792ed11957a750d567e82dffb0ddb199f",
            "4a7cafcb5f569ed7a62bb1f5f77e0f0f44fd1edd",
            "c969e7dec8838365fa5dad1e3048f8a142e4d50d",
            "1820715b0c5bb0d9a13c7c678ff82182d19e857d",
            "d6d2971dfa338cc20c4de49681c3d7e378e1fde8",
            "e309d8cf5c011a8c15e08d6082dc0dab804114aa",
            "ccdc50de7a0602d3df5ed9bd9782565bbff2a8eb"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "60"
    },
    {
        "Id": "b8f609b4b95a59697dbd8fc21adb6705aafc9df2",
        "title": "Text dialogue analysis Based ChatGPT for Primary Screening of Mild Cognitive Impairment",
        "authors": [
            "Cognitive Impairment",
            "MD Jialin Liu"
        ],
        "date": "28 June 2023",
        "abstract": "Improved standardization of prompts by professional clinicians would also improve the performance of the model, and ChatGPT was effective in primary screening of participants with possible MCI. Abstract Background: AI models tailored to diagnose cognitive impairment have shown excellent results. However, it is unclear whether large linguistic models can rival specialized models by text alone. Objectives: We would explore the effectiveness of ChatGPT for primary screening of mild cognitive impairment (MCI) and standardize the design steps and components of the prompt. Methods: We obtained 174 participants from the DementiaBank screening and classified 70% of them into the training set and 30% into the test set. Three dimensions of variables were incorporated, including: vocabulary, syntax and grammar, and semantics. These variables were generated from published studies and statistical analyses. We used R 4.3.0. for the analysis of variables and diagnostic indicators. Results: The final variables included by published studies included: word frequency and word ratio, phrase frequency and phrase ratio, lexical complexity, syntactic complexity, grammatical components, semantic density, and semantic coherence; variables included in the analysis included: tip-of-the-tongue phenomenon (P < 0.001), difficulty with complex ideas (P < 0.001), and memory issues (P < 0.001). The final GPT4 model achieved the sensitivity (SEN) of 0.8636, specificity (SPE) of 0.9487 and area under the curve (AUC) of 0.9062 on the training set; on the test set, the SEN, SPE and AUC reached 0.7727, 0.8333 and 0.8030, respectively. The prompt consisted of five main parts, including character setting, scoring system setting, indicator setting, output setting, and explanatory information setting. Conclusion: ChatGPT was effective in primary screening of participants with possible MCI. Improved standardization of prompts by professional clinicians would also improve the performance of the model. It is important to note that ChatGPT is not a substitute for a clinician making a diagnosis.",
        "references": [
            "f7254ae607056ba5522c10dbcf21b394967b6d42",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "343a5ab97e47368da0aa7b50256736297cbb9ce6",
            "d17a21d5c53035f64a85247d6eb25139ffd95a95",
            "0121cf0a348608b6a50cc88cacba1514f3f38d3c",
            "d943e73b7e71d117ef364e0881ebbf360dc0b36b",
            "fe43903e21fb94455004bd70a2b49b4db4d0de4b",
            "a727707b54c59e917f8e71639eda8cec0d8c69c0",
            "d6e16ee467ea9d3772827273698fda5e0520c9a3",
            "b3537407b00c76103ac21bb7cd0ce7047dfdf025"
        ],
        "related_topics": [],
        "reference_count": "28",
        "citation_count": "4"
    },
    {
        "Id": "4f442fc4904c7db2091ded93c6d0e92c8e09c67e",
        "title": "Artificial Intelligence for Dementia Research Methods Optimization",
        "authors": [
            "Magda Bucholc",
            "Charlotte James",
            "Ahmad Al Khleifat",
            "AmanPreet Badhwar",
            "Natasha Clarke",
            "Amir Dehsarvi",
            "Christopher R. Madan",
            "Sarah J. Marzi",
            "Cameron Shand",
            "Brian M. Schilder",
            "Stefano Tamburin",
            "Hanz M. Tantiangco",
            "Ilianna Lourida",
            "David J. Llewellyn",
            "Janice M. Ranson"
        ],
        "date": "2 March 2023",
        "abstract": "To enhance the acceptability of models and AI\u2010enabled systems to users, researchers should prioritize interpretable methods that provide insights into how decisions are generated and adhere to reporting guidelines that are co\u2010produced with multiple stakeholders. Artificial intelligence (AI) and machine learning (ML) approaches are increasingly being used in dementia research. However, several methodological challenges exist that may limit the insights we can obtain from high\u2010dimensional data and our ability to translate these findings into improved patient outcomes. To improve reproducibility and replicability, researchers should make their well\u2010documented code and modeling pipelines openly available. Data should also be shared where appropriate. To enhance the acceptability of models and AI\u2010enabled systems to users, researchers should prioritize interpretable methods that provide insights into how decisions are generated. Models should be developed using multiple, diverse datasets to improve robustness, generalizability, and reduce potentially harmful bias. To improve clarity and reproducibility, researchers should adhere to reporting guidelines that are co\u2010produced with multiple stakeholders. If these methodological challenges are overcome, AI and ML hold enormous promise for changing the landscape of dementia research and care.",
        "references": [
            "6b95ef988831bfcfb75dcbd06945f307de98efc0",
            "c3f2b1a5210ac37b48f9f9c5753ec880a6631a7f",
            "1e66429be5124943280045b1b1071bef8a72b2c3",
            "783c5bbb6da1b15fbde35af0780cfe75aced20a8",
            "f3d7661345e7e612c84505c080b4c393568ff3ed",
            "ffb1968b59dbd8897474c52548b8c2b327c82d4d",
            "587c11117655859d137d9a538d99c0d8fd1de296",
            "3c15d27ac9463e5701735d4dbf293ba445bc3573",
            "f0da233351f3d1dba752cfeebf332e1c459a75b2",
            "44479cc5266788c3bafcc0b12ef0758827741fe3"
        ],
        "related_topics": [],
        "reference_count": "188",
        "citation_count": "3"
    },
    {
        "Id": "0509758ffb8448aa367db8f81e961e9dbd932918",
        "title": "An Assessment System for Alzheimer's Disease Based on Speech Using a Novel Feature Sequence Design and Recurrent Neural Network",
        "authors": [
            "Yi-Wei Chien",
            "Sheng-Yi Hong",
            "Wen-Ting Cheah",
            "Li-Chen Fu",
            "Yu-Ling Chang"
        ],
        "date": "1 October 2018",
        "abstract": "A novel Feature Sequence representation is proposed and a recurrent neural network is utilized and utilized to perform classification in this paper, potentially outperforming the current state-of-the-art method. Alzheimer disease and other dementias have become the 7th cause of death worldwide. Still lacking a cure, an early detection of the disease in order to provide the best intervention is crucial. To develop an assessment system for the general public, speech analysis is the optimal solution since it reflects the speaker's cognitive skills abundantly and data collection is relatively inexpensive. While most of the related studies extracted statistics-based features and relied on a feature selection process, we have proposed a novel Feature Sequence representation and utilized a recurrent neural network to perform classification in this paper. To validate our work, an experiment has been conducted with 150 speech samples, and the score in terms of the area under the receiver operating characteristic curve is as high as 0.954, potentially outperforming the current state-of-the-art method.",
        "references": [],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "10"
    },
    {
        "Id": "1a9fba77d6f4f8ceb754fbc7d4f02574f4ab3ea5",
        "title": "Ophtha-LLaMA2: A Large Language Model for Ophthalmology",
        "authors": [
            "Huan Zhao",
            "Qiang Ling",
            "Yi Pan",
            "Tianyang Zhong",
            "Jin-Yu Hu",
            "Junjie Yao",
            "Fengqian Xiao",
            "Zhe Xiao",
            "Yutong Zhang",
            "San-Hua Xu",
            "Shi-Nan Wu",
            "Min Kang",
            "Zihao Wu",
            "Zheng Liu",
            "Xi Jiang",
            "Tianming Liu",
            "Yi Shao"
        ],
        "date": "8 December 2023",
        "abstract": "This research demonstrates that the Ophtha-LLaMA2 exhibits satisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a valuable tool for ophthalmologists to provide improved diagnostic support for patients. In recent years, pre-trained large language models (LLMs) have achieved tremendous success in the field of Natural Language Processing (NLP). Prior studies have primarily focused on general and generic domains, with relatively less research on specialized LLMs in the medical field. The specialization and high accuracy requirements for diagnosis in the medical field, as well as the challenges in collecting large-scale data, have constrained the application and development of LLMs in medical scenarios. In the field of ophthalmology, clinical diagnosis mainly relies on doctors' interpretation of reports and making diagnostic decisions. In order to take advantage of LLMs to provide decision support for doctors, we collected three modalities of ophthalmic report data and fine-tuned the LLaMA2 model, successfully constructing an LLM termed the\"Ophtha-LLaMA2\"specifically tailored for ophthalmic disease diagnosis. Inference test results show that even with a smaller fine-tuning dataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis compared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits satisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a valuable tool for ophthalmologists to provide improved diagnostic support for patients. This research provides a useful reference for the application of LLMs in the field of ophthalmology, while showcasing the immense potential and prospects in this domain.",
        "references": [
            "94ce1d5924e05e8d75e43ce70044293ddcef850a",
            "9cd4fc0517ea310cc85504f35857a74aedff65bb",
            "089f6328085066263fedc083952624ca121ebbf3",
            "fefe0ca0b7cfc0d988e0e97dac868d4b10e673b1",
            "c234381686e782987a556e44aed061aaedd8c2de",
            "833677f4b048e116920ad041248b9df5223951f9",
            "9ec42d155e2014e86ab49adcf76fd40a41a867ea",
            "31a7d8c4a5ab6bab522494b57270249105c8748e",
            "b4583fe942ec2514dc21ce63a697453063f74fb5",
            "d818f40ea693a335e02f32dab520351d271c58bf"
        ],
        "related_topics": [],
        "reference_count": "39",
        "citation_count": "One"
    },
    {
        "Id": "2525f8185ff4eee23dea96f2a820714a1619fb89",
        "title": "Evaluating Large Language Models for Radiology Natural Language Processing",
        "authors": [
            "Zheng Liu",
            "Tianyang Zhong",
            "Yiwei Li",
            "Yutong Zhang",
            "Yirong Pan",
            "Zihao Zhao",
            "Pei Dong",
            "Chao-Yang Cao",
            "Yu\u2010Xin Liu",
            "Peng Shu",
            "Yaonai Wei",
            "Zihao Wu",
            "Chong-Yi Ma",
            "Jiaqi Wang",
            "Shengming Wang",
            "Mengyue Zhou",
            "Zuowei Jiang",
            "Chunlin Li",
            "Jason M. Holmes",
            "Shaochen Xu",
            "Lu Zhang",
            "Haixing Dai",
            "Kailiang Zhang",
            "Lin Zhao",
            "Yuanhao",
            "Chen",
            "X. Liu",
            "Pei Wang",
            "Pingkun Yan",
            "Jun Liu",
            "Bao Ge",
            "Lichao Sun",
            "Dajiang",
            "Zhu",
            "Xiang Li",
            "W. Liu",
            "Xiaoyan Cai",
            "Xintao Hu",
            "Xi Jiang",
            "Shu Zhang",
            "Xin Zhang",
            "Tuo Zhang",
            "Shijie Zhao",
            "Quanzheng Li",
            "Hongtu Zhu",
            "Dinggang Shen",
            "Tianming Liu"
        ],
        "date": "25 July 2023",
        "abstract": "Critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP, provides key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain. The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP). LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field. Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese. However, a comprehensive evaluation of these models remains to be conducted. This lack of assessment is especially apparent within the context of radiology NLP. This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP. Specifically, the ability to derive impressions from radiologic findings is assessed. The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.",
        "references": [
            "42780f9c7f73d73d7a887e2f787af0e079703d40",
            "a4f16dda8d25bdc0f93d2deb3b0876d278de9284",
            "04ee9597be4d6d2457214334e495e591000b5542",
            "6052486bc9144dc1730c12bf35323af3792a1fd0",
            "80d8f048ec3d5ab8595ae58cc9105eaafbc57f14",
            "f628a947995d43b3e6e51a06bcd33badded0d22b",
            "686d9ee744fa013cc21cdd86acd864c936e9e456",
            "2979b4a59d3aa847b2e2b3254d351060dff50e55",
            "25632c3f7e7a23bfe2bcf4fbeed58c2ac3146d81",
            "348a1efa54376fa39053e5e25d52bd0eb6a0ba68"
        ],
        "related_topics": [],
        "reference_count": "135",
        "citation_count": "3"
    },
    {
        "Id": "420d6754315ac5db8a040386245cd15b9fe5b459",
        "title": "Radiology-Llama2: Best-in-Class Large Language Model for Radiology",
        "authors": [
            "Zheng Liu",
            "Yiwei Li",
            "Peng Shu",
            "Aoxiao Zhong",
            "Longtao Yang",
            "Chao Ju",
            "Zihao Wu",
            "Chong-Yi Ma",
            "Jie Luo",
            "Cheng Chen",
            "Sekeun Kim",
            "Jiang Hu",
            "Haixing Dai",
            "Lin Zhao",
            "Dajiang Zhu",
            "Jun Liu",
            "W. Liu",
            "Dinggang Shen",
            "Tianming Liu",
            "Quanzheng Li",
            "Xiang Li"
        ],
        "date": "29 August 2023",
        "abstract": "Quantitative evaluations using ROUGE metrics demonstrate that Radiology-Llama2 achieves state-of-the-art performance compared to other generative language models, with a Rouge-1 score of 0.4834 on MIMIC-CXR and OpenI. This paper introduces Radiology-Llama2, a large language model specialized for radiology through a process known as instruction tuning. Radiology-Llama2 is based on the Llama2 architecture and further trained on a large dataset of radiology reports to generate coherent and clinically useful impressions from radiological findings. Quantitative evaluations using ROUGE metrics on the MIMIC-CXR and OpenI datasets demonstrate that Radiology-Llama2 achieves state-of-the-art performance compared to other generative language models, with a Rouge-1 score of 0.4834 on MIMIC-CXR and 0.4185 on OpenI. Additional assessments by radiology experts highlight the model's strengths in understandability, coherence, relevance, conciseness, and clinical utility. The work illustrates the potential of localized language models designed and tuned for specialized domains like radiology. When properly evaluated and deployed, such models can transform fields like radiology by automating rote tasks and enhancing human expertise.",
        "references": [
            "a4f16dda8d25bdc0f93d2deb3b0876d278de9284",
            "73025a7866764e009483c07f30dd2954b06ab0d6",
            "a7f8fd45fbcdd81449cb7a1a6a2b2c18b38f8151",
            "9ec42d155e2014e86ab49adcf76fd40a41a867ea",
            "258605dc5b00fe66b72091f947642a554e472aee",
            "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
            "302ee27524a717ddc21f332ca634b9211c6ec6aa",
            "eb9ab13a412befa0ac793cb510ea7a78b9881c5b",
            "089f6328085066263fedc083952624ca121ebbf3",
            "094ff971d6a8b8ff870946c9b3ce5aa173617bfb"
        ],
        "related_topics": [],
        "reference_count": "66",
        "citation_count": "12"
    },
    {
        "Id": "6770061933096bc52b4e2f817923c285be68204f",
        "title": "Artificial General Intelligence for Radiation Oncology",
        "authors": [
            "Chenbin Liu",
            "Zheng Liu",
            "Jason M. Holmes",
            "Lu Zhang",
            "Lian-Cheng Zhang",
            "Yuzhen Ding",
            "Peng Shu",
            "Zihao Wu",
            "Haixing Dai",
            "Yiwei Li",
            "Dinggang Shen",
            "Ninghao Liu",
            "Quanzheng Li",
            "Xiang Li",
            "Dajiang Zhu",
            "Tianming Liu",
            "W. Liu"
        ],
        "date": "5 September 2023",
        "abstract": "Semantic Scholar extracted view of \"Artificial General Intelligence for Radiation Oncology\" by Chenbin Liu et al.",
        "references": [
            "05c5718b35549120a982cd464a28c8f95ef3e19c",
            "5ae1181ca2a1e1ff28d5ffd7b76ac0109dbbbd72",
            "08f9382d4531eedb4be20dcdce32a1a7063a9fca",
            "d818f40ea693a335e02f32dab520351d271c58bf",
            "d61f0b49e6a8ba647fd18455f5aa7468bda765c6",
            "42cd084af70ab04fe4e460f6942cbcb277bc32b2",
            "2fec469a9370566a1e55d51615659faf3c61d41a",
            "5ac14b8867686fb603e95033e94255a9e1efde27",
            "57eda34b0030d56f7c55eb8cc53c3202abb218b9",
            "3fd654261bd7eaa1a7e18cbaff7a21990a189f13"
        ],
        "related_topics": [],
        "reference_count": "212",
        "citation_count": "8"
    },
    {
        "Id": "5ac14b8867686fb603e95033e94255a9e1efde27",
        "title": "RadOnc-GPT: A Large Language Model for Radiation Oncology",
        "authors": [
            "Zheng Liu",
            "Peilong Wang",
            "Yiwei Li",
            "Jason M. Holmes",
            "Peng Shu",
            "Lian-Cheng Zhang",
            "Chenbin Liu",
            "Ninghao Liu",
            "Dajiang Zhu",
            "Xiang Li",
            "Quanzheng Li",
            "Samir H. Patel",
            "Terence T. Sio",
            "Tianming Liu",
            "W. Liu"
        ],
        "date": "18 September 2023",
        "abstract": "The study demonstrated the potential of using large language models fine-tuned using domain-specific knowledge like RadOnc-GPT to achieve transformational capabilities in highly specialized healthcare fields such as radiation oncology. This paper presents RadOnc-GPT, a large language model specialized for radiation oncology through advanced tuning methods. RadOnc-GPT was finetuned on a large dataset of radiation oncology patient records and clinical notes from the Mayo Clinic in Arizona. The model employs instruction tuning on three key tasks - generating radiotherapy treatment regimens, determining optimal radiation modalities, and providing diagnostic descriptions/ICD codes based on patient diagnostic details. Evaluations conducted by comparing RadOnc-GPT outputs to general large language model outputs showed that RadOnc-GPT generated outputs with significantly improved clarity, specificity, and clinical relevance. The study demonstrated the potential of using large language models fine-tuned using domain-specific knowledge like RadOnc-GPT to achieve transformational capabilities in highly specialized healthcare fields such as radiation oncology.",
        "references": [
            "a4f16dda8d25bdc0f93d2deb3b0876d278de9284",
            "6770061933096bc52b4e2f817923c285be68204f",
            "9ec42d155e2014e86ab49adcf76fd40a41a867ea",
            "8fd79e9d44b70c2aa2a1d5f0a9a66285ed6b48b6",
            "2525f8185ff4eee23dea96f2a820714a1619fb89",
            "74363a0fae7c2187c75ecedb0408d627c9485eeb",
            "089f6328085066263fedc083952624ca121ebbf3",
            "a135b06987665f34fb4ed869a584d931ca8a7805",
            "47887611dac586cfa02b06297dccd4275fa1b032",
            "eaf85d5696cbcbb27afd79cebfb1824074e4bc66"
        ],
        "related_topics": [],
        "reference_count": "60",
        "citation_count": "9"
    },
    {
        "Id": "8ef83aec0d772ebb9fb22e49d15aa979d38d3ef4",
        "title": "PharmacyGPT: The AI Pharmacist",
        "authors": [
            "Zheng Liu",
            "Zihao Wu",
            "Mengxuan Hu",
            "Bokai Zhao",
            "Lin Zhao",
            "Tianyi Zhang",
            "Haixing Dai",
            "Xianyan Chen",
            "Ye Shen",
            "Sheng Li",
            "Brian Murray",
            "Tianming Liu",
            "Andrea Sikora"
        ],
        "date": "19 July 2023",
        "abstract": "This study introduces PharmacyGPT, a novel framework to assess the capabilities of large language models such as ChatGPT and GPT-4 in emulating the role of clinical pharmacists and aims to contribute to the ongoing discourse surrounding the integration of artificial intelligence in healthcare settings. In this study, we introduce PharmacyGPT, a novel framework to assess the capabilities of large language models (LLMs) such as ChatGPT and GPT-4 in emulating the role of clinical pharmacists. Our methodology encompasses the utilization of LLMs to generate comprehensible patient clusters, formulate medication plans, and forecast patient outcomes. We conduct our investigation using real data acquired from the intensive care unit (ICU) at the University of North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable insights into the potential applications and limitations of LLMs in the field of clinical pharmacy, with implications for both patient care and the development of future AI-driven healthcare solutions. By evaluating the performance of PharmacyGPT, we aim to contribute to the ongoing discourse surrounding the integration of artificial intelligence in healthcare settings, ultimately promoting the responsible and efficacious use of such technologies.",
        "references": [
            "a4f16dda8d25bdc0f93d2deb3b0876d278de9284",
            "d818f40ea693a335e02f32dab520351d271c58bf",
            "dfdf7ff01aa6f691831e663fd29bc71890be39e2",
            "7a942329e2e9d96628e7714b6b47f98d6b347f97",
            "6052486bc9144dc1730c12bf35323af3792a1fd0",
            "92d8bd3113e4e6c493662024e18f3a2badb93a13",
            "2bc01f1feec095a4959e5bb82c317190050e33b8",
            "7d5657c78f3fee9756061c6a82db44db9d413e0b",
            "1a2b671bb3e3b708f117674dec4480ed885c4d6a",
            "aee7142fe0da51d3004df62596205d7b4cfd3674"
        ],
        "related_topics": [
            "Large Language Models",
            "Artificial Intelligence",
            "Intensive Care Unit",
            "GPT-4",
            "ChatGPT",
            "Uncinate Fasciculus"
        ],
        "reference_count": "74",
        "citation_count": "7"
    },
    {
        "Id": "37b87993a3681f83810e8a412a20e4c233f1f228",
        "title": "Temporal Integration of Text Transcripts and Acoustic Features for Alzheimer's Diagnosis Based on Spontaneous Speech",
        "authors": [
            "Matej Martinc",
            "Fasih Haider",
            "Senja Pollak",
            "Saturnino Luz"
        ],
        "date": "14 June 2021",
        "abstract": "The proposed combination of ADR audio and textual features is capable of successfully modelling temporal aspects of the data and achieves best performance when ADR features are combined with strong semantic bag-of-n-grams features. Background: Advances in machine learning (ML) technology have opened new avenues for detection and monitoring of cognitive decline. In this study, a multimodal approach to Alzheimer's dementia detection based on the patient's spontaneous speech is presented. This approach was tested on a standard, publicly available Alzheimer's speech dataset for comparability. The data comprise voice samples from 156 participants (1:1 ratio of Alzheimer's to control), matched by age and gender. Materials and Methods: A recently developed Active Data Representation (ADR) technique for voice processing was employed as a framework for fusion of acoustic and textual features at sentence and word level. Temporal aspects of textual features were investigated in conjunction with acoustic features in order to shed light on the temporal interplay between paralinguistic (acoustic) and linguistic (textual) aspects of Alzheimer's speech. Combinations between several configurations of ADR features and more traditional bag-of-n-grams approaches were used in an ensemble of classifiers built and evaluated on a standardised dataset containing recorded speech of scene descriptions and textual transcripts. Results: Employing only semantic bag-of-n-grams features, an accuracy of 89.58% was achieved in distinguishing between Alzheimer's patients and healthy controls. Adding temporal and structural information by combining bag-of-n-grams features with ADR audio/textual features, the accuracy could be improved to 91.67% on the test set. An accuracy of 93.75% was achieved through late fusion of the three best feature configurations, which corresponds to a 4.7% improvement over the best result reported in the literature for this dataset. Conclusion: The proposed combination of ADR audio and textual features is capable of successfully modelling temporal aspects of the data. The machine learning approach toward dementia detection achieves best performance when ADR features are combined with strong semantic bag-of-n-grams features. This combination leads to state-of-the-art performance on the AD classification task.",
        "references": [
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "d8dd064712d8c7d6bdc4dc5ea02ac2b43539ebcf",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
            "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
            "5c9eb6965c362599beceac8fd29f23581991f5fd",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "a97936567f0f980600d34485c5e9f0e9c3eb1205",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d"
        ],
        "related_topics": [],
        "reference_count": "70",
        "citation_count": "26"
    },
    {
        "Id": "664b507618929d9da1d7f4c30e4f849e765102eb",
        "title": "Speech Processing for Early Alzheimer Disease Diagnosis: Machine Learning Based Approach",
        "authors": [
            "Randa Ben Ammar",
            "Yassine Ben Ayed"
        ],
        "date": "1 October 2018",
        "abstract": "The current findings show that the proposed model can be strongly recommended for classifying Alzheimer's patient from healthy individuals with an accuracy of 79%. Alzheimer's disease (AD) is a neurodegenerative disease characterized by the insidious onset of cognitive, emotional and language disorders. These attacks are sufficiently intense to affect the daily social and professional lives of patients. Today, in the absence of a reliable diagnosis and effective curative treatments, fighting this disease is becoming a real public health issue, prompting research to consider non-drug techniques. Among these techniques, speech processing is proving to be a relevant and innovative field of investigation. Several Machine Learning algorithms achieved promising results in distinguishing AD from healthy control subjects. Alternatively, many other factors such as feature extraction, the number of attributes for feature selection, used classifiers, may affect the prediction accuracy evaluation. To surmount these weaknesses, a model is suggested which include a feature extraction step followed by imperative attribute selection and classification is achieved using a machine learning classifiers. The current findings show that the proposed model can be strongly recommended for classifying Alzheimer's patient from healthy individuals with an accuracy of 79%.",
        "references": [
            "4d4117e4e5214dcc887317e302db724df545729e",
            "841a8390f3a7ee55c45860eb14cff373795ec859",
            "3720bc93ed64a447b25a2be1efafa3b6b0f8fcd5",
            "6ca330477a1509b0a5b3d1848564b954bb5e29a4",
            "cc884f5d29e3024baa77295f2db37b37ab7facde",
            "bbeae238e2d1373b75ce20ce96b4a5b87383a622",
            "6fcbf100eb09852c645ca20e04aafa37b1fe4536",
            "a30f5fc88098e08917442cbde90346231dbc9bb5",
            "37d2d04f8c09da1f0cf8434a38a51841b5b703bf",
            "1d58333a0af989ee95aef7e4b6b9b8d5875c1980"
        ],
        "related_topics": [],
        "reference_count": "37",
        "citation_count": "21"
    },
    {
        "Id": "5cc356276c7b6c9494cde942cd93689d12025d08",
        "title": "Identifying Alzheimer\u2019s Dementia Patients Using MRI Clinical Data",
        "authors": [
            "Chavda Ritul",
            "Nalini Sampath"
        ],
        "date": "6 July 2023",
        "abstract": "The proposed model utilizes three blocks of convolutional neural network layers, each containing different filter sizes, to improve the accuracy of the model in identifying images based on visual cues, and the model achieved an impressive 98.64% accuracy in training classification and 96%\" accuracy in testing. Alzheimer's disease is a debilitating and progressive neurological disorder that is characterized by a range of symptoms, including memory loss, difficulties with thinking, language, and perception, and a loss of the ability to perform simple daily tasks. Although the exact cause of Alzheimer's disease is unknown, a number of factors are believed to contribute to its development, including the accumulation of amyloid proteins and neurofibrillary tangles in the brain, genetic predisposition, age-related changes in the brain, and lifestyle factors. [1] Given the lack of a cure for Alzheimer's, a model has been proposed to decrease the number of pa-tients with dementia. This model utilizes three blocks of convolutional neural network (CNN) layers, each containing different filter sizes, to improve the accuracy of the model in identifying images based on visual cues. This approach resulted in high loss and validation accuracy, and the model achieved an impressive 98.64% accuracy in training classification and 96% accuracy in testing. When compared with other models, including VGG16, VGG19, and InceptionResNet V2, the proposed model performed better with a higher accuracy rate. InceptionResNet V2 was the closest competitor with an accuracy of 86%, while VGG16 and VGG19 performed similarly, achieving accuracies of 74% and 76% respectively. The accuracy rates suggest that the proposed model is a promising approach to decreasing the number of patients with Alzheimer's disease.",
        "references": [
            "ec7136879bc8151771c9ff98910bdee8704c396d",
            "7c2059ec1f0ba4eb2d2dd771afd9102266e9d14a",
            "9358d9e9afbc1eaf6b2f2042a8adc573556f566e",
            "3d9f77d2897273f6a79dc5f195f3f72f15b45393",
            "0d0c1ed5018d48326c143ffb37623f4a29214134",
            "7ec013b55dec19b6d23de409e1dd6eff4bc1bb2e",
            "33182de6ab254a05cb34effcf9325f99351346e4",
            "f68aea751151c587d975016bb99a17174aa7d4af",
            "071fd42ecfa73ba1ade332e690976b0e5d4f93b6",
            "1b3ae2d31249cf6db15b9d5caff76ff694bcb45c"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "15"
    },
    {
        "Id": "50e39f76040d4f43c7a4830f7c75621f59b0a573",
        "title": "Multilingual and Mixed-lingual Digit Speech Recognition System for Indian Context",
        "authors": [
            "Lalitha S",
            "Rachana N",
            "Vinay Bhargav J"
        ],
        "date": "6 July 2023",
        "abstract": "An extensive database of digit utterances from 0 to 9 for various Indian languages of Telugu, Kannada, Hindi & Tamil are self-recorded and used for the experimental work and a Convolutional Neural Network is applied for classification to identify the digits. Voice assistants, customer service center automation, and voice-controlled devices all rely heavily on digit speech recognition. For multilingual countries like India, Canada, and Belgium to communicate in more than one language, there is a need for multilingual and mixed-lingual digit speech recognition (DSR) systems. This is the main emphasis of the proposed work. An extensive database of digit utterances from 0 to 9 for various Indian languages of Telugu, Kannada, Hindi & Tamil are self-recorded and used for the experimental work. Following the initial preprocessing by noise elimination from the self-recorded samples, spectrographic characteristics were extracted, and finally, a Convolutional Neural Network (CNN) is applied for classification to identify the digits. The proposed multilingual DSR model resulted in an accuracy of range 89% to 96% and a loss value between 0.144 to 0.878 varying for each language whereas the mixed-lingual DSR model resulted in an accuracy of 92% and a loss value of 0.615.",
        "references": [
            "5cbc4ca43b7b4078c03ea847dfd63c29dcddeb0d",
            "03e74949820681196fdd9f25ef775a0447200bdd",
            "ba8bc11565240398427e52203e873e07c68265c6",
            "dbc743d0d756cb4bce7d3c5a993ab5b55b814154",
            "dc5ff31246fc1f68cd9bca17f5a4eb9cabee3946",
            "51f56e649fa8b629dd629c456c7f3b19cb454690",
            "ab2e5ca4390e3a757688cfdcfb3d41c2f883b3fe",
            "eec174709eb3ee4e3cf11203f8ae48b13cd073fd",
            "36c6525a88f4506e8e2692487b3bb401c9f1bc0f",
            "790eb7e93f1d3fce470c0222fd2be83bab55a428"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "20"
    },
    {
        "Id": "5b63aef5d7e53b83ebb82a5166a2b4ce34e72ddb",
        "title": "Dementia Detection using Transformer-Based Deep Learning and Natural Language Processing Models",
        "authors": [
            "Ploypaphat Saltz",
            "Shih-Yin Lin",
            "Sunny Chieh Cheng",
            "Dong Si"
        ],
        "date": "1 August 2021",
        "abstract": "Transformer-based deep learning models were applied to automatically extract linguistic features for identifying individuals with dementia to suggest the potential possibility of a more flexible examination setting, casual semi-structured individual or group interview, for detecting incoherent or illogical thoughts and speech in patients with dementia. Dementia is a disease characterized by cognitive impairment that leads to incoherent or illogical thoughts and speech. There are attempts to identify dementia through speech analyses, but there is a dearth of research on casual conversation analysis. This work examined communication impairment detection of people with early-stage memory loss, including mild dementia and mild cognitive impairment. The data sets included semi-structured interviews from two studies conducted at the University of Washington (UW), the DementiaBank\u2019s Pitt Corpus, and the ADReSS Challenge at INTERSPEECH 2020. We applied Transformer-based deep learning models to automatically extract linguistic features for identifying individuals with dementia. Our results showed the models\u2019 abilities on detecting linguistic deficits with the best mean F1-score of 76% on the Pitt Corpus, 84% on the ADReSS, 90% on the augmented ADReSS, and 74% on the UW transcripts. The results suggest the potential possibility of a more flexible examination setting, casual semi-structured individual or group interview, for detecting incoherent or illogical thoughts and speech in patients with dementia.",
        "references": [],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "7"
    },
    {
        "Id": "d19701ccfb9170cc4b8b7856ba186ed3db7eb56d",
        "title": "Acoustic and Language Based Deep Learning Approaches for Alzheimer's Dementia Detection From Spontaneous Speech",
        "authors": [
            "Pranav Mahajan",
            "Veeky Baths"
        ],
        "date": "5 February 2021",
        "abstract": "This work re-implements the existing NLP methods, which used CNN-LSTM architectures and targeted features from conversational transcripts, and proposes a bi-modal approach for AD classification and discusses the merits and opportunities of this approach. Current methods for early diagnosis of Alzheimer's Dementia include structured questionnaires, structured interviews, and various cognitive tests. Language difficulties are a major problem in dementia as linguistic skills break down. Current methods do not provide robust tools to capture the true nature of language deficits in spontaneous speech. Early detection of Alzheimer's Dementia (AD) from spontaneous speech overcomes the limitations of earlier approaches as it is less time consuming, can be done at home, and is relatively inexpensive. In this work, we re-implement the existing NLP methods, which used CNN-LSTM architectures and targeted features from conversational transcripts. Our work sheds light on why the accuracy of these models drops to 72.92% on the ADReSS dataset, whereas, they gave state of the art results on the DementiaBank dataset. Further, we build upon these language input-based recurrent neural networks by devising an end-to-end deep learning-based solution that performs a binary classification of Alzheimer's Dementia from the spontaneous speech of the patients. We utilize the ADReSS dataset for all our implementations and explore the deep learning-based methods of combining acoustic features into a common vector using recurrent units. Our approach of combining acoustic features using the Speech-GRU improves the accuracy by 2% in comparison to acoustic baselines. When further enriched by targeted features, the Speech-GRU performs better than acoustic baselines by 6.25%. We propose a bi-modal approach for AD classification and discuss the merits and opportunities of our approach.",
        "references": [
            "a67e59ba96d86a0b609b84363dc212f3dfef97dd",
            "cc2e10b0a706f22bc0117709f99949459fca19d1",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "06961f070ae235beb6e4424e2e2c740a4444a5ae",
            "73ee478f44296ee9a9e810fa106462ca52ece708",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "43d17de93cad046fd96caa955b6ba07d53e12de1",
            "4d4117e4e5214dcc887317e302db724df545729e",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "d8dd064712d8c7d6bdc4dc5ea02ac2b43539ebcf"
        ],
        "related_topics": [],
        "reference_count": "25",
        "citation_count": "36"
    },
    {
        "Id": "3f424216d8a086defd73da2432f181ef88d8674b",
        "title": "Comparing Natural Language Processing Techniques for Alzheimer's Dementia Prediction in Spontaneous Speech",
        "authors": [
            "Thomas Searle",
            "Zina M. Ibrahim",
            "Richard J. B. Dobson"
        ],
        "date": "12 June 2020",
        "abstract": "The Alzheimer's Dementia Recognition through Spontaneous Speech task offers acoustically pre-processed and balanced datasets for the classification and prediction of AD and associated phenotypes through the modelling of spontaneous speech. Alzheimer's Dementia (AD) is an incurable, debilitating, and progressive neurodegenerative condition that affects cognitive function. Early diagnosis is important as therapeutics can delay progression and give those diagnosed vital time. Developing models that analyse spontaneous speech could eventually provide an efficient diagnostic modality for earlier diagnosis of AD. The Alzheimer's Dementia Recognition through Spontaneous Speech task offers acoustically pre-processed and balanced datasets for the classification and prediction of AD and associated phenotypes through the modelling of spontaneous speech. We exclusively analyse the supplied textual transcripts of the spontaneous speech dataset, building and comparing performance across numerous models for the classification of AD vs controls and the prediction of Mental Mini State Exam scores. We rigorously train and evaluate Support Vector Machines (SVMs), Gradient Boosting Decision Trees (GBDT), and Conditional Random Fields (CRFs) alongside deep learning Transformer based models. We find our top performing models to be a simple Term Frequency-Inverse Document Frequency (TF-IDF) vectoriser as input into a SVM model and a pre-trained Transformer based model `DistilBERT' when used as an embedding layer into simple linear models. We demonstrate test set scores of 0.81-0.82 across classification metrics and a RMSE of 4.58.",
        "references": [
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "a97936567f0f980600d34485c5e9f0e9c3eb1205",
            "8a1b537ed71e681c9e9f882bf34b3048a68eef37",
            "90272b8038d334c8587c9a7751097c5882ce3f0c",
            "1df9679897dc9c05ef324ae1be1149bfd8611be2",
            "07913998c7dfe4ee33a9ddac8c1f93d8447bfc03",
            "15d8fc2bcd17df5532d32ff0bba63aef6615fa3c",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "10945c6ee44d86a3e3238b360f4a6ec21a1d5072",
            "157a7ae44613a1fcf34e2be8c1e19a4f6e3c50e3"
        ],
        "related_topics": [
            "Alzheimer's Dementia Recognition Through Spontaneous Speech",
            "Alzheimer ' S Dementia Recognition Through Spontaneous Speech",
            "Classification",
            "Alzheimer's Dementia",
            "Natural Language Processing",
            "Conditional Random Fields",
            "Embedding Layers",
            "Deep Learning",
            "Relative MSE"
        ],
        "reference_count": "29",
        "citation_count": "30"
    },
    {
        "Id": "194c36d79c7af11254637cfaa5cc54389ae7ab9b",
        "title": "Classifying Alzheimer's Disease Using Audio and Text-Based Representations of Speech",
        "authors": [
            "R&#x27;mani Haulcy",
            "James R. Glass"
        ],
        "date": "15 January 2021",
        "abstract": "The feasibility of using speech to classify AD and predict neuropsychological scores is illustrated and the top-performing classification models were the support vector machine and random forest classifiers trained on BERT embeddings, which both achieved an accuracy of 85.4% on the test set. Alzheimer's Disease (AD) is a form of dementia that affects the memory, cognition, and motor skills of patients. Extensive research has been done to develop accessible, cost-effective, and non-invasive techniques for the automatic detection of AD. Previous research has shown that speech can be used to distinguish between healthy patients and afflicted patients. In this paper, the ADReSS dataset, a dataset balanced by gender and age, was used to automatically classify AD from spontaneous speech. The performance of five classifiers, as well as a convolutional neural network and long short-term memory network, was compared when trained on audio features (i-vectors and x-vectors) and text features (word vectors, BERT embeddings, LIWC features, and CLAN features). The same audio and text features were used to train five regression models to predict the Mini-Mental State Examination score for each patient, a score that has a maximum value of 30. The top-performing classification models were the support vector machine and random forest classifiers trained on BERT embeddings, which both achieved an accuracy of 85.4% on the test set. The best-performing regression model was the gradient boosting regression model trained on BERT embeddings and CLAN features, which had a root mean squared error of 4.56 on the test set. The performance on both tasks illustrates the feasibility of using speech to classify AD and predict neuropsychological scores.",
        "references": [
            "494d1214ad408719bd5e267cf6a4dad163af4121",
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "cc2e10b0a706f22bc0117709f99949459fca19d1",
            "1d21ee08b6af747d4cce3c5cc6432f7312f3bb58",
            "a97936567f0f980600d34485c5e9f0e9c3eb1205",
            "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "93bdefc9d8feccdef5ff1396fd3c117968899794",
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b"
        ],
        "related_topics": [],
        "reference_count": "63",
        "citation_count": "48"
    },
    {
        "Id": "f2a93c2ecdfc2d6407feda6d848f1194e18697ae",
        "title": "Exploring neural models for predicting dementia from language",
        "authors": [
            "Weirui Kong",
            "Hyeju Jang",
            "Giuseppe Carenini",
            "Thalia Shoshana Field"
        ],
        "date": "1 July 2021",
        "abstract": "Semantic Scholar extracted view of \"Exploring neural models for predicting dementia from language\" by Weirui Kong et al.",
        "references": [
            "4d4117e4e5214dcc887317e302db724df545729e",
            "61c4ac6340b58569973e1a7d4edb7a21d6726423",
            "4e3c4e875973515a405713588b42e61425ac33a5",
            "a7425f74a9e7bdd3ae6763c515c9534fb18a3560",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "964930b97056dce8a2bfb38f3f3d66ab3e160cb1",
            "c940a209c47594443c5f352890b37a8d3fa9525f",
            "c1c33280fe9e00d8047ced66815e7232403e4ca2",
            "647c4649b11a92d4797950d50a8294b1beaba22b",
            "9eb018471ead7824f3e093673669a9c088044dce"
        ],
        "related_topics": [
            "Acoustic Features",
            "Neural Coherence Model"
        ],
        "reference_count": "64",
        "citation_count": "8"
    },
    {
        "Id": "acacb4176fa29ebd4ba328af8cf0b960375725fe",
        "title": "Recognition of Alzheimer\u2019s Dementia From the Transcriptions of Spontaneous Speech Using fastText and CNN Models",
        "authors": [
            "Amit Meghanani",
            "Chandran Savithri Anoop",
            "Angarai Ganesan Ramakrishnan"
        ],
        "date": "24 March 2021",
        "abstract": "This work explores the transcriptions of spontaneous speech for dementia recognition and suggests that the n-gram-based features are worth pursuing, for the task of AD detection. Alzheimer\u2019s dementia (AD) is a type of neurodegenerative disease that is associated with a decline in memory. However, speech and language impairments are also common in Alzheimer\u2019s dementia patients. This work is an extension of our previous work, where we had used spontaneous speech for Alzheimer\u2019s dementia recognition employing log-Mel spectrogram and Mel-frequency cepstral coefficients (MFCC) as inputs to deep neural networks (DNN). In this work, we explore the transcriptions of spontaneous speech for dementia recognition and compare the results with several baseline results. We explore two models for dementia recognition: 1) fastText and 2) convolutional neural network (CNN) with a single convolutional layer, to capture the n-gram-based linguistic information from the input sentence. The fastText model uses a bag of bigrams and trigrams along with the input text to capture the local word orderings. In the CNN-based model, we try to capture different n-grams (we use n = 2, 3, 4, 5) present in the text by adapting the kernel sizes to n. In both fastText and CNN architectures, the word embeddings are initialized using pretrained GloVe vectors. We use bagging of 21 models in each of these architectures to arrive at the final model using which the performance on the test data is assessed. The best accuracies achieved with CNN and fastText models on the text data are 79.16 and 83.33%, respectively. The best root mean square errors (RMSE) on the prediction of mini-mental state examination (MMSE) score are 4.38 and 4.28 for CNN and fastText, respectively. The results suggest that the n-gram-based features are worth pursuing, for the task of AD detection. fastText models have competitive results when compared to several baseline methods. Also, fastText models are shallow in nature and have the advantage of being faster in training and evaluation, by several orders of magnitude, compared to deep models.",
        "references": [
            "92e0608730573341ac43955f2946513f2a5814c4",
            "3f424216d8a086defd73da2432f181ef88d8674b",
            "e60d7fd5323ddd732c29a1c05cfcd69a4099eb43",
            "c77d14e649bc2a6a421676dc36c44da26a400f66",
            "7c4224f253709a0797a956383c884770b65cd5f1",
            "97ecaf51724f76f1a93818be3f6d5721c5677889",
            "040af9f95aa39415e374e9671b9b7c73c8e5b499",
            "134d608f4e78da82c9c3c119f57cbde32e220f5e",
            "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d",
            "1fe4906d57dab8d93d5695533ba6e5eb0facbec8"
        ],
        "related_topics": [
            "fastText",
            "Convolutional Neural Network",
            "Alzheimer's Dementia",
            "Bagging",
            "Deep Model",
            "GloVe Vectors",
            "Bigram",
            "Word Embeddings",
            "Test Data",
            "Log Mel Spectrogram"
        ],
        "reference_count": "43",
        "citation_count": "21"
    },
    {
        "Id": "f214e1faf9f4172efd46c9bec3b2a90029c0564c",
        "title": "Natural Language Processing to Identify Patients with Cognitive Impairment",
        "authors": [
            "Khalil Ian Hussein",
            "Lydia Chan",
            "Tielman T. Van Vleck",
            "Kelly Beers",
            "Monica Rivera Mindt",
            "M. Wolf",
            "Laura M. Curtis",
            "Purva Agarwal",
            "Juan P Wisnivesky",
            "Girish N. Nadkarni",
            "Alex D. Federman"
        ],
        "date": "17 February 2022",
        "abstract": "NLP can identify adults with cognitive impairment with moderate test performance that is enhanced with machine learning. INTRODUCTION: Early detection of patients with cognitive impairment may facilitate care for individuals in this population. Natural language processing (NLP) is a potential approach to identifying patients with cognitive impairment from electronic health records (EHR). METHODS: We used three machine learning algorithms (logistic regression, multilayer perceptron, and random forest) using clinical terms extracted by NLP to predict cognitive impairment in a cohort of 199 patients. Cognitive impairment was defined as a mini-mental status exams (MMSE) score <24. RESULTS: NLP identified 69 (35%) patients with cognitive impairment and ICD codes identified 44 (22%). Using MMSE as a reference standard, NLP sensitivity was 35%, specificity 66%, precision 41%, and NPV 61%. The random forest method had the best test parameters; sensitivity 95%, specificity 100%, precision 100%, and NPV 97% DISCUSSION: NLP can identify adults with cognitive impairment with moderate test performance that is enhanced with machine learning.",
        "references": [
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "6ea0b0faa0b59dee1bbd60fab8522f1057f7687d",
            "6ca330477a1509b0a5b3d1848564b954bb5e29a4",
            "d5e593b99886e6d5b66a443a4c424908025a4a08",
            "d4b5344c959ea05a880bd816cc4b1ed7ef46262b",
            "483f3236516d7c01647a12d864708f3ec963f1aa",
            "a69403915b39cdbe51cc106486fd61b2659250df",
            "fa1466d908ec10f5689f54605be1fee4c42c246f",
            "0d0459c13edd84e55f58a0e12e5196523c78a9c0",
            "9d00722adfe7b59169c634f995e23db5e10f1dff"
        ],
        "related_topics": [],
        "reference_count": "44",
        "citation_count": "2"
    },
    {
        "Id": "8869037e4e806a546e1d75ec610fbb81a11011f4",
        "title": "Emotion recognition and artificial intelligence: A systematic review (2014-2023) and research recommendations",
        "authors": [
            "Smith K. Khare",
            "Victoria Blanes-Vidal",
            "Esmaeil S. Nadimi",
            "U. Rajendra Acharya"
        ],
        "date": "1 September 2023",
        "abstract": "Semantic Scholar extracted view of \"Emotion recognition and artificial intelligence: A systematic review (2014-2023) and research recommendations\" by S. K. Khare et al.",
        "references": [
            "e5822c78e94e53fb56094fc443bb1c650168d014",
            "e520aecba49bd5d8c89d8e63a6f61034f8f5cc9d",
            "1c2a293b00546808a3ad9bb1fe6f107210c759ae",
            "24c6dbd134f660f653e3dd995770c664c29457a4",
            "83ff0d07919edd8977f7e9df63f1be09fc1cb0db",
            "ab1a871fbc475bd88e39c679cfd90ff99393037b",
            "e4a628c73fcc7c5fb6953d6ea35055b4ac2e0c68",
            "3bca7200a1aadd1b0c7b109c2ecfb4d8a152efb9",
            "d0dd8d523fd7dbb59ef267625c68703f18739b8b",
            "6fe7117a6bc1bf3ee103e74df5de0f387a10cc1d"
        ],
        "related_topics": [],
        "reference_count": "300",
        "citation_count": "5"
    },
    {
        "Id": "12b57d7bd118aa5bffe6677b080fb752f7a6d41e",
        "title": "Information Fusion",
        "authors": [
            "Smith K. Khare",
            "Victoria Blanes-Vidal",
            "Esmaeil S. Nadimi",
            "U. Rajendra Acharya"
        ],
        "date": "",
        "abstract": "A comprehensive and systematic review of emotion recognition techniques of the current decade and an introduction to various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems are provided. Emotion recognition is the ability to precisely infer human emotions from numerous sources and modalities using questionnaires, physical signals, and physiological signals. Recently, emotion recognition has gained attention because of its diverse application areas, like affective computing, healthcare, human\u2013robot interactions, and market research. This paper provides a comprehensive and systematic review of emotion recognition techniques of the current decade. The paper includes emotion recognition using physical and physiological signals. Physical signals involve speech and facial expression, while physiological signals include electroencephalogram, electrocardiogram, galvanic skin response, and eye tracking. The paper provides an introduction to various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems. This paper covers comprehensive searching and scanning of well-known datasets followed by design criteria for review. After a thorough analysis and discussion, we selected 142 journal articles using PRISMA guidelines. The review provides a detailed analysis of existing studies and available datasets of emotion recognition. Our review analysis also presented potential challenges in the existing literature and directions for future research.",
        "references": [
            "e5822c78e94e53fb56094fc443bb1c650168d014",
            "83ff0d07919edd8977f7e9df63f1be09fc1cb0db",
            "e520aecba49bd5d8c89d8e63a6f61034f8f5cc9d",
            "1c2a293b00546808a3ad9bb1fe6f107210c759ae",
            "ab1a871fbc475bd88e39c679cfd90ff99393037b",
            "076a740856352fae343adc4b5ca26860f3e854e6",
            "6fe7117a6bc1bf3ee103e74df5de0f387a10cc1d",
            "41bdf09f3cb4266a3d1f069fbd5e159ff07156cb",
            "24c6dbd134f660f653e3dd995770c664c29457a4",
            "0d8144d4bb0e8c21952abe423c78b21cc11e9a47"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "299"
    },
    {
        "Id": "ca352ea6ac66c03a0cc22759098713e4202c71c6",
        "title": "Aspect-Level Sentiment Analysis Via Convolution over Dependency Tree",
        "authors": [
            "Kai Sun",
            "Richong Zhang",
            "Samuel Mensah",
            "Yongyi Mao",
            "Xudong Liu"
        ],
        "date": "1 November 2019",
        "abstract": "A convolution over a dependency tree (CDT) model which exploits a Bi-directional Long Short Term Memory (Bi-LSTM) to learn representations for features of a sentence, and further enhance the embeddings with a graph convolutional network (GCN) which operates directly on the dependency tree of the sentence. We propose a method based on neural networks to identify the sentiment polarity of opinion words expressed on a specific aspect of a sentence. Although a large majority of works typically focus on leveraging the expressive power of neural networks in handling this task, we explore the possibility of integrating dependency trees with neural networks for representation learning. To this end, we present a convolution over a dependency tree (CDT) model which exploits a Bi-directional Long Short Term Memory (Bi-LSTM) to learn representations for features of a sentence, and further enhance the embeddings with a graph convolutional network (GCN) which operates directly on the dependency tree of the sentence. Our approach propagates both contextual and dependency information from opinion words to aspect words, offering discriminative properties for supervision. Experimental results ranks our approach as the new state-of-the-art in aspect-based sentiment classification.",
        "references": [
            "9d07141dfb2ebfbc03e66c79f2ed0dd811271f47",
            "6e4ffbbb9de148ee334f07e74ddf98d9bf062f13",
            "4f8591abcc44031714f412068d781759e1bca6a1",
            "3d28cb8c175323409ab302780a55382a3cf5c2c9",
            "ecb5336bf7b54a62109f325e7152bb74c4c7f527",
            "677e0ce81f561a07d1864b18092b669552e9166b",
            "8e3a3ba309fe68f5b1d02266a03395332f7d945c",
            "48a2661c7fb56cb762fe541304c5785d793e5a0f",
            "dacc7684db98e7e64c441fd7107ccf7fbbc304b6",
            "82bb306038446302cedd20fa986d20640ed88a2e"
        ],
        "related_topics": [
            "Opinion Words",
            "Aspect Words",
            "Syntactic Dependency Trees",
            "Aspect-specific Representations",
            "Target Aspect",
            "Sentences",
            "Neural Network",
            "Graph Convolutional Networks",
            "Dependency Trees",
            "Convolutions"
        ],
        "reference_count": "32",
        "citation_count": "213"
    },
    {
        "Id": "d24d3b28c48d1049395a7dc4e05cd00db87f32ea",
        "title": "Spontaneous Language Analysis in Alzheimer\u2019s Disease: Evaluation of Natural Language Processing Technique for Analyzing Lexical Performance",
        "authors": [
            "Ning-hong Liu",
            "Zhenming Yuan"
        ],
        "date": "28 November 2021",
        "abstract": "A computer-assisted AD diagnosis model on small Chinese dataset is proposed in this paper, which provides a potential way for assisting diagnosis of AD and analyzing lexical performance in clinical setting. Language disorder, a common manifestation of Alzheimer\u2019s disease (AD), has attracted widespread attention in recent years. This paper uses a novel natural language processing (NLP) method, compared with latest deep learning technology, to detect AD and explore the lexical performance. Our proposed approach is based on two stages. First, the dialogue contents are summarized into two categories with the same category. Second, term frequency \u2014 inverse document frequency (TF-IDF) algorithm is used to extract the keywords of transcripts, and the similarity of keywords between the groups was calculated separately by cosine distance. Several deep learning methods are used to compare the performance. In the meanwhile, keywords with the best performance are used to analyze AD patients\u2019 lexical performance. In the Predictive Challenge of Alzheimer\u2019s Disease held by iFlytek in 2019, the proposed AD diagnosis model achieves a better performance in binary classification by adjusting the number of keywords. The F1 score of the model has a considerable improvement over the baseline of 75.4%, and the training process of which is simple and efficient. We analyze the keywords of the model and find that AD patients use less noun and verb than normal controls. A computer-assisted AD diagnosis model on small Chinese dataset is proposed in this paper, which provides a potential way for assisting diagnosis of AD and analyzing lexical performance in clinical setting.",
        "references": [
            "3c0edbe173aa15ffa3eb203cfa463e7f0abb8240",
            "cc435c9efd3a6454c150ab781dadc7f4fc5c8e9d",
            "494d1214ad408719bd5e267cf6a4dad163af4121",
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "dbcc61f2bfb5fd4edd48aa70e375a3d4b81a8d2a",
            "3d0bffdf62b34efbd2535a9c6b72289306d12511",
            "841a8390f3a7ee55c45860eb14cff373795ec859",
            "a214611baf46be5a21276218f892753177eed1f8",
            "eba36ac75bf22edf9a1bfd33244d459c75b98305",
            "4116c78bf8f0126f1da005cdf0c6054f54db2325"
        ],
        "related_topics": [],
        "reference_count": "26",
        "citation_count": "9"
    },
    {
        "Id": "3d28cb8c175323409ab302780a55382a3cf5c2c9",
        "title": "Effective Attention Modeling for Aspect-Level Sentiment Classification",
        "authors": [
            "Ruidan He",
            "Wee Sun Lee",
            "Hwee Tou Ng",
            "Daniel Dahlmeier"
        ],
        "date": "1 August 2018",
        "abstract": "This work proposes a method for target representation that better captures the semantic meaning of the opinion target and introduces an attention model that incorporates syntactic information into the attention mechanism. Aspect-level sentiment classification aims to determine the sentiment polarity of a review sentence towards an opinion target. A sentence could contain multiple sentiment-target pairs; thus the main challenge of this task is to separate different opinion contexts for different targets. To this end, attention mechanism has played an important role in previous state-of-the-art neural models. The mechanism is able to capture the importance of each context word towards a target by modeling their semantic associations. We build upon this line of research and propose two novel approaches for improving the effectiveness of attention. First, we propose a method for target representation that better captures the semantic meaning of the opinion target. Second, we introduce an attention model that incorporates syntactic information into the attention mechanism. We experiment on attention-based LSTM (Long Short-Term Memory) models using the datasets from SemEval 2014, 2015, and 2016. The experimental results show that the conventional attention-based LSTM can be substantially improved by incorporating the two approaches.",
        "references": [
            "fb2734de76d9713f97d1156aed4c8eca8fc4d542",
            "82bb306038446302cedd20fa986d20640ed88a2e",
            "0b0dc14b8a8dcccbfc62a38355fff2f6a361e9d2",
            "3b0e05f72b9b14ba50f3ec2e9059f3284e6a4cbd",
            "8e3a3ba309fe68f5b1d02266a03395332f7d945c",
            "cf3dfce20514078413ea911164c872bf85a4d80a",
            "4ff5cdeeed3dfeeea542d463dc2f5ad64fd38281",
            "677e0ce81f561a07d1864b18092b669552e9166b",
            "c9faf8c7c8e1f13b7a14a86b57c6432c4fd953eb",
            "688d8718e662d931d8c0ab1bfd03314c2ba711af"
        ],
        "related_topics": [
            "Aspect-level Sentiment Classification",
            "SemEval 2014",
            "Aspect Embedding",
            "Recurrent Attention On Memory",
            "ATAE-LSTM",
            "Attention-based LSTM",
            "Opinion Targets",
            "Sentiment Polarity",
            "Review Sentences",
            "Long Short-Term Memory"
        ],
        "reference_count": "26",
        "citation_count": "179"
    },
    {
        "Id": "beccf5bc709167e483e8ea0f58829c34a2bde2e7",
        "title": "Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks",
        "authors": [
            "Chen Zhang",
            "Qiuchi Li",
            "Dawei Song"
        ],
        "date": "8 September 2019",
        "abstract": "This work proposes to build a Graph Convolutional Network (GCN) over the dependency tree of a sentence to exploit syntactical information and word dependencies and raises a novel aspect-specific sentiment classification framework. Due to their inherent capability in semantic alignment of aspects and their context words, attention mechanism and Convolutional Neural Networks (CNNs) are widely applied for aspect-based sentiment classification. However, these models lack a mechanism to account for relevant syntactical constraints and long-range word dependencies, and hence may mistakenly recognize syntactically irrelevant contextual words as clues for judging aspect sentiment. To tackle this problem, we propose to build a Graph Convolutional Network (GCN) over the dependency tree of a sentence to exploit syntactical information and word dependencies. Based on it, a novel aspect-specific sentiment classification framework is raised. Experiments on three benchmarking collections illustrate that our proposed model has comparable effectiveness to a range of state-of-the-art models, and further demonstrate that both syntactical information and long-range word dependencies are properly captured by the graph convolution structure.",
        "references": [
            "6e4ffbbb9de148ee334f07e74ddf98d9bf062f13",
            "82bb306038446302cedd20fa986d20640ed88a2e",
            "f201abc6045f79c85ea555bb2ab4abbbe469aa41",
            "b28f7e2996b6ee2784dd2dbb8212cfa0c79ba9e7",
            "3d28cb8c175323409ab302780a55382a3cf5c2c9",
            "48a2661c7fb56cb762fe541304c5785d793e5a0f",
            "7c595b2c81ad4f05eb5c659de4d856e0d317dd0b",
            "0b0dc14b8a8dcccbfc62a38355fff2f6a361e9d2",
            "5e40be36d11483923cb12260bed6e8f7ed355ff3",
            "c3a3c163f25b9181f1fb7e71a32482a7393d2088"
        ],
        "related_topics": [
            "Syntactical Information",
            "ASGCN",
            "ASGCN-DG",
            "Aspect-based Sentiment Classification",
            "Long-range Word Dependencies",
            "Aspect-specific Graph Convolutional Network",
            "Aspect-specific Features",
            "Syntactical Dependency Trees",
            "Target Aspect",
            "REST16"
        ],
        "reference_count": "34",
        "citation_count": "309"
    },
    {
        "Id": "4e4136382ddab4b5b357dd8c9c81789d930065fb",
        "title": "An Attention-Based Hybrid Network for Automatic Detection of Alzheimer's Disease from Narrative Speech",
        "authors": [
            "Jun Chen",
            "Ji Zhu",
            "Jieping Ye"
        ],
        "date": "15 September 2019",
        "abstract": "An automatic speech analysis framework to identify AD subjects from short narrative speech transcript elicited with a picture description task and obtained state-of-the-art cross-validation accuracy of 97 in distinguishing individuals with AD from elderly normal controls is proposed. Alzheimer\u2019s disease (AD) is one of the leading causes of death in the world and affects at least 50 million individuals. Currently, there is no cure for the disease. So a convenient and reliable early detection approach before irreversible brain damage and cognitive decline have occurred is of great importance. One prominent sign of AD is language dysfunction. Some aspects of language are affected at the same time or even before the memory problems emerge. Therefore, we propose an automatic speech analysis framework to identify AD subjects from short narrative speech transcript elicited with a picture description task. The proposed network is based on attention mechanism and is composed of a CNN and a GRU module. We obtained state-of-the-art cross-validation accuracy of 97 in distinguishing individuals with AD from elderly normal controls. The performance of our model makes it reasonable to conclude that our approach reveals a considerable part of the language deficits of AD patients and can help with the diagnosis of the disease from spontaneous speech.",
        "references": [
            "c940a209c47594443c5f352890b37a8d3fa9525f",
            "9620bda083e3a3b7d55a5fdc5198c5f62052d323",
            "9eb018471ead7824f3e093673669a9c088044dce",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "8aed7cdbc093dd14c20181ce35d4162dde914ccb",
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "c97d93b29ade6ff3b639efc7667bc91343d2039b",
            "3720bc93ed64a447b25a2be1efafa3b6b0f8fcd5",
            "9a1fdc7dc4b41f055f28032b5eae96ac9bb6ceb8",
            "3d0bffdf62b34efbd2535a9c6b72289306d12511"
        ],
        "related_topics": [
            "Convolutional Neural Network"
        ],
        "reference_count": "36",
        "citation_count": "31"
    },
    {
        "Id": "bbeae238e2d1373b75ce20ce96b4a5b87383a622",
        "title": "Idea density for predicting Alzheimer\u2019s disease from transcribed speech",
        "authors": [
            "Kairit Sirts",
            "Olivier Piguet",
            "Mark Johnson"
        ],
        "date": "1 June 2017",
        "abstract": "DDEPID is developed, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas\u2014a feature characteristic to AD speech. Idea Density (ID) measures the rate at which ideas or elementary predications are expressed in an utterance or in a text. Lower ID is found to be associated with an increased risk of developing Alzheimer\u2019s disease (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas\u2014a feature characteristic to AD speech. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8.",
        "references": [
            "360806c34ea0dcb5faab9824dababc094bb05c07",
            "be9de6c52b9567d1306d1cc703d9cac698c15b7e",
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "bdd7750c5be25be75e39c7ff0c383ff50065acbf",
            "4d4117e4e5214dcc887317e302db724df545729e",
            "6ca330477a1509b0a5b3d1848564b954bb5e29a4",
            "fd46e4c4ad23ea006523b305a401de92e11f1f49",
            "c35396244ee8028d3553ff1fd920248d534ae2ae",
            "7d50bfd726677efb91ee21a7fec90de18d273c5b",
            "8cd1d603498e65ae19baa59bdb31617f441d4296"
        ],
        "related_topics": [
            "Speaker Identification",
            "Partial Information Decomposition",
            "Idea Density",
            "Word Embedding Clustering",
            "Propositional Idea Density",
            "Transcribed Speech"
        ],
        "reference_count": "35",
        "citation_count": "23"
    },
    {
        "Id": "8e3a3ba309fe68f5b1d02266a03395332f7d945c",
        "title": "Recurrent Attention Network on Memory for Aspect Sentiment Analysis",
        "authors": [
            "Peng Chen",
            "Zhongqian Sun",
            "Lidong Bing",
            "Wei Yang"
        ],
        "date": "1 September 2017",
        "abstract": "A novel framework based on neural networks to identify the sentiment of opinion targets in a comment/review that adopts multiple-attention mechanism to capture sentiment features separated by a long distance, so that it is more robust against irrelevant information. We propose a novel framework based on neural networks to identify the sentiment of opinion targets in a comment/review. Our framework adopts multiple-attention mechanism to capture sentiment features separated by a long distance, so that it is more robust against irrelevant information. The results of multiple attentions are non-linearly combined with a recurrent neural network, which strengthens the expressive power of our model for handling more complications. The weighted-memory mechanism not only helps us avoid the labor-intensive feature engineering work, but also provides a tailor-made memory for different opinion targets of a sentence. We examine the merit of our model on four datasets: two are from SemEval2014, i.e. reviews of restaurants and laptops; a twitter dataset, for testing its performance on social media data; and a Chinese news comment dataset, for testing its language sensitivity. The experimental results show that our model consistently outperforms the state-of-the-art methods on different types of data.",
        "references": [
            "8fd81fdf4b340256233e43a8161c542483a2dbf2",
            "82bb306038446302cedd20fa986d20640ed88a2e",
            "b28f7e2996b6ee2784dd2dbb8212cfa0c79ba9e7",
            "844703f4daa223aa940f1ec6c1c35419ca9451c6",
            "cfa2646776405d50533055ceb1b7f050e9014dcb",
            "687bac2d3320083eb4530bf18bb8f8f721477600",
            "452059171226626718eb677358836328f884298e",
            "2ff4b9ca75a37cec1607f1f49333b948b1c8d08b",
            "7ba9dcbd2e9163f2684b098786bbc3abb4784905",
            "06e122f475a21d92dba137609c40f35690217475"
        ],
        "related_topics": [
            "Position-Weighted Memory",
            "Recurrent Attention On Memory",
            "TD-LSTM",
            "Opinion Targets",
            "Aspect Sentiment Analysis",
            "Multiple-attention Mechanism",
            "Aspect Sentiment Classification",
            "Multiple Attentions",
            "Recurrent Attention Network",
            "Target-dependent LSTM"
        ],
        "reference_count": "25",
        "citation_count": "690"
    },
    {
        "Id": "360806c34ea0dcb5faab9824dababc094bb05c07",
        "title": "Vector-space topic models for detecting Alzheimer\u2019s disease",
        "authors": [
            "Maria Yancheva",
            "Frank Rudzicz"
        ],
        "date": "1 August 2016",
        "abstract": "A generalizable method for automatic generation of information content units (ICUs) for a picture used in a standard clinical task, achieving high recall, 96.8%, of human-supplied ICUs. Semantic de\ufb01cit is a symptom of language impairment in Alzheimer\u2019s disease (AD). We present a generalizable method for automatic generation of information content units (ICUs) for a picture used in a standard clinical task, achieving high recall, 96.8%, of human-supplied ICUs. We use the automatically generated topic model to extract semantic features, and train a random forest classi\ufb01er to achieve an F-score of 0.74 in binary classi\ufb01cation of controls versus people with AD using a set of only 12 features. This is comparable to re-sults (0.72 F-score) with a set of 85 manual features. Adding semantic information to a set of standard lexicosyntactic and acoustic features improves F-score to 0.80. While control and dementia subjects discuss the same topics in the same contexts, controls are more informative per second of speech.",
        "references": [
            "bdd4aee4ea351e615eae0e4ab317bf974f1f731b",
            "2da167f503f3eea7f591b672068e3ff941af53d8",
            "bdd7750c5be25be75e39c7ff0c383ff50065acbf",
            "647c4649b11a92d4797950d50a8294b1beaba22b",
            "1e46a6d8d52c8d254706509a81748d766405dc85",
            "c705c9be9e8debdc40a30d637a4b533b7e4fc390",
            "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "c1c33280fe9e00d8047ced66815e7232403e4ca2",
            "f47e58797316ca268fa08b601bca33c0eefdc791",
            "068a3d62f1d3eaaaba03df23912db89b5adeb41c"
        ],
        "related_topics": [
            "Information Content Units",
            "Lexicosyntactic",
            "DementiaBank",
            "Cookie Theft",
            "Topic Models",
            "Binary Classification",
            "Semantic Deficits",
            "Acoustic Features"
        ],
        "reference_count": "22",
        "citation_count": "53"
    },
    {
        "Id": "cb15531827bf5b090d4873afd51a9ecba8ed2cdf",
        "title": "Explainable Vision Transformer with Self-Supervised Learning to Predict Alzheimer\u2019s Disease Progression Using 18F-FDG PET",
        "authors": [
            "Uttam Khatri",
            "Goo-Rak Kwon"
        ],
        "date": "1 October 2023",
        "abstract": "A self-supervised learning method to automatically acquire meaningful AD characteristics using the ViT architecture by pretraining the feature extractor using the self-distillation with no labels and extreme learning machine (ELM) as classifier models is presented. Alzheimer\u2019s disease (AD) is a progressive neurodegenerative disorder that affects millions of people worldwide. Early and accurate prediction of AD progression is crucial for early intervention and personalized treatment planning. Although AD does not yet have a reliable therapy, several medications help slow down the disease\u2019s progression. However, more study is still needed to develop reliable methods for detecting AD and its phases. In the recent past, biomarkers associated with AD have been identified using neuroimaging methods. To uncover biomarkers, deep learning techniques have quickly emerged as a crucial methodology. A functional molecular imaging technique known as fluorodeoxyglucose positron emission tomography (18F-FDG-PET) has been shown to be effective in assisting researchers in understanding the morphological and neurological alterations to the brain associated with AD. Convolutional neural networks (CNNs) have also long dominated the field of AD progression and have been the subject of substantial research, while more recent approaches like vision transformers (ViT) have not yet been fully investigated. In this paper, we present a self-supervised learning (SSL) method to automatically acquire meaningful AD characteristics using the ViT architecture by pretraining the feature extractor using the self-distillation with no labels (DINO) and extreme learning machine (ELM) as classifier models. In this work, we examined a technique for predicting mild cognitive impairment (MCI) to AD utilizing an SSL model which learns powerful representations from unlabeled 18F-FDG PET images, thus reducing the need for large-labeled datasets. In comparison to several earlier approaches, our strategy showed state-of-the-art classification performance in terms of accuracy (92.31%), specificity (90.21%), and sensitivity (95.50%). Then, to make the suggested model easier to understand, we highlighted the brain regions that significantly influence the prediction of MCI development. Our methods offer a precise and efficient strategy for predicting the transition from MCI to AD. In conclusion, this research presents a novel Explainable SSL-ViT model that can accurately predict AD progress based on 18F-FDG PET scans. SSL, attention, and ELM mechanisms are integrated into the model to make it more predictive and interpretable. Future research will enable the development of viable treatments for neurodegenerative disorders by combining brain areas contributing to projection with observed anatomical traits.",
        "references": [
            "64023908cd9171ded5394d093f9cddb87acc0b59",
            "82f1374687df62e4564c8a135e907a0e014f2aac",
            "f46caee0c79d9461b18a3190e51cd6a1eaa4ac41",
            "a5ac9ad2c7e21bf215b31eb9c160b1d4ec4442e4",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "101aad03db53cac05e89e5d474fe68948afae09d",
            "7b1711d3c8145673aaf2708a21e233186acb13ee",
            "b904fc6c0492b8ab5481315f54429f1a68783f84",
            "d03061507a97350c3260cf52559718d29b944c98",
            "ff07196b9c4c49b21449d7279d1476a71587daa1"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "62"
    },
    {
        "Id": "7b2cf4599fdbfa7bb073ce3737e6350c8a7d8c3d",
        "title": "Vision Transformer Approach for Classification of Alzheimer\u2019s Disease Using 18F-Florbetaben Brain Images",
        "authors": [
            "Hyunji Shin",
            "Soomin Jeon",
            "Youngsoo Seol",
            "Sangjin Kim",
            "Doyoung Kang"
        ],
        "date": "8 March 2023",
        "abstract": "A method for classifying dementia images by applying 18F-Florbetaben positron emission tomography images to ViT, and results show that it is hard to argue that the ViT model is better at AD classification than the CNN model. Dementia is a degenerative disease that is increasingly prevalent in an aging society. Alzheimer\u2019s disease (AD), the most common type of dementia, is best mitigated via early detection and management. Deep learning is an artificial intelligence technique that has been used to diagnose and predict diseases by extracting meaningful features from medical images. The convolutional neural network (CNN) is a representative application of deep learning, serving as a powerful tool for the diagnosis of AD. Recently, vision transformers (ViT) have yielded classification performance exceeding that of CNN in some diagnostic image classifications. Because the brain is a very complex network with interrelated regions, ViT, which captures direct relationships between images, may be more effective for brain image analysis than CNN. Therefore, we propose a method for classifying dementia images by applying 18F-Florbetaben positron emission tomography (PET) images to ViT. Data were evaluated via binary (normal control and abnormal) and ternary (healthy control, mild cognitive impairment, and AD) classification. In a performance comparison with the CNN, VGG19 was selected as the comparison model. Consequently, ViT yielded more effective performance than VGG19 in binary classification. However, in ternary classification, the performance of ViT cannot be considered excellent. These results show that it is hard to argue that the ViT model is better at AD classification than the CNN model.",
        "references": [
            "14b38796fef8bfdb77e9b5760fd18ce5b091e309",
            "a992e1cef96d356f29654a2849b7d8c2e77e12c4",
            "9da3fadf092c864f61d6fd1e8eab5a6ca2397194",
            "a7d5a9c56b1d57210f33eb01f8008124929819a7",
            "9e69dfc608a3131d01542ac57857c777a42761db",
            "a38d62f79977769d934f253c3162d1ffec3b2d8c",
            "a6dcb852e74de9cce3be858f677d1eddd384f46f",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "dc0415973b5573cc368a3d8b7ca1a38ec0fb4504",
            "8edd660ebe3962feba625628642a00a8665f07ba"
        ],
        "related_topics": [],
        "reference_count": "44",
        "citation_count": "2"
    },
    {
        "Id": "1764110f11fed5a893b348002074cbd3350b35b8",
        "title": "fMRI-Based Alzheimer\u2019s Disease Detection Using the SAS Method with Multi-Layer Perceptron Network",
        "authors": [
            "Aarthi Chelladurai",
            "Dayanand Lal Narayan",
            "Parameshachari Bidare Divakarachari",
            "Umasankar Loganathan"
        ],
        "date": "31 May 2023",
        "abstract": "A novel automated model was proposed in this manuscript for early diagnosis of AD using fMRI images that attained 99.44% of classification accuracy, 88.90% of Dice Similarity Coefficient, 90.82% of Jaccard Coefficient (JC), and 88.43% of Hausdorff Distance. In the present scenario, Alzheimer\u2019s Disease (AD) is one of the incurable neuro-degenerative disorders, which accounts for nearly 60% to 70% of dementia cases. Currently, several machine-learning approaches and neuroimaging modalities are utilized for diagnosing AD. Among the available neuroimaging modalities, functional Magnetic Resonance Imaging (fMRI) is extensively utilized for studying brain activities related to AD. However, analyzing complex brain structures in fMRI is a time-consuming and complex task; so, a novel automated model was proposed in this manuscript for early diagnosis of AD using fMRI images. Initially, the fMRI images are acquired from an online dataset: Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI). Further, the quality of the acquired fMRI images was improved by implementing a normalization technique. Then, the Segmentation by Aggregating Superpixels (SAS) method was implemented for segmenting the brain regions (AD, Normal Controls (NC), Mild Cognitive Impairment (MCI), Early Mild Cognitive Impairment (EMCI), Late Mild Cognitive Impairment (LMCI), and Significant Memory Concern (SMC)) from the denoised fMRI images. From the segmented brain regions, feature vectors were extracted by employing Gabor and Gray Level Co-Occurrence Matrix (GLCM) techniques. The obtained feature vectors were dimensionally reduced by implementing Honey Badger Optimization Algorithm (HBOA) and fed to the Multi-Layer Perceptron (MLP) model for classifying the fMRI images as AD, NC, MCI, EMCI, LMCI, and SMC. The extensive investigation indicated that the presented model attained 99.44% of classification accuracy, 88.90% of Dice Similarity Coefficient (DSC), 90.82% of Jaccard Coefficient (JC), and 88.43% of Hausdorff Distance (HD). The attained results are better compared with the conventional segmentation and classification models.",
        "references": [
            "677a3d0fc891cd0b281b24e89592400d6e630141",
            "087e27cb43982378aa102b5be7c9054bc9e00f59",
            "588112ec72114e7131426476ab4f929654d56711",
            "3df6ab893db3c80672b587af5e98a2884f6a141c",
            "c6884cf1369b10d0da26bb536951e853d99879b7",
            "1ec346757d9fee32b6a713e640eb6bc64c0f0bd8",
            "d80a79d254243b6a0ac7518895804354c3125780",
            "8fbadb917778a4fb12fcb1ad95a5e1ec34a8753e",
            "81831456b12b2f7a8861199484720720e9282f8d",
            "3d7e25c440656b023e765665530c55986dfdfcb5"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "41"
    },
    {
        "Id": "9f3cd0b46507d50caf71101f1dc3b23e339a8ba0",
        "title": "Comparative Analysis of Alzheimer's Disease Detection via MRI Scans Using Convolutional Neural Network and Vision Transformer",
        "authors": [
            "Pinky Sherwani",
            "P. Nandhakumar",
            "Pihu Srivastava",
            "Jayant Jagtap",
            "Viren Narvekar",
            "Harikrishnan R."
        ],
        "date": "5 January 2023",
        "abstract": "The paper focuses on the detection of Alzheimer's Disease via Brain MRI Scans using Convolutional Neural Network (CNN) which minimizes an image's high dimensionality without sacrificing its information and using Vision Transformers that are for image classification and apply an architecture akin to a Transformer over selected areas of the image. Progressive damage to brain neurons is caused by a neurodegenerative disease (ND) that the body cannot heal or restore. Dementia like Alzheimer's Disease (AD), which affects millions of lives each year, is a well-known instance of such illnesses. Despite extensive research, the aforementioned disorders currently have no viable therapies. However, a timely diagnosis is essential for the management of diseases. For neurologists, diagnosing NDs is difficult and needs years of education and experience. The paper focuses on the detection of Alzheimer's Disease via Brain MRI Scans using Convolutional Neural Network (CNN) which minimizes an image's high dimensionality without sacrificing its information and using Vision Transformers that are for image classification and apply an architecture akin to a Transformer over selected areas of the image. In the proposed work three different Vision Transformer namely: Vanilla Vision Transformer (Vanilla ViT), Deep Vision Transformer (DeepViT), Class Attention in Image Transformer (CaiT). The Vision Transformers turned out to be better than CNN as when training on fewer datasets, ViT exhibits inductive bias, which increases dependency on model regularisation or data augmentation (AgReg). In terms of accuracy and computing efficiency, ViT models exceed the present CNN by almost a factor of four.",
        "references": [
            "6f972f13c6e85b8a582846ab0500f35855b81e2c",
            "cfb2948bc7f1633d01ccb270f218b5ff68fec561",
            "9da3fadf092c864f61d6fd1e8eab5a6ca2397194",
            "b02af4dc519a86701066399fa90c4fdf71778f06",
            "bb95ef99ae56f6b1087d6a3aec6ba18b766b237a",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "a1482fb22d3061fae243acddc197bf1e6584d574",
            "1f93588bb075eed40ffdfae2f7907c946e5974d9",
            "ab43362d0b11b22a2990fae7310765ca67f1c4f2",
            "96da196d6f8c947db03d13759f030642f8234abf"
        ],
        "related_topics": [],
        "reference_count": "17",
        "citation_count": "One"
    },
    {
        "Id": "871fce542513c42e8f4287d939d12dc366d4856a",
        "title": "A Multimodal Vision Transformer for Interpretable Fusion of Functional and Structural Neuroimaging Data",
        "authors": [
            "Yuda Bi",
            "Anees Abrol",
            "Zening Fu",
            "Vince D. Calhoun"
        ],
        "date": "18 July 2023",
        "abstract": "A novel deep learning model is introduced, the multimodal vision transformer (MultiViT), specifically engineered to enhance the accuracy of classifying schizophrenia by using structural MRI and functional MRI data independently and simultaneously leveraging the combined information from both modalities. Deep learning models, despite their potential for increasing our understanding of intricate neuroimaging data, can be hampered by challenges related to interpretability. Multimodal neuroimaging appears to be a promising approach that allows us to extract supplementary information from various imaging modalities. It\u2019s noteworthy that functional brain changes are often more pronounced in schizophrenia, albeit potentially less reproducible, while structural MRI effects are more replicable but usually manifest smaller effects. Instead of conducting isolated analyses for each modality, the joint analysis of these data can bolster the effects and further refine our neurobiological understanding of schizophrenia. This paper introduces a novel deep learning model, the multimodal vision transformer (MultiViT), specifically engineered to enhance the accuracy of classifying schizophrenia by using structural MRI (sMRI) and functional MRI (fMRI) data independently and simultaneously leveraging the combined information from both modalities. This study uses functional network connectivity data derived from a fully automated independent component analysis method as the fMRI features and segmented gray matter volume (GMV) as the sMRI features. These offer sensitive, high-dimensional features for learning from structural and functional MRI data. The resulting MultiViT model is lightweight and robust, outperforming unimodal analyses. Our approach has been applied to data collected from control subjects and patients with schizophrenia, with the MultiViT model achieving an AUC of 0.833, which is significantly higher than the average 0.766 AUC for unimodal baselines and 0.78 AUC for multimodal baselines. Advanced algorithmic approaches for predicting and characterizing these disorders have consistently evolved, though subject and diagnostic heterogeneity pose significant challenges. Given that each modality provides only a partial representation of the brain, we can gather more comprehensive information by harnessing both modalities than by relying on either one independently. Furthermore, we conducted a saliency analysis to gain insights into the co-alterations in structural gray matter and functional network connectivity disrupted in schizophrenia. While it\u2019s clear that the MultiViT model demonstrates differences compared to previous multimodal methods, the specifics of how it compares to methods such as MCCA and JICA are still under investigation, and more research is needed in this area. The findings underscore the potential of interpretable multimodal data fusion models like the MultiViT, highlighting their robustness and potential in the classification and understanding of schizophrenia.",
        "references": [
            "3eb00275234fd8845287bfd211d85f0300d42343",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "9afbfe958426b10f81da465f6656abfc52c55be9",
            "fe68c074890181ed69351711c9fe4952ad29bbf4",
            "edb6395bb2041d6003ae4fceef7073d38c1d3e9b",
            "d9dc456eedfe23c9f64b8b72e0089d739827cb38",
            "fafaa22d3a3c5072995874c3932d36a54519b0b0",
            "665a2d3289252d8f86c2ff8f98410dce2d787bed",
            "f63d83f63436f359f29e339fff2c074cd2335f73",
            "c020bb8dc809e30c1c95084b6cadf32dea8a7026"
        ],
        "related_topics": [],
        "reference_count": "42",
        "citation_count": "One"
    },
    {
        "Id": "b35400e044c8f4aa192adcc44842002ff3c542cd",
        "title": "Gray Matters: An Efficient Vision Transformer GAN Framework for Predicting Functional Network Connectivity Biomarkers from Brain Structure",
        "authors": [
            "Yuda Bi",
            "Anees Abrol",
            "Sihan Jia",
            "Zening Fu",
            "Vince D. Calhoun"
        ],
        "date": "12 January 2024",
        "abstract": "A new generative deep learning architecture using a conditional efficient vision transformer generative adversarial network (cEViTGAN) to capture the distinct information in structural and functional MRI of the human brain and suggests the links between gray matter volume and brain function may be stronger than previously considered. The field of brain connectivity research has under-gone revolutionary changes thanks to state-of-the-art advancements in neuroimaging, particularly regarding structural and functional magnetic resonance imaging (MRI). To navigate the intricate neural dynamics, one must possess a keen comprehension of the interdependent links between structure and function. Such relationships are understudied as they are complex and likely nonlinear. To address this, we created a new generative deep learning architecture using a conditional efficient vision transformer generative adversarial network (cEViTGAN) to capture the distinct information in structural and functional MRI of the human brain. Our model generates functional network connectivity (FNC) matrices directly from three-dimensional sMRI data. Two pioneering innovations are central to our approach. First, we use a novel linear embedding method for structural MRI (sMRI) data that retains the 3D spatial detail. This embedding is best for representative learning, and when used on a consistent dataset, and shows that it is good at upstream classification assignments. To estimate neural biomarkers, we need to process much smaller patches using ViT-based architectures, which usually makes the computations more difficult because of the self-attention operations. We present a new, lightweight self-attention mechanism to address this challenge. Our mechanism not only overcomes computational shortcomings of traditional softmax self-attention but also surpasses pure linear self-attention models in accuracy and performance. This optimization enables us to analyze even the tiniest neuroanatomical details with exceptional precision. Our model allows for the identification of functional network connectivity (FNC) with 74.2% accuracy and also predicts subject differences in FNC for schizophrenia patients versus controls. The results are intriguing and suggest the links between gray matter volume and brain function may be stronger than previously considered.",
        "references": [
            "8c9329747a33c1407dc57002e2d34e22656df2ef",
            "30297b8d5c84b6787d78620e536b6fa826758f80",
            "bca03520ba6f9f53094ed9447d01ae2939093169",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "569837f1d76d225950a29782b92a4334521130c1",
            "157530e815652b7e864a9f7885977c7ae8214b6f",
            "5f974e2765228e4357cb1afeac60ce8188a52c4b",
            "3883df2f5e7e18cbf41db34ee6b8373da715464d",
            "6b59cd34fe244592b8e5a364d1bb89a8a3b4c535",
            "9e46706f34914c650392447b018272f748ddee10"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "43"
    },
    {
        "Id": "1b4ac29a08b2272bd6b3fbf293544816e9d31c5a",
        "title": "SMIL-DeiT:Multiple Instance Learning and Self-supervised Vision Transformer network for Early Alzheimer's disease classification",
        "authors": [
            "Yue Yin",
            "Weikang Jin",
            "Jing Bai",
            "Ruotong Liu",
            "Haowei Zhen"
        ],
        "date": "18 July 2022",
        "abstract": "The accuracy obtained by the SMIL-DeiT network for AD classification tasks amongst three groups: Alzheimer's Disease, Mild Cognitive Impairment, and Normal Cognitive in this study is higher than the transformer's 90.1% and CNN's 89.8%, reaching 93.2%. Early diagnosis of Alzheimer's disease(AD) is becoming increasingly important in preventing and treating the disease as the world's population ages. We proposed a SMIL-DeiT network for AD classification tasks amongst three groups: Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI), and Normal Cognitive (NC) in this study. Vision Transformer is the fundamental structure of our work. The data pre-training is performed utilizing DINO, a self-supervised technique, whereas the downstream classification task is done with Multiple Instance Learning. Our proposed technique works on the ADNI dataset. We used four performance metrics accuracy rates, precision, recall, and Fl-score in the evaluation, the most important of which was accuracy. The accuracy obtained by our method is higher than the transformer's 90.1% and CNN's 90.8%, reaching 93.2%.",
        "references": [
            "04997a4505d6ecad56ae40eafbd2aaa59ec333b8",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "139e07e62b48c1f0bd658374c882a25269877001",
            "062eebcc51489e443d4c6004458a45d19fd4e5e5",
            "349a1900bf11f80c69b4ce647d45fbc59195123b",
            "681586c29e09eeb9bb45125d738a716ba2a8fa61",
            "c22e211f19291622f4745e5f83fb06de7b31b562",
            "d49bc4aa1d6838bc8a5b40e163a40a784cfc520c",
            "966199affabf34143d6a9db063fe6586bfd370e7",
            "2b446f63c98e8ec0176866fe66168faf89611ba5"
        ],
        "related_topics": [
            "Multiple-Instance Learning",
            "Classification",
            "Mild Cognitive Impairment",
            "Transformer",
            "DINO",
            "Convolutional Neural Network"
        ],
        "reference_count": "22",
        "citation_count": "2"
    },
    {
        "Id": "03680206720c6de8371edf9c57b72a50942c9ba1",
        "title": "Understanding the brain with attention: A survey of transformers in brain sciences",
        "authors": [
            "Cheng Chen",
            "Huilin Wang",
            "Yunqing Chen",
            "Zihan Yin",
            "Xinye Yang",
            "Huansheng Ning",
            "Qian Zhang",
            "Weiguang Li",
            "Ruoxiu Xiao",
            "Jizong Zhao"
        ],
        "date": "1 September 2023",
        "abstract": "This study comprehensively review and discusses the applications of Transformers in brain sciences, including brain disease diagnosis, brain age prediction, brain anomaly detection, semantic segmentation, multi\u2010modal registration, functional Magnetic Resonance Imaging (fMRI) modeling, Electroencephalogram (EEG) processing, and multi\u2010task collaboration. Owing to their superior capabilities and advanced achievements, Transformers have gradually attracted attention with regard to understanding complex brain processing mechanisms. This study aims to comprehensively review and discuss the applications of Transformers in brain sciences. First, we present a brief introduction of the critical architecture of Transformers. Then, we overview and analyze their most relevant applications in brain sciences, including brain disease diagnosis, brain age prediction, brain anomaly detection, semantic segmentation, multi\u2010modal registration, functional Magnetic Resonance Imaging (fMRI) modeling, Electroencephalogram (EEG) processing, and multi\u2010task collaboration. We organize the model details and open sources for reference and replication. In addition, we discuss the quantitative assessments, model complexity, and optimization of Transformers, which are topics of great concern in the field. Finally, we explore possible future challenges and opportunities, exploiting some concrete and recent cases to provoke discussion and innovation. We hope that this review will stimulate interest in further research on Transformers in the context of brain sciences.",
        "references": [
            "6694e0164aa40d6bb44499c6ef99998d1e727771",
            "4884e4edb5268c065cbc191a65eadde172d66bbf",
            "745df2ef26135577b7fa171a8ee4264f39018236",
            "24aa57dae649b6683d8f5bc8deaf2ff549cdacc4",
            "3883df2f5e7e18cbf41db34ee6b8373da715464d",
            "0fe58d4aa4e6f0f6c1cef42e1b1201a6106f9ce0",
            "6aeb17f02edf4b6ebc72549e34dba8aadbe8bf19",
            "0423573da62582f4445c36fa6b2c81aa5077b849",
            "71f2f9ef5b9f62d7e5588aea82d52fcabb984d85",
            "edb6395bb2041d6003ae4fceef7073d38c1d3e9b"
        ],
        "related_topics": [],
        "reference_count": "89",
        "citation_count": "2"
    },
    {
        "Id": "be2899888cf83e858d4b19682d92f8508b4b665b",
        "title": "MRI and Clinical Biomarkers Overlap between Glaucoma and Alzheimer\u2019s Disease",
        "authors": [
            "Alessio Martucci",
            "Francesca Di Giuliano",
            "Silvia Minosse",
            "Giulio Pocobelli",
            "Carlo Nucci",
            "Francesco Garaci"
        ],
        "date": "1 October 2023",
        "abstract": "The current state of the art on the use of advanced neuroimaging techniques in glaucoma and Alzheimer\u2019s disease is summarized, highlighting the emerging biomarkers shared by both diseases. Glaucoma is the leading cause of blindness worldwide. It is classically associated with structural and functional changes in the optic nerve head and retinal nerve fiber layer, but the damage is not limited to the eye. The involvement of the central visual pathways and disruption of brain network organization have been reported using advanced neuroimaging techniques. The brain structural changes at the level of the areas implied in processing visual information could justify the discrepancy between signs and symptoms and underlie the analogy of this disease with neurodegenerative dementias, such as Alzheimer\u2019s disease, and with the complex group of pathologies commonly referred to as \u201cdisconnection syndromes.\u201d This review aims to summarize the current state of the art on the use of advanced neuroimaging techniques in glaucoma and Alzheimer\u2019s disease, highlighting the emerging biomarkers shared by both diseases.",
        "references": [
            "8858381215bb4355a2c6de03ccffe526ba4bd78d",
            "aefc1d68e75edeb49691d8489d9501c1b9c8fd04",
            "035986ee9fcfc3d580463f5615110052c0dddf95",
            "574f748f9cf97a0f352c34784bcbd18b2843a20b",
            "c9e0fda834970c3bf246ceceba999f8a15a7eb83",
            "78937c5fd77797d96ce0a82303472efe45719904",
            "ed5b262dfab78d015673f8ad8836961dbce441cf",
            "cf79e1db4f073ef28e8930d8b1cafa3ef69dd8cd",
            "180d033f92a56284e5df18bfad44dd94c3f079d8",
            "f741f67105cb49ce65498383c524481fd74b085b"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "95"
    },
    {
        "Id": "8cff2a163a6367c935ca59feeae320e8ea583dfb",
        "title": "Self-attention based high order sequence feature reconstruction of dynamic functional connectivity networks with rs-fMRI for brain disease classification",
        "authors": [
            "Zhixiang Zhang",
            "Biao Jie",
            "Zhengdong Wang",
            "Jie Zhou",
            "Yang Yang"
        ],
        "date": "2022",
        "abstract": ". The experimental results on a public dataset (i.e., ADNI) demonstrate the e \ufb00 ectiveness of our proposed SA-CRN method.",
        "references": [
            "33d408f6874a5f667d0ab4863068999abf0a1931",
            "2c002c19b54c7c57e0a73ade3a2b591d6b8d755c",
            "c3e6b915f4c393b136ca4133242b87d8c0ffb063",
            "f28885e2b9a557a25cf927b645faba12131f2142",
            "a879316d0e90a8616040a6e637f334462ab52111",
            "2e00c496e37d9387e224d7efdb3709da6cfb2f76",
            "f63d83f63436f359f29e339fff2c074cd2335f73",
            "8a1f97a0e51e6deb1af2b77ce5fcddc1908fdc36",
            "b0a49b0616f0ef017b3198e81a0bd2609c5f2677",
            "7483e5a8cf206744f636ce24a7e1abc3f631a593"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "52"
    },
    {
        "Id": "5e4773768ccd5b215a5669b9dec6a69f55fa2387",
        "title": "Early Stage Detection of Alzheimer's using Hybrid Artificial Intelligence Model: A Review",
        "authors": [
            "Mrutyunjaya S. Hiremath",
            "Rajashekhar C. Biradar"
        ],
        "date": "23 June 2023",
        "abstract": "The present state-of-the-art in Alzheimer's Disease diagnosis using Deep Learning is evaluated to examine the potential of Deep Learning in Alzheimers Disease diagnosis and highlight the current trends and findings using a comprehensive literature analysis. The most well-known form of dementia, AD - Alzheimer's Disease, is a critical problem in contemporary medicine. AD affects over 5.8 million individuals aged 65 and older, causing the sixth greatest reason for death in the US. A loss of cognitive function is the hallmark of AD, a degenerative brain condition that is irreversible and for which there is no known therapy. Deep learning approaches have been increasingly popular recently, especially in natural language processing and computer vision. These methods have started to get significant in research on Alzheimer's Disease diagnosis, and the volume of publications published in this area has been rapidly increasing since 2014. According to reports, deep learning methods are superior to traditional machine learning models for diagnosing AD. This paper evaluates the present state-of-the-art in Alzheimer's Disease diagnosis using Deep Learning to examine the potential of Deep Learning in Alzheimer's Disease diagnosis. Moreover, highlight the current trends and findings using a comprehensive literature analysis. The study investigates several datasets and biomarkers for diagnosing AD. Despite the potential that Deep Learning has shown in diagnosing AD, several issues still need to be resolved.",
        "references": [
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "abd236ae32c45dc73941cf56503c628f54fe233b",
            "39ff9301f10b37172a084ed6a86e531fffd7d8a2",
            "8659d7ce98c034771244358c81e39fba2e3ecfa2",
            "d1b00d225ca6eb4f9e2231a70a6dd85c0e6955df",
            "665a2d3289252d8f86c2ff8f98410dce2d787bed",
            "154b36bc7a27b8b15c28a168f209fcd440df40b3",
            "09acfd8cf60d44a2a7091f8f90b927567a7b4a16",
            "49aa918d596bbca54af39b7974fc1de2d2410edc",
            "273b099498525ca3ed5df6a86c0f3134b337d1a3"
        ],
        "related_topics": [],
        "reference_count": "23",
        "citation_count": "One"
    },
    {
        "Id": "2a9fef734c8a606372a64ba712f75fcb9999fbfb",
        "title": "A Comprehensive Study of Alzheimer's Disease Detection and Its Classification By Deep Learning",
        "authors": [
            "Priyanka Datta",
            "Ishan Chaturvedi",
            "K.R.N Kiran Kumar",
            "Gaurav Bhadula",
            "Shreya Singh"
        ],
        "date": "28 April 2023",
        "abstract": "This study aims to summarize the most suitable way of predicting and classifying AD by Deep Learning using a comprehensive study and contains a detailed study of various biomarkers and datasets for AD prediction and classification. Alzheimer's Disease (AD) is a neurogenerative disease, the most familiar type of dementia, and one of the critical brain diseases which are associated with aging. It is the cause of 60-70% of cases of dementia. AD is the sixth major reason of death in the United States of America. Nearly 50 million people suffer from Alzheimer's disease or similar dementia worldwide. The early diagnosis of an AD patient is important because it helps the patient to receive some preventive methods before the appearance of invariable damage in the brain. AD cannot be detected at an early stage, because it can only be detected once it becomes noticeable. Deep Learning (DL) approach in diagnosing AD was more accurate compared to the conventional machine learning models at early stages. This study aims to summarize the most suitable way of predicting and classifying AD by Deep Learning using a comprehensive study. The study also contains a detailed study of various biomarkers and datasets for AD prediction and classification.",
        "references": [
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "2b972120059c2ff00a9649a6f54430e923cb9acc",
            "1ec346757d9fee32b6a713e640eb6bc64c0f0bd8",
            "1a49051da2a2c3e18c487c87efae2ea8e619177b",
            "5b486ddeaa7a1e7cfa3686c25afe3330937513a5",
            "67613bfb03ee9ae39811dac24b36dcc188eeeaef",
            "367f7fe3d24ca2e6ec655969b443d2539a4c21ee",
            "7308d3a552e57a1c162bde6100a7383ef96aeb24",
            "bdf1caceb1cdf3b29c612618fcc3f9ab0cb57325",
            "ca10501019ef65c76fa5bb24e1d84db4eb1a20ce"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "34"
    },
    {
        "Id": "8cb973053ac02ccee138c40f6edcbbb7e8ac9d40",
        "title": "A deep learning model for Alzheimer's disease diagnosis based on patient clinical records.",
        "authors": [
            "Jos{\\&#x27;e} Luis {\\&#x27;A}vila-Jim{\\&#x27;e}nez",
            "Vanesa Cant{\\&#x27;o}n-Habas",
            "Mar{\\&#x27;i}a del Pilar Carrera-Gonz{\\&#x27;a}lez",
            "Manuel Rich-Ruiz",
            "Sebasti{\\&#x27;a}n Ventura"
        ],
        "date": "1 December 2023",
        "abstract": "Semantic Scholar extracted view of \"A deep learning model for Alzheimer's disease diagnosis based on patient clinical records.\" by J. \u00c1vila-Jim\u00e9nez et al.",
        "references": [
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "643a53e1159006bc5af8344a2d85a053b52eba0f",
            "7b9638747777cb7b4d88b01d6a9f7fce48fd4296",
            "95a841f91250a76816bb48fbd88737f4e69dfa3a",
            "f2d36024d701c6067fed49764cb05a8dac77f84f",
            "416378a8c1d2134031fa25e7f39af2b962c10389",
            "84cec40dcf5f0d2186e3040afff49a1705260c60",
            "75afaecdca94756852eb74b8e1a797a5246c42bc",
            "a196d58483d02835898663cbefcff5eb70f6c998",
            "f7325452a824decb188bd2eb2dd1d21cafc91567"
        ],
        "related_topics": [],
        "reference_count": "43",
        "citation_count": "One"
    },
    {
        "Id": "bc9dda4454c9eea76b208a2d14a03200d1ba5fae",
        "title": "Deep Learning Based Model for Alzheimer's Disease Detection Using Brain MRI Images",
        "authors": [
            "Muntasir Mamun",
            "Siam Bin Shawkat",
            "Md Salim Ahammed",
            "Md. Milon Uddin",
            "Md Ishtyaq Mahmud",
            "Asm Mohaimenul Islam"
        ],
        "date": "26 October 2022",
        "abstract": "Four deep learning models that are utilized in this study are Convolutional Neural Network (CNN), ResNet101, DenseNet121, and Visual Geometry Group16 (VGG16), which outperformed other models and achieved an accuracy of 97.60%, recall of 97%, and AUC of 99.26%, with a nominal loss of 0.091. Alzheimer's disease (AD) is a progressive neurodegenerative disorder that causes problems with memory, thinking, and behavior. And with time, symptoms become severe enough to interfere with daily activities. Although there is no cure for the disease, a proper management strategy starting at an early stage can help improve quality of life and potentially slow the disease progression. In clinical research, machine learning techniques are frequently being used in different ways to help detect disease conditions and progressions. Magnetic resonance imaging (MRI) is one of the best available tools that is used to diagnose Alzheimer's disease. However, detecting very small changes in AD brain during the early stage of the disease is challenging. In this study, we developed deep learning-based models for Alzheimer's detection using the 6219 MRI images dataset. The dataset consists of images of different degrees of demented and non-demented brains. Four deep learning models that are utilized in this study are Convolutional Neural Network (CNN), ResNet101, DenseNet121, and Visual Geometry Group16 (VGG16). From the analysis, we found that CNN outperformed other models and achieved an accuracy of 97.60%, recall of 97%, and AUC of 99.26%, with a nominal loss of 0.091.",
        "references": [
            "fd81880d09fa9997be8a0fccd5f1bf3fc4eb3fcb",
            "39ff9301f10b37172a084ed6a86e531fffd7d8a2",
            "22a39ed889a1552b1a8f725bf0fa7321b2d705a6",
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "53a339cde6d5f34e3c29d7e703541bb63102e984",
            "809903d837638f092a7dab0c88d6f0816a1b317f",
            "e3548fa98f191444d3be693ae3bc2507ad393818",
            "eaf35385d79ef18dc22291ed3fecd8547dd91165",
            "01e2793ea6a9d2d3fad64248be88b016911e95b7",
            "9a62d8d1587b92fee2058426100f6d352ec22d6b"
        ],
        "related_topics": [
            "Deep Learning",
            "Convolutional Neural Network",
            "DenseNet121",
            "ResNet-101",
            "Area Under The ROC Curve",
            "Magnetic Resonance Images"
        ],
        "reference_count": "26",
        "citation_count": "11"
    },
    {
        "Id": "809c7fa7d380fe98921db374801ecb9e95c5b518",
        "title": "Novel Deep-Learning Approach for Automatic Diagnosis of Alzheimer\u2019s Disease from MRI",
        "authors": [
            "Omar Altwijri",
            "Reem Alanazi",
            "Adham Aleid",
            "Khalid Alhussaini",
            "Ziyad Aloqalaa",
            "Mohammed Almijalli",
            "Ali Saad"
        ],
        "date": "7 December 2023",
        "abstract": "A deep-learning approach that utilizes pre-trained convolutional neural networks (CNNs) to accurately detect the severity levels of AD, particularly in situations where the quantity and quality of available datasets are limited is developed. This study introduces a novel deep-learning methodology that is customized to automatically diagnose Alzheimer\u2019s disease (AD) through the analysis of MRI datasets. The process of diagnosing AD via the visual examination of magnetic resonance imaging (MRI) presents considerable challenges. The visual diagnosis of mild to very mild stages of AD is challenging due to the MRI similarities observed between a brain that is aging normally and one that has AD. The detection of AD with extreme precision is critical during its early stages. Deep-learning techniques have recently been shown to be significantly more effective than human detection in identifying various stages of AD, enabling early-stage diagnosis. The aim of this research is to develop a deep-learning approach that utilizes pre-trained convolutional neural networks (CNNs) to accurately detect the severity levels of AD, particularly in situations where the quantity and quality of available datasets are limited. In this approach, the AD dataset is preprocessed via a refined image processing module prior to the training phase. The proposed method was compared to two well-known deep-learning algorithms (VGG16 and ResNet50) using four Kaggle AD datasets: one for the normal stage of the disease and three for the mild, very mild, and moderate stages, respectively. This allowed us to evaluate the effectiveness of the classification results. The three models were compared using six performance metrics. The results achieved with our approach indicate an overall detection accuracy of 99.3%, which is superior to the other existing models.",
        "references": [
            "39ff9301f10b37172a084ed6a86e531fffd7d8a2",
            "f90e37dc39cbdf49cd44b41071fb5a4cdd07ad14",
            "1364feb23a0a0326d3f5ae5c49c3c763f162bd2f",
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "d1b00d225ca6eb4f9e2231a70a6dd85c0e6955df",
            "f2b3bd44dbdafc79324173700e7bba492e634eac",
            "e6821575cf6b692ce3327422822a9a929f903443",
            "853af639e5f77390f8d7cc27178d143fa9a1dc33",
            "bb1a82463394a150da7ff3afc53818a6eadd131e",
            "fd81880d09fa9997be8a0fccd5f1bf3fc4eb3fcb"
        ],
        "related_topics": [],
        "reference_count": "29",
        "citation_count": "One"
    },
    {
        "Id": "705bf021eb299b176f4d95c25776a49e47d0e83e",
        "title": "A Novel Method for Diagnosing Alzheimer\u2019s Disease from MRI Scans using the ResNet50 Feature Extractor and the SVM Classifier",
        "authors": [
            "Farhana Islam",
            "Md. Habibur Rahman",
            "Nurjahan",
            "Md. Selim Hossain",
            "Samsuddin Ahmed"
        ],
        "date": "2023",
        "abstract": "This research focuses on how to support the multi-stage classification of AD particularly in its early stage, exploiting the Alzheimer\u2019s disease Neuroimaging Initiative data set consisting of AD, MCIs (MCI), and cognitive normal (CN) classes of images. \u2014Alzheimer\u2019s disease (AD), a chronic neurodegenerative brain disorder, caused by the accumulation of abnormal proteins called amyloid, is one of the prominent causes of mortality worldwide. Since there is a scarcity of experienced neurologists, manual diagnosis of AD is very time-consuming and error-prone. Hence, automatic diagnosis of AD draws significant attention nowadays. Machine learning (ML) algorithms such as deep learning are widely used to support early diagnosis of AD from magnetic resonance imaging (MRI). However, they provide better accuracy in binary classification, which is not the case with multi-class classification. On the other hand, AD consists of a number of early stages, and accurate detection of them is necessary. Hence, this research focuses on how to support the multi-stage classification of AD particularly in its early stage. After the MRI scans have been preprocessed (through median filtering and watershed segmentation), benchmark pre-trained convolutional neural network (CNN) models (AlexNet, VGG16, VGG19, ResNet18, ResNet50) carry out automatic feature extraction. Then, principal component analysis is used to optimize features. Conventional machine learning classifiers (Decision Tree, K-Nearest Neighbors, Support Vector Machine, Linear Programming Boost, and Total Boost) are deployed using the optimized features for staging AD. We have exploited the Alzheimer\u2019s disease Neuroimaging Initiative(ADNI) data set consisting of AD, MCIs (MCI), and cognitive normal (CN) classes of images. In our experiment, the SVM classifier performed better with the extracted ResNet50 features, achieving multi-class classification accuracy of 99.78% during training, 99.52% during validation, and 98.71% during testing. Our approach is distinctive because it combines the advantages of deep feature extractors, conventional classifiers, and feature optimization.",
        "references": [
            "4845194917aba7287709e89cb1c876c98563f820",
            "52d2f27da12d2ac4202d2d1db2c7a04d623cadf0",
            "63e13545e992830c08737ad77831376af298dbe4",
            "656961a9ff04770cd92f7b172a8df2f8b9f96900",
            "075ef6870bd3f5ab3405ed5d506b7bd4e80e52e3",
            "ae76c7a8a7a8a0c92aa35722c6dab512db1e0273",
            "00e67911c11e62b79b5cb05ea1366e7b89cdee4b",
            "d1b00d225ca6eb4f9e2231a70a6dd85c0e6955df",
            "6671e93ce19280427fa48b88d0e53a73979cd314",
            "d9ca3f7672eb1a9f140fd0c7c0e35dc8a32a7cb1"
        ],
        "related_topics": [],
        "reference_count": "38",
        "citation_count": "One"
    },
    {
        "Id": "9980bc00af463ec4d0b828fe2cc699d85333f4a1",
        "title": "Alzheimer\u2019s Disease Detection: A Deep Learning-Based Approach",
        "authors": [
            "Muhammad Wasim",
            "Affan Alim",
            "Waqas Ahmed"
        ],
        "date": "7 June 2023",
        "abstract": "The proposed research employs a deep learning methodology using a 3D convolutional neural network (3D CNN) that has been proposed to detect Alzheimer's disease at an early stage to achieve the highest of 78.07% accuracy using 3D CNN. Mental health is an important part of a successful life for a person whether elderly, children, or young. Alzheimer\u2019s is a fatal brain disease that severely damages the human brain, especially in the elderly. One way to prevent Alzheimer's disease is by detecting it early. The proposed research employs a deep learning methodology using a 3D convolutional neural network (3D CNN) that has been proposed to detect Alzheimer's disease at an early stage. The proposed model is primarily evaluated using three-dimensional brain images. A series of preprocessing have been applied that is an advanced normalization tool (ANT). The underlying pattern has a size of 128\u00d7128\u00d764 and is passed to 17 layers of a neural network that is 3D-CNN. Another contribution of this study is the conversion of a 3D Alzheimer\u2019s image into a 2D image. A 2D convolutional neural network such that RestNET50 and VGG16 are proposed to be used for Alzheimer\u2019s detection. The proposed model has attained the highest of 78.07% accuracy using 3D CNN.",
        "references": [
            "eded0cb8c4776e077661f33bba756055e8731ad1",
            "d1b00d225ca6eb4f9e2231a70a6dd85c0e6955df",
            "baf9d9194d7a7d03c303dab3ae80a5754c5d9581",
            "cfb2948bc7f1633d01ccb270f218b5ff68fec561",
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "f2d36024d701c6067fed49764cb05a8dac77f84f",
            "20a1a5d64a0f812ac2aa80c0f5f6ddf157fcc79c",
            "3d8e5b22263bd8af54d4c799010bfc637e6ec7f4",
            "cbb01ec1eeb343712710dbe7cef85da0c08695a6",
            "bfbcbb9cfe2fb2b8c8211443a6f62c1d4f568cea"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "33"
    },
    {
        "Id": "23ca2e37760fe8fdad318b51c28bed784fab6c51",
        "title": "Interpretable Hierarchical Deep Learning Model for Noninvasive Alzheimer\u2019s Disease Diagnosis",
        "authors": [
            "Maryam Zokaeinikoo",
            "Pooyan Kazemian",
            "Prasenjit Mitra"
        ],
        "date": "17 November 2023",
        "abstract": "An interpretable hierarchical deep learning model that can detect Alzheimer\u2019s disease from the transcripts of patient interviews with 96% accuracy when tested on the DementiaBank data set is developed. Alzheimer\u2019s disease is one of the leading causes of death in the world. Alzheimer\u2019s is typically diagnosed through expensive imaging methods, such as positron emission tomography (PET) scan and magnetic resonance imaging (MRI), as well as invasive methods, such as cerebrospinal fluid analysis. In this study, we develop an interpretable hierarchical deep learning model to detect the presence of Alzheimer\u2019s disease from transcripts of interviews of individuals who were asked to describe a picture. Our deep recurrent neural network employs a novel three-level hierarchical attention over self-attention (AoS3) mechanism to model the temporal dependencies of longitudinal data. We demonstrate the interpretability of the model with the importance score of words, sentences, and transcripts extracted from our AoS3 model. Numerical results demonstrate that our deep learning model can detect Alzheimer\u2019s disease from the transcripts of patient interviews with 96% accuracy when tested on the DementiaBank data set. Our interpretable neural network model can help diagnose Alzheimer\u2019s disease in a noninvasive and affordable manner, improve patient outcomes, and result in cost containment. History: Rema Padman served as the senior editor for this article. Data Ethics & Reproducibility Note: The code capsule is available on Code Ocean at https://codeocean.com/capsule/2881658/tree/v1 and in the e-Companion to this article (available at https://doi.org/10.1287/ijds.2020.0005 ). The study involves secondary use of already-collected data. None of the authors were part of the original study team. The authors had no interaction with living individuals and had no access to protected health information (PHI) or private identifiable information about living individuals.",
        "references": [
            "373b26525f64edfa9d36f5096e8964d73b97d7de",
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "3f6989f605e650e14bae236568768172f4037382",
            "bb83cccd9309861aeff98bfcba3653d4dde1dc87",
            "72b3390486d9b9e4f520e158eae290219d68fc16",
            "3bbf04b842e08d28a39e0e0dd4b54a6ab36ace75",
            "9f79b994b6bbb2da8002582200f6f0b8ba6daf91",
            "85ee1f6e762dd7cb3944154c13d847c9c94907ee",
            "0f80f167eb9b90c76c13baf90eab2077d89f9b21",
            "ab43362d0b11b22a2990fae7310765ca67f1c4f2"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "20"
    },
    {
        "Id": "77b3b7898fb563a4abe80a5b3eb409632780ae46",
        "title": "Early Detection of Alzheimer\u2019s disease by using the Latest Techniques",
        "authors": [
            "Dr. Shmmon Ahmad",
            "Mohsin Aijaz",
            "Mumtaz Ahmad",
            "Abdul Hafeez",
            "Mohammad Asif",
            "Ajay Kumar",
            "Anmar Al-taie",
            "Mohamamd Anas Ansari"
        ],
        "date": "2023",
        "abstract": "This study focuses on developing an efficient computing technique to pre-process and classify AD, especially in the early stages, and highlights the most promising screening tools, including neuropsychiatric, clinical, blood, and neurophysiological tests. : Alzheimer's disease (AD) is a prevalent neurodegenerative disease affecting cognitive functions and is particularly common among elderly people worldwide. It is considered incurable, and its symptoms progressively deteriorate over time. Early detection of AD is critical for developing new and effective treatment strategies. Dementia causes irreversible damage to brain neurons, leading to changes in brain structure that can be analyzed through multifractal frameworks. This study focuses on developing an efficient computing technique to pre-process and classify AD, especially in the early stages. The development of additional non-invasive and cost-effective tools for identifying individuals in the preclinical or early clinical stages of AD is necessary. These tools can aid in early detection and potentially more effective therapeutic and preventative strategies for AD. Large clinical trials are necessary to validate these tools before implementing them in clinical practice. This review will summarize and highlight the most promising screening tools, including neuropsychiatric, clinical, blood, and neurophysiological tests.",
        "references": [
            "68b2b8df2a8ffb58f4496c06892446a7ad014dbe",
            "e104b75d6d2a2449a868c3cb4d54a174418690da",
            "017e26883e33f2db7b939561be4338ee9d759dbb",
            "a8e74b5000f8e2a2f50f1167904e0ba3a9d8d72a",
            "b32d9cbbcddf16a7e870e7af7a554ef9500f8bfe",
            "33caecb2cd1ae27f8c8262633ab636052b1637e1",
            "918a44444d14f22b350af989ae9724c34b4d1780",
            "a464b8ec96d2f10f77cbfb36c749160c13f5bde4",
            "8e1b7750d1792e57c01ec8fd08813ffdac3892fb",
            "a690dbbdd0a9d096947451d07efcc109d5791529"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "33"
    },
    {
        "Id": "b4aa3aa47386d9474da8bf0f9962563881542d5c",
        "title": "Dual Semi-Supervised Learning for Classification of Alzheimer\u2019s Disease and Mild Cognitive Impairment Based on Neuropsychological Data",
        "authors": [
            "Yan Wang",
            "Xuming Gu",
            "Wenju Hou",
            "Meng Zhao",
            "Li Sun",
            "Chunjie Guo"
        ],
        "date": "1 February 2023",
        "abstract": "A novel semi-supervised method using neuropsychological test scores and scarce labeled data, which introduces difference regularization and consistency regularization with pseudo-labeling and shows that DSSL achieves the best accuracy and stability in classifying AD, MCI, and NC. Deep learning has shown impressive diagnostic abilities in Alzheimer\u2019s disease (AD) research in recent years. However, although neuropsychological tests play a crucial role in screening AD and mild cognitive impairment (MCI), there is still a lack of deep learning algorithms only using such basic diagnostic methods. This paper proposes a novel semi-supervised method using neuropsychological test scores and scarce labeled data, which introduces difference regularization and consistency regularization with pseudo-labeling. A total of 188 AD, 402 MCI, and 229 normal controls (NC) were enrolled in the study from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database. We first chose the 15 features most associated with the diagnostic outcome by feature selection among the seven neuropsychological tests. Next, we proposed a dual semi-supervised learning (DSSL) framework that uses two encoders to learn two different feature vectors. The diagnosed 60 and 120 subjects were randomly selected as training labels for the model. The experimental results show that DSSL achieves the best accuracy and stability in classifying AD, MCI, and NC (85.47% accuracy for 60 labels and 88.40% accuracy for 120 labels) compared to other semi-supervised methods. DSSL is an excellent semi-supervised method to provide clinical insight for physicians to diagnose AD and MCI.",
        "references": [
            "a68d1ff61480b4fa082c5b37a55add8515b4cbcc",
            "3d4c998bbedb6ca0fa73ce1bdded905245c7765b",
            "1ec346757d9fee32b6a713e640eb6bc64c0f0bd8",
            "d8eacc06ed7c04997543b4ed0e634ab7700d729e",
            "c35749e72c9bdc6826a0b5147221b9b9d2b41e63",
            "1e3bf081a2374cc74a7059c8dc4892a467981a6c",
            "7d96e0fd04544cdcf73f2c34504bd7784cbc7b28",
            "4de44eabebeee5d03c450eff23bce2694589359e",
            "8ce6fb3321d29b344b4568439a2a0ed40b9fabe9",
            "a9f6926cc103ab8ecb07e634b1ebc176d6f459cb"
        ],
        "related_topics": [],
        "reference_count": "43",
        "citation_count": "5"
    },
    {
        "Id": "648d90b713997a771e2c49f02cd771e8b7b10b37",
        "title": "Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency",
        "authors": [
            "Xiang Zhang",
            "Ziyuan Zhao",
            "Theodoros Tsiligkaridis",
            "Marinka Zitnik"
        ],
        "date": "17 June 2022",
        "abstract": "A decomposable pre-training model is defined, where the self-supervised signal is provided by the distance between time and frequency components, each individually trained by contrastive estimation. Pre-training on time series poses a unique challenge due to the potential mismatch between pre-training and target domains, such as shifts in temporal dynamics, fast-evolving trends, and long-range and short-cyclic effects, which can lead to poor downstream performance. While domain adaptation methods can mitigate these shifts, most methods need examples directly from the target domain, making them suboptimal for pre-training. To address this challenge, methods need to accommodate target domains with different temporal dynamics and be capable of doing so without seeing any target examples during pre-training. Relative to other modalities, in time series, we expect that time-based and frequency-based representations of the same example are located close together in the time-frequency space. To this end, we posit that time-frequency consistency (TF-C) -- embedding a time-based neighborhood of an example close to its frequency-based neighborhood -- is desirable for pre-training. Motivated by TF-C, we define a decomposable pre-training model, where the self-supervised signal is provided by the distance between time and frequency components, each individually trained by contrastive estimation. We evaluate the new method on eight datasets, including electrodiagnostic testing, human activity recognition, mechanical fault detection, and physical status monitoring. Experiments against eight state-of-the-art methods show that TF-C outperforms baselines by 15.4% (F1 score) on average in one-to-one settings (e.g., fine-tuning an EEG-pretrained model on EMG data) and by 8.4% (precision) in challenging one-to-many settings (e.g., fine-tuning an EEG-pretrained model for either hand-gesture recognition or mechanical fault prediction), reflecting the breadth of scenarios that arise in real-world applications. Code and datasets: https://github.com/mims-harvard/TFC-pretraining.",
        "references": [
            "3035a4531fe4a71ee4e25515d65c434bd5a93e35",
            "47e0dab08c920b589a9ddd11643c694d47ccd1c4",
            "3bc63b8ebe8195525e7a6a2c06fe129814789928",
            "c090ff3dec01e06f46735b7b9ab133a5db8c73c3",
            "0998a7e7626d2a558db7bffd37d7b6395ad3a384",
            "e19ca3c11fd45dfc9bc6e43ddf9b03b6c798e66d",
            "32edb525204f5821af5da38b89f66909e9a045a5",
            "7f36d87c89afa1eb39554bc21d125b4b2609262b",
            "2051548f7681c96d603de932ee23406c525276f9",
            "751535ffda2d4589d0e2651d9a76d3fac63adc68"
        ],
        "related_topics": [
            "Time-Frequency Consistency",
            "TS-TCC",
            "TS2Vec",
            "Temporal Neighborhood Coding",
            "Pre-training",
            "Fine-tuning",
            "Contrastive Estimation",
            "Self-supervised Signals",
            "Human Activity Recognition",
            "Domain Adaptation Methods"
        ],
        "reference_count": "120",
        "citation_count": "89"
    },
    {
        "Id": "25537e42debcefe3de4600735890beeb37abf276",
        "title": "Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events",
        "authors": [
            "Matthew B. A. McDermott",
            "Bret A. Nestor",
            "Peniel N. Argaw",
            "Isaac S. Kohane"
        ],
        "date": "20 June 2023",
        "abstract": "ESGPT is introduced, an open-source library designed to streamline the end-to-end process for building GPTs for continuous-time event sequences, and allows users to build flexible, foundation-model scale input datasets by specifying only a minimal configuration file. Generative, pre-trained transformers (GPTs, a.k.a.\"Foundation Models\") have reshaped natural language processing (NLP) through their versatility in diverse downstream tasks. However, their potential extends far beyond NLP. This paper provides a software utility to help realize this potential, extending the applicability of GPTs to continuous-time sequences of complex events with internal dependencies, such as medical record datasets. Despite their potential, the adoption of foundation models in these domains has been hampered by the lack of suitable tools for model construction and evaluation. To bridge this gap, we introduce Event Stream GPT (ESGPT), an open-source library designed to streamline the end-to-end process for building GPTs for continuous-time event sequences. ESGPT allows users to (1) build flexible, foundation-model scale input datasets by specifying only a minimal configuration file, (2) leverage a Hugging Face compatible modeling API for GPTs over this modality that incorporates intra-event causal dependency structures and autoregressive generation capabilities, and (3) evaluate models via standardized processes that can assess few and even zero-shot performance of pre-trained models on user-specified fine-tuning tasks.",
        "references": [
            "8730b02af1d76156e71aa821d21dfaa163d0a34c",
            "b628204e8718c49b26f7d3bb58692595c378aa31",
            "cd7e947c7b9f85ed88f79ef8eb07ee38854f6694",
            "5425de16356015c2f26d2a50684c6c46d6998f51",
            "27c4018861fc347505bb83d488598be7420a392d",
            "dcaf3718e173a30a5d01491582acbf5b5355099c",
            "7d19356f6023b2bbc045643bded6dcacc6256436",
            "df85f3fd44f32dca29fe53b3396f629c7cea62e8",
            "dd2819016c6bf244c39b3e6707b60389bbdbcd21"
        ],
        "related_topics": [
            "Natural Language Processing",
            "Generative",
            "Pre-trained Models",
            "Foundation Model",
            "Generative Pre-trained Transformer",
            "Event Stream"
        ],
        "reference_count": "40",
        "citation_count": "One"
    },
    {
        "Id": "c4366fd7747408cd2a16c02892ccc612f601ce05",
        "title": "Contextualizing protein representations using deep learning on protein networks and single-cell data",
        "authors": [
            "Michelle M. Li",
            "Yepeng Huang",
            "Marissa G. Sumathipala",
            "Man Qing Liang",
            "Alberto Valdeolivas",
            "Ashwin N. Ananthakrishnan",
            "Katherine P. Liao",
            "Daniel Marbach",
            "Marinka Zitnik"
        ],
        "date": "19 July 2023",
        "abstract": "Pinnacle is a graph-based contextual AI model that dynamically adjusts its outputs based on biological contexts in which it operates that outperforms state-of-the-art, yet context-free, models in nominating therapeutic targets for rheumatoid arthritis and inflammatory bowel diseases and can pinpoint cell type contexts that predict therapeutic targets better than context-free models. Understanding protein function and developing molecular therapies require deciphering the cell types in which proteins act as well as the interactions between proteins. However, modeling protein interactions across diverse biological contexts, such as tissues and cell types, remains a significant challenge for existing algorithms. We introduce Pinnacle, a flexible geometric deep learning approach that is trained on contextualized protein interaction networks to generate context-aware protein representations. Leveraging a human multiorgan single-cell transcriptomic atlas, Pinnacle provides 394,760 protein representations split across 156 cell type contexts from 24 tissues and organs. Pinnacle\u2019s contextualized representations of proteins reflect cellular and tissue organization and Pinnacle\u2019s tissue representations enable zero-shot retrieval of the tissue hierarchy. Pretrained Pinnacle\u2019s protein representations can be adapted for downstream tasks: to enhance 3D structure-based protein representations for important protein interactions in immuno-oncology (PD-1/PD-L1 and B7-1/CTLA-4) and to study the effects of drugs across cell type contexts. Pinnacle outperforms state-of-the-art, yet context-free, models in nominating therapeutic targets for rheumatoid arthritis and inflammatory bowel diseases, and can pinpoint cell type contexts that predict therapeutic targets better than context-free models (29 out of 156 cell types in rheumatoid arthritis; 13 out of 152 cell types in inflammatory bowel diseases). Pinnacle is a graph-based contextual AI model that dynamically adjusts its outputs based on biological contexts in which it operates.",
        "references": [
            "7c8c1b97463a976e0a133fd72425d6b4cb12c1bc",
            "7d1e59ce254bea5228da634dbe7c5c4160df6f98",
            "a369d6b57e6127c74eee39b381327d403892c5d6",
            "1adff6300cad0338c5922704f258a9fa3b015eb1",
            "b05eba937871ec8c2961413cd8f5d60f903c157e",
            "b7c4570d7d97f327e7f82fe28100172ec5e94cac",
            "97e69774695752b9d5b3b45473dec6b6196374e7",
            "6da359cfa88d7a431462d51a279f2c83e6e3e6ae",
            "e9ca8921aac04698203eff3d47f7843b31652b46",
            "e4f2c471d27ced746f26cc6e8337ea5cb7c8faf3"
        ],
        "related_topics": [],
        "reference_count": "174",
        "citation_count": "3"
    },
    {
        "Id": "8fbe88f9af293a1d53640ad6057d89bc22d5e8e0",
        "title": "Drug-Target-Interaction Prediction with Contrastive and Siamese Transformers",
        "authors": [
            "Daniel Ikechukwu",
            "Arav Kumar"
        ],
        "date": "31 October 2023",
        "abstract": "This study introduces two innovative methodologies that combine Generative Pretraining and Contrastive Learning to specialize Transformers for bio-chemical modeling that are designed to best incorporate cross-attention, which enables a nuanced alignment of multi-representation embeddings. As machine learning (ML) becomes increasingly integrated into the drug development process, accurately predicting Drug-Target Interactions (DTI) becomes a necessity for pharmaceutical research. This prediction plays a crucial role in various aspects of drug development, including virtual screening, repurposing of drugs, and proactively identifying potential side effects. While Deep Learning has made significant progress in enhancing DTI prediction, challenges related to interpretability and consistent performance persist in the field. This study introduces two innovative methodologies that combine Generative Pretraining and Contrastive Learning to specialize Transformers for bio-chemical modeling. These systems are designed to best incorporate cross-attention, which enables a nuanced alignment of multi-representation embeddings. Our empirical evaluation will showcase the effectiveness and interpretability of this proposed framework. Through a series of experiments, we provide compelling evidence of its superior predictive accuracy and enhanced interpretability. The primary objective of this research is not only to contribute to the advancement of novel DTI prediction methods but also to promote greater transparency and reliability within the drug discovery pipeline.",
        "references": [
            "ac3bb973c1c2f5b22b95722213d410262add604a",
            "3691f3c2a4aa139bc480788f8a723ff7c8b2772e",
            "3eb85dbadeb5074325a404304313bed536fb6157",
            "600004f0d7fcb08ccf11b878a2b1ce89a2959259",
            "fa5a326f9e3729f114b041fd68e632edc17f2f97",
            "eb93dfa43194d6897eeb1e4fe6bacadd40051862",
            "648ea5719ff9c0b81806aa6cc64e600a599e4a59",
            "ef56e1a6a0189243e1a9858670821341d77f0901",
            "64d025132b34770bfa43d16c1e36662af687607d",
            "20bb3aaf6655ef5555d995a0cba60421742794e7"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "61"
    },
    {
        "Id": "6376d79602eb8053d8a389110df970923f0a99fd",
        "title": "Graph AI in Medicine",
        "authors": [
            "Ruth Johnson",
            "Michelle M. Li",
            "Ayush Noori",
            "Owen Queen",
            "Marinka Zitnik"
        ],
        "date": "20 October 2023",
        "abstract": "Graph AI facilitates model transfer across clinical tasks, enabling models to generalize across patient populations without additional parameters or minimal re-training, but the importance of human-centered design and model interpretability in clinical decision-making cannot be overstated. In clinical artificial intelligence (AI), graph representation learning, mainly through graph neural networks (GNNs), stands out for its capability to capture intricate relationships within structured clinical datasets. With diverse data -- from patient records to imaging -- GNNs process data holistically by viewing modalities as nodes interconnected by their relationships. Graph AI facilitates model transfer across clinical tasks, enabling models to generalize across patient populations without additional parameters or minimal re-training. However, the importance of human-centered design and model interpretability in clinical decision-making cannot be overstated. Since graph AI models capture information through localized neural transformations defined on graph relationships, they offer both an opportunity and a challenge in elucidating model rationale. Knowledge graphs can enhance interpretability by aligning model-driven insights with medical knowledge. Emerging graph models integrate diverse data modalities through pre-training, facilitate interactive feedback loops, and foster human-AI collaboration, paving the way to clinically meaningful predictions.",
        "references": [
            "64060b3ae356acd18180f6d2e980b5cf898638d9",
            "dab8e83316a34dfb8a8bd752b1ba693097a68c4e",
            "dc28434a6d10ae9b151dce1fed9591ddfcaf2b81",
            "167c4607722d10f350c320bc36a5612e72deba00",
            "d79683524b2f8ef26d4fbc7b4930aa03ae0cf783",
            "a594403e8ad4357d005281f4982c2928332f48c6",
            "99559d3d32042d7fe34153e167d5c8f40a83fcca",
            "d17d53c2720146564c36cc392e1673309fb01566",
            "5cc58bcfb9bf39d4114eab88fca36eb0ce36afd9",
            "c9f6a0866670131774918418227e6b5e5af13570"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "148"
    },
    {
        "Id": "83c43b613fe2917c883bdf8866206cb0c35e97f3",
        "title": "A Systematic Survey in Geometric Deep Learning for Structure-based Drug Design",
        "authors": [
            "Zaixin Zhang",
            "Jiaxian Yan",
            "Qi Liu",
            "Enhong Chen",
            "Marinka Zitnik"
        ],
        "date": "20 June 2023",
        "abstract": "This paper systematically reviews the current state of geometric deep learning in SBDD, and offers in-depth reviews of each key task, including binding site prediction, binding pose generation, de novo molecule generation, linker design, and binding affinity prediction. Structure-based drug design (SBDD) utilizes the three-dimensional geometry of proteins to identify potential drug candidates. Traditional methods, grounded in physicochemical modeling and informed by domain expertise, are resource-intensive. Recent developments in geometric deep learning, focusing on the integration and processing of 3D geometric data, coupled with the availability of accurate protein 3D structure predictions from tools like AlphaFold, have greatly advanced the field of structure-based drug design. This paper systematically reviews the current state of geometric deep learning in SBDD. We first outline foundational tasks in SBDD, detail prevalent 3D protein representations, and highlight representative predictive and generative models. We then offer in-depth reviews of each key task, including binding site prediction, binding pose generation, \\emph{de novo} molecule generation, linker design, and binding affinity prediction. We provide formal problem definitions and outline each task's representative methods, datasets, evaluation metrics, and performance benchmarks. Finally, we summarize the current challenges and future opportunities: current challenges in SBDD include oversimplified problem formulations, inadequate out-of-distribution generalization, a lack of reliable evaluation metrics and large-scale benchmarks, and the need for experimental verification and enhanced model understanding; opportunities include leveraging multimodal datasets, integrating domain knowledge, building comprehensive benchmarks, designing criteria based on clinical endpoints, and developing foundation models that broaden the range of design tasks. We also curate \\url{https://github.com/zaixizhang/Awesome-SBDD}, reflecting ongoing contributions and new datasets in SBDD.",
        "references": [
            "5309f4bcb15e3dafbed759488551c1650b55dd81",
            "d651f7b09f554482bc7a5ffa1381dda1dc73050c",
            "1439336f3f14bf129ee2dceb04770aa4d100049c",
            "ece9d2d10ce3863e171e2dc093478af3aed029c4",
            "15215eb9ad3826cb538f3eded033f054bb37be45",
            "02b86623755c6541a3799c26b31bd8f2918ce3f8",
            "81f5792e7bce2ff5edc2148e6f46989e372e14e8",
            "b212b0270cf5874f9a1c8e0b4cb144c49dfc2eca",
            "cbba6806a864086b5ddf56a0db7462eab2271f30",
            "a1aed6c0f20b659bb0c5f559c6d33584d51c5aab"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "198"
    },
    {
        "Id": "98538552448434483168c56becdafd590c3b91ad",
        "title": "Current and future directions in network biology",
        "authors": [
            "Marinka Zitnik",
            "Michelle M. Li",
            "Aydin Wells",
            "Kimberly Glass",
            "Deisy Morselli Gysi",
            "Arjun Krishnan",
            "T. M. Murali",
            "Predrag Radivojac",
            "Sushmita Roy",
            "Anais Baudot",
            "S. Bozdag",
            "Danny Z. Chen",
            "Lenore J. Cowen",
            "Kapil Devkota",
            "Anthony Gitter",
            "Sara Gosline",
            "Pengfei Gu",
            "Pietro Hiram Guzzi",
            "Heng Huang",
            "Meng Jiang",
            "Ziynet Nesibe Kesimoglu",
            "Mehmet Koyuturk",
            "Jian Ma",
            "Alexander R. Pico",
            "Natavsa Prvzulj",
            "Teresa M. Przytycka",
            "Benjamin J. Raphael",
            "Anna M. Ritz",
            "Roded Sharan",
            "Yang Shen",
            "Mona Singh",
            "Donna K. Slonim",
            "Hanghang Tong",
            "Xinan Holly Yang",
            "Byung-Jun Yoon",
            "Haiyuan Yu",
            "Tijana Milenkovi&#x27;c"
        ],
        "date": "15 September 2023",
        "abstract": "A workshop on Future Directions in Network Biology was organized and held at the University of Notre Dame in 2022, which brought together active researchers in various computational and in particular algorithmic aspects of network biology to identify pressing challenges in this field. Network biology, an interdisciplinary field at the intersection of computational and biological sciences, is critical for deepening understanding of cellular functioning and disease. While the field has existed for about two decades now, it is still relatively young. There have been rapid changes to it and new computational challenges have arisen. This is caused by many factors, including increasing data complexity, such as multiple types of data becoming available at different levels of biological organization, as well as growing data size. This means that the research directions in the field need to evolve as well. Hence, a workshop on Future Directions in Network Biology was organized and held at the University of Notre Dame in 2022, which brought together active researchers in various computational and in particular algorithmic aspects of network biology to identify pressing challenges in this field. Topics that were discussed during the workshop include: inference and comparison of biological networks, multimodal data integration and heterogeneous networks, higher-order network analysis, machine learning on networks, and network-based personalized medicine. Video recordings of the workshop presentations are publicly available on YouTube. For even broader impact of the workshop, this paper, co-authored mostly by the workshop participants, summarizes the discussion from the workshop. As such, it is expected to help shape short- and long-term vision for future computational and algorithmic research in network biology.",
        "references": [
            "5bdce7d391c27c7079fa51ac85cc1ae4573d9fa7",
            "230ac06f71e9571165082d09dd1088767cc234da",
            "2134b04cae1a0600c183f9e20e4d0b3031d392b4",
            "bd00e11a9d6f5451cd023e21d8ddc65c5d5edc3a",
            "a0c95626d29b96dc133c24788a6fda1632de71a7",
            "610019414e6179f8db0a7948625677efe68cd043",
            "182588f1f22b2390907127bb7d71f4a1c2ecec65",
            "a9e2d3bd26cc2d952a7502d938f39ba64fba4a52",
            "22b396113d4249a055eeba65b9ebc6b23e583bb3",
            "01454bc7240032241855658d4337528953e58a44"
        ],
        "related_topics": [],
        "reference_count": "496",
        "citation_count": "2"
    },
    {
        "Id": "1840f90d990d75070eae0885adc99dcaae9a7d38",
        "title": "A 3D-Shape Similarity-based Contrastive Approach to Molecular Representation Learning",
        "authors": [
            "Austin O. Atsango",
            "Nathaniel Diamant",
            "Ziqing Lu",
            "Tommaso Biancalani",
            "Gabriele Scalia",
            "Kangway V. Chuang"
        ],
        "date": "3 November 2022",
        "abstract": "A new contrastive-learning procedure for graph neural networks is proposed, Molecular Contrastive Learning from Shape Similarity (MolCLaSS), that implicitly learns a three-dimensional representation of molecular shape. Molecular shape and geometry dictate key biophysical recognition processes, yet many graph neural networks disregard 3D information for molecular property prediction. Here, we propose a new contrastive-learning procedure for graph neural networks, Molecular Contrastive Learning from Shape Similarity (MolCLaSS), that implicitly learns a three-dimensional representation. Rather than directly encoding or targeting three-dimensional poses, MolCLaSS matches a similarity objective based on Gaussian overlays to learn a meaningful representation of molecular shape. We demonstrate how this framework naturally captures key aspects of three-dimensionality that two-dimensional representations cannot and provides an inductive framework for scaffold hopping.",
        "references": [
            "020dd99d8d3adacf70780456bb53512d2a206244",
            "b8f816e23ff40d6afabccca2ee4770087ef0ef57",
            "fde21588606b6f73534b269d54106fe7078dc44b",
            "a5eb31131ec807648d6b61eacbce5b2deb0d3727",
            "5182f13b28d35fa3b3e2f78c0b37ed89058f6809",
            "561c3fa53d36405186da9cab02bd68635c3738aa",
            "900d806b06f38174cd063a0b6ad3e9f92b020e46",
            "f8079b38314b9a78e2558d26126ed649e9c3d2dc",
            "5bdec04934bd8e428bc9db760c6524e69d951a16",
            "6420a334687d290d77c6b5ec99ca17f9d069df4a"
        ],
        "related_topics": [
            "Inductive Framework",
            "Molecular Representation Learning",
            "Geometry",
            "Molecular Property Prediction"
        ],
        "reference_count": "38",
        "citation_count": "One"
    },
    {
        "Id": "d56c1fc337fb07ec004dc846f80582c327af717c",
        "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding",
        "authors": [
            "Wei Wang",
            "Bin Bi",
            "Ming Yan",
            "Chen Wu",
            "Zuyi Bao",
            "Liwei Peng",
            "Luo Si"
        ],
        "date": "1 August 2019",
        "abstract": "Inspired by the linearization exploration work of Elman, BERT is extended to a new model, StructBERT, by incorporating language structures into pre-training, and the new model is adapted to different levels of language understanding required by downstream tasks. Recently, the pre-trained language model, BERT (and its robustly optimized version RoBERTa), has attracted a lot of attention in natural language understanding (NLU), and achieved state-of-the-art accuracy in various NLU tasks, such as sentiment classification, natural language inference, semantic textual similarity and question answering. Inspired by the linearization exploration work of Elman [8], we extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. Specifically, we pre-train StructBERT with two auxiliary tasks to make the most of the sequential order of words and sentences, which leverage language structures at the word and sentence levels, respectively. As a result, the new model is adapted to different levels of language understanding required by downstream tasks. The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 89.0 (outperforming all published models), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac",
            "b47381e04739ea3f392ba6c8faaf64105493c196",
            "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "687bac2d3320083eb4530bf18bb8f8f721477600",
            "e7046bf945ad6326537a1ac78a96fd2f45acc900",
            "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "8c1b00128e74f1cd92aede3959690615695d5101"
        ],
        "related_topics": [
            "StructBERT",
            "Word Structural Objective",
            "Natural Language Understanding",
            "Pre-training",
            "Bidirectional Encoder Representations From Transformers",
            "Semantic Textual Similarity",
            "Question Answering",
            "Sentences",
            "State-of-the-art Accuracy",
            "Auxiliary Tasks"
        ],
        "reference_count": "38",
        "citation_count": "227"
    },
    {
        "Id": "9ba6ad0de7dbe1a3b10c44106049adb96f87d483",
        "title": "KgPLM: Knowledge-guided Language Model Pre-training via Generative and Discriminative Learning",
        "authors": [
            "Bin He",
            "Xin Jiang",
            "Jinghui Xiao",
            "Qun Liu"
        ],
        "date": "7 December 2020",
        "abstract": "This work presents a language model pre-training framework guided by factual knowledge completion and verification, and uses the generative and discriminative approaches cooperatively to learn the model. Recent studies on pre-trained language models have demonstrated their ability to capture factual knowledge and applications in knowledge-aware downstream tasks. In this work, we present a language model pre-training framework guided by factual knowledge completion and verification, and use the generative and discriminative approaches cooperatively to learn the model. Particularly, we investigate two learning schemes, named two-tower scheme and pipeline scheme, in training the generator and discriminator with shared parameter. Experimental results on LAMA, a set of zero-shot cloze-style question answering tasks, show that our model contains richer factual knowledge than the conventional pre-trained language models. Furthermore, when fine-tuned and evaluated on the MRQA shared tasks which consists of several machine reading comprehension datasets, our model achieves the state-of-the-art performance, and gains large improvements on NewsQA (+1.26 F1) and TriviaQA (+1.56 F1) over RoBERTa.",
        "references": [
            "0ff7f557203d1489110b9d2f89a76245def7b530",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "5e0cffc51e8b64a8f11326f955fa4b4f1803e3be",
            "8668fd1cb5cab820f8b2a136b2ef4adfad6c4dc1",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "4f03e69963b9649950ba29ae864a0de8c14f1f86"
        ],
        "related_topics": [
            "Factual Knowledge",
            "Language Model Analysis",
            "TriviaQA",
            "NewsQA",
            "Discriminator",
            "Robustly Optimized Bert Pretraining Approach"
        ],
        "reference_count": "31",
        "citation_count": "15"
    },
    {
        "Id": "d56c1fc337fb07ec004dc846f80582c327af717c",
        "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding",
        "authors": [
            "Wei Wang",
            "Bin Bi",
            "Ming Yan",
            "Chen Wu",
            "Zuyi Bao",
            "Liwei Peng",
            "Luo Si"
        ],
        "date": "1 August 2019",
        "abstract": "Inspired by the linearization exploration work of Elman, BERT is extended to a new model, StructBERT, by incorporating language structures into pre-training, and the new model is adapted to different levels of language understanding required by downstream tasks. Recently, the pre-trained language model, BERT (and its robustly optimized version RoBERTa), has attracted a lot of attention in natural language understanding (NLU), and achieved state-of-the-art accuracy in various NLU tasks, such as sentiment classification, natural language inference, semantic textual similarity and question answering. Inspired by the linearization exploration work of Elman [8], we extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. Specifically, we pre-train StructBERT with two auxiliary tasks to make the most of the sequential order of words and sentences, which leverage language structures at the word and sentence levels, respectively. As a result, the new model is adapted to different levels of language understanding required by downstream tasks. The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 89.0 (outperforming all published models), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac",
            "b47381e04739ea3f392ba6c8faaf64105493c196",
            "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "687bac2d3320083eb4530bf18bb8f8f721477600",
            "e7046bf945ad6326537a1ac78a96fd2f45acc900",
            "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "8c1b00128e74f1cd92aede3959690615695d5101"
        ],
        "related_topics": [
            "StructBERT",
            "Word Structural Objective",
            "Natural Language Understanding",
            "Pre-training",
            "Bidirectional Encoder Representations From Transformers",
            "Semantic Textual Similarity",
            "Question Answering",
            "Sentences",
            "State-of-the-art Accuracy",
            "Auxiliary Tasks"
        ],
        "reference_count": "38",
        "citation_count": "227"
    },
    {
        "Id": "832fff14d2ed50eb7969c4c4b976c35776548f56",
        "title": "REALM: Retrieval-Augmented Language Model Pre-Training",
        "authors": [
            "Kelvin Guu",
            "Kenton Lee",
            "Zora Tung",
            "Panupong Pasupat",
            "Ming-Wei Chang"
        ],
        "date": "10 February 2020",
        "abstract": "The effectiveness of Retrieval-Augmented Language Model pre-training (REALM) is demonstrated by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA) and is found to outperform all previous methods by a significant margin, while also providing qualitative benefits such as interpretability and modularity. Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. \nTo capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. \nWe demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.",
        "references": [
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "97e6ed1f7e5de0034f71c370c01f59c87aaf9a72",
            "a81874b4a651a740fffbfc47ef96515e8c7f782f",
            "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
            "f6335a158a3f4fcfffe74f2df1d55d835bf95095"
        ],
        "related_topics": [
            "REALM",
            "Retrieval-Augmented Language Model",
            "Salient Span Masking",
            "ORQA",
            "Open-QA",
            "Open-Domain Question Answering",
            "Inverse Cloze Task",
            "Knowledge Retriever",
            "World Knowledge",
            "GRAPHRETRIEVER"
        ],
        "reference_count": "43",
        "citation_count": "1,145"
    },
    {
        "Id": "abaadb4c6affc4d874c4f59bfac60686e851cb5e",
        "title": "Pre-training Text-to-Text Transformers for Concept-centric Common Sense",
        "authors": [
            "Wangchunshu Zhou",
            "Dong-Ho Lee",
            "Ravi Kiran Selvam",
            "Seyeon Lee",
            "Bill Yuchen Lin",
            "Xiang Ren"
        ],
        "date": "24 October 2020",
        "abstract": "It is shown that while only incrementally pre-trained on a relatively small corpus for a few steps, CALM outperforms baseline methods by a consistent margin and even comparable with some larger PTLMs, which suggests that CALM can serve as a general, plug-and-play method for improving the commonsense reasoning ability of a PTLM. Pre-trained language models (PTLM) have achieved impressive results in a range of natural language understanding (NLU) and generation (NLG) tasks. However, current pre-training objectives such as masked token prediction (for BERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not explicitly model the relational commonsense knowledge about everyday concepts, which is crucial to many downstream tasks that need common sense to understand or generate. To augment PTLMs with concept-centric commonsense knowledge, in this paper, we propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self-supervised learning tasks for incrementally pre-training PTLMs (before task-specific fine-tuning on downstream datasets). Furthermore, we develop a joint pre-training framework to unify generative and contrastive objectives so that they can mutually reinforce each other. Extensive experimental results show that our method, concept-aware language model (CALM), can pack more commonsense knowledge into the parameters of a pre-trained text-to-text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG tasks. We show that while only incrementally pre-trained on a relatively small corpus for a few steps, CALM outperforms baseline methods by a consistent margin and even comparable with some larger PTLMs, which suggests that CALM can serve as a general, plug-and-play method for improving the commonsense reasoning ability of a PTLM.",
        "references": [
            "1c71771c701aadfd72c5866170a9f5d71464bb88",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "0119a57cf88ef16e6dc291252fae340bb6b3953c",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "6dbe700f79ebff749c89dc63e7127b810f64881f"
        ],
        "related_topics": [
            "KG-BART",
            "Natural Language Understanding",
            "Consistency As Logical Monotonicity",
            "Circumpolar Active Layer Monitoring",
            "Contrastive Objectives",
            "Commonsense Knowledge",
            "Graphs",
            "Transformer",
            "Fine-tuning",
            "Text-to-Text Transformer"
        ],
        "reference_count": "45",
        "citation_count": "64"
    },
    {
        "Id": "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
        "title": "Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model",
        "authors": [
            "Wenhan Xiong",
            "Jingfei Du",
            "William Yang Wang",
            "Veselin Stoyanov"
        ],
        "date": "20 December 2019",
        "abstract": "This work proposes a simple yet effective weakly supervised pretraining objective, which explicitly forces the model to incorporate knowledge about real-world entities, and consistently outperforms BERT on four entity-related question answering datasets. Recent breakthroughs of pretrained language models have shown the effectiveness of self-supervised learning for a wide range of natural language processing (NLP) tasks. In addition to standard syntactic and semantic NLP tasks, pretrained models achieve strong improvements on tasks that involve real-world knowledge, suggesting that large-scale language modeling could be an implicit method to capture knowledge. In this work, we further investigate the extent to which pretrained models such as BERT capture knowledge using a zero-shot fact completion task. Moreover, we propose a simple yet effective weakly supervised pretraining objective, which explicitly forces the model to incorporate knowledge about real-world entities. Models trained with our new objective yield significant improvements on the fact completion task. When applied to downstream tasks, our model consistently outperforms BERT on four entity-related question answering datasets (i.e., WebQuestions, TriviaQA, SearchQA and Quasar-T) with an average 2.7 F1 improvements and a standard fine-grained entity typing dataset (i.e., FIGER) with 5.7 accuracy gains.",
        "references": [
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "0fa5142f908afc94c923ca2adbe14a5673bc76eb",
            "880f418fef7a768a9a24f872eab3b1ce5de83e53",
            "f7df82c5417b9ec7582def05b79ca080a07c4f3b"
        ],
        "related_topics": [
            "Entity Knowledge",
            "Enhanced Language Representation With Informative Entity",
            "Natural Language Processing",
            "Bidirectional Encoder Representations From Transformers",
            "Accuracy Gains",
            "Quasar-T",
            "Pretrained Language Models",
            "Self-Supervised Learning",
            "SearchQA",
            "TriviaQA"
        ],
        "reference_count": "52",
        "citation_count": "181"
    },
    {
        "Id": "319b84be7a843250bc81d7086f79a4126d550277",
        "title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation",
        "authors": [
            "Yu Sun",
            "Shuohuan Wang",
            "Shikun Feng",
            "Siyu Ding",
            "Chao Pang",
            "Junyuan Shang",
            "Jiaxiang Liu",
            "Xuyi Chen",
            "Yanbin Zhao",
            "Yuxiang Lu",
            "Weixin Liu",
            "Zhihua Wu",
            "Weibao Gong",
            "Jianzhong Liang",
            "Zhizhou Shang",
            "Peng Sun",
            "Wei Liu",
            "Ouyang Xuan",
            "Dianhai Yu",
            "Hao Tian",
            "Hua Wu",
            "Haifeng Wang"
        ],
        "date": "5 July 2021",
        "abstract": "A unified framework named ERNIE 3.0 is proposed for pre-training large-scale knowledge enhanced models that fuses auto-regressive network and auto-encoding network, so that the trained model can be easily tailored for both natural language understanding and generation tasks with zero-shot learning, few- shot learning or fine-tuning. Pre-trained models have achieved state-of-the-art results in various Natural Language Processing (NLP) tasks. Recent works such as T5 and GPT-3 have shown that scaling up pre-trained language models can improve their generalization abilities. Particularly, the GPT-3 model with 175 billion parameters shows its strong task-agnostic zero-shot/few-shot learning capabilities. Despite their success, these large-scale models are trained on plain texts without introducing knowledge such as linguistic knowledge and world knowledge. In addition, most large-scale models are trained in an auto-regressive way. As a result, this kind of traditional fine-tuning approach demonstrates relatively weak performance when solving downstream language understanding tasks. In order to solve the above problems, we propose a unified framework named ERNIE 3.0 for pre-training large-scale knowledge enhanced models. It fuses auto-regressive network and auto-encoding network, so that the trained model can be easily tailored for both natural language understanding and generation tasks with zero-shot learning, few-shot learning or fine-tuning. We trained the model with 10 billion parameters on a 4TB corpus consisting of plain texts and a large-scale knowledge graph. Empirical results show that the model outperforms the state-of-the-art models on 54 Chinese NLP tasks, and its English version achieves the first place on the SuperGLUE benchmark (July 3, 2021), surpassing the human performance by +0.8% (90.6% vs. 89.8%).",
        "references": [
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "cc50f846ed7222698d130cddbc58ed4d547914ed",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "abaadb4c6affc4d874c4f59bfac60686e851cb5e",
            "04b40daa1ca74bdbb578beb314bf662538ecd18e",
            "6191a5122d67dfbab421bc89540d264822dd8173",
            "00a95c2e2af1c6ef7ba41fe502a8cc729cdd284d",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "6b85b63579a916f705a8e10a49bd8d849d91b1fc",
            "7eda139d737eea10fc1d95364327a41ec0cee4a4"
        ],
        "related_topics": [
            "ERNIE 3.0",
            "Chinese Scientific Literature",
            "Word-knowledge Graph",
            "CMRC-2017",
            "CMRC2018",
            "Natural Language Processing",
            "Few-shot Learning",
            "GPT-3",
            "Zero-Shot Learning",
            "SuperGLUE Benchmark"
        ],
        "reference_count": "102",
        "citation_count": "220"
    },
    {
        "Id": "a2412fdebd53bd25476f834ae2b8aa8cb44cb1e1",
        "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design",
        "authors": [
            "Yoav Levine",
            "Noam Wies",
            "Daniel Jannai",
            "Daniel Navon",
            "Yedid Hoshen",
            "Amnon Shashua"
        ],
        "date": "9 October 2021",
        "abstract": "It is shown that including semantically related non-neighboring sentences in the same pretraining example yields improved sentence representations and open domain question answering abilities, and indicates new training schemes for self-improving representations. Pretraining Neural Language Models (NLMs) over a large corpus involves chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture. We highlight a bias introduced by this common practice: we prove that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segments that appeared in different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine-tuning stages, which do not necessarily appear related at first glance. Second, our result clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks. As an example, we propose\"kNN-Pretraining\": we show that including semantically related non-neighboring sentences in the same pretraining example yields improved sentence representations and open domain question answering abilities. This theoretically motivated degree of freedom for pretraining example design indicates new training schemes for self-improving representations.",
        "references": [
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "e816f788767eec6a8ef0ea9eddd0e902435d4271",
            "c00ba15810496669d47d2ed5b627e6c7d2b1f6aa",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "7be8c119dbe065c52125ee7716601751f3116844",
            "85e7d63f75c0916bd350a229e040c5fbb1472e7a",
            "c26759e6c701201af2f62f7ee4eb68742b5bf085",
            "6b85b63579a916f705a8e10a49bd8d849d91b1fc",
            "301e13f3df8f9dfb79ea782da3693e2942392279",
            "002c256d30d6be4b23d365a8de8ae0e67e4c9641"
        ],
        "related_topics": [
            "Separation Rank",
            "Pretraining",
            "Neural Language Models",
            "Inductive Biases",
            "Sentence Representations",
            "Neural Architecture",
            "Non Local Means"
        ],
        "reference_count": "44",
        "citation_count": "25"
    },
    {
        "Id": "9ba6ad0de7dbe1a3b10c44106049adb96f87d483",
        "title": "KgPLM: Knowledge-guided Language Model Pre-training via Generative and Discriminative Learning",
        "authors": [
            "Bin He",
            "Xin Jiang",
            "Jinghui Xiao",
            "Qun Liu"
        ],
        "date": "7 December 2020",
        "abstract": "This work presents a language model pre-training framework guided by factual knowledge completion and verification, and uses the generative and discriminative approaches cooperatively to learn the model. Recent studies on pre-trained language models have demonstrated their ability to capture factual knowledge and applications in knowledge-aware downstream tasks. In this work, we present a language model pre-training framework guided by factual knowledge completion and verification, and use the generative and discriminative approaches cooperatively to learn the model. Particularly, we investigate two learning schemes, named two-tower scheme and pipeline scheme, in training the generator and discriminator with shared parameter. Experimental results on LAMA, a set of zero-shot cloze-style question answering tasks, show that our model contains richer factual knowledge than the conventional pre-trained language models. Furthermore, when fine-tuned and evaluated on the MRQA shared tasks which consists of several machine reading comprehension datasets, our model achieves the state-of-the-art performance, and gains large improvements on NewsQA (+1.26 F1) and TriviaQA (+1.56 F1) over RoBERTa.",
        "references": [
            "0ff7f557203d1489110b9d2f89a76245def7b530",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "5e0cffc51e8b64a8f11326f955fa4b4f1803e3be",
            "8668fd1cb5cab820f8b2a136b2ef4adfad6c4dc1",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "4f03e69963b9649950ba29ae864a0de8c14f1f86"
        ],
        "related_topics": [
            "Factual Knowledge",
            "Language Model Analysis",
            "TriviaQA",
            "NewsQA",
            "Discriminator",
            "Robustly Optimized Bert Pretraining Approach"
        ],
        "reference_count": "31",
        "citation_count": "15"
    },
    {
        "Id": "789a7069d1a2d02d784e4821685b216cc63e6ec8",
        "title": "Strategies for Pre-training Graph Neural Networks",
        "authors": [
            "Weihua Hu",
            "Bowen Liu",
            "Joseph Gomes",
            "Marinka Zitnik",
            "Percy Liang",
            "Vijay S. Pande",
            "Jure Leskovec"
        ],
        "date": "29 May 2019",
        "abstract": "A new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs) that avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction. Many applications of machine learning require a model to make accurate pre-dictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naive strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction.",
        "references": [
            "48ddd9101a90fe65e3061de69626741b843ff5e4",
            "62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9",
            "967a21a111757d6af7f7a25ca7ea2bdf6d505098",
            "d0ab11de3077490c80a08abd0fb8827bac84c454",
            "44ee7dbae6ad53cb13e49e7e641b54089ca5788d",
            "cb2722b202b2b0b1b9b87eb4a984dee9040f34c3",
            "d81fc968196e06ccafd7ea4c008b13e1cad1be64",
            "33998aff64ce51df8dee45989cdca4b6b1329ec4",
            "ecf6c42d84351f34e1625a6a2e4cc6526da45c74",
            "d2a8e1857dbfaef6713e33a1946ea7548f8209a3"
        ],
        "related_topics": [
            "Molecular Property Prediction",
            "Attribute Masking",
            "Unlabeled Molecules",
            "Graph-level Representations",
            "NODE-LEVEL PRE-TRAINING",
            "Context Prediction",
            "Entire Graph",
            "Species Split",
            "Graph Isomorphism Network",
            "Molecular Datasets"
        ],
        "reference_count": "92",
        "citation_count": "904"
    },
    {
        "Id": "018987cad9845a37cd0e6f1d78596041c911d4f5",
        "title": "Dict-BERT: Enhancing Language Model Pre-training with Dictionary",
        "authors": [
            "W. Yu",
            "Chenguang Zhu",
            "Yuwei Fang",
            "Donghan Yu",
            "Shuohang Wang",
            "Yichong Xu",
            "Michael Zeng",
            "Meng Jiang"
        ],
        "date": "13 October 2021",
        "abstract": "This work proposes two novel self-supervised pre-training tasks on word and sentence-level alignment between input text sequence and rare word definitions to enhance language modeling representation with dictionary and evaluates the proposed Dict-BERT model on the language understanding benchmark GLUE and eight specialized domain benchmark datasets. Pre-trained language models (PLMs) aim to learn universal language representations by conducting self-supervised training tasks on large-scale corpora. Since PLMs capture word semantics in different contexts, the quality of word representations highly depends on word frequency, which usually follows a heavy-tailed distributions in the pre-training corpus. Therefore, the embeddings of rare words on the tail are usually poorly optimized. In this work, we focus on enhancing language model pre-training by leveraging definitions of the rare words in dictionaries (e.g., Wiktionary). To incorporate a rare word definition as a part of input, we fetch its definition from the dictionary and append it to the end of the input text sequence. In addition to training with the masked language modeling objective, we propose two novel self-supervised pre-training tasks on word and sentence-level alignment between input text sequence and rare word definitions to enhance language modeling representation with dictionary. We evaluate the proposed Dict-BERT model on the language understanding benchmark GLUE and eight specialized domain benchmark datasets. Extensive experiments demonstrate that Dict-BERT can significantly improve the understanding of rare words and boost model performance on various NLP downstream tasks.",
        "references": [
            "abaadb4c6affc4d874c4f59bfac60686e851cb5e",
            "480815ff593a7c36f64db8ca197014e2ad4a2a5f",
            "44b7ed6badc8d45330fef5961346ac9e70511356",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "a9a5d671271fff45429084e184a788f611b6f194",
            "be18e1f566baeffb71fc4eed24f79dc8724879d4",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "a9c3a009d754a110379574b069b48c0b4c75db40",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992"
        ],
        "related_topics": [
            "Rare Words",
            "Dictionary",
            "Pre-trained Language Models",
            "Language Models",
            "Embeddings",
            "Heavy-tailed Distribution",
            "General Language Understanding Evaluation",
            "Word Representations",
            "Wiktionary",
            "Language Understanding Benchmark"
        ],
        "reference_count": "41",
        "citation_count": "49"
    },
    {
        "Id": "a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f",
        "title": "LinkBERT: Pretraining Language Models with Document Links",
        "authors": [
            "Michihiro Yasunaga",
            "Jure Leskovec",
            "Percy Liang"
        ],
        "date": "29 March 2022",
        "abstract": "This work proposes LinkBERT, an LM pretraining method that leverages links between documents that outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain ( pretrained on PubMed with citation links). Language model (LM) pretraining captures various knowledge from text corpora, helping downstream tasks. However, existing methods such as BERT model a single document, and do not capture dependencies or knowledge that span across documents. In this work, we propose LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks. Given a text corpus, we view it as a graph of documents and create LM inputs by placing linked documents in the same context. We then pretrain the LM with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction. We show that LinkBERT outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain (pretrained on PubMed with citation links). LinkBERT is especially effective for multi-hop reasoning and few-shot QA (+5% absolute improvement on HotpotQA and TriviaQA), and our biomedical LinkBERT sets new states of the art on various BioNLP tasks (+7% on BioASQ and USMLE). We release our pretrained models, LinkBERT and BioLinkBERT, as well as code and data.",
        "references": [
            "a3e4ceb42cbcd2c807d53aff90a8cb1f5ee3f031",
            "54523ff961a1ac57a86696ef9a53b3a630b482c0",
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "6aaec722a90eee0185d4bbfebbcd4f228ed1577f",
            "e596b8adbffa546dbc163e817fb3de72744ec4f6",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "7eda139d737eea10fc1d95364327a41ec0cee4a4",
            "156d217b0a911af97fa1b5a71dc909ccef7a8028"
        ],
        "related_topics": [
            "LinkBERT",
            "BioLinkBERT",
            "Document Relation Prediction",
            "Linked Documents",
            "Biomedical Language Understanding And Reasoning Benchmark",
            "MedQA-USMLE",
            "Pubmed Parser",
            "BLURB Benchmark",
            "Biomedical NLP Tasks",
            "PubMedQA"
        ],
        "reference_count": "98",
        "citation_count": "169"
    },
    {
        "Id": "333bddf6fe58ca3994805fd475cd35b6faa41adb",
        "title": "CKG: Dynamic Representation Based on Context and Knowledge Graph",
        "authors": [
            "Xunzhu Tang",
            "Tiezhu Sun",
            "Rujie Zhu",
            "Shi Wang"
        ],
        "date": "10 January 2021",
        "abstract": "This paper argues that entities in KGs could be used to enhance the correct semantic meaning of language sentences and proposes a new method CKG: Dynamic Representation Based on Context and Knowledge Graph, which can extract rich semantic information of large corpus and make full use of inside information such as co-occurrence in large corpus. Recently, neural language representation models pre-trained on large corpus can capture rich co-occurrence information and be fine-tuned in downstream tasks to improve the performance. As a result, they have achieved state-of-the-art results in a large range of language tasks. However, there exists other valuable semantic information such as similar, opposite, or other possible meanings in external knowledge graphs (KGs). We argue that entities in KGs could be used to enhance the correct semantic meaning of language sentences. In this paper, we propose a new method CKG: Dynamic Representation Based on Context and Knowledge Graph. On the one side, CKG can extract rich semantic information of large corpus. On the other side, it can make full use of inside information such as co-occurrence in large corpus and outside information such as similar entities in KGs. We conduct extensive experiments on a wide range of tasks, including QQP, MRPC, SST-5, SQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA 89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and $\\text{BERT}_{Base}$ (88.5).",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "b36b2914f16c78b1bf88ee720342d893d8a9fc46",
            "83e7654d545fbbaaf2328df365a781fb67b841b4",
            "687bac2d3320083eb4530bf18bb8f8f721477600",
            "c6b53dd64d79a59f49f261baac8d2581a29ca06a",
            "f04df4e20a18358ea2f689b4c129781628ef7fc1",
            "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
            "5c22ff7fe5fc588e3648b5897255f151feb61fee",
            "803742d83c9fae7cdafe2f3b901790c9db0da1b2",
            "3febb2bed8865945e7fddc99efd791887bb7e14f"
        ],
        "related_topics": [
            "Cybersecurity Knowledge Graph",
            "Semantic Information",
            "Stanford Question Answering Dataset",
            "CoNLL 2003",
            "Language Tasks",
            "Quorum Question Pair",
            "State-of-the-art Results",
            "Embeddings From Language Models",
            "SST-5",
            "Entities"
        ],
        "reference_count": "25",
        "citation_count": "2"
    },
    {
        "Id": "419d6ca6faf224c98a62ddbb5f75bd0d4ea31b6c",
        "title": "SPOT: Knowledge-Enhanced Language Representations for Information Extraction",
        "authors": [
            "Jiacheng Li"
        ],
        "date": "20 August 2022",
        "abstract": "A new pre-trained model is proposed that learns representations of both entities and relationships from token spans and span pairs in the text respectively that can represent both entity and their relationships but requires fewer parameters than existing models. Knowledge-enhanced pre-trained models for language representation have been shown to be more effective in knowledge base construction tasks (i.e.,~relation extraction) than language models such as BERT. These knowledge-enhanced language models incorporate knowledge into pre-training to generate representations of entities or relationships. However, existing methods typically represent each entity with a separate embedding. As a result, these methods struggle to represent out-of-vocabulary entities and a large amount of parameters, on top of their underlying token models (i.e., the transformer), must be used and the number of entities that can be handled is limited in practice due to memory constraints. Moreover, existing models still struggle to represent entities and relationships simultaneously. To address these problems, we propose a new pre-trained model that learns representations of both entities and relationships from token spans and span pairs in the text respectively. By encoding spans efficiently with span modules, our model can represent both entities and their relationships but requires fewer parameters than existing models. We pre-trained our model with the knowledge graph extracted from Wikipedia and test it on a broad range of supervised and unsupervised information extraction tasks. Results show that our model learns better representations for both entities and relationships than baselines, while in supervised settings, fine-tuning our model outperforms RoBERTa consistently and achieves competitive results on information extraction tasks.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "25c3b294b9ed2786c4476a25e8b36ebf49fd5b4b",
            "5066c41ef26ac9876ba797a7c7f49548cf713f9b",
            "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8",
            "4ab41d9780f1d1ac34d39fa7e527e73652507fcc",
            "6a5608e6fee3ecc65361525906b0d092ad9952bb",
            "4af09143735210777281b66997ec12994dbb43d4",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0"
        ],
        "related_topics": [
            "Entities",
            "Language Models",
            "Parameters",
            "Bidirectional Encoder Representations From Transformers",
            "Transformer",
            "Embeddings",
            "Language Representations",
            "Pre-training",
            "Wikipedia",
            "Pre-trained Models"
        ],
        "reference_count": "72",
        "citation_count": "4"
    },
    {
        "Id": "eeaf05f6f3a8dbd14cc318736d6ec833f8ef3f60",
        "title": "Knowledge Graph Fusion for Language Model Fine-Tuning",
        "authors": [
            "Nimesh Bhana",
            "Terence L van Zyl"
        ],
        "date": "21 June 2022",
        "abstract": "This work investigates the benefits of knowledge incorporation into the fine-tuning stages of BERT and shows evidence that, given the appropriate task, modest injection with relevant, high-quality knowledge is most performant. Language Models such as BERT (Bidirectional Encoder Representations from Transformers) have grown in popularity due to their ability to be pre-trained and perform robustly on a wide range of Natural Language Processing tasks. Often seen as an evolution over traditional word embedding techniques, they can produce semantic representations of text, useful for tasks such as semantic similarity. However, state-of-the-art models often have high computational requirements and lack global context or domain knowledge which is required for complete language understanding. To address these limitations, we investigate the benefits of knowledge incorporation into the fine-tuning stages of BERT. An existing K-BERT model, which enriches sentences with triplets from a Knowledge Graph, is adapted for the English language and extended to inject contextually relevant information into sentences. As a side-effect, changes made to K-BERT for accommodating the English language also extend to other word-based languages. Experiments conducted indicate that injected knowledge introduces noise. We see statistically significant improvements for knowledge-driven tasks when this noise is minimised. We show evidence that, given the appropriate task, modest injection with relevant, high-quality knowledge is most performant.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "06a73ad09664435f8b3cd90293f4e05a047cf375",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "a022bda79947d1f656a1164003c1b3ae9a843df9",
            "5075a0df5fc7ad5f1399450498044627ebe7a9f9",
            "7c1a11fcc0d4aa8d7fcfcfa8e375f31f8f23c77a",
            "5124ed6b9e84046ab4e785adb431ecf5d5bf8a41",
            "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096",
            "8a58b7896edaca4860b45401460b0462b228352c"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Language Models",
            "K-BERT",
            "Natural Language Processing",
            "Language Understanding",
            "Knowledge-driven Tasks",
            "Fine-tuning",
            "Global Context",
            "State-of-the-art Models",
            "Pre-trained"
        ],
        "reference_count": "0",
        "citation_count": "34"
    },
    {
        "Id": "5066c41ef26ac9876ba797a7c7f49548cf713f9b",
        "title": "Coreferential Reasoning Learning for Language Representation",
        "authors": [
            "Deming Ye",
            "Yankai Lin",
            "Jiaju Du",
            "Zhenghao Liu",
            "Maosong Sun",
            "Zhiyuan Liu"
        ],
        "date": "15 April 2020",
        "abstract": "The CorefBERT model is presented, a novel language representation model designed to capture the relations between noun phrases that co-refer to each other, and has made significant progress on several downstream NLP tasks that require coreferential reasoning. Language representation models such as BERT could effectively capture contextual semantic information from plain text, and have been proved to achieve promising results in lots of downstream NLP tasks with appropriate fine-tuning. However, existing language representation models seldom consider coreference explicitly, the relationship between noun phrases referring to the same entity, which is essential to a coherent understanding of the whole discourse. To address this issue, we present CorefBERT, a novel language representation model designed to capture the relations between noun phrases that co-refer to each other. According to the experimental results, compared with existing baseline models, the CorefBERT model has made significant progress on several downstream NLP tasks that require coreferential reasoning, while maintaining comparable performance to previous models on other common NLP tasks.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "f03ff33bbc473c4e3efc62cced53ff16b172d9d8",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "5744f56d3253bd7c4341d36de40a93fceaa266b3",
            "cccd1e6fead0a0a0689d8dd53a0b235b3c27b2c4",
            "7442a18a55f257a68f21d0cbb8b1395f8915a452",
            "8ae1af4a424f5e464d46903bc3d18fe1cf1434ff",
            "101d1b1872df566088cb31b95b7e78024a484a64",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "3febb2bed8865945e7fddc99efd791887bb7e14f"
        ],
        "related_topics": [
            "CorefBERT",
            "Coreferential Reasoning",
            "Hierarchical Inference Network",
            "Knowledge Graph Attention Network",
            "Evidence Pieces",
            "DocRED",
            "Downstream NLP Tasks",
            "Language Representation Model",
            "Bidirectional Encoder Representations From Transformers",
            "Entities"
        ],
        "reference_count": "99",
        "citation_count": "135"
    },
    {
        "Id": "06a73ad09664435f8b3cd90293f4e05a047cf375",
        "title": "K-BERT: Enabling Language Representation with Knowledge Graph",
        "authors": [
            "Weijie Liu",
            "Peng Zhou",
            "Zhe Zhao",
            "Zhiruo Wang",
            "Qi Ju",
            "Haotang Deng",
            "Ping Wang"
        ],
        "date": "17 September 2019",
        "abstract": "This work proposes a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge, which significantly outperforms BERT and reveals promising results in twelve NLP tasks. Pre-trained language representation models, such as BERT, capture a general language representation from large-scale corpora, but lack domain-specific knowledge. When reading a domain text, experts make inferences with relevant knowledge. For machines to achieve this capability, we propose a knowledge-enabled language representation model (K-BERT) with knowledge graphs (KGs), in which triples are injected into the sentences as domain knowledge. However, too much knowledge incorporation may divert the sentence from its correct meaning, which is called knowledge noise (KN) issue. To overcome KN, K-BERT introduces soft-position and visible matrix to limit the impact of knowledge. K-BERT can easily inject domain knowledge into the models by being equipped with a KG without pre-training by itself because it is capable of loading model parameters from the pre-trained BERT. Our investigation reveals promising results in twelve NLP tasks. Especially in domain-specific tasks (including finance, law, and medicine), K-BERT significantly outperforms BERT, which demonstrates that K-BERT is an excellent choice for solving the knowledge-driven problems that require experts.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
            "6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "f0efb4f8e1e5957bb252d9d530202b1cef9b0494",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "2c69bbb3b7ba3f324276924bab6f41de467c928a",
            "7e928ef936c2815d7522c5176163d6ab7309a8b7"
        ],
        "related_topics": [
            "K-BERT",
            "Visible Matrix",
            "Soft-position",
            "Knowledge Noise",
            "Sentence Tree",
            "Knowledge-driven Tasks",
            "Mask-Self-Attention",
            "CN-DBpedia",
            "MSRA-NER",
            "Large-scale Chinese Question Matching Corpus"
        ],
        "reference_count": "25",
        "citation_count": "575"
    },
    {
        "Id": "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
        "title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation",
        "authors": [
            "Xiaozhi Wang",
            "Tianyu Gao",
            "Zhaocheng Zhu",
            "Zhiyuan Liu",
            "Juan-Zi Li",
            "Jian Tang"
        ],
        "date": "13 November 2019",
        "abstract": "A unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs is proposed. Abstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "06a73ad09664435f8b3cd90293f4e05a047cf375",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "96acb1c882ad655c6b8459c2cd331803801446ca",
            "f0efb4f8e1e5957bb252d9d530202b1cef9b0494",
            "70af3ee98c53441d9090119f7b76efb1b6d03edd",
            "6dd3b79f34a8b40320d1d745b9abf2d70e1d4db8",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "994afdf0db0cb0456f4f76468380822c2f532726",
            "f7b0d94fd4a32c4c9be472b4e8d6c5bc308f0dfa"
        ],
        "related_topics": [
            "Wikidata5m",
            "Knowledge Embedding",
            "Kepler",
            "Knowledge-enhanced PLM",
            "Factual Knowledge",
            "Entity Typing",
            "Entity Descriptions",
            "OpenEntity",
            "Entity Linker",
            "Enhanced Language Representation With Informative Entity"
        ],
        "reference_count": "75",
        "citation_count": "420"
    },
    {
        "Id": "6e00e5a0380e1e36e3c5caa68b0834d5029187e0",
        "title": "Enriching Language Models with Semantics",
        "authors": [
            "Tobias Mayer"
        ],
        "date": "29 August 2020",
        "abstract": "This paper highlights existing approaches to combine different types of semantics with language models during the pre-training or fine-tuning phase to improve various natural language processing tasks. Recent advances in language model (LM) pre-training from large-scale corpora have shown to improve various natural language processing tasks. They achieve performances comparable to non-expert humans on the GLUE benchmark for natural language understanding (NLU). While the improvement of the different contextualized representations comes from (i) the usage of more and more data, (ii) changing the types of lexical pre-training tasks or (iii) increasing the model size, NLU is more than memorizing word co-occurrences. But how much world knowledge and common sense can those language model capture? How much can those models infer from just the lexical information? To overcome this problem, some approaches include semantic information in the training process. In this paper, we highlight existing approaches to combine different types of semantics with language models during the pre-training or fine-tuning phase.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "5744f56d3253bd7c4341d36de40a93fceaa266b3",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef",
            "97906df07855b029b7aae7c2a1c6c5e8df1d531c",
            "d9f6ada77448664b71128bb19df15765336974a6",
            "e0f41a30fe692c76e9a27396b9494f2e017dd333",
            "8209a8703d8c48aaca1523cfa307dd1c069e58f3",
            "1b97b4623cf2f183340e548e0aa53abf0f2963d8"
        ],
        "related_topics": [
            "Language Models",
            "Natural Language Understanding",
            "Pre-training",
            "Model Size",
            "Natural Language Processing",
            "GLUE Benchmark",
            "Semantic Information",
            "Co-occurrences",
            "World Knowledge"
        ],
        "reference_count": "9",
        "citation_count": "4"
    },
    {
        "Id": "84c8d939c765dd30574e6c7e6d0a3eb82db1c8fb",
        "title": "ERNIE-NLI: Analyzing the Impact of Domain-Specific External Knowledge on Enhanced Representations for NLI",
        "authors": [
            "Lisa Bauer",
            "Lingjia Deng",
            "Mohit Bansal"
        ],
        "date": "1 June 2021",
        "abstract": "Using the ERNIE architecture, a detailed analysis is provided on the types of knowledge that result in a performance increase on the Natural Language Inference task, specifically on the Multi-Genre Natural language Inference Corpus (MNLI). We examine the effect of domain-specific external knowledge variations on deep large scale language model performance. Recent work in enhancing BERT with external knowledge has been very popular, resulting in models such as ERNIE (Zhang et al., 2019a). Using the ERNIE architecture, we provide a detailed analysis on the types of knowledge that result in a performance increase on the Natural Language Inference (NLI) task, specifically on the Multi-Genre Natural Language Inference Corpus (MNLI). While ERNIE uses general TransE embeddings, we instead train domain-specific knowledge embeddings and insert this knowledge via an information fusion layer in the ERNIE architecture, allowing us to directly control and analyze knowledge input. Using several different knowledge training objectives, sources of knowledge, and knowledge ablations, we find a strong correlation between knowledge and classification labels within the same polarity, illustrating that knowledge polarity is an important feature in predicting entailment. We also perform classification change analysis across different knowledge variations to illustrate the importance of selecting appropriate knowledge input regarding content and polarity, and show representative examples of these changes.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810",
            "3b1d8eb163ffff598c2faa0d9d7cf933857a359f",
            "3af5a41e43158a75bf7a8bb3f9517edc4163b3ca",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "681fbcd98acf20df3355eff3585994bd1f9008b7",
            "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac",
            "5744f56d3253bd7c4341d36de40a93fceaa266b3"
        ],
        "related_topics": [
            "Enhanced Language Representation With Informative Entity",
            "Enhanced Representation Through Knowledge",
            "Polarity",
            "Natural Language Inference",
            "Bidirectional Encoder Representations From Transformers",
            "Multi-Genre Natural Language Inference",
            "Entailment",
            "Information Fusion Layer"
        ],
        "reference_count": "43",
        "citation_count": "7"
    },
    {
        "Id": "a26623d52d24e03044a158cddad931ec5ab7304c",
        "title": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
        "authors": [
            "Linmei Hu",
            "Zeyi Liu",
            "Ziwang Zhao",
            "Lei Hou",
            "Liqiang Nie",
            "Juanzi Li"
        ],
        "date": "11 November 2022",
        "abstract": "A comprehensive review of Knowledge Enhanced Pre-trained Language Models (KE-PLMs) is presented to provide a clear insight into this thriving field and introduces appropriate taxonomies respectively for Natural Language Understanding (NLU) and Natural Language Generation (NLG) to highlight these two main tasks of NLP. Pre-trained Language Models (PLMs) which are trained on large text corpus via self-supervised learning method, have yielded promising performance on various tasks in Natural Language Processing (NLP). However, though PLMs with huge parameters can effectively possess rich knowledge learned from massive training text and benefit downstream tasks at the fine-tuning stage, they still have some limitations such as poor reasoning ability due to the lack of external knowledge. Research has been dedicated to incorporating knowledge into PLMs to tackle these issues. In this paper, we present a comprehensive review of Knowledge Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear insight into this thriving field. We introduce appropriate taxonomies respectively for Natural Language Understanding (NLU) and Natural Language Generation (NLG) to highlight these two main tasks of NLP. For NLU, we divide the types of knowledge into four categories: linguistic knowledge, text knowledge, knowledge graph (KG), and rule knowledge. The KE-PLMs for NLG are categorized into KG-based and retrieval-based methods. Finally, we point out some promising future directions of KE-PLMs.",
        "references": [
            "97f456643712e9618edd7465676c62af3c8ae690",
            "290867638c5ca520de5c48aa4336f196d426c226",
            "17dcfef70619c0423e0527f0c9d90f4858125f5f",
            "1833ad08d52a454a50490fed91181fc7e2cc397a",
            "319b84be7a843250bc81d7086f79a4126d550277",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "2fab75cfd8394de70bca365572bc5bb04a1b1eb5"
        ],
        "related_topics": [
            "Natural Language Processing",
            "Natural Language Understanding",
            "Natural Language Generation",
            "Pre-trained Language Models",
            "KE-PLM",
            "Reasoning Ability",
            "Retrieval Based Methods",
            "Linguistic Knowledge",
            "Self-Supervised Learning",
            "Parameters"
        ],
        "reference_count": "110",
        "citation_count": "24"
    },
    {
        "Id": "3eb419ca9b1760222178605787057561685791c7",
        "title": "LM-CORE: Language Models with Contextually Relevant External Knowledge",
        "authors": [
            "Jivat Neet Kaur",
            "Sumit Kaur Bhatia",
            "Milan Aggarwal",
            "Rachit Bansal",
            "Balaji Krishnamurthy"
        ],
        "date": "12 August 2022",
        "abstract": "Experimental results show that LM-CORE, having access to external knowledge, achieves significant and robust outperformance over state-of-the-art knowledge-enhanced language models on knowledge probing tasks; can effectively handle knowledge updates; and performs well on two downstream tasks. Large transformer-based pre-trained language models have achieved impressive performance on a variety of knowledge-intensive tasks and can capture factual knowledge in their parameters. We argue that storing large amounts of knowledge in the model parameters is sub-optimal given the ever-growing amounts of knowledge and resource requirements. We posit that a more efficient alternative is to provide explicit access to contextually relevant structured knowledge to the model and train it to use that knowledge. We present LM-CORE -- a general framework to achieve this -- that allows \\textit{decoupling} of the language model training from the external knowledge source and allows the latter to be updated without affecting the already trained model. Experimental results show that LM-CORE, having access to external knowledge, achieves significant and robust outperformance over state-of-the-art knowledge-enhanced language models on knowledge probing tasks; can effectively handle knowledge updates; and performs well on two downstream tasks. We also present a thorough error analysis highlighting the successes and failures of LM-CORE.",
        "references": [
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "7eda139d737eea10fc1d95364327a41ec0cee4a4",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "06a73ad09664435f8b3cd90293f4e05a047cf375",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "4f03e69963b9649950ba29ae864a0de8c14f1f86",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810"
        ],
        "related_topics": [
            "Language Models",
            "Knowledge Intensive Tasks",
            "External Knowledge Sources",
            "Parameters",
            "Factual Knowledge"
        ],
        "reference_count": "40",
        "citation_count": "10"
    },
    {
        "Id": "beb91a773677872fc21f08722bdcc737bf5917b5",
        "title": "Syntax-Infused Transformer and BERT models for Machine Translation and Natural Language Understanding",
        "authors": [
            "Dhanasekar Sundararaman",
            "Vivek Subramanian",
            "Guoyin Wang",
            "Shijing Si",
            "Dinghan Shen",
            "Dong Wang",
            "Lawrence Carin"
        ],
        "date": "10 November 2019",
        "abstract": "This work shows that the syntax-infused Transformer with multiple features achieves an improvement of 0.7 BLEU when trained on the full WMT 14 English to German translation dataset, and finds that the incorporation of syntax into BERT fine-tuning outperforms baseline on a number of downstream tasks from the GLUE benchmark. Attention-based models have shown significant improvement over traditional algorithms in several NLP tasks. The Transformer, for instance, is an illustrative example that generates abstract representations of tokens inputted to an encoder based on their relationships to all tokens in a sequence. Recent studies have shown that although such models are capable of learning syntactic features purely by seeing examples, explicitly feeding this information to deep learning models can significantly enhance their performance. Leveraging syntactic information like part of speech (POS) may be particularly beneficial in limited training data settings for complex models such as the Transformer. We show that the syntax-infused Transformer with multiple features achieves an improvement of 0.7 BLEU when trained on the full WMT 14 English to German translation dataset and a maximum improvement of 1.99 BLEU points when trained on a fraction of the dataset. In addition, we find that the incorporation of syntax into BERT fine-tuning outperforms baseline on a number of downstream tasks from the GLUE benchmark.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "2f9700e197e5bdfd6fffa9dc1badd25f224739fe",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "46d0aa6b357c5427f46c7f8ff7053617c4309649",
            "2784000e1a3554374662f4d18cb5ad52f59c8de6",
            "ebb222fff7b71b82d1a5971e198982858abcd03d",
            "3aa52436575cf6768a0a1a476601825f6a62e58f",
            "93499a7c7f699b6630a86fad964536f9423bb6d0",
            "3abc5ffb1757ec3f35cb7b4100410570b0b51e09"
        ],
        "related_topics": [
            "Tokens",
            "Transformer",
            "Bleu",
            "Bilingual Evaluation Understudy",
            "Machine Translation",
            "WMT 14",
            "Part-of-speech",
            "BERT Model",
            "Natural Language Understanding",
            "GLUE Benchmark"
        ],
        "reference_count": "19",
        "citation_count": "38"
    },
    {
        "Id": "224060b48c1576e34ba9a7ca28424cadd9d27318",
        "title": "Extending Answer Prediction for Deep Bi-directional Transformers",
        "authors": [
            "Peter Dun"
        ],
        "date": "2019",
        "abstract": "The best-performing model, the Dynamic Decoder, uses pre-trained BERT encodings and improves F1 from the baseline BiDAF on the test set from 59.920% to 75.035% and the EM score from 56.298% to 71.784%. The current state-of-the-art technique used to tackle the Stanford Question Answering Dataset (SQuAD) makes use of Bidirectional Encoder Representations from Transformers, or BERT. After pre-training a deep bidirectional representation conditioned on both the left and right contexts, BERT can be simply \ufb01ne-tuned for the SQuAD task with a linear layer that outputs the predicted answer span. We investigate alternative ways to interpret and process BERT encoding outputs, including Pointer-Net, Dynamic Pointing Decoder, and Dynamic Chunk Reader. The best-performing model, the Dynamic Decoder, uses pre-trained BERT encodings and improves F1 from the baseline BiDAF on the test set from 59.920% to 75.035% and the EM score from 56.298% to 71.784%.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "e978d832a4d86571e1b52aa1685dc32ccb250f50",
            "3a7b63b50c64f4ec3358477790e84cbd6be2a0b4",
            "4d1c856275744c0284312a3a50efb6ca9dc4cd4c",
            "a8c33413a626bafc67d46029ed28c2a28cc08899"
        ],
        "related_topics": [],
        "reference_count": "5",
        "citation_count": "3"
    },
    {
        "Id": "c79a8fd667f59e6f1ca9d54afc34f792e9079c7e",
        "title": "TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding",
        "authors": [
            "Zhiheng Huang",
            "Peng Xu",
            "Davis Liang",
            "Ajay K. Mishra",
            "Bing Xiang"
        ],
        "date": "16 March 2020",
        "abstract": "It is shown that TRANS-BLSTM models consistently lead to improvements in accuracy compared to BERT baselines in GLUE and SQuAD 1.1 experiments, and is proposed as a joint modeling framework for transformer and BLSTM. Bidirectional Encoder Representations from Transformers (BERT) has recently achieved state-of-the-art performance on a broad range of NLP tasks including sentence classification, machine translation, and question answering. The BERT model architecture is derived primarily from the transformer. Prior to the transformer era, bidirectional Long Short-Term Memory (BLSTM) has been the dominant modeling architecture for neural machine translation and question answering. In this paper, we investigate how these two modeling techniques can be combined to create a more powerful model architecture. We propose a new architecture denoted as Transformer with BLSTM (TRANS-BLSTM) which has a BLSTM layer integrated to each transformer block, leading to a joint modeling framework for transformer and BLSTM. We show that TRANS-BLSTM models consistently lead to improvements in accuracy compared to BERT baselines in GLUE and SQuAD 1.1 experiments. Our TRANS-BLSTM model obtains an F1 score of 94.01% on the SQuAD 1.1 development dataset, which is comparable to the state-of-the-art result.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "c6850869aa5e78a107c378d2e8bfa39633158c0c",
            "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "af88ce6116c2cd2927a4198745e99e5465173783"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Transformer",
            "Question Answering",
            "Machine Translation",
            "SQuAD 1.1",
            "Neural Machine Translation",
            "Long Short-Term Memory",
            "General Language Understanding Evaluation",
            "Language Understanding",
            "Bidirectional LSTM"
        ],
        "reference_count": "29",
        "citation_count": "20"
    },
    {
        "Id": "6c8503803760c5c7790f72437d0f8b874334e6f0",
        "title": "Span Selection Pre-training for Question Answering",
        "authors": [
            "Michael R. Glass",
            "A. Gliozzo",
            "Rishav Chakravarti",
            "Anthony Ferritto",
            "Lin Pan",
            "G P Shrivatsa Bhargav",
            "Dinesh Garg",
            "Avirup Sil"
        ],
        "date": "9 September 2019",
        "abstract": "This paper introduces a new pre-training task inspired by reading comprehension to better align the pre- training from memorization to understanding, and shows that the proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pretrained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension to better align the pre-training from memorization to understanding. Span Selection PreTraining (SSPT) poses cloze-like training instances, but rather than draw the answer from the model\u2019s parameters, it is selected from a relevant passage. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple Machine Reading Comprehension (MRC) datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also show significant impact in HotpotQA, improving answer prediction F1 by 4 points and supporting fact prediction F1 by 1 point and outperforming the previous best system. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.",
        "references": [
            "17dbd7b72029181327732e4d11b52a08ed4630d0",
            "9405cc0d6169988371b2755e573cc28650d14dfe",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "7650d705b85dc399112a5b6a79e9c6f81c7c6146",
            "47ced790a563344efae66588b5fb7fe6cca29ed3",
            "d2071c1e4a6030dc0005dbfeefdd196a8b293e84",
            "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef",
            "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "81f5810fbbab9b7203b9556f4ce3c741875407bc"
        ],
        "related_topics": [
            "SSPT",
            "Bidirectional Encoder Representations From Transformers",
            "Machine Reading Comprehension",
            "Maximum-ratio Combining",
            "Self-organizing Tree Algorithm",
            "Masked Language Model",
            "Transformer",
            "Question Answering",
            "HotpotQA",
            "Language Understanding"
        ],
        "reference_count": "28",
        "citation_count": "54"
    },
    {
        "Id": "de10005b1355734ceaad86e17a1d88c40bf4507f",
        "title": "ReBERT-An Enhanced BERT",
        "authors": [
            "Priyanka Shee",
            "Santayo Kundu",
            "Anirban Bhar",
            "Moumita Ghosh",
            "B. Tech"
        ],
        "date": "",
        "abstract": "This article shows that BERT can be a competitive lexical normalization model without the need of any UGC resources aside from 3,000 training sentences, and adapt and analyze the ability of this model to handle noisy UGC data. - BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based language model that comprehends the context of words by considering surrounding words in both directions. It revolutionized natural language processing by capturing rich contextual information, enhancing performance in various language understanding tasks like sentiment analysis, text classification. In this article, focusing on User Generated Content (UGC) in a resource-scarce scenario, we study the ability of BERT (Devlinet al., 2018) to perform lexical normalization. by enhancing its architecture and by carefully finetuning it, we show that BERT can be a competitive lexical normalization model without the need of any UGC resources aside from 3,000 training sentences. The enhanced BERT model features a hierarchical contextualization module for improved long-range dependency understanding, a domain-specific adaptation layer for specialized language contexts, and efficiency optimization through dynamic attention head pruning and weight sharing. Fine-tuned pre-training broadens language comprehension, while task-specific heads enable fine-tuning. Rigorous evaluation and iterative refinement ensure performance enhancement across tasks, addressing limitations and advancing language understanding. It will be our first work done in adapting and analyzing the ability of this model to handle noisy UGC data.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "eedadc970a4419f617a5c14c588ea9447643c380",
            "bb02e08e6212757416fc179d9c25b9c44d171610",
            "1741c93e4270019e368a3b93eee21174f6f34974",
            "455a8838cde44f288d456d01c76ede95b56dc675",
            "8d662ab209ae6624fbab7c7015c57d335060048f",
            "0c7e77f04c321fbb871e166fe2f2fecb7533d653",
            "c069c8bd3683fe271c74475fed0b91e6235729ac",
            "753e30826f1908a62a8d251fc6b1b598f86d2bb2"
        ],
        "related_topics": [],
        "reference_count": "0",
        "citation_count": "13"
    },
    {
        "Id": "bb2afd8172469fef7276e9789b306e085ed6e650",
        "title": "Real-time Inference in Multi-sentence Tasks with Deep Pretrained Transformers",
        "authors": [
            "Samuel Humeau",
            "Kurt Shuster",
            "Marie-Anne Lachaux",
            "Jason Weston"
        ],
        "date": "22 April 2019",
        "abstract": "A new architecture, the Poly-encoder, is developed that is designed to approach the performance of the Cross-encoders while maintaining reasonable computation time and achieves state-of-the-art results on both dialogue tasks. The use of deep pretrained bidirectional transformers has led to remarkable progress in learning multi-sentence representations for downstream language understanding tasks (Devlin et al., 2018). For tasks that make pairwise comparisons, e.g. matching a given context with a corresponding response, two approaches have permeated the literature. A Cross-encoder performs full self-attention over the pair; a Bi-encoder performs self-attention for each sequence separately, and the final representation is a function of the pair. While Cross-encoders nearly always outperform Bi-encoders on various tasks, both in our work and others' (Urbanek et al., 2019), they are orders of magnitude slower, which hampers their ability to perform real-time inference. In this work, we develop a new architecture, the Poly-encoder, that is designed to approach the performance of the Cross-encoder while maintaining reasonable computation time. Additionally, we explore two pretraining schemes with different datasets to determine how these affect the performance on our chosen dialogue tasks: ConvAI2 and DSTC7 Track 1. We show that our models achieve state-of-the-art results on both tasks; that the Poly-encoder is a suitable replacement for Bi-encoders and Cross-encoders; and that even better results can be obtained by pretraining on a large dialogue dataset.",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "f239a2bbe29637e3e8131293a237d55071c8002c",
            "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "e81b50f68265b84d55d03dab3c296b9fd4516857",
            "97ebfbdbbd6fe2fff6140d56bce912e9dcb1f973",
            "dde89e64a7f375b90e1cc594142940f4161e1592",
            "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
            "9ae17b09c59f06f02ef824b856a440de663471d0",
            "b48ed494e4c6a1d73b499ae9e8d734c86746646c",
            "227458886343b86bd15adf58c769be326b4b058a"
        ],
        "related_topics": [
            "Cross-encoders",
            "Bi-encoders",
            "Poly-encoder",
            "State-of-the-art Results",
            "Pretraining Schemes",
            "Dialogue Task",
            "ConvAI2",
            "Self-attention"
        ],
        "reference_count": "28",
        "citation_count": "41"
    },
    {
        "Id": "2c4cd2b456ab8e4f1e6195f5eb6954eb084060ec",
        "title": "Utilizing Bidirectional Encoder Representations from Transformers for Answer Selection",
        "authors": [
            "Md Tahmid Rahman Laskar",
            "Enamul Hoque",
            "J. Huang"
        ],
        "date": "14 November 2020",
        "abstract": "This paper adopts the pre-trained Bidirectional Encoder Representations from Transformer (BERT) language model and fine-tuning the BERT model for the answer selection task is very effective and observes a maximum improvement in the QA and CQA datasets compared to the previous state-of-the-art models. Pre-training a transformer-based model for the language modeling task in a large dataset and then fine-tuning it for downstream tasks has been found very useful in recent years. One major advantage of such pre-trained language models is that they can effectively absorb the context of each word in a sentence. However, for tasks such as the answer selection task, the pre-trained language models have not been extensively used yet. To investigate their effectiveness in such tasks, in this paper, we adopt the pre-trained Bidirectional Encoder Representations from Transformer (BERT) language model and fine-tune it on two Question Answering (QA) datasets and three Community Question Answering (CQA) datasets for the answer selection task. We find that fine-tuning the BERT model for the answer selection task is very effective and observe a maximum improvement of 13.1% in the QA datasets and 18.7% in the CQA datasets compared to the previous state-of-the-art.",
        "references": [
            "28307bc149a74cfcae657f782f1c7630b6f4acce",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "336ce21be76879f19c01b68726558269907ea02b",
            "bc34eee11d8ddba18a262a637ea336322c93ba6c",
            "fd26f8069cfa528463fdf8a90864587e997ee86d",
            "1fa9ed2bea208511ae698a967875e943049f16b6",
            "ceb763e36fbd189b1034204a960195e7e134e703",
            "c58738fade559d02a71bedba51bc62d42587777c",
            "edafa08d896f073f49ed9302a2b843b488143c23"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Answer Selection Task",
            "Community Question Answering",
            "Fine-tuning",
            "Answer Selection",
            "Transformer",
            "Question Answering",
            "Language Modeling",
            "Sentences"
        ],
        "reference_count": "39",
        "citation_count": "12"
    },
    {
        "Id": "8617b501fedf65efaf82c3f911fe490407ba3650",
        "title": "BERT for Question Answering on SQuAD 2 . 0",
        "authors": [
            "Yuwen Zhang"
        ],
        "date": "2019",
        "abstract": "This project picked up BERT model and tried to fine-tune it with additional task-specific layers to improve its performance on Stanford Question Answering Dataset (SQuAD 2.0). Machine reading comprehension and question answering is an essential task in natural language processing. Recently, Pre-trained Contextual Embeddings (PCE) models like Embeddings from Language Models (ELMo) [1] and Bidirectional Encoder Representations from Transformers (BERT) [2] have attracted lots of attention due to their great performance in a wide range of NLP tasks. In this project, we picked up BERT model and tried to fine-tune it with additional task-specific layers to improve its performance on Stanford Question Answering Dataset (SQuAD 2.0). We designed several output architectures and compared their performance to BERT baseline model in great details. So far, our best-proposed single model built an LSTM Encoder, an LSTM decoder and a highway network on top of the BERT base uncased model and achieved an F1 score of 77.96 on the dev set. By applying ensemble technique with selected models, our final version model currently ranks 12th on the Stanford CS224N SQuAD 2.0 test leaderboard with an F1 score 77.827 (name: Pisces_BERT).",
        "references": [
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "8c1b00128e74f1cd92aede3959690615695d5101",
            "05dd7254b632376973f3a1b4d39485da17814df5",
            "3a7b63b50c64f4ec3358477790e84cbd6be2a0b4",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "13fe71da009484f240c46f14d9330e932f8de210",
            "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "deb0d1d658104642598c3b268765dfa119de27dd"
        ],
        "related_topics": [],
        "reference_count": "10",
        "citation_count": "14"
    },
    {
        "Id": "0cbf97173391b0430140117027edcaf1a37968c7",
        "title": "TinyBERT: Distilling BERT for Natural Language Understanding",
        "authors": [
            "Xiaoqi Jiao",
            "Yichun Yin",
            "Lifeng Shang",
            "Xin Jiang",
            "Xiao Chen",
            "Linlin Li",
            "Fang Wang",
            "Qun Liu"
        ],
        "date": "23 September 2019",
        "abstract": "A novel Transformer distillation method that is specially designed for knowledge distillation (KD) of the Transformer-based models is proposed and, by leveraging this new KD method, the plenty of knowledge encoded in a large \u201cteacher\u201d BERT can be effectively transferred to a small \u201cstudent\u201d TinyBERT. Language model pre-training, such as BERT, has significantly improved the performances of many natural language processing tasks. However, pre-trained language models are usually computationally expensive, so it is difficult to efficiently execute them on resource-restricted devices. To accelerate inference and reduce model size while maintaining accuracy, we first propose a novel Transformer distillation method that is specially designed for knowledge distillation (KD) of the Transformer-based models. By leveraging this new KD method, the plenty of knowledge encoded in a large \u201cteacher\u201d BERT can be effectively transferred to a small \u201cstudent\u201d TinyBERT. Then, we introduce a new two-stage learning framework for TinyBERT, which performs Transformer distillation at both the pre-training and task-specific learning stages. This framework ensures that TinyBERT can capture the general-domain as well as the task-specific knowledge in BERT. TinyBERT4 with 4 layers is empirically effective and achieves more than 96.8% the performance of its teacher BERT-Base on GLUE benchmark, while being 7.5x smaller and 9.4x faster on inference. TinyBERT4 is also significantly better than 4-layer state-of-the-art baselines on BERT distillation, with only ~28% parameters and ~31% inference time of them. Moreover, TinyBERT6 with 6 layers performs on-par with its teacher BERT-Base.",
        "references": [
            "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "57a10537978600fd33dcdd48922c791609a4851a",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "48fdf50da3d2bbd3b85ea9d17bbf3d173f6164ea",
            "95a251513853c6032bdecebd4b74e15795662986"
        ],
        "related_topics": [
            "TinyBERT",
            "Transformer Distillation",
            "Task-specific Distillation",
            "Prediction-layer Distillation",
            "General Distillation",
            "Question Natural Language Inference",
            "Tiny-BERTs",
            "BERT-of-Theseus",
            "Intermediate Layer Distillation",
            "BERT BASE"
        ],
        "reference_count": "57",
        "citation_count": "1,323"
    },
    {
        "Id": "eeaf05f6f3a8dbd14cc318736d6ec833f8ef3f60",
        "title": "Knowledge Graph Fusion for Language Model Fine-Tuning",
        "authors": [
            "Nimesh Bhana",
            "Terence L van Zyl"
        ],
        "date": "21 June 2022",
        "abstract": "This work investigates the benefits of knowledge incorporation into the fine-tuning stages of BERT and shows evidence that, given the appropriate task, modest injection with relevant, high-quality knowledge is most performant. Language Models such as BERT (Bidirectional Encoder Representations from Transformers) have grown in popularity due to their ability to be pre-trained and perform robustly on a wide range of Natural Language Processing tasks. Often seen as an evolution over traditional word embedding techniques, they can produce semantic representations of text, useful for tasks such as semantic similarity. However, state-of-the-art models often have high computational requirements and lack global context or domain knowledge which is required for complete language understanding. To address these limitations, we investigate the benefits of knowledge incorporation into the fine-tuning stages of BERT. An existing K-BERT model, which enriches sentences with triplets from a Knowledge Graph, is adapted for the English language and extended to inject contextually relevant information into sentences. As a side-effect, changes made to K-BERT for accommodating the English language also extend to other word-based languages. Experiments conducted indicate that injected knowledge introduces noise. We see statistically significant improvements for knowledge-driven tasks when this noise is minimised. We show evidence that, given the appropriate task, modest injection with relevant, high-quality knowledge is most performant.",
        "references": [
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "06a73ad09664435f8b3cd90293f4e05a047cf375",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "a022bda79947d1f656a1164003c1b3ae9a843df9",
            "5075a0df5fc7ad5f1399450498044627ebe7a9f9",
            "7c1a11fcc0d4aa8d7fcfcfa8e375f31f8f23c77a",
            "5124ed6b9e84046ab4e785adb431ecf5d5bf8a41",
            "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096",
            "8a58b7896edaca4860b45401460b0462b228352c"
        ],
        "related_topics": [
            "Bidirectional Encoder Representations From Transformers",
            "Language Models",
            "K-BERT",
            "Natural Language Processing",
            "Language Understanding",
            "Knowledge-driven Tasks",
            "Fine-tuning",
            "Global Context",
            "State-of-the-art Models",
            "Pre-trained"
        ],
        "reference_count": "0",
        "citation_count": "34"
    },
    {
        "Id": "450c65dce00b05bdf5d58e48289acd066aca8383",
        "title": "Exploring Large Language Models for Knowledge Graph Completion",
        "authors": [
            "Liang Yao",
            "Jiazhen Peng",
            "Chengsheng Mao",
            "Yuan Luo"
        ],
        "date": "26 August 2023",
        "abstract": "This study considers triples in knowledge graphs as text sequences and introduces an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples, which attains state-of-the-art performance in tasks such as triple classification and relation prediction. Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.",
        "references": [
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "35631fd55c2545615811fa8072015356ac8198e7",
            "6d40db49cec2a543e01a4ef651f053ae935274fc",
            "6602100baa3399b5d3a390d6281a7caadb626ea6",
            "cab46caf83a9e0390c6ca4d8603187969c9a53ad",
            "86ac98157da100a529ca65fe6e1da064b0a651e8",
            "ea5907c9b0742baa2593d3abf99b7d0084a902a9",
            "2b4f212522b1744fcfdad2d591abda2db66db7d8",
            "5401296cb8594a0e0c7a90387b5738e63b86d903",
            "845b4941d8c016aa5f8967da2f86d38ef6c18fa3"
        ],
        "related_topics": [
            "Large Language Models",
            "Knowledge Graph",
            "Triples",
            "Artificial Intelligence",
            "Triple Classification",
            "Text Sequence",
            "Fine-tuning",
            "Relation Descriptions",
            "Knowledge Graph Completion",
            "GPT-4"
        ],
        "reference_count": "41",
        "citation_count": "3"
    },
    {
        "Id": "f684e44c7c8daeb0b2311635d710a399433980ad",
        "title": "Knowledge-Infused Pre-trained Models for KG Completion",
        "authors": [
            "Han Yu",
            "Rong Jiang",
            "Bin Zhou",
            "Aiping Li"
        ],
        "date": "20 October 2020",
        "abstract": "This paper introduces a novel method for KG completion task by knowledge-infused pre-trained language models which can capture both linguistic information and factual knowledge to compute the plausible of the triples. Knowledge graphs (KG) are the basis for many artificial intelligence applications but still suffer from incompleteness. In this paper, we introduce a novel method for KG completion task by knowledge-infused pre-trained language models. We represent each triple in the KG as textual sequences and transform the KG completion task into a sentence classification task that fits the input of the language model. Our KG completion framework based on the knowledge-infused pre-trained language model which can capture both linguistic information and factual knowledge to compute the plausible of the triples. Experiments show that our method achieves better results than previous state-of-the-art on multiple benchmark datasets.",
        "references": [
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "4f03e69963b9649950ba29ae864a0de8c14f1f86",
            "50d53cc562225549457cbc782546bfbe1ac6f0cf",
            "aa1b05e8449eb5ee93b114453d9c946ae00459b1",
            "e379f7c85441df5d8ddc1565cabf4b4290c22f1f",
            "cd8a9914d50b0ac63315872530274d158d6aff09",
            "86ac98157da100a529ca65fe6e1da064b0a651e8",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "3ce14b7a3c1b89c717eba10229d9d80d80bd0e04"
        ],
        "related_topics": [
            "Artificial Intelligence",
            "KG Completion",
            "Knowledge Graph",
            "Benchmark Dataset",
            "Factual Knowledge"
        ],
        "reference_count": "42",
        "citation_count": "One"
    },
    {
        "Id": "e336712fb929213abcce5a90b1e1c771d5bef2fc",
        "title": "Knowledge Graph Refinement based on Triplet BERT-Networks",
        "authors": [
            "Armita Khajeh Nassiri",
            "Nathalie Pernelle",
            "Fatiha Sa{\\&quot;i}s",
            "Gianluca Quercini"
        ],
        "date": "18 November 2022",
        "abstract": "The proposed GilBERT method is evaluated on triplet classification and relation prediction tasks on multiple well-known benchmark knowledge graphs such as FB13, WN11, and FB15K and achieves better or comparable results to the state-of-the-art performance on these two refinement tasks. Knowledge graph embedding techniques are widely used for knowledge graph refinement tasks such as graph completion and triple classification. These techniques aim at embedding the entities and relations of a Knowledge Graph (KG) in a low dimensional continuous feature space. This paper adopts a transformer-based triplet network creating an embedding space that clusters the information about an entity or relation in the KG. It creates textual sequences from facts and fine-tunes a triplet network of pre-trained transformer-based language models. It adheres to an evaluation paradigm that relies on an efficient spatial semantic search technique. We show that this evaluation protocol is more adapted to a few-shot setting for the relation prediction task. Our proposed GilBERT method is evaluated on triplet classification and relation prediction tasks on multiple well-known benchmark knowledge graphs such as FB13, WN11, and FB15K. We show that GilBERT achieves better or comparable results to the state-of-the-art performance on these two refinement tasks.",
        "references": [
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "96acb1c882ad655c6b8459c2cd331803801446ca",
            "cab46caf83a9e0390c6ca4d8603187969c9a53ad",
            "17a1e5d78bffb17979ac55aa792698727fe25a21",
            "ef9537e4f719c24022ad46378613df2bc12ef8c3",
            "e3274206b36a603abc4a335af91273ecba5e73cc",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "aa1b05e8449eb5ee93b114453d9c946ae00459b1",
            "8f096071a09701012c9c279aee2a88143a295935",
            "845b4941d8c016aa5f8967da2f86d38ef6c18fa3"
        ],
        "related_topics": [
            "Knowledge Graph",
            "Few-shot Setting",
            "Embedding Space",
            "Triple Classification",
            "Knowledge Graph Refinement",
            "Entities",
            "WN11",
            "FB15k",
            "FB13",
            "Triplet Network"
        ],
        "reference_count": "0",
        "citation_count": "20"
    },
    {
        "Id": "b1e6aa78db5478be5eaa47697382241c2b7aab1f",
        "title": "Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models",
        "authors": [
            "Bosung Kim",
            "Taesuk Hong",
            "Youngjoong Ko",
            "Jungyun Seo"
        ],
        "date": "1 December 2020",
        "abstract": "An effective multi-task learning method is proposed that can learn more relational properties in KGs and properly perform even when lexical similarity occurs and achieve the state-of-the-art performances in Mean Rank and Hits@10 on the WN18RR dataset. As research on utilizing human knowledge in natural language processing has attracted considerable attention in recent years, knowledge graph (KG) completion has come into the spotlight. Recently, a new knowledge graph completion method using a pre-trained language model, such as KG-BERT, is presented and showed high performance. However, its scores in ranking metrics such as Hits@k are still behind state-of-the-art models. We claim that there are two main reasons: 1) failure in sufficiently learning relational information in knowledge graphs, and 2) difficulty in picking out the correct answer from lexically similar candidates. In this paper, we propose an effective multi-task learning method to overcome the limitations of previous works. By combining relation prediction and relevance ranking tasks with our target link prediction, the proposed model can learn more relational properties in KGs and properly perform even when lexical similarity occurs. Experimental results show that we not only largely improve the ranking performances compared to KG-BERT but also achieve the state-of-the-art performances in Mean Rank and Hits@10 on the WN18RR dataset.",
        "references": [
            "06a73ad09664435f8b3cd90293f4e05a047cf375",
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "7572aefcd241ec76341addcb2e2e417587cb2e4c",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "96acb1c882ad655c6b8459c2cd331803801446ca",
            "86412306b777ee35aba71d4795b02915cb8a04c3",
            "8f096071a09701012c9c279aee2a88143a295935",
            "bfeb827d06c1a3583b5cc6d25241203a81f6af09",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248"
        ],
        "related_topics": [
            "KG-BERT",
            "Knowledge Graph",
            "Mean Ranks",
            "Natural Language Processing",
            "HITS@k",
            "Hits@10",
            "State-of-the-art Models",
            "Knowledge Graph Completion",
            "WN18RR Datasets",
            "Multi-Task Learning"
        ],
        "reference_count": "22",
        "citation_count": "61"
    },
    {
        "Id": "03d9b59c84d648007d05fe8d50cdb20e0349b333",
        "title": "From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer",
        "authors": [
            "Xin Xie",
            "Ningyu Zhang",
            "Zhoubo Li",
            "Shumin Deng",
            "Hui Chen",
            "Feiyu Xiong",
            "Mosha Chen",
            "Huajun Chen"
        ],
        "date": "4 February 2022",
        "abstract": "This paper provides an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model and introduces relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset OpenBG500 for research purpose1.",
        "references": [
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "7e928ef936c2815d7522c5176163d6ab7309a8b7",
            "6071b89c257d36490fd6f0877174adabad265d92",
            "10be7d45b3736cb9eac13a0c07d00c7f8e4f84b4",
            "7e40a61b8faa5f71d5df67c0d0ece4bf6f62ce11",
            "df4d715898e04038a3a367b977fe82e479dcb291",
            "0e31660210a4f683fe22acd5bc53f737d765f1f3"
        ],
        "related_topics": [
            "GenKGC",
            "Knowledge Graph Completion",
            "Missing Triples",
            "Generative Transformers",
            "Discrimination",
            "Inference Speeds",
            "Representation Learning"
        ],
        "reference_count": "21",
        "citation_count": "38"
    },
    {
        "Id": "e35ed36c73b7ccf3462cd5c0c5d9c9b266c19712",
        "title": "Deep Learning For Knowledge Graph Completion With XLNET",
        "authors": [
            "Mengmeng Su",
            "Hongyi Su",
            "Hong Zheng",
            "Bo Yan"
        ],
        "date": "23 July 2021",
        "abstract": "A novel method based on the pre-trained model XLNET and the classification model to verify whether the triples of Knowledge Graph are valid or not is proposed, which takes description of entities or relations as the input sentence text for fine-tuning. Knowledge Graph is a graph knowledge base composed of fact entities and relations. Recently, the adoption of Knowledge Graph in Natural Language Processing tasks has proved the efficiency and convenience of KG. Therefore, the plausibility of Knowledge Graph become an import subject, which is also named as KG Completion or Link Prediction. The plausibility of Knowledge Graph reflects in the validness of triples which is structured representation of the entities and relations of Knowledge Graph. Some research work has devoted to KG Completion tasks. The typical methods include semantic matching models like TransE or TransH and Pre-trained models like KG-BERT. In this article, we propose a novel method based on the pre-trained model XLNET and the classification model to verify whether the triples of Knowledge Graph are valid or not. This method takes description of entities or relations as the input sentence text for fine-tuning. Meanwhile contextualized representations with rich semantic information can be obtained by XLNET, avoiding limitations and shortcomings of other typical neural network models. Then these representations are fed into a classifier for classification. Experimental results show that there is an improvement in KG Completion Tasks that the proposed method has achieved.",
        "references": [
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "30321b036607a7936221235ea8ec7cf7c1627100",
            "50d53cc562225549457cbc782546bfbe1ac6f0cf",
            "76610c8292bc987b9225c02e8667d77c86ee567c",
            "86412306b777ee35aba71d4795b02915cb8a04c3",
            "2a3f862199883ceff5e3c74126f0c80770653e05",
            "5740f80fb61c4489674c9a0beb40c4f5e0ed19ff",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "913f54b44dfb9202955fe296cf5586e1105565ea"
        ],
        "related_topics": [
            "Knowledge Graph",
            "XLNet",
            "KG Completion",
            "Triples",
            "Natural Language Processing",
            "Fine-tuning",
            "Deep Learning",
            "KG-BERT",
            "Semantic Matching Models",
            "Knowledge Graph Completion"
        ],
        "reference_count": "33",
        "citation_count": "3"
    },
    {
        "Id": "4fb212603fd1b428b0fd3444ae031cb60dfe2fc2",
        "title": "PPKE: Knowledge Representation Learning by Path-based Pre-training",
        "authors": [
            "Bin He",
            "Di Zhou",
            "Jing Xie",
            "Jinghui Xiao",
            "Xin Jiang",
            "Qun Liu"
        ],
        "date": "7 December 2020",
        "abstract": "A Path-based Pre-training model to learn Knowledge Embeddings, called PPKE, which aims to integrate more graph contextual information between entities into the KRL model, and achieves state-of-the-art results on several benchmark datasets for link prediction and relation prediction tasks. Entities may have complex interactions in a knowledge graph (KG), such as multi-step relationships, which can be viewed as graph contextual information of the entities. Traditional knowledge representation learning (KRL) methods usually treat a single triple as a training unit, and neglect most of the graph contextual information exists in the topological structure of KGs. In this study, we propose a Path-based Pre-training model to learn Knowledge Embeddings, called PPKE, which aims to integrate more graph contextual information between entities into the KRL model. Experiments demonstrate that our model achieves state-of-the-art results on several benchmark datasets for link prediction and relation prediction tasks, indicating that our model provides a feasible way to take advantage of graph contextual information in KGs.",
        "references": [
            "aa1b05e8449eb5ee93b114453d9c946ae00459b1",
            "fddd3dab90c243ab7fc038bc6449ef62c0e06037",
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "2e925a02db26a60ee1cc022f3923e09f3fae7b39",
            "cd8a9914d50b0ac63315872530274d158d6aff09",
            "e3274206b36a603abc4a335af91273ecba5e73cc",
            "8f096071a09701012c9c279aee2a88143a295935",
            "2582ab7c70c9e7fcb84545944eba8f3a7f253248",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "1fb3fa2a6a8c0d7a58b1d5dee8b676104d1a5da6"
        ],
        "related_topics": [
            "Entities",
            "Knowledge Graph",
            "Knowledge Representation Learning",
            "Link Prediction",
            "State-of-the-art Results",
            "Topological Structure",
            "Feasible",
            "Benchmark Dataset",
            "Knowledge Embedding"
        ],
        "reference_count": "24",
        "citation_count": "One"
    },
    {
        "Id": "938d2951ba3aa26f3752d489c3c044ae67d5e809",
        "title": "Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion",
        "authors": [
            "Donghan Yu",
            "Yiming Yang"
        ],
        "date": "18 July 2023",
        "abstract": "ReSKGC is introduced, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning, and has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2. The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.",
        "references": [
            "5401296cb8594a0e0c7a90387b5738e63b86d903",
            "2a561c9650d27218054aa2c87474f0121ba3f33b",
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "5515fd5d14ac7b19806294119560a8c74f7fa4b2",
            "37bf0bf34603145246c3311df19e2afdf6e0270a",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "d67b20cc794c4ab5536fc665678f67042190f685",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "895396389a9fee1b607bf5141a6cc7925bb1e069",
            "572c12e81319ccd47cc0c637c82efadd03fd05ab"
        ],
        "related_topics": [
            "Knowledge Graph Completion",
            "Entities",
            "Triplets",
            "Graphs",
            "Generative Models",
            "WikiKG90Mv2",
            "Memorize",
            "Wikidata5m",
            "Inference",
            "Benchmark Dataset"
        ],
        "reference_count": "0",
        "citation_count": "34"
    },
    {
        "Id": "ba507ee9f9e506dc7d3769cf47ace718a3ac19d9",
        "title": "Knowledge Graph Completion with Triple Structure and Text Representation",
        "authors": [
            "Shuang Liu",
            "YuFeng Qin",
            "Man Xu",
            "Simon Kolmani{\\vc}"
        ],
        "date": "30 May 2023",
        "abstract": "This paper proposes an approach using BERT and deep neural networks to fully extract the semantic information of knowledge, and designs an aggregated re-ranking scheme that incorporates existing graph embedding approach to learn the structural information of triples. Knowledge Graphs (KGs) describe objective facts in the form of RDF triples, each triple contains sufficient semantic information and triple structure information. Knowledge Graph Completion (KGC) is to acquire new knowledge by predicting hidden relationships between entities and adding the new knowledge to the KG. At present, the mainstream KGC approaches only applied the triple structure information or only utilized the semantic information of the text. This paper proposes an approach (TSTR) using BERT and deep neural networks to fully extract the semantic information of knowledge, and designs an aggregated re-ranking scheme that incorporates existing graph embedding approach to learn the structural information of triples. In experiments, the approach achieves state-of-the-art performance on three benchmark datasets, and outperforms recent KGC approaches on sparsely connected datasets.",
        "references": [
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "b770eaea1124b5f5805713428daf023c792b15cd",
            "6602100baa3399b5d3a390d6281a7caadb626ea6",
            "3a52afccd3056ade553f47ed64a15235ebcb876d",
            "86614e40a910cc37ed74a04a67e5ccecafb6d26e",
            "433d704797c2d6a9b3ae67ab94240e1d4aa2b060",
            "322aa32b2a409d2e135dbb14736d9aeb497f1c52",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "81e82158510edb72680a9a832df970d2743d9a63",
            "994afdf0db0cb0456f4f76468380822c2f532726"
        ],
        "related_topics": [
            "Knowledge Graph Completion",
            "Semantic Information",
            "Bidirectional Encoder Representations From Transformers",
            "Knowledge Graph",
            "RDF Triples",
            "Entities",
            "Benchmark Dataset",
            "Train On Synthetic , Test On Real"
        ],
        "reference_count": "0",
        "citation_count": "37"
    },
    {
        "Id": "7ae13b8ff959331b9872acde519999c20195fc6b",
        "title": "KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction",
        "authors": [
            "Jason Youn",
            "Ilias Tagkopoulos"
        ],
        "date": "4 November 2022",
        "abstract": "This work proposes the Knowledge Graph Language Model (KGLM) architecture, where a new entity/relation embedding layer is introduced that learns to differentiate distinctive entity and relation types, therefore allowing the model to learn the structure of the knowledge graph. The ability of knowledge graphs to represent complex relationships at scale has led to their adoption for various needs including knowledge representation, question-answering, and recommendation systems. Knowledge graphs are often incomplete in the information they represent, necessitating the need for knowledge graph completion tasks. Pre-trained and fine-tuned language models have shown promise in these tasks although these models ignore the intrinsic information encoded in the knowledge graph, namely the entity and relation types. In this work, we propose the Knowledge Graph Language Model (KGLM) architecture, where we introduce a new entity/relation embedding layer that learns to differentiate distinctive entity and relation types, therefore allowing the model to learn the structure of the knowledge graph. In this work, we show that further pre-training the language models with this additional embedding layer using the triples extracted from the knowledge graph, followed by the standard fine-tuning phase sets a new state-of-the-art performance for the link prediction task on the benchmark datasets.",
        "references": [
            "0cd4ac8890c4d5c652552ca5ec15123fa0de67d5",
            "9697d32ed0a16da167f2bdba05ef96d0da066eb5",
            "6602100baa3399b5d3a390d6281a7caadb626ea6",
            "e39afdbd832bd8fd0fb4f4f7df3722dc5f5cab2a",
            "31184789ef4c3084af930b1e0dede3215b4a9240",
            "8c93f3cecf79bd9f8d021f589d095305e281dd2f",
            "95c3d25b40f963eb248136555bd9b9e35817cc09",
            "30321b036607a7936221235ea8ec7cf7c1627100",
            "86412306b777ee35aba71d4795b02915cb8a04c3",
            "8f096071a09701012c9c279aee2a88143a295935"
        ],
        "related_topics": [
            "Language Models",
            "Entities",
            "Relation Type",
            "Knowledge Graph",
            "Fine-tuned",
            "Link Prediction",
            "Question Answering",
            "Pre-training",
            "Fine-tuning",
            "Benchmark Dataset"
        ],
        "reference_count": "45",
        "citation_count": "6"
    },
    {
        "Id": "04407b388432e957031cebd1859e868c96006522",
        "title": "Artefact Retrieval: Overview of NLP Models with Knowledge Base Access",
        "authors": [
            "Vil{\\&#x27;e}m Zouhar",
            "Marius Mosbach",
            "Debanjali Biswas",
            "Dietrich Klakow"
        ],
        "date": "24 January 2022",
        "abstract": "This paper systematically describes the typology of artefacts, retrieval mechanisms and the way these artefacts are fused into the model to uncover combinations of design decisions that had not yet been tried in NLP systems. Many NLP models gain performance by having access to a knowledge base. A lot of research has been devoted to devising and improving the way the knowledge base is accessed and incorporated into the model, resulting in a number of mechanisms and pipelines. Despite the diversity of proposed mechanisms, there are patterns in the designs of such systems. In this paper, we systematically describe the typology of artefacts (items retrieved from a knowledge base), retrieval mechanisms and the way these artefacts are fused into the model. This further allows us to uncover combinations of design decisions that had not yet been tried. Most of the focus is given to language models, though we also show how question answering, fact-checking and knowledgable dialogue models fit into this system as well. Having an abstract model which can describe the architecture of specific models also helps with transferring these architectures between multiple NLP tasks.",
        "references": [
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "227458886343b86bd15adf58c769be326b4b058a",
            "9ebb12faa38a9c7e2a43da932abe907a92933000",
            "ea8c46e193d5121e440daf96edfd15a47151c293",
            "81dd3faf762ad8f084ab1d7b8fc9e77e9e160f85",
            "2b2090eab4abe27e6e5e4ca94afaf82e511b63bd",
            "8d17543c20f23b6a40bec9334d50e9c15a08c1c4",
            "0b09448f7543453cc066416f547292dc1e4471f6",
            "832fff14d2ed50eb7969c4c4b976c35776548f56",
            "58ed1fbaabe027345f7bb3a6312d41c5aac63e22"
        ],
        "related_topics": [
            "NLP Models",
            "Architecture",
            "Question Answering",
            "Fact Checking",
            "Retrieval Mechanism",
            "Language Models",
            "NLP Tasks"
        ],
        "reference_count": "91",
        "citation_count": "3"
    },
    {
        "Id": "290867638c5ca520de5c48aa4336f196d426c226",
        "title": "Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey",
        "authors": [
            "Xiaokai Wei",
            "Shen Wang",
            "Dejiao Zhang",
            "Parminder Bhatia",
            "Andrew O. Arnold"
        ],
        "date": "16 October 2021",
        "abstract": "A comprehensive survey of the literature on this emerging and fast-growing field - Knowledge Enhanced Pretrained Language Models (KE-PLMs) is provided and three taxonomies are introduced to categorize existing work. Pretrained Language Models (PLM) have established a new paradigm through learning informative contextualized representations on large-scale text corpus. This new paradigm has revolutionized the entire field of natural language processing, and set the new state-of-the-art performance for a wide variety of NLP tasks. However, though PLMs could store certain knowledge/facts from training corpus, their knowledge awareness is still far from satisfactory. To address this issue, integrating knowledge into PLMs have recently become a very active research area and a variety of approaches have been developed. In this paper, we provide a comprehensive survey of the literature on this emerging and fast-growing field - Knowledge Enhanced Pretrained Language Models (KE-PLMs). We introduce three taxonomies to categorize existing work. Besides, we also survey the various NLU and NLG applications on which KE-PLM has demonstrated superior performance over vanilla PLMs. Finally, we discuss challenges that face KE-PLMs and also promising directions for future research.",
        "references": [
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "d0086b86103a620a86bc918746df0aa642e2a8a3",
            "7eda139d737eea10fc1d95364327a41ec0cee4a4",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "9ba6ad0de7dbe1a3b10c44106049adb96f87d483",
            "3af5a41e43158a75bf7a8bb3f9517edc4163b3ca",
            "3bcb17559ce96eb20fa79af8194f4af0380d194a",
            "56cafbac34f2bb3f6a9828cd228ff281b810d6bb",
            "58ed1fbaabe027345f7bb3a6312d41c5aac63e22"
        ],
        "related_topics": [
            "JAKET",
            "Pretrained Language Models",
            "KE-PLM",
            "Pre-trained Language Models",
            "Natural Language Understanding",
            "Training Corpus",
            "Natural Language Processing",
            "Natural Language Generation",
            "Knowledge Awareness",
            "NLP Tasks"
        ],
        "reference_count": "111",
        "citation_count": "24"
    },
    {
        "Id": "ff20f19ffd6783d480ab249c893d1235e8a3780b",
        "title": "On Importance Sampling-Based Evaluation of Latent Language Models",
        "authors": [
            "Robert L Logan IV",
            "Matt Gardner",
            "Sameer Singh"
        ],
        "date": "1 July 2020",
        "abstract": "This paper elucidate subtle differences in how importance sampling is applied in these works that can have substantial effects on the final estimates, as well as provide theoretical results which reinforce the validity of this technique. Language models that use additional latent structures (e.g., syntax trees, coreference chains, knowledge graph links) provide several advantages over traditional language models. However, likelihood-based evaluation of these models is often intractable as it requires marginalizing over the latent space. Existing works avoid this issue by using importance sampling. Although this approach has asymptotic guarantees, analysis is rarely conducted on the effect of decisions such as sample size and choice of proposal distribution on the reported estimates. In this paper, we carry out this analysis for three models: RNNG, EntityNLM, and KGLM. In addition, we elucidate subtle differences in how importance sampling is applied in these works that can have substantial effects on the final estimates, as well as provide theoretical results which reinforce the validity of this technique.",
        "references": [
            "88051a6dce3b67541d8096647da2f6d31daa9e9a",
            "0fa5142f908afc94c923ca2adbe14a5673bc76eb",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "9c81f16df774c772dbefc947fe0e467b72500844",
            "d7dc79050f17154e7cf57501cf6cab1b9c18f232",
            "35a198b491246f989574a6edc7f2550664e8fb11",
            "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "7345843e87c81e24e42264859b214d26042f8d51",
            "4c8684b45d6d4635ca2384145334772469479e9d",
            "ed4f2bfeca8ff29f0c8364cc422412f4bdb2be8a"
        ],
        "related_topics": [
            "EntityNLM",
            "Language Models",
            "Latent Space",
            "Coreference Chains",
            "Recurrent Neural Network Grammars"
        ],
        "reference_count": "14",
        "citation_count": "2"
    },
    {
        "Id": "751f55beac45cec14b0aff6174ed0139afb54b08",
        "title": "Modelling Symbolic Knowledge Using Neural Representations",
        "authors": [
            "Steven Schockaert",
            "V{\\&#x27;i}ctor Guti{\\&#x27;e}rrez-Basulto"
        ],
        "date": "2021",
        "abstract": "An overview of recent work on the relationship between symbolic knowledge and neural representations is presented, with a focus on the use of neural networks, and vector representations more generally, for encoding knowledge. . Symbolic reasoning and deep learning are two fundamentally di\ufb00erent approaches to building AI systems, with complementary strengths and weaknesses. Despite their clear di\ufb00erences, however, the line between these two approaches is increasingly blurry. For instance, the neural language models which are popular in Natural Language Processing are increasingly playing the role of knowledge bases, while neural network learning strategies are being used to learn symbolic knowledge, and to develop strategies for reasoning more \ufb02exibly with such knowledge. This blurring of the boundary between symbolic and neural methods o\ufb00ers signi\ufb01cant opportunities for developing systems that can combine the \ufb02exibility and inductive capabilities of neural networks with the transparency and systematic reasoning abilities of symbolic frameworks. At the same time, there are still many open questions around how such a combination can best be achieved. This paper presents an overview of recent work on the relationship between symbolic knowledge and neural representations, with a focus on the use of neural networks, and vector representations more generally, for encoding knowledge.",
        "references": [
            "833c4ac0599f4b8c5f1ee6ea948ec675fbe56b15",
            "f9a45caaab1b6d3d777b53053d94181a3bf20cca",
            "2ed575c344e23aa14989b270977b98cec9b39407",
            "79e5447a394ad178aa0fdaef1d2f1ecf9bf07e88",
            "0d6e349e385ed1765e4063bd820e2f541ee93b89",
            "6f2b90ee5a0feea87264148c25a874f84bae20a0",
            "5889e9afbcc3935867f9ae16fe46c71b9f2b071f",
            "9fa9d5dd481400b2f3904b33d542d70a6affccb9",
            "d33c248cd536d9b9144a02f9e1ee76e4ef95867a",
            "a3e0ae9da7c1b1163f886f9c5b1943c9b76b7b26"
        ],
        "related_topics": [
            "Symbolic Knowledge",
            "Neural Representations",
            "Neural Network",
            "Natural Language Processing",
            "Vector Representations",
            "Neural Language Models",
            "Deep Learning",
            "AI Systems",
            "Symbolic Reasoning"
        ],
        "reference_count": "90",
        "citation_count": "2"
    },
    {
        "Id": "f65cf7b125baa484a024a56272b8eeadcf5152ff",
        "title": "Free Lunch for Efficient Textual Commonsense Integration in Language Models",
        "authors": [
            "Wanyun Cui",
            "Xingran Chen"
        ],
        "date": "24 May 2023",
        "abstract": "The idea is to group training samples with similar commonsense descriptions into a single batch, thus reusing the encoded description across multiple samples, and proposes a spectral clustering-based algorithm to solve this problem. Recent years have witnessed the emergence of textual commonsense knowledge bases, aimed at providing more nuanced and context-rich knowledge. The integration of external commonsense into language models has been shown to be a key enabler in advancing the state-of-the-art for a wide range of NLP tasks. However, incorporating textual commonsense descriptions is computationally expensive, as compared to encoding conventional symbolic knowledge. In this paper, we propose a method to improve its efficiency without modifying the model. Our idea is to group training samples with similar commonsense descriptions into a single batch, thus reusing the encoded description across multiple samples. We theoretically investigate this problem and demonstrate that its upper bound can be reduced to the classic graph k-cut problem. Consequently, we propose a spectral clustering-based algorithm to solve this problem. Extensive experiments illustrate that the proposed batch partitioning approach effectively reduces the computational cost while preserving performance. The efficiency improvement is more pronounced on larger datasets and on devices with more memory capacity, attesting to its practical utility for large-scale applications.",
        "references": [
            "f8a22859230e0ccafefc020dccc66b5a646fe0ac",
            "f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
            "96901acc92d68350443774596fa2b38bc522a0ce",
            "5f994dc8cae24ca9d1ed629e517fcc652660ddde",
            "b4c9e1f4546e75537856f404b129a1d7f6a26d6a",
            "628e570a6e992d68f141a2533cb9b3f6d994c7ad",
            "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c",
            "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
            "412747e62bb254485487e0a0046d18bd20d58fab",
            "c6a84615bc36486cd0170f8a3e1b7e5ec8f5344e"
        ],
        "related_topics": [
            "Language Models",
            "Symbolic Knowledge",
            "Commonsense",
            "Computational Cost",
            "NLP Tasks"
        ],
        "reference_count": "43",
        "citation_count": "One"
    },
    {
        "Id": "7ebdc4ed93e37e7d3691085f4d08c495557ba71b",
        "title": "A survey on knowledge-enhanced multimodal learning",
        "authors": [
            "Maria Lymperaiou",
            "G. Stamou"
        ],
        "date": "19 November 2022",
        "abstract": "The current survey aims to unify the fields of VL representation learning and knowledge graphs, and provides a taxonomy and analysis of knowledge-enhanced VL models. Multimodal learning has been a field of increasing interest, aiming to combine various modalities in a single joint representation. Especially in the area of visiolinguistic (VL) learning multiple models and techniques have been developed, targeting a variety of tasks that involve images and text. VL models have reached unprecedented performances by extending the idea of Transformers, so that both modalities can learn from each other. Massive pre-training procedures enable VL models to acquire a certain level of real-world understanding, although many gaps can be identified: the limited comprehension of commonsense, factual, temporal and other everyday knowledge aspects questions the extendability of VL tasks. Knowledge graphs and other knowledge sources can fill those gaps by explicitly providing missing information, unlocking novel capabilities of VL models. In the same time, knowledge graphs enhance explainability, fairness and validity of decision making, issues of outermost importance for such complex implementations. The current survey aims to unify the fields of VL representation learning and knowledge graphs, and provides a taxonomy and analysis of knowledge-enhanced VL models.",
        "references": [
            "48847adb786cb8a193818aca8519a887680c2d83",
            "e5d143ae82ede67726aa1a9aeac3de4bf53d8920",
            "fe6e9bc5040a69e310d88677a1045a2fef640f48",
            "d0b59b3e34a79c8c79a31bf3944ded8ab7a803ae",
            "e526624783b3b5687da54b8cd4a7190a26a0b5e8",
            "9f620ad41b4e506e777c0665681b839c89cd682a",
            "6b13065b4050800e30bb74e010b8aaba3355525d",
            "1c83f3f9789df43bf937ae2618721e2da83dcc06",
            "63c74d15940af1af9b386b5762e4445e54c73719",
            "def584565d05d6a8ba94de6621adab9e301d375d"
        ],
        "related_topics": [
            "Knowledge Graph",
            "Transformer",
            "Commonsense",
            "Fairness",
            "Explainability",
            "Multimodal Learning"
        ],
        "reference_count": "260",
        "citation_count": "6"
    },
    {
        "Id": "706c6b3781374b0b11f98f204a4ddd05b26ed009",
        "title": "Knowledge Infused Decoding",
        "authors": [
            "Ruibo Liu",
            "Guoqing Zheng",
            "Shashank Gupta",
            "Radhika Gaonkar",
            "Chongyang Gao",
            "Soroush Vosoughi",
            "Milad Shokouhi",
            "Ahmed Hassan Awadallah"
        ],
        "date": "6 April 2022",
        "abstract": "Knowledge Infused Decoding (KID) -- a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding, which maintains a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning. Pre-trained language models (LMs) have been shown to memorize a substantial amount of knowledge from the pre-training corpora; however, they are still limited in recalling factually correct knowledge given a certain context. Hence, they tend to suffer from counterfactual or hallucinatory generation when used in knowledge-intensive natural language generation (NLG) tasks. Recent remedies to this problem focus on modifying either the pre-training or task fine-tuning objectives to incorporate knowledge, which normally require additional costly training or architecture modification of LMs for practical applications. We present Knowledge Infused Decoding (KID) -- a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding. Specifically, we maintain a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning. On six diverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART) armed with KID outperform many task-optimized state-of-the-art models, and show particularly strong performance in few-shot scenarios over seven related knowledge-infusion techniques. Human evaluation confirms KID's ability to generate more relevant and factual language for the input context when compared with multiple baselines. Finally, KID also alleviates exposure bias and provides stable generation quality when generating longer sequences. Code for KID is available at https://github.com/microsoft/KID.",
        "references": [
            "07ded4cf00095d91e8689a0a52d9e20eb64aca0b",
            "2b4bc49a3b23229a060609380752666b24b435fb",
            "ea8c46e193d5121e440daf96edfd15a47151c293",
            "c6a84615bc36486cd0170f8a3e1b7e5ec8f5344e",
            "04f4e55e14150b7c48b0287ba77c7443df76ed45",
            "e04a80263d252a3d8a382ba37a249b9345620570",
            "0c3c4c88c7b07596221ac640c7b7102686e3eae3",
            "168a8a4b3006a760a9aa4cfe58c805c9086b8a30",
            "6fc991dbc1714b425d11b4de3d9d247d21d77c0b",
            "d7da009f457917aa381619facfa5ffae9329a6e9"
        ],
        "related_topics": [
            "Natural Language Generation",
            "Language Models",
            "Generation Quality",
            "GPT-2",
            "Reinforcement Learning",
            "Pre-training",
            "State-of-the-art Models",
            "Human Evaluations",
            "Exposure Bias",
            "Counterfactuals"
        ],
        "reference_count": "93",
        "citation_count": "12"
    }
]